{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import cPickle as pickle\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import urllib2\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import nltk\n",
    "\n",
    "from thesis.utils.text import get_sentences, sentence_wordtokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATIO = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# root_location = \"/mnt/data2/shalaby/\"\n",
    "root_location = \"/home/local/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "# training_file = root_location + 'docs_output_training_validation_documents_' + str(SAMPLE_RATIO)\n",
    "training_file = root_location + 'docs_output.json'\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "# training_docs_list_file = exports_location + \"training_documents_\" + str(SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "# validation_docs_list_file = exports_location + \"validation_documents_\" + str(SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "training_docs_list_file = exports_location + \"extended_pv_training_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "validation_docs_list_file = exports_location + \"extended_pv_validation_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "test_docs_list_file = exports_location + \"extended_pv_test_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 s, sys: 1.4 s, total: 26.5 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254767"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Extraction Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ES_URL = 'http://localhost:9200/patents/patent/{}'\n",
    "ES_URL = 'http://yell.dbs.ifi.lmu.de:9200/patents/patent/{}'\n",
    "HEADING_TAG = 'heading'\n",
    "PARAGRAPH_TAG = 'p'\n",
    "UL_TAG = 'ul'\n",
    "LI_TAG = 'li'\n",
    "OL_TAG = 'ol'\n",
    "DESC_OF_DRAWINGS_TAG = 'description-of-drawings'\n",
    "MIN_PARAGRAPH_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_with_previous(curr_node_tag, previous_node_tag, previous_node_text):\n",
    "    if curr_node_tag == PARAGRAPH_TAG and previous_node_tag == HEADING_TAG:\n",
    "        return True\n",
    "    if previous_node_text and len(previous_node_text) < MIN_PARAGRAPH_LENGTH:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def get_paragraphs(root):\n",
    "    paragraphs = []\n",
    "    previous_node_text = None\n",
    "    previous_tag = None\n",
    "    for child in root:\n",
    "        node_text = None\n",
    "        if child.tag != DESC_OF_DRAWINGS_TAG:\n",
    "            node_text = get_node_text(child)\n",
    "            if node_text.strip():\n",
    "                if merge_with_previous(child.tag, previous_tag, previous_node_text) and len(paragraphs) > 0:\n",
    "                    paragraphs[-1] += ' ' + node_text\n",
    "                else:\n",
    "                    paragraphs.append(node_text)\n",
    "        else:\n",
    "            node_text = extract_desc_of_drawings_paragraph(child)\n",
    "            paragraphs.append(node_text)\n",
    "            \n",
    "        previous_tag = child.tag\n",
    "        previous_node_text = node_text\n",
    "    return paragraphs\n",
    "    \n",
    "def extract_desc_of_drawings_paragraph(node):\n",
    "    previous_tag = None\n",
    "    sentences = []\n",
    "    for child in node:\n",
    "        node_text = get_node_text(child)\n",
    "        if child.tag == PARAGRAPH_TAG and previous_tag == HEADING_TAG:\n",
    "            sentences[-1] += ' ' + node_text\n",
    "        else:\n",
    "            # a paragraph in drawings descriptions is treated as a sentence\n",
    "            if child.tag == PARAGRAPH_TAG:\n",
    "                node_text = apply_sentence_end(node_text)\n",
    "            sentences.append(node_text)\n",
    "        previous_tag = child.tag\n",
    "    \n",
    "    return ' '.join(sentences)\n",
    "\n",
    "def apply_sentence_end(text):\n",
    "    if text and text.strip():\n",
    "        text = text.strip().strip(';.')\n",
    "        text += '. '\n",
    "    return text\n",
    "\n",
    "def itertext_custom(self):\n",
    "    tag = self.tag\n",
    "    if not isinstance(tag, basestring) and tag is not None:\n",
    "        return\n",
    "    if self.text:\n",
    "        if tag == LI_TAG:\n",
    "            yield apply_sentence_end(self.text)\n",
    "        else:\n",
    "            yield self.text.replace('\\n',' ')\n",
    "    for e in self:\n",
    "        for s in e.itertext_custom():\n",
    "            yield s\n",
    "        if e.tail:\n",
    "            yield e.tail\n",
    "\n",
    "ET.Element.itertext_custom = itertext_custom\n",
    "# def get_node_text(node):\n",
    "#     node_text = ''\n",
    "#     for child in node:\n",
    "#         # for ul tags, get li tags as sentences\n",
    "#         if child.tag == UL_TAG:\n",
    "#             li_sentences = [apply_sentence_end(get_node_text_iterative(c)) for c in child]\n",
    "#             child_text = ' '.join(li_sentences)\n",
    "#         else:\n",
    "#             child_text = get_node_text_iterative(child)\n",
    "#         node_text += child_text\n",
    "#     return node_text\n",
    "        \n",
    "get_node_text = lambda node: ''.join(node.itertext_custom()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conc_paragraphs(parag1, parag2):\n",
    "    return parag1.strip('.') + '.' + ' ' + parag2\n",
    "\n",
    "def concatenate_sentences_to_paragraphs(paragraphs):\n",
    "    \"\"\"\n",
    "    for 1 sentence paragraphs, concatenate them to the next or previous paragraph depending on context\n",
    "    \"\"\"\n",
    "    for i in range(len(paragraphs)):\n",
    "        if i >= len((paragraphs)): break\n",
    "        parag = paragraphs[i]\n",
    "        sentences = get_sentences(parag)\n",
    "        \n",
    "        if len(sentences) == 1:\n",
    "            prev_paragraph = paragraphs[i-1] if i-1 >= 0 else None\n",
    "            next_paragraph = paragraphs[i+1] if i+1 < len(paragraphs) else None\n",
    "\n",
    "            if (next_paragraph and len(get_sentences(next_paragraph)) == 1):\n",
    "                # If a series of 1 sentence length paragraphs exist, conc all of them in one paragraph\n",
    "                while True:\n",
    "                    if next_paragraph and len(get_sentences(next_paragraph)) == 1:\n",
    "                        parag = conc_paragraphs(parag, next_paragraph)\n",
    "                        paragraphs[i] = parag\n",
    "                        del paragraphs[i+1]\n",
    "\n",
    "                        # reinitialize for loop\n",
    "                        next_paragraph = paragraphs[i+1] if i+1 < len(paragraphs) else None\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            # otherwise, just concatenate the 1 sentence paragraph to the previous paragraph\n",
    "            elif prev_paragraph:\n",
    "#                 print '============== Found prev eligible paragraph'\n",
    "                prev_paragraph = conc_paragraphs(prev_paragraph, parag)\n",
    "                paragraphs[i-1] = prev_paragraph\n",
    "                del paragraphs[i]\n",
    "\n",
    "            # if this is the first paragraph, then just concatenate it with the next one\n",
    "            elif next_paragraph:\n",
    "                parag = conc_paragraphs(parag, next_paragraph)\n",
    "                paragraphs[i] = parag\n",
    "                del paragraphs[i+1]\n",
    "\n",
    "def get_adjusted_paragraphs(root, conc_sentences=True):\n",
    "    paragraphs = get_paragraphs(root)\n",
    "    if conc_sentences:\n",
    "        concatenate_sentences_to_paragraphs(paragraphs)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_patent(doc_id):\n",
    "    url_to_fetch = ES_URL.format(doc_id)\n",
    "\n",
    "    response = urllib2.urlopen(url_to_fetch)\n",
    "    patent_content = response.read()\n",
    "\n",
    "    patent_object = json.loads(patent_content)['_source']\n",
    "    return patent_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Actual Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ABSTRACT_ID = \"{}_abstract\"\n",
    "DESC_ID = \"{}_description\"\n",
    "CLAIMS_ID = \"{}_claims\"\n",
    "\n",
    "ABSTRACT_PARAGRAPH_ID = \"{}_abstract_p{}\"\n",
    "DESCRIPTION_PARAGRAPH_ID = \"{}_description_p{}\"\n",
    "CLAIMS_PARAGRAPH_ID = \"{}_claims_p{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10000\n",
    "\n",
    "preprocessed_location = \"/home/local/shalaby/\" + \"preprocessed_data/extended_pv_abs_desc_claims_large_sample_parags/\"\n",
    "TRAINING_PREPROCESSED_FILES_PREFIX = preprocessed_location + \"extended_pv_training_docs_data_preprocessed-\"\n",
    "VALIDATION_PREPROCESSED_FILES_PREFIX = preprocessed_location + \"extended_pv_validation_docs_data_preprocessed-\"\n",
    "TEST_PREPROCESSED_FILES_PREFIX = preprocessed_location + \"extended_pv_test_docs_data_preprocessed-\"\n",
    "\n",
    "if not os.path.exists(preprocessed_location):\n",
    "    os.makedirs(preprocessed_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def multithreaded_extended_batch_creation(start_index):\n",
    "\n",
    "    if os.path.exists(FILE_PREFIX + str(start_index)):\n",
    "        info(\"Batch {} already exists, skipping..\".format(start_index))\n",
    "        return\n",
    "    \n",
    "    info(\"Batch creation working on {}\\n\".format(start_index))\n",
    "    token_lines = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for doc_index, doc_id in enumerate(DOCS_LIST[start_index:]):\n",
    "        patent_doc = get_patent(doc_id)\n",
    "        \n",
    "        # Abstract\n",
    "        abstract = patent_doc['abstract'][0]\n",
    "        root = ET.fromstring(abstract.encode('utf-8'))\n",
    "        abs_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Description\n",
    "        desc = patent_doc['description'][0]\n",
    "        root = ET.fromstring(desc.encode('utf-8'))\n",
    "        desc_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Claims\n",
    "        claims = patent_doc['claims'][0]\n",
    "        root = ET.fromstring(claims.encode('utf-8'))\n",
    "        claims_paragraphs = get_adjusted_paragraphs(root, conc_sentences=False)\n",
    "        \n",
    "\n",
    "        # Level 1\n",
    "        # ==========\n",
    "        list_abstract_paragraphs_tokens = [sentence_wordtokenizer(parag) for parag in abs_paragraphs]\n",
    "        list_description_paragraphs_tokens = [sentence_wordtokenizer(parag) for parag in desc_paragraphs]\n",
    "        list_claims_paragraphs_tokens = [sentence_wordtokenizer(parag) for parag in claims_paragraphs]\n",
    "        \n",
    "        abstract_tokens = sum(list_abstract_paragraphs_tokens, [])\n",
    "        desc_tokens = sum(list_description_paragraphs_tokens, [])\n",
    "        claims_tokens = sum(list_claims_paragraphs_tokens, [])\n",
    "        \n",
    "        doc_tokens_list = [doc_id]  + abstract_tokens + desc_tokens + claims_tokens\n",
    "        abstract_tokens_list = [ABSTRACT_ID.format(doc_id)] + abstract_tokens\n",
    "        description_tokens_list = [DESC_ID.format(doc_id)] + desc_tokens\n",
    "        claims_tokens_list = [CLAIMS_ID.format(doc_id)] + claims_tokens\n",
    "        \n",
    "        token_lines.append(doc_tokens_list)\n",
    "        token_lines.append(abstract_tokens_list)\n",
    "        token_lines.append(description_tokens_list)\n",
    "        token_lines.append(claims_tokens_list)\n",
    "        \n",
    "        # Level 2\n",
    "        # ==========\n",
    "        # now add the tokens lists that will be written to the file\n",
    "        \n",
    "#         for i in range(len(list_abstract_paragraphs_tokens)):\n",
    "#             token_lines.append([ABSTRACT_PARAGRAPH_ID.format(doc_id, i+1)] + list_abstract_paragraphs_tokens[i])\n",
    "        \n",
    "        for i in range(len(list_description_paragraphs_tokens)):\n",
    "            token_lines.append([DESCRIPTION_PARAGRAPH_ID.format(doc_id, i+1)] + list_description_paragraphs_tokens[i])\n",
    "            \n",
    "#         for i in range(len(list_claims_paragraphs_tokens)):\n",
    "#             token_lines.append([CLAIMS_PARAGRAPH_ID.format(doc_id, i+1)] + list_claims_paragraphs_tokens[i])\n",
    "            \n",
    "        \n",
    "        if doc_index % 1000 == 0: info(\"Doc: {:6} -> Total Lines to write: {:8}\".format(start_index + doc_index, len(token_lines)))\n",
    "        if doc_index >= BATCH_SIZE - 1:\n",
    "            break\n",
    "    duration = time.time() - start_time\n",
    "    info(\"Finished batch {} of size {:d} in {:.0f}m {:.0f}s\".format(start_index, BATCH_SIZE, * divmod(duration, 60)))\n",
    "    info(\"For index {}, the actual number of lines written is: {}\".format(start_index, len(token_lines)))\n",
    "    \n",
    "    write_batch(FILE_PREFIX, token_lines, start_index)\n",
    "    del token_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_batch(file_prefix, batch_lines, batch_start):\n",
    "    if len(batch_lines):\n",
    "        print \"writing batch %d\" % batch_start\n",
    "        with open(file_prefix + str(batch_start), 'w') as batch_file:\n",
    "            for line in batch_lines:\n",
    "                batch_file.write((u\" \".join(line) + \"\\n\").encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 12:56:50,403 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-22 12:56:50,474 : INFO : Doc:      0 -> Total Lines to write:       21\n",
      "2017-03-22 12:56:51,317 : INFO : Finished batch 0 of size 10 in 0m 1s\n",
      "2017-03-22 12:56:51,321 : INFO : For index 0, the actual number of lines written is: 344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    }
   ],
   "source": [
    "multithreaded_extended_batch_creation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = training_docs_list\n",
    "FILE_PREFIX = TRAINING_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 10000,\n",
       " 20000,\n",
       " 30000,\n",
       " 40000,\n",
       " 50000,\n",
       " 60000,\n",
       " 70000,\n",
       " 80000,\n",
       " 90000,\n",
       " 100000,\n",
       " 110000,\n",
       " 120000,\n",
       " 130000,\n",
       " 140000,\n",
       " 150000,\n",
       " 160000,\n",
       " 170000,\n",
       " 180000,\n",
       " 190000,\n",
       " 200000,\n",
       " 210000,\n",
       " 220000,\n",
       " 230000,\n",
       " 240000,\n",
       " 250000]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 12:58:20,991 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-22 12:58:20,991 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-22 12:58:20,992 : INFO : Batch creation working on 40000\n",
      "\n",
      "2017-03-22 12:58:20,997 : INFO : Batch creation working on 60000\n",
      "\n",
      "2017-03-22 12:58:20,991 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-22 12:58:20,990 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-22 12:58:20,996 : INFO : Batch creation working on 50000\n",
      "\n",
      "2017-03-22 12:58:21,007 : INFO : Batch creation working on 70000\n",
      "\n",
      "2017-03-22 12:58:21,019 : INFO : Batch creation working on 80000\n",
      "\n",
      "2017-03-22 12:59:12,801 : INFO : Doc:  20000 -> Total Lines to write:      117\n",
      "2017-03-22 12:59:14,220 : INFO : Doc:  10000 -> Total Lines to write:       33\n",
      "2017-03-22 12:59:16,041 : INFO : Doc:  80000 -> Total Lines to write:      180\n",
      "2017-03-22 12:59:16,194 : INFO : Doc:  60000 -> Total Lines to write:       36\n",
      "2017-03-22 12:59:17,896 : INFO : Doc:  30000 -> Total Lines to write:       36\n",
      "2017-03-22 12:59:18,441 : INFO : Doc:  50000 -> Total Lines to write:       52\n",
      "2017-03-22 12:59:18,673 : INFO : Doc:  70000 -> Total Lines to write:       34\n",
      "2017-03-22 12:59:18,725 : INFO : Doc:  40000 -> Total Lines to write:       38\n",
      "2017-03-22 12:59:21,061 : INFO : Doc:      0 -> Total Lines to write:       21\n",
      "2017-03-22 13:04:06,713 : INFO : Doc:   1000 -> Total Lines to write:    60966\n",
      "2017-03-22 13:04:09,271 : INFO : Doc:  21000 -> Total Lines to write:    62033\n",
      "2017-03-22 13:04:17,994 : INFO : Doc:  11000 -> Total Lines to write:    64652\n",
      "2017-03-22 13:04:18,011 : INFO : Doc:  61000 -> Total Lines to write:    66327\n",
      "2017-03-22 13:04:21,560 : INFO : Doc:  31000 -> Total Lines to write:    63545\n",
      "2017-03-22 13:04:27,823 : INFO : Doc:  81000 -> Total Lines to write:    66263\n",
      "2017-03-22 13:04:34,706 : INFO : Doc:  51000 -> Total Lines to write:    68731\n",
      "2017-03-22 13:04:44,443 : INFO : Doc:  41000 -> Total Lines to write:    64148\n",
      "2017-03-22 13:04:47,787 : INFO : Doc:  71000 -> Total Lines to write:    70837\n",
      "2017-03-22 13:09:04,515 : INFO : Doc:   2000 -> Total Lines to write:   121031\n",
      "2017-03-22 13:09:21,856 : INFO : Doc:  32000 -> Total Lines to write:   126151\n",
      "2017-03-22 13:09:28,373 : INFO : Doc:  22000 -> Total Lines to write:   127976\n",
      "2017-03-22 13:09:32,959 : INFO : Doc:  62000 -> Total Lines to write:   129934\n",
      "2017-03-22 13:09:34,153 : INFO : Doc:  42000 -> Total Lines to write:   124546\n",
      "2017-03-22 13:09:42,041 : INFO : Doc:  12000 -> Total Lines to write:   130063\n",
      "2017-03-22 13:09:46,258 : INFO : Doc:  52000 -> Total Lines to write:   133177\n",
      "2017-03-22 13:09:46,372 : INFO : Doc:  82000 -> Total Lines to write:   130714\n",
      "2017-03-22 13:10:56,982 : INFO : Doc:  72000 -> Total Lines to write:   140523\n",
      "2017-03-22 13:13:47,496 : INFO : Doc:   3000 -> Total Lines to write:   179525\n",
      "2017-03-22 13:14:37,047 : INFO : Doc:  33000 -> Total Lines to write:   190450\n",
      "2017-03-22 13:14:46,875 : INFO : Doc:  63000 -> Total Lines to write:   194360\n",
      "2017-03-22 13:15:00,620 : INFO : Doc:  43000 -> Total Lines to write:   190537\n",
      "2017-03-22 13:15:15,380 : INFO : Doc:  23000 -> Total Lines to write:   196257\n",
      "2017-03-22 13:15:23,811 : INFO : Doc:  83000 -> Total Lines to write:   199861\n",
      "2017-03-22 13:15:33,696 : INFO : Doc:  53000 -> Total Lines to write:   204612\n",
      "2017-03-22 13:15:44,876 : INFO : Doc:  13000 -> Total Lines to write:   200053\n",
      "2017-03-22 13:16:19,437 : INFO : Doc:  73000 -> Total Lines to write:   206015\n",
      "2017-03-22 13:18:28,336 : INFO : Doc:   4000 -> Total Lines to write:   239701\n",
      "2017-03-22 13:19:44,894 : INFO : Doc:  44000 -> Total Lines to write:   254028\n",
      "2017-03-22 13:19:56,190 : INFO : Doc:  34000 -> Total Lines to write:   257333\n",
      "2017-03-22 13:20:04,100 : INFO : Doc:  24000 -> Total Lines to write:   257411\n",
      "2017-03-22 13:20:10,714 : INFO : Doc:  64000 -> Total Lines to write:   260382\n",
      "2017-03-22 13:20:33,815 : INFO : Doc:  14000 -> Total Lines to write:   262668\n",
      "2017-03-22 13:21:22,545 : INFO : Doc:  84000 -> Total Lines to write:   273113\n",
      "2017-03-22 13:21:27,445 : INFO : Doc:  54000 -> Total Lines to write:   278151\n",
      "2017-03-22 13:21:35,705 : INFO : Doc:  74000 -> Total Lines to write:   272224\n",
      "2017-03-22 13:23:41,661 : INFO : Doc:   5000 -> Total Lines to write:   302033\n",
      "2017-03-22 13:24:53,957 : INFO : Doc:  45000 -> Total Lines to write:   316007\n",
      "2017-03-22 13:25:47,846 : INFO : Doc:  35000 -> Total Lines to write:   322339\n",
      "2017-03-22 13:26:00,450 : INFO : Doc:  25000 -> Total Lines to write:   325533\n",
      "2017-03-22 13:26:02,425 : INFO : Doc:  65000 -> Total Lines to write:   329685\n",
      "2017-03-22 13:26:09,560 : INFO : Doc:  15000 -> Total Lines to write:   325845\n",
      "2017-03-22 13:26:39,366 : INFO : Doc:  55000 -> Total Lines to write:   341250\n",
      "2017-03-22 13:26:47,883 : INFO : Doc:  85000 -> Total Lines to write:   336825\n",
      "2017-03-22 13:27:42,190 : INFO : Doc:  75000 -> Total Lines to write:   343508\n",
      "2017-03-22 13:29:31,373 : INFO : Doc:   6000 -> Total Lines to write:   368594\n",
      "2017-03-22 13:29:57,986 : INFO : Doc:  46000 -> Total Lines to write:   378829\n",
      "2017-03-22 13:30:40,144 : INFO : Doc:  36000 -> Total Lines to write:   385388\n",
      "2017-03-22 13:31:00,859 : INFO : Doc:  26000 -> Total Lines to write:   389199\n",
      "2017-03-22 13:31:40,418 : INFO : Doc:  66000 -> Total Lines to write:   399185\n",
      "2017-03-22 13:31:54,332 : INFO : Doc:  56000 -> Total Lines to write:   406291\n",
      "2017-03-22 13:31:55,804 : INFO : Doc:  86000 -> Total Lines to write:   402824\n",
      "2017-03-22 13:32:09,522 : INFO : Doc:  16000 -> Total Lines to write:   393809\n",
      "2017-03-22 13:33:27,209 : INFO : Doc:  76000 -> Total Lines to write:   410821\n",
      "2017-03-22 13:34:55,809 : INFO : Doc:   7000 -> Total Lines to write:   436312\n",
      "2017-03-22 13:35:43,494 : INFO : Doc:  47000 -> Total Lines to write:   445153\n",
      "2017-03-22 13:36:09,089 : INFO : Doc:  37000 -> Total Lines to write:   448251\n",
      "2017-03-22 13:36:37,760 : INFO : Doc:  27000 -> Total Lines to write:   452673\n",
      "2017-03-22 13:37:15,370 : INFO : Doc:  67000 -> Total Lines to write:   465417\n",
      "2017-03-22 13:37:17,040 : INFO : Doc:  57000 -> Total Lines to write:   472312\n",
      "2017-03-22 13:37:47,646 : INFO : Doc:  17000 -> Total Lines to write:   458128\n",
      "2017-03-22 13:37:55,978 : INFO : Doc:  87000 -> Total Lines to write:   471690\n",
      "2017-03-22 13:39:26,507 : INFO : Doc:  77000 -> Total Lines to write:   481068\n",
      "2017-03-22 13:40:09,410 : INFO : Doc:   8000 -> Total Lines to write:   499289\n",
      "2017-03-22 13:42:17,688 : INFO : Doc:  48000 -> Total Lines to write:   515653\n",
      "2017-03-22 13:42:19,322 : INFO : Doc:  38000 -> Total Lines to write:   516402\n",
      "2017-03-22 13:42:20,312 : INFO : Doc:  28000 -> Total Lines to write:   518247\n",
      "2017-03-22 13:42:37,790 : INFO : Doc:  68000 -> Total Lines to write:   529360\n",
      "2017-03-22 13:43:10,474 : INFO : Doc:  58000 -> Total Lines to write:   539637\n",
      "2017-03-22 13:43:27,082 : INFO : Doc:  18000 -> Total Lines to write:   524946\n",
      "2017-03-22 13:43:27,438 : INFO : Doc:  88000 -> Total Lines to write:   537619\n",
      "2017-03-22 13:44:59,748 : INFO : Doc:  78000 -> Total Lines to write:   547370\n",
      "2017-03-22 13:45:06,075 : INFO : Doc:   9000 -> Total Lines to write:   559345\n",
      "2017-03-22 13:47:59,604 : INFO : Doc:  39000 -> Total Lines to write:   581237\n",
      "2017-03-22 13:48:05,624 : INFO : Doc:  29000 -> Total Lines to write:   582700\n",
      "2017-03-22 13:48:31,208 : INFO : Doc:  59000 -> Total Lines to write:   604687\n",
      "2017-03-22 13:49:04,094 : INFO : Doc:  49000 -> Total Lines to write:   579068\n",
      "2017-03-22 13:49:12,024 : INFO : Doc:  19000 -> Total Lines to write:   588423\n",
      "2017-03-22 13:49:13,500 : INFO : Doc:  69000 -> Total Lines to write:   604011\n",
      "2017-03-22 13:50:02,455 : INFO : Doc:  89000 -> Total Lines to write:   611375\n",
      "2017-03-22 13:50:10,001 : INFO : Finished batch 0 of size 10000 in 51m 49s\n",
      "2017-03-22 13:50:10,019 : INFO : For index 0, the actual number of lines written is: 617045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:51:02,632 : INFO : Doc:  79000 -> Total Lines to write:   616661\n",
      "2017-03-22 13:51:02,663 : INFO : Batch creation working on 90000\n",
      "\n",
      "2017-03-22 13:51:02,972 : INFO : Doc:  90000 -> Total Lines to write:       16\n",
      "2017-03-22 13:53:21,706 : INFO : Finished batch 30000 of size 10000 in 55m 1s\n",
      "2017-03-22 13:53:21,715 : INFO : For index 30000, the actual number of lines written is: 643976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:53:33,934 : INFO : Finished batch 50000 of size 10000 in 55m 13s\n",
      "2017-03-22 13:53:33,955 : INFO : For index 50000, the actual number of lines written is: 666009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:53:53,311 : INFO : Finished batch 20000 of size 10000 in 55m 32s\n",
      "2017-03-22 13:53:53,342 : INFO : For index 20000, the actual number of lines written is: 648468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:54:19,528 : INFO : Batch creation working on 100000\n",
      "\n",
      "2017-03-22 13:54:19,877 : INFO : Doc: 100000 -> Total Lines to write:       63\n",
      "2017-03-22 13:54:24,557 : INFO : Finished batch 40000 of size 10000 in 56m 4s\n",
      "2017-03-22 13:54:24,559 : INFO : For index 40000, the actual number of lines written is: 644504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:54:30,005 : INFO : Batch creation working on 110000\n",
      "\n",
      "2017-03-22 13:54:30,632 : INFO : Doc: 110000 -> Total Lines to write:       31\n",
      "2017-03-22 13:54:51,271 : INFO : Batch creation working on 120000\n",
      "\n",
      "2017-03-22 13:54:51,649 : INFO : Doc: 120000 -> Total Lines to write:       34\n",
      "2017-03-22 13:55:01,777 : INFO : Finished batch 10000 of size 10000 in 56m 41s\n",
      "2017-03-22 13:55:01,809 : INFO : For index 10000, the actual number of lines written is: 654890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:55:11,920 : INFO : Finished batch 60000 of size 10000 in 56m 51s\n",
      "2017-03-22 13:55:11,944 : INFO : For index 60000, the actual number of lines written is: 669832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:55:22,787 : INFO : Finished batch 80000 of size 10000 in 57m 2s\n",
      "2017-03-22 13:55:22,810 : INFO : For index 80000, the actual number of lines written is: 670546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:55:26,627 : INFO : Batch creation working on 130000\n",
      "\n",
      "2017-03-22 13:55:27,586 : INFO : Doc: 130000 -> Total Lines to write:       80\n",
      "2017-03-22 13:56:01,693 : INFO : Batch creation working on 140000\n",
      "\n",
      "2017-03-22 13:56:01,958 : INFO : Doc: 140000 -> Total Lines to write:       34\n",
      "2017-03-22 13:56:18,022 : INFO : Batch creation working on 150000\n",
      "\n",
      "2017-03-22 13:56:18,452 : INFO : Doc: 150000 -> Total Lines to write:       48\n",
      "2017-03-22 13:56:23,687 : INFO : Batch creation working on 160000\n",
      "\n",
      "2017-03-22 13:56:24,256 : INFO : Doc: 160000 -> Total Lines to write:       50\n",
      "2017-03-22 13:56:43,218 : INFO : Doc:  91000 -> Total Lines to write:    67284\n",
      "2017-03-22 13:57:02,548 : INFO : Finished batch 70000 of size 10000 in 58m 41s\n",
      "2017-03-22 13:57:02,568 : INFO : For index 70000, the actual number of lines written is: 684962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 13:57:49,841 : INFO : Batch creation working on 170000\n",
      "\n",
      "2017-03-22 13:57:50,463 : INFO : Doc: 170000 -> Total Lines to write:       41\n",
      "2017-03-22 14:00:03,890 : INFO : Doc: 101000 -> Total Lines to write:    71449\n",
      "2017-03-22 14:00:11,296 : INFO : Doc: 121000 -> Total Lines to write:    67722\n",
      "2017-03-22 14:00:14,526 : INFO : Doc: 111000 -> Total Lines to write:    71370\n",
      "2017-03-22 14:00:32,489 : INFO : Doc: 131000 -> Total Lines to write:    63562\n",
      "2017-03-22 14:01:36,314 : INFO : Doc: 141000 -> Total Lines to write:    69633\n",
      "2017-03-22 14:01:43,059 : INFO : Doc: 151000 -> Total Lines to write:    68519\n",
      "2017-03-22 14:02:06,084 : INFO : Doc:  92000 -> Total Lines to write:   136083\n",
      "2017-03-22 14:02:24,811 : INFO : Doc: 161000 -> Total Lines to write:    73352\n",
      "2017-03-22 14:03:15,231 : INFO : Doc: 171000 -> Total Lines to write:    65056\n",
      "2017-03-22 14:05:28,786 : INFO : Doc: 112000 -> Total Lines to write:   134824\n",
      "2017-03-22 14:05:38,094 : INFO : Doc: 102000 -> Total Lines to write:   139357\n",
      "2017-03-22 14:06:08,227 : INFO : Doc: 132000 -> Total Lines to write:   132974\n",
      "2017-03-22 14:06:26,535 : INFO : Doc: 122000 -> Total Lines to write:   140862\n",
      "2017-03-22 14:07:27,065 : INFO : Doc: 142000 -> Total Lines to write:   139133\n",
      "2017-03-22 14:07:42,727 : INFO : Doc: 152000 -> Total Lines to write:   141883\n",
      "2017-03-22 14:07:53,502 : INFO : Doc:  93000 -> Total Lines to write:   207307\n",
      "2017-03-22 14:08:02,045 : INFO : Doc: 162000 -> Total Lines to write:   142460\n",
      "2017-03-22 14:09:32,159 : INFO : Doc: 172000 -> Total Lines to write:   140864\n",
      "2017-03-22 14:11:01,460 : INFO : Doc: 103000 -> Total Lines to write:   204633\n",
      "2017-03-22 14:11:15,529 : INFO : Doc: 113000 -> Total Lines to write:   206849\n",
      "2017-03-22 14:12:14,777 : INFO : Doc: 133000 -> Total Lines to write:   206467\n",
      "2017-03-22 14:12:27,186 : INFO : Doc: 123000 -> Total Lines to write:   210941\n",
      "2017-03-22 14:12:53,431 : INFO : Doc: 143000 -> Total Lines to write:   207064\n",
      "2017-03-22 14:13:04,070 : INFO : Doc: 153000 -> Total Lines to write:   208558\n",
      "2017-03-22 14:13:29,486 : INFO : Doc: 163000 -> Total Lines to write:   213598\n",
      "2017-03-22 14:13:29,740 : INFO : Doc:  94000 -> Total Lines to write:   274596\n",
      "2017-03-22 14:14:51,535 : INFO : Doc: 173000 -> Total Lines to write:   210947\n",
      "2017-03-22 14:16:44,167 : INFO : Doc: 114000 -> Total Lines to write:   276594\n",
      "2017-03-22 14:17:13,492 : INFO : Doc: 104000 -> Total Lines to write:   276565\n",
      "2017-03-22 14:17:58,302 : INFO : Doc: 144000 -> Total Lines to write:   271871\n",
      "2017-03-22 14:18:01,592 : INFO : Doc: 134000 -> Total Lines to write:   278195\n",
      "2017-03-22 14:18:26,584 : INFO : Doc: 124000 -> Total Lines to write:   283171\n",
      "2017-03-22 14:18:39,897 : INFO : Doc:  95000 -> Total Lines to write:   337409\n",
      "2017-03-22 14:18:53,934 : INFO : Doc: 154000 -> Total Lines to write:   280074\n",
      "2017-03-22 14:19:41,278 : INFO : Doc: 164000 -> Total Lines to write:   287920\n",
      "2017-03-22 14:20:54,762 : INFO : Doc: 174000 -> Total Lines to write:   282229\n",
      "2017-03-22 14:21:57,787 : INFO : Doc: 115000 -> Total Lines to write:   340295\n",
      "2017-03-22 14:23:57,882 : INFO : Doc: 135000 -> Total Lines to write:   345445\n",
      "2017-03-22 14:24:08,379 : INFO : Doc:  96000 -> Total Lines to write:   401188\n",
      "2017-03-22 14:24:24,854 : INFO : Doc: 125000 -> Total Lines to write:   351973\n",
      "2017-03-22 14:24:30,735 : INFO : Doc: 155000 -> Total Lines to write:   343262\n",
      "2017-03-22 14:25:48,699 : INFO : Doc: 165000 -> Total Lines to write:   361565\n",
      "2017-03-22 14:26:36,888 : INFO : Doc: 175000 -> Total Lines to write:   351210\n",
      "2017-03-22 14:27:51,872 : INFO : Doc: 105000 -> Total Lines to write:   363008\n",
      "2017-03-22 14:28:00,824 : INFO : Doc: 116000 -> Total Lines to write:   413438\n",
      "2017-03-22 14:29:50,384 : INFO : Doc: 136000 -> Total Lines to write:   415251\n",
      "2017-03-22 14:30:01,625 : INFO : Doc: 126000 -> Total Lines to write:   421444\n",
      "2017-03-22 14:30:09,388 : INFO : Doc:  97000 -> Total Lines to write:   471631\n",
      "2017-03-22 14:30:27,284 : INFO : Doc: 156000 -> Total Lines to write:   414681\n",
      "2017-03-22 14:31:59,344 : INFO : Doc: 166000 -> Total Lines to write:   432277\n",
      "2017-03-22 14:33:36,066 : INFO : Doc: 176000 -> Total Lines to write:   426287\n",
      "2017-03-22 14:33:53,884 : INFO : Doc: 106000 -> Total Lines to write:   432464\n",
      "2017-03-22 14:35:43,151 : INFO : Doc: 137000 -> Total Lines to write:   482136\n",
      "2017-03-22 14:36:15,182 : INFO : Doc: 157000 -> Total Lines to write:   482517\n",
      "2017-03-22 14:36:19,331 : INFO : Doc:  98000 -> Total Lines to write:   541907\n",
      "2017-03-22 14:37:11,675 : INFO : Doc: 127000 -> Total Lines to write:   497297\n",
      "2017-03-22 14:37:59,610 : INFO : Doc: 167000 -> Total Lines to write:   502962\n",
      "2017-03-22 14:38:11,661 : INFO : Doc: 117000 -> Total Lines to write:   501718\n",
      "2017-03-22 14:39:22,273 : INFO : Doc: 177000 -> Total Lines to write:   498044\n",
      "2017-03-22 14:40:12,040 : INFO : Doc: 107000 -> Total Lines to write:   506973\n",
      "2017-03-22 14:42:03,729 : INFO : Doc: 138000 -> Total Lines to write:   554214\n",
      "2017-03-22 14:42:16,002 : INFO : Doc: 158000 -> Total Lines to write:   556355\n",
      "2017-03-22 14:42:43,570 : INFO : Doc:  99000 -> Total Lines to write:   613477\n",
      "2017-03-22 14:42:53,503 : INFO : Doc: 128000 -> Total Lines to write:   568676\n",
      "2017-03-22 14:43:50,983 : INFO : Doc: 168000 -> Total Lines to write:   572693\n",
      "2017-03-22 14:44:59,948 : INFO : Doc: 118000 -> Total Lines to write:   574829\n",
      "2017-03-22 14:46:05,871 : INFO : Doc: 108000 -> Total Lines to write:   573803\n",
      "2017-03-22 14:46:42,679 : INFO : Doc: 178000 -> Total Lines to write:   579980\n",
      "2017-03-22 14:47:56,497 : INFO : Doc: 139000 -> Total Lines to write:   619778\n",
      "2017-03-22 14:48:36,888 : INFO : Doc: 159000 -> Total Lines to write:   631020\n",
      "2017-03-22 14:48:43,024 : INFO : Finished batch 90000 of size 10000 in 57m 40s\n",
      "2017-03-22 14:48:43,035 : INFO : For index 90000, the actual number of lines written is: 682507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 14:49:12,427 : INFO : Doc: 129000 -> Total Lines to write:   638099\n",
      "2017-03-22 14:49:42,945 : INFO : Batch creation working on 180000\n",
      "\n",
      "2017-03-22 14:49:43,620 : INFO : Doc: 180000 -> Total Lines to write:      100\n",
      "2017-03-22 14:49:44,176 : INFO : Doc: 169000 -> Total Lines to write:   642987\n",
      "2017-03-22 14:50:33,993 : INFO : Doc: 119000 -> Total Lines to write:   642771\n",
      "2017-03-22 14:51:56,018 : INFO : Doc: 109000 -> Total Lines to write:   638586\n",
      "2017-03-22 14:53:09,662 : INFO : Doc: 179000 -> Total Lines to write:   654335\n",
      "2017-03-22 14:53:40,250 : INFO : Finished batch 130000 of size 10000 in 58m 13s\n",
      "2017-03-22 14:53:40,259 : INFO : For index 130000, the actual number of lines written is: 686283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 130000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 14:54:19,116 : INFO : Finished batch 150000 of size 10000 in 58m 1s\n",
      "2017-03-22 14:54:19,123 : INFO : For index 150000, the actual number of lines written is: 698839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 14:54:38,708 : INFO : Batch creation working on 190000\n",
      "\n",
      "2017-03-22 14:54:39,489 : INFO : Doc: 190000 -> Total Lines to write:       69\n",
      "2017-03-22 14:55:04,152 : INFO : Finished batch 120000 of size 10000 in 60m 13s\n",
      "2017-03-22 14:55:04,173 : INFO : For index 120000, the actual number of lines written is: 707329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 14:55:17,721 : INFO : Batch creation working on 200000\n",
      "\n",
      "2017-03-22 14:55:17,859 : INFO : Doc: 200000 -> Total Lines to write:       14\n",
      "2017-03-22 14:56:14,130 : INFO : Doc: 181000 -> Total Lines to write:    77751\n",
      "2017-03-22 14:56:14,886 : INFO : Batch creation working on 210000\n",
      "\n",
      "2017-03-22 14:56:15,589 : INFO : Doc: 210000 -> Total Lines to write:       53\n",
      "2017-03-22 14:56:27,198 : INFO : Finished batch 160000 of size 10000 in 60m 3s\n",
      "2017-03-22 14:56:27,218 : INFO : For index 160000, the actual number of lines written is: 718500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 14:57:02,295 : INFO : Finished batch 110000 of size 10000 in 62m 32s\n",
      "2017-03-22 14:57:02,321 : INFO : For index 110000, the actual number of lines written is: 711124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 14:57:32,045 : INFO : Batch creation working on 220000\n",
      "\n",
      "2017-03-22 14:57:32,361 : INFO : Doc: 220000 -> Total Lines to write:       95\n",
      "2017-03-22 14:57:52,932 : INFO : Finished batch 100000 of size 10000 in 63m 33s\n",
      "2017-03-22 14:57:52,948 : INFO : For index 100000, the actual number of lines written is: 708929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 14:58:02,124 : INFO : Batch creation working on 230000\n",
      "\n",
      "2017-03-22 14:58:02,870 : INFO : Doc: 230000 -> Total Lines to write:       51\n",
      "2017-03-22 14:58:57,089 : INFO : Batch creation working on 240000\n",
      "\n",
      "2017-03-22 14:58:57,340 : INFO : Doc: 240000 -> Total Lines to write:       40\n",
      "2017-03-22 14:59:23,180 : INFO : Finished batch 170000 of size 10000 in 61m 33s\n",
      "2017-03-22 14:59:23,208 : INFO : For index 170000, the actual number of lines written is: 723950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 170000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:00:27,040 : INFO : Batch creation working on 250000\n",
      "\n",
      "2017-03-22 15:00:27,442 : INFO : Doc: 250000 -> Total Lines to write:       38\n",
      "2017-03-22 15:00:55,809 : INFO : Doc: 191000 -> Total Lines to write:    74291\n",
      "2017-03-22 15:02:27,261 : INFO : Doc: 201000 -> Total Lines to write:    80796\n",
      "2017-03-22 15:02:31,762 : INFO : Doc: 182000 -> Total Lines to write:   150965\n",
      "2017-03-22 15:02:41,629 : INFO : Doc: 211000 -> Total Lines to write:    75352\n",
      "2017-03-22 15:03:38,606 : INFO : Doc: 221000 -> Total Lines to write:    72391\n",
      "2017-03-22 15:03:53,262 : INFO : Doc: 231000 -> Total Lines to write:    70202\n",
      "2017-03-22 15:05:25,441 : INFO : Doc: 241000 -> Total Lines to write:    74911\n",
      "2017-03-22 15:06:28,377 : INFO : Doc: 251000 -> Total Lines to write:    70930\n",
      "2017-03-22 15:07:28,861 : INFO : Doc: 192000 -> Total Lines to write:   149432\n",
      "2017-03-22 15:08:12,118 : INFO : Doc: 212000 -> Total Lines to write:   142280\n",
      "2017-03-22 15:08:34,860 : INFO : Doc: 202000 -> Total Lines to write:   154261\n",
      "2017-03-22 15:09:02,133 : INFO : Doc: 183000 -> Total Lines to write:   226903\n",
      "2017-03-22 15:09:48,825 : INFO : Doc: 222000 -> Total Lines to write:   149168\n",
      "2017-03-22 15:10:13,944 : INFO : Doc: 232000 -> Total Lines to write:   144817\n",
      "2017-03-22 15:11:34,468 : INFO : Doc: 242000 -> Total Lines to write:   152247\n",
      "2017-03-22 15:12:01,295 : INFO : Doc: 252000 -> Total Lines to write:   140225\n",
      "2017-03-22 15:12:58,687 : INFO : Doc: 193000 -> Total Lines to write:   221582\n",
      "2017-03-22 15:14:20,433 : INFO : Doc: 213000 -> Total Lines to write:   218945\n",
      "2017-03-22 15:14:20,814 : INFO : Doc: 203000 -> Total Lines to write:   228142\n",
      "2017-03-22 15:14:39,194 : INFO : Doc: 184000 -> Total Lines to write:   297125\n",
      "2017-03-22 15:15:14,638 : INFO : Doc: 223000 -> Total Lines to write:   222971\n",
      "2017-03-22 15:15:31,926 : INFO : Doc: 233000 -> Total Lines to write:   218856\n",
      "2017-03-22 15:16:02,803 : INFO : Doc: 243000 -> Total Lines to write:   221344\n",
      "2017-03-22 15:16:53,183 : INFO : Doc: 253000 -> Total Lines to write:   217414\n",
      "2017-03-22 15:17:14,018 : INFO : Doc: 194000 -> Total Lines to write:   289798\n",
      "2017-03-22 15:18:15,802 : INFO : Doc: 254000 -> Total Lines to write:   235218\n",
      "2017-03-22 15:18:50,573 : INFO : Doc: 214000 -> Total Lines to write:   291386\n",
      "2017-03-22 15:18:55,778 : INFO : Doc: 204000 -> Total Lines to write:   301521\n",
      "2017-03-22 15:19:19,917 : INFO : Doc: 224000 -> Total Lines to write:   288060\n",
      "2017-03-22 15:19:24,891 : INFO : Doc: 185000 -> Total Lines to write:   373207\n",
      "2017-03-22 15:20:17,151 : INFO : Doc: 234000 -> Total Lines to write:   289718\n",
      "2017-03-22 15:21:20,211 : INFO : Doc: 244000 -> Total Lines to write:   297053\n",
      "2017-03-22 15:22:17,777 : INFO : Finished batch 250000 of size 10000 in 21m 50s\n",
      "2017-03-22 15:22:17,787 : INFO : For index 250000, the actual number of lines written is: 282735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:23:16,549 : INFO : Doc: 195000 -> Total Lines to write:   365966\n",
      "2017-03-22 15:24:03,456 : INFO : Doc: 205000 -> Total Lines to write:   373524\n",
      "2017-03-22 15:24:20,513 : INFO : Doc: 215000 -> Total Lines to write:   364688\n",
      "2017-03-22 15:24:23,808 : INFO : Doc: 225000 -> Total Lines to write:   358886\n",
      "2017-03-22 15:24:36,811 : INFO : Doc: 186000 -> Total Lines to write:   444976\n",
      "2017-03-22 15:25:15,583 : INFO : Doc: 235000 -> Total Lines to write:   360211\n",
      "2017-03-22 15:26:51,782 : INFO : Doc: 245000 -> Total Lines to write:   372994\n",
      "2017-03-22 15:27:58,683 : INFO : Doc: 196000 -> Total Lines to write:   436158\n",
      "2017-03-22 15:28:59,738 : INFO : Doc: 206000 -> Total Lines to write:   443804\n",
      "2017-03-22 15:29:06,601 : INFO : Doc: 216000 -> Total Lines to write:   433585\n",
      "2017-03-22 15:29:17,133 : INFO : Doc: 226000 -> Total Lines to write:   431501\n",
      "2017-03-22 15:29:19,577 : INFO : Doc: 187000 -> Total Lines to write:   514111\n",
      "2017-03-22 15:30:32,530 : INFO : Doc: 236000 -> Total Lines to write:   434957\n",
      "2017-03-22 15:32:05,696 : INFO : Doc: 246000 -> Total Lines to write:   449269\n",
      "2017-03-22 15:33:20,060 : INFO : Doc: 197000 -> Total Lines to write:   509200\n",
      "2017-03-22 15:34:24,886 : INFO : Doc: 217000 -> Total Lines to write:   507777\n",
      "2017-03-22 15:34:28,175 : INFO : Doc: 227000 -> Total Lines to write:   503832\n",
      "2017-03-22 15:34:32,485 : INFO : Doc: 207000 -> Total Lines to write:   516093\n",
      "2017-03-22 15:35:14,830 : INFO : Doc: 188000 -> Total Lines to write:   587410\n",
      "2017-03-22 15:36:20,440 : INFO : Doc: 237000 -> Total Lines to write:   518112\n",
      "2017-03-22 15:37:36,648 : INFO : Doc: 247000 -> Total Lines to write:   525064\n",
      "2017-03-22 15:38:02,201 : INFO : Doc: 198000 -> Total Lines to write:   578856\n",
      "2017-03-22 15:39:32,114 : INFO : Doc: 228000 -> Total Lines to write:   573819\n",
      "2017-03-22 15:39:38,840 : INFO : Doc: 218000 -> Total Lines to write:   577381\n",
      "2017-03-22 15:39:39,670 : INFO : Doc: 208000 -> Total Lines to write:   589908\n",
      "2017-03-22 15:40:42,088 : INFO : Doc: 189000 -> Total Lines to write:   661945\n",
      "2017-03-22 15:41:24,462 : INFO : Doc: 238000 -> Total Lines to write:   594927\n",
      "2017-03-22 15:43:18,176 : INFO : Doc: 199000 -> Total Lines to write:   650521\n",
      "2017-03-22 15:44:15,931 : INFO : Doc: 248000 -> Total Lines to write:   607840\n",
      "2017-03-22 15:44:34,561 : INFO : Doc: 229000 -> Total Lines to write:   643789\n",
      "2017-03-22 15:45:00,051 : INFO : Doc: 209000 -> Total Lines to write:   660447\n",
      "2017-03-22 15:45:09,077 : INFO : Doc: 219000 -> Total Lines to write:   651138\n",
      "2017-03-22 15:45:33,896 : INFO : Finished batch 180000 of size 10000 in 55m 51s\n",
      "2017-03-22 15:45:33,915 : INFO : For index 180000, the actual number of lines written is: 731714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 180000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:46:50,444 : INFO : Doc: 239000 -> Total Lines to write:   668605\n",
      "2017-03-22 15:48:48,403 : INFO : Finished batch 190000 of size 10000 in 54m 9s\n",
      "2017-03-22 15:48:48,420 : INFO : For index 190000, the actual number of lines written is: 727668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 190000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:49:26,472 : INFO : Doc: 249000 -> Total Lines to write:   676103\n",
      "2017-03-22 15:49:53,918 : INFO : Finished batch 210000 of size 10000 in 53m 39s\n",
      "2017-03-22 15:49:53,939 : INFO : For index 210000, the actual number of lines written is: 720610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 210000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:50:06,372 : INFO : Finished batch 200000 of size 10000 in 54m 49s\n",
      "2017-03-22 15:50:06,395 : INFO : For index 200000, the actual number of lines written is: 737799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:50:21,266 : INFO : Finished batch 220000 of size 10000 in 52m 49s\n",
      "2017-03-22 15:50:21,289 : INFO : For index 220000, the actual number of lines written is: 722187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 220000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:51:51,584 : INFO : Finished batch 230000 of size 10000 in 53m 49s\n",
      "2017-03-22 15:51:51,600 : INFO : For index 230000, the actual number of lines written is: 745680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 230000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 15:53:27,204 : INFO : Finished batch 240000 of size 10000 in 54m 30s\n",
      "2017-03-22 15:53:27,206 : INFO : For index 240000, the actual number of lines written is: 753571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 16:14:18,462 : INFO : Doc: 145000 -> Total Lines to write:   400650\n",
      "2017-03-22 16:17:52,145 : INFO : Doc: 146000 -> Total Lines to write:   469147\n",
      "2017-03-22 16:21:21,346 : INFO : Doc: 147000 -> Total Lines to write:   534385\n",
      "2017-03-22 16:25:10,632 : INFO : Doc: 148000 -> Total Lines to write:   609511\n",
      "2017-03-22 16:28:38,253 : INFO : Doc: 149000 -> Total Lines to write:   679632\n",
      "2017-03-22 16:32:06,957 : INFO : Finished batch 140000 of size 10000 in 156m 5s\n",
      "2017-03-22 16:32:06,962 : INFO : For index 140000, the actual number of lines written is: 751135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 140000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(9)\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 10:44:02,083 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-16 10:44:02,175 : INFO : Doc:      0 -> Total Lines to write:       78\n",
      "2017-03-16 10:44:18,155 : INFO : Finished batch 0 of size 100 in 0m 16s\n",
      "2017-03-16 10:44:18,160 : INFO : For index 0, the actual number of lines written is: 7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    }
   ],
   "source": [
    "multithreaded_extended_batch_creation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = validation_docs_list\n",
    "FILE_PREFIX = VALIDATION_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 17:48:52,001 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-22 17:48:52,002 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-22 17:48:52,002 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-22 17:48:52,027 : INFO : Batch creation working on 60000\n",
      "\n",
      "2017-03-22 17:48:52,015 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-22 17:48:52,014 : INFO : Batch creation working on 40000\n",
      "\n",
      "2017-03-22 17:48:52,027 : INFO : Batch creation working on 50000\n",
      "\n",
      "2017-03-22 17:48:52,929 : INFO : Doc:  50000 -> Total Lines to write:       56\n",
      "2017-03-22 17:48:52,994 : INFO : Doc:  60000 -> Total Lines to write:       59\n",
      "2017-03-22 17:48:52,991 : INFO : Doc:      0 -> Total Lines to write:       17\n",
      "2017-03-22 17:48:53,013 : INFO : Doc:  10000 -> Total Lines to write:       28\n",
      "2017-03-22 17:48:53,062 : INFO : Doc:  30000 -> Total Lines to write:       55\n",
      "2017-03-22 17:48:53,089 : INFO : Doc:  40000 -> Total Lines to write:       69\n",
      "2017-03-22 17:48:53,123 : INFO : Doc:  20000 -> Total Lines to write:       79\n",
      "2017-03-22 17:52:04,379 : INFO : Finished batch 60000 of size 10000 in 3m 12s\n",
      "2017-03-22 17:52:04,389 : INFO : For index 60000, the actual number of lines written is: 52545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 17:52:16,905 : INFO : Doc:   1000 -> Total Lines to write:    56405\n",
      "2017-03-22 17:52:26,985 : INFO : Doc:  11000 -> Total Lines to write:    59498\n",
      "2017-03-22 17:52:45,531 : INFO : Doc:  41000 -> Total Lines to write:    67494\n",
      "2017-03-22 17:52:53,967 : INFO : Doc:  21000 -> Total Lines to write:    66364\n",
      "2017-03-22 17:52:56,284 : INFO : Doc:  51000 -> Total Lines to write:    71973\n",
      "2017-03-22 17:52:57,315 : INFO : Doc:  31000 -> Total Lines to write:    69987\n",
      "2017-03-22 17:56:04,978 : INFO : Doc:   2000 -> Total Lines to write:   115158\n",
      "2017-03-22 17:56:10,504 : INFO : Doc:  12000 -> Total Lines to write:   119685\n",
      "2017-03-22 17:56:48,789 : INFO : Doc:  52000 -> Total Lines to write:   137569\n",
      "2017-03-22 17:56:50,789 : INFO : Doc:  42000 -> Total Lines to write:   135252\n",
      "2017-03-22 17:56:57,055 : INFO : Doc:  22000 -> Total Lines to write:   132914\n",
      "2017-03-22 17:56:58,551 : INFO : Doc:  32000 -> Total Lines to write:   135099\n",
      "2017-03-22 17:59:42,091 : INFO : Doc:  13000 -> Total Lines to write:   182423\n",
      "2017-03-22 17:59:47,293 : INFO : Doc:   3000 -> Total Lines to write:   180209\n",
      "2017-03-22 18:00:25,367 : INFO : Doc:  23000 -> Total Lines to write:   198163\n",
      "2017-03-22 18:00:26,251 : INFO : Doc:  43000 -> Total Lines to write:   204371\n",
      "2017-03-22 18:00:27,836 : INFO : Doc:  53000 -> Total Lines to write:   207348\n",
      "2017-03-22 18:00:28,630 : INFO : Doc:  33000 -> Total Lines to write:   201753\n",
      "2017-03-22 18:02:39,785 : INFO : Doc:  14000 -> Total Lines to write:   245680\n",
      "2017-03-22 18:02:58,213 : INFO : Doc:   4000 -> Total Lines to write:   243104\n",
      "2017-03-22 18:03:30,407 : INFO : Doc:  24000 -> Total Lines to write:   262095\n",
      "2017-03-22 18:03:30,740 : INFO : Doc:  34000 -> Total Lines to write:   268079\n",
      "2017-03-22 18:03:45,663 : INFO : Doc:  44000 -> Total Lines to write:   272834\n",
      "2017-03-22 18:03:55,928 : INFO : Doc:  54000 -> Total Lines to write:   277494\n",
      "2017-03-22 18:06:35,431 : INFO : Doc:  15000 -> Total Lines to write:   309945\n",
      "2017-03-22 18:06:52,070 : INFO : Doc:   5000 -> Total Lines to write:   305426\n",
      "2017-03-22 18:08:03,623 : INFO : Doc:  35000 -> Total Lines to write:   335354\n",
      "2017-03-22 18:08:16,095 : INFO : Doc:  25000 -> Total Lines to write:   331644\n",
      "2017-03-22 18:08:23,072 : INFO : Doc:  45000 -> Total Lines to write:   344281\n",
      "2017-03-22 18:08:36,108 : INFO : Doc:  55000 -> Total Lines to write:   350366\n",
      "2017-03-22 18:11:12,065 : INFO : Doc:  16000 -> Total Lines to write:   375101\n",
      "2017-03-22 18:11:21,274 : INFO : Doc:   6000 -> Total Lines to write:   367499\n",
      "2017-03-22 18:12:50,674 : INFO : Doc:  26000 -> Total Lines to write:   399812\n",
      "2017-03-22 18:13:02,135 : INFO : Doc:  36000 -> Total Lines to write:   404110\n",
      "2017-03-22 18:13:17,122 : INFO : Doc:  46000 -> Total Lines to write:   417153\n",
      "2017-03-22 18:13:34,754 : INFO : Doc:  56000 -> Total Lines to write:   421898\n",
      "2017-03-22 18:15:26,594 : INFO : Doc:   7000 -> Total Lines to write:   428730\n",
      "2017-03-22 18:15:46,954 : INFO : Doc:  17000 -> Total Lines to write:   441421\n",
      "2017-03-22 18:16:46,488 : INFO : Doc:  27000 -> Total Lines to write:   463729\n",
      "2017-03-22 18:17:19,465 : INFO : Doc:  37000 -> Total Lines to write:   474486\n",
      "2017-03-22 18:17:58,128 : INFO : Doc:  47000 -> Total Lines to write:   488331\n",
      "2017-03-22 18:18:19,903 : INFO : Doc:  57000 -> Total Lines to write:   496679\n",
      "2017-03-22 18:19:21,692 : INFO : Doc:   8000 -> Total Lines to write:   489205\n",
      "2017-03-22 18:20:10,233 : INFO : Doc:  18000 -> Total Lines to write:   505901\n",
      "2017-03-22 18:21:04,770 : INFO : Doc:  28000 -> Total Lines to write:   525673\n",
      "2017-03-22 18:22:16,976 : INFO : Doc:  38000 -> Total Lines to write:   545030\n",
      "2017-03-22 18:22:37,590 : INFO : Doc:  48000 -> Total Lines to write:   558429\n",
      "2017-03-22 18:23:18,173 : INFO : Doc:  58000 -> Total Lines to write:   570611\n",
      "2017-03-22 18:23:52,886 : INFO : Doc:   9000 -> Total Lines to write:   551490\n",
      "2017-03-22 18:24:41,831 : INFO : Doc:  19000 -> Total Lines to write:   570665\n",
      "2017-03-22 18:25:23,209 : INFO : Doc:  29000 -> Total Lines to write:   591257\n",
      "2017-03-22 18:27:08,285 : INFO : Doc:  39000 -> Total Lines to write:   613701\n",
      "2017-03-22 18:27:21,920 : INFO : Doc:  49000 -> Total Lines to write:   626882\n",
      "2017-03-22 18:27:50,863 : INFO : Doc:  59000 -> Total Lines to write:   638590\n",
      "2017-03-22 18:28:41,118 : INFO : Finished batch 0 of size 10000 in 39m 49s\n",
      "2017-03-22 18:28:41,120 : INFO : For index 0, the actual number of lines written is: 619004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 18:29:03,037 : INFO : Finished batch 10000 of size 10000 in 40m 11s\n",
      "2017-03-22 18:29:03,041 : INFO : For index 10000, the actual number of lines written is: 638829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 18:30:00,309 : INFO : Finished batch 20000 of size 10000 in 41m 8s\n",
      "2017-03-22 18:30:00,312 : INFO : For index 20000, the actual number of lines written is: 660093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 18:31:30,338 : INFO : Finished batch 30000 of size 10000 in 42m 38s\n",
      "2017-03-22 18:31:30,346 : INFO : For index 30000, the actual number of lines written is: 683886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 18:31:38,686 : INFO : Finished batch 40000 of size 10000 in 42m 47s\n",
      "2017-03-22 18:31:38,706 : INFO : For index 40000, the actual number of lines written is: 700228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 18:31:53,906 : INFO : Finished batch 50000 of size 10000 in 43m 2s\n",
      "2017-03-22 18:31:53,912 : INFO : For index 50000, the actual number of lines written is: 707349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 50000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(8)\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = test_docs_list\n",
    "FILE_PREFIX = TEST_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(test_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-08 04:30:26,423 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-08 04:30:26,423 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-08 04:30:26,423 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-08 04:30:26,423 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-08 04:30:48,394 : INFO : Doc:  10000 -> Total Lines to write:      105\n",
      "2017-03-08 04:30:48,491 : INFO : Doc:      0 -> Total Lines to write:       86\n",
      "2017-03-08 04:30:48,639 : INFO : Doc:  20000 -> Total Lines to write:      188\n",
      "2017-03-08 04:30:53,858 : INFO : Doc:  30000 -> Total Lines to write:      514\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(16)\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def multithreaded_extended_batch_creation(start_index):\n",
    "\n",
    "#     if os.path.exists(FILE_PREFIX + str(start_index)):\n",
    "#         info(\"Batch {} already exists, skipping..\".format(start_index))\n",
    "#         return\n",
    "    \n",
    "    info(\"Batch creation working on {}\\n\".format(start_index))\n",
    "    token_lines = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    len_abs_sentences = 0\n",
    "    len_desc_sentences = 0\n",
    "    len_desc_paragraphs = 0\n",
    "    len_claims_sentences = 0\n",
    "    \n",
    "    len_abs_tokens = []\n",
    "    len_desc_tokens = []\n",
    "    len_claims_tokens = []\n",
    "    \n",
    "    \n",
    "    len_desc_parag_tokens = []\n",
    "\n",
    "    len_claims_paragraphs = []\n",
    "    \n",
    "    for doc_index, doc_id in enumerate(DOCS_LIST[start_index:]):\n",
    "        patent_doc = get_patent(doc_id)\n",
    "        \n",
    "        # Abstract\n",
    "        abstract = patent_doc['abstract'][0]\n",
    "        root = ET.fromstring(abstract.encode('utf-8'))\n",
    "        abs_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Description\n",
    "        desc = patent_doc['description'][0]\n",
    "        root = ET.fromstring(desc.encode('utf-8'))\n",
    "        desc_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Claims\n",
    "        claims = patent_doc['claims'][0]\n",
    "        root = ET.fromstring(claims.encode('utf-8'))\n",
    "        claims_paragraphs = get_adjusted_paragraphs(root, conc_sentences=False)\n",
    "#         claims_paragraphs = []\n",
    "#         for claim in patent_doc['claims']:\n",
    "#             claims_paragraphs.append(claim.strip())\n",
    "\n",
    "        len_claims_paragraphs.append(len(claims_paragraphs))\n",
    "    \n",
    "        abstract_sentences = sum([get_sentences(abs_parag) for abs_parag in abs_paragraphs], [])\n",
    "        desc_sentences = sum([get_sentences(desc_parag) for desc_parag in desc_paragraphs], [])\n",
    "        claims_sentences = sum([get_sentences(claim_parag) for claim_parag in claims_paragraphs], [])\n",
    "        \n",
    "        len_abs_sentences += len(abstract_sentences)\n",
    "        len_desc_sentences += len(desc_sentences)\n",
    "        len_claims_sentences += len(claims_sentences)\n",
    "        \n",
    "        len_desc_paragraphs += len(desc_paragraphs)\n",
    "        \n",
    "\n",
    "        abstract_tokens = sum([sentence_wordtokenizer(parag) for parag in abs_paragraphs], [])\n",
    "        \n",
    "        len_desc_parag_tokens.extend([len(sentence_wordtokenizer(parag)) for parag in desc_paragraphs])\n",
    "        desc_tokens = sum([sentence_wordtokenizer(parag) for parag in desc_paragraphs], [])\n",
    "        \n",
    "        claims_tokens = sum([sentence_wordtokenizer(parag) for parag in claims_paragraphs], [])\n",
    "        \n",
    "        \n",
    "        len_abs_tokens.append(len(abstract_tokens))\n",
    "        len_desc_tokens.append(len(desc_tokens))\n",
    "        len_claims_tokens.append(len(claims_tokens))\n",
    "        \n",
    "        # lists of list of tokens\n",
    "        doc_tokens_list = [doc_id]  + abstract_tokens + desc_tokens + claims_tokens\n",
    "        abstract_tokens_list = [ABSTRACT_ID.format(doc_id)] + abstract_tokens\n",
    "        description_tokens_list = [DESC_ID.format(doc_id)] + desc_tokens\n",
    "        claims_tokens_list = [CLAIMS_ID.format(doc_id)] + claims_tokens\n",
    "        \n",
    "        # now add the tokens lists that will be written to the file\n",
    "        token_lines.append(doc_tokens_list)\n",
    "        token_lines.append(abstract_tokens_list)\n",
    "        token_lines.append(description_tokens_list)\n",
    "        token_lines.append(claims_tokens_list)\n",
    "        \n",
    "        if doc_index % 1000 == 0: info(\"Doc: {:6} -> Total Lines to write: {:8}\".format(start_index + doc_index, len(token_lines)))\n",
    "        if doc_index >= BATCH_SIZE - 1:\n",
    "            break\n",
    "    duration = time.time() - start_time\n",
    "    info(\"Finished batch {} of size {:d} in {:.0f}m {:.0f}s\".format(start_index, BATCH_SIZE, * divmod(duration, 60)))\n",
    "    info(\"For index {}, the actual number of lines written is: {}\".format(start_index, len(token_lines)))\n",
    "    \n",
    "    print \"Average Abstract Sentences: {}\".format(len_abs_sentences/doc_index)\n",
    "    print \"Average Desc Sentences: {}\".format(len_desc_sentences/doc_index)\n",
    "    print \"Average Desc Paragraphs: {}\".format(len_desc_paragraphs/doc_index)\n",
    "    print \"Average Claims Sentences: {}\".format(len_claims_sentences/doc_index)\n",
    "    \n",
    "    \n",
    "    print \"Abstract Tokens: Mean: {} - Median: {}\".format(np.mean(len_abs_tokens), np.median(len_abs_tokens))\n",
    "    print \"Description Tokens: Mean: {} - Median: {}\".format(np.mean(len_desc_tokens), np.median(len_desc_tokens))\n",
    "    print \"Claims Tokens: Mean: {} - Median: {}\".format(np.mean(len_claims_tokens), np.median(len_claims_tokens))\n",
    "    print \"Description Paragraphs Tokens: Mean: {} - Median: {}\".format(np.mean(len_desc_parag_tokens), \n",
    "                                                                        np.median(len_desc_parag_tokens))\n",
    "    \n",
    "    print \"Claims Paragraphs: Mean: {} - Median: {}\".format(np.mean(len_claims_paragraphs), \n",
    "                                                                        np.median(len_claims_paragraphs))\n",
    "#     write_batch(FILE_PREFIX, token_lines, start_index)\n",
    "    del token_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = training_docs_list\n",
    "FILE_PREFIX = TRAINING_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:00:43,555 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-16 01:00:43,555 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-16 01:00:43,558 : INFO : Batch creation working on 40000\n",
      "\n",
      "2017-03-16 01:00:43,555 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-16 01:00:43,558 : INFO : Batch creation working on 50000\n",
      "\n",
      "2017-03-16 01:00:43,559 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-16 01:00:43,591 : INFO : Batch creation working on 60000\n",
      "\n",
      "2017-03-16 01:00:43,601 : INFO : Batch creation working on 70000\n",
      "\n",
      "2017-03-16 01:00:43,690 : INFO : Doc:  50000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,742 : INFO : Doc:  60000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,767 : INFO : Doc:      0 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,806 : INFO : Doc:  40000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,846 : INFO : Doc:  20000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,904 : INFO : Doc:  10000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,900 : INFO : Doc:  30000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,927 : INFO : Doc:  70000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:30,660 : INFO : Finished batch 0 of size 1000 in 4m 47s\n",
      "2017-03-16 01:05:30,663 : INFO : For index 0, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 236\n",
      "Average Desc Paragraphs: 56\n",
      "Average Claims Sentences: 19\n",
      "Abstract Tokens: Mean: 118.576 - Median: 114.0\n",
      "Description Tokens: Mean: 7694.354 - Median: 5256.5\n",
      "Claims Tokens: Mean: 1101.352 - Median: 828.0\n",
      "Description Paragraphs Tokens: Mean: 137.372194747 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 19.411 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:31,749 : INFO : Batch creation working on 80000\n",
      "\n",
      "2017-03-16 01:05:33,147 : INFO : Doc:  80000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:49,041 : INFO : Finished batch 40000 of size 1000 in 5m 5s\n",
      "2017-03-16 01:05:49,060 : INFO : For index 40000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 261\n",
      "Average Desc Paragraphs: 61\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 119.666 - Median: 119.0\n",
      "Description Tokens: Mean: 8411.443 - Median: 6107.0\n",
      "Claims Tokens: Mean: 1111.596 - Median: 944.0\n",
      "Description Paragraphs Tokens: Mean: 137.076788944 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 17.226 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:49,886 : INFO : Batch creation working on 90000\n",
      "\n",
      "2017-03-16 01:05:50,033 : INFO : Doc:  90000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:56,244 : INFO : Finished batch 50000 of size 1000 in 5m 13s\n",
      "2017-03-16 01:05:56,248 : INFO : For index 50000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 265\n",
      "Average Desc Paragraphs: 62\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 116.916 - Median: 118.0\n",
      "Description Tokens: Mean: 8561.637 - Median: 5910.0\n",
      "Claims Tokens: Mean: 1082.717 - Median: 892.0\n",
      "Description Paragraphs Tokens: Mean: 137.32235713 - Median: 112.0\n",
      "Claims Paragraphs: Mean: 17.019 - Median: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:57,120 : INFO : Batch creation working on 100000\n",
      "\n",
      "2017-03-16 01:05:57,343 : INFO : Doc: 100000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:58,003 : INFO : Finished batch 20000 of size 1000 in 5m 14s\n",
      "2017-03-16 01:05:58,006 : INFO : For index 20000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 266\n",
      "Average Desc Paragraphs: 61\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 118.616 - Median: 121.0\n",
      "Description Tokens: Mean: 8539.343 - Median: 5729.0\n",
      "Claims Tokens: Mean: 1096.825 - Median: 894.0\n",
      "Description Paragraphs Tokens: Mean: 138.749581607 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 17.846 - Median: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:59,193 : INFO : Batch creation working on 110000\n",
      "\n",
      "2017-03-16 01:06:00,006 : INFO : Doc: 110000 -> Total Lines to write:        4\n",
      "2017-03-16 01:06:07,053 : INFO : Finished batch 30000 of size 1000 in 5m 23s\n",
      "2017-03-16 01:06:07,059 : INFO : For index 30000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 271\n",
      "Average Desc Paragraphs: 64\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 118.392 - Median: 118.0\n",
      "Description Tokens: Mean: 8803.666 - Median: 6171.5\n",
      "Claims Tokens: Mean: 1099.404 - Median: 923.0\n",
      "Description Paragraphs Tokens: Mean: 137.510012183 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 17.875 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:06:08,003 : INFO : Batch creation working on 120000\n",
      "\n",
      "2017-03-16 01:06:08,152 : INFO : Doc: 120000 -> Total Lines to write:        4\n",
      "2017-03-16 01:06:14,886 : INFO : Finished batch 10000 of size 1000 in 5m 31s\n",
      "2017-03-16 01:06:14,891 : INFO : For index 10000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 272\n",
      "Average Desc Paragraphs: 63\n",
      "Average Claims Sentences: 19\n",
      "Abstract Tokens: Mean: 117.434 - Median: 116.0\n",
      "Description Tokens: Mean: 8971.263 - Median: 5658.5\n",
      "Claims Tokens: Mean: 1131.289 - Median: 896.0\n",
      "Description Paragraphs Tokens: Mean: 141.313113334 - Median: 114.0\n",
      "Claims Paragraphs: Mean: 19.008 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:06:18,493 : INFO : Finished batch 70000 of size 1000 in 5m 35s\n",
      "2017-03-16 01:06:18,497 : INFO : For index 70000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 282\n",
      "Average Desc Paragraphs: 66\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 116.501 - Median: 117.0\n",
      "Description Tokens: Mean: 9176.843 - Median: 6447.5\n",
      "Claims Tokens: Mean: 1058.939 - Median: 924.5\n",
      "Description Paragraphs Tokens: Mean: 137.616864615 - Median: 112.0\n",
      "Claims Paragraphs: Mean: 16.587 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:06:41,087 : INFO : Finished batch 60000 of size 1000 in 5m 57s\n",
      "2017-03-16 01:06:41,089 : INFO : For index 60000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 295\n",
      "Average Desc Paragraphs: 71\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 116.293 - Median: 118.0\n",
      "Description Tokens: Mean: 9770.952 - Median: 6617.0\n",
      "Claims Tokens: Mean: 1059.014 - Median: 906.5\n",
      "Description Paragraphs Tokens: Mean: 137.735438399 - Median: 112.0\n",
      "Claims Paragraphs: Mean: 16.633 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:07:02,979 : INFO : Finished batch 120000 of size 1000 in 0m 55s\n",
      "2017-03-16 01:07:02,982 : INFO : For index 120000, the actual number of lines written is: 624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 295\n",
      "Average Desc Paragraphs: 67\n",
      "Average Claims Sentences: 34\n",
      "Abstract Tokens: Mean: 123.487179487 - Median: 123.5\n",
      "Description Tokens: Mean: 9056.32051282 - Median: 6444.0\n",
      "Claims Tokens: Mean: 2129.06410256 - Median: 1735.0\n",
      "Description Paragraphs Tokens: Mean: 135.207771079 - Median: 111.0\n",
      "Claims Paragraphs: Mean: 34.3141025641 - Median: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:10:54,091 : INFO : Finished batch 80000 of size 1000 in 5m 22s\n",
      "2017-03-16 01:10:54,093 : INFO : For index 80000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 277\n",
      "Average Desc Paragraphs: 65\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 114.978 - Median: 118.0\n",
      "Description Tokens: Mean: 9035.3 - Median: 6557.0\n",
      "Claims Tokens: Mean: 1052.833 - Median: 908.0\n",
      "Description Paragraphs Tokens: Mean: 137.333373866 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 16.561 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:11:22,433 : INFO : Finished batch 90000 of size 1000 in 5m 33s\n",
      "2017-03-16 01:11:22,436 : INFO : For index 90000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 276\n",
      "Average Desc Paragraphs: 65\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 116.039 - Median: 118.0\n",
      "Description Tokens: Mean: 9215.904 - Median: 6593.5\n",
      "Claims Tokens: Mean: 1066.299 - Median: 932.5\n",
      "Description Paragraphs Tokens: Mean: 141.239908046 - Median: 116.0\n",
      "Claims Paragraphs: Mean: 16.451 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:11:36,285 : INFO : Finished batch 100000 of size 1000 in 5m 39s\n",
      "2017-03-16 01:11:36,288 : INFO : For index 100000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 287\n",
      "Average Desc Paragraphs: 67\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 113.675 - Median: 117.0\n",
      "Description Tokens: Mean: 9544.564 - Median: 6973.5\n",
      "Claims Tokens: Mean: 1108.746 - Median: 977.5\n",
      "Description Paragraphs Tokens: Mean: 141.208486211 - Median: 116.0\n",
      "Claims Paragraphs: Mean: 16.438 - Median: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:11:54,205 : INFO : Finished batch 110000 of size 1000 in 5m 55s\n",
      "2017-03-16 01:11:54,208 : INFO : For index 110000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 311\n",
      "Average Desc Paragraphs: 73\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 114.923 - Median: 118.0\n",
      "Description Tokens: Mean: 10124.423 - Median: 7225.5\n",
      "Claims Tokens: Mean: 1053.8 - Median: 936.5\n",
      "Description Paragraphs Tokens: Mean: 138.761056974 - Median: 115.0\n",
      "Claims Paragraphs: Mean: 16.433 - Median: 16.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(8) # use just 6 because every batch requires a lot of memory\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE*10 )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
