{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/bin/python2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_WORD_COUNT = 100 # Suggested by Levy and goldberg\n",
    "MIN_SIZE = 0\n",
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_file = \"/home/local/shalaby/docs_output_sample_100.json\"\n",
    "\n",
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "doc2vec_model_save_location = os.path.join(root_location, \"parameter_search_doc2vec_models_new\", \"full\")\n",
    "if not os.path.exists(doc2vec_model_save_location):\n",
    "    os.makedirs(doc2vec_model_save_location)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL)):\n",
    "    os.makedirs(os.path.join(doc2vec_model_save_location, VOCAB_MODEL))\n",
    "\n",
    "training_file = root_location + \"docs_output.json\"\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\"\n",
    "\n",
    "preprocessed_location = root_location + \"preprocessed_data/\"\n",
    "\n",
    "training_preprocessed_files_prefix = preprocessed_location + \"training_docs_merged_data_preprocessed-\"\n",
    "training_preprocessed_docids_files_prefix = preprocessed_location + \"training_docs_merged_docids_preprocessed-\"\n",
    "validation_preprocessed_files_prefix = preprocessed_location + \"validation_docs_merged_data_preprocessed-\"\n",
    "validation_preprocessed_docids_files_prefix = preprocessed_location + \"validation_docs_merged_docids_preprocessed-\"\n",
    "\n",
    "word2vec_questions_file = result = root_location + 'tensorflow/word2vec/questions-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 628 ms, total: 17.1 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "#test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            else:\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append(stem)\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ensure_hdfs_location_exists(location):\n",
    "    parent = os.path.dirname(location)\n",
    "    os.system(\"hdfs dfs -mkdir -p \" + location)\n",
    "\n",
    "def ensure_disk_location_exists(location):\n",
    "    if not os.path.exists(location):\n",
    "        os.makedirs(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference(doc2vec_model, doc_classification_map):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # do inference and store results in dict\n",
    "        i = 0\n",
    "        for (doc_id, doc_contents_array) in ValidationDocumentGenerator(training_file, validation_docs_list):\n",
    "            i += 1\n",
    "            if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "            validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "\n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in validation_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            validation_labels.append([classf for classf in doc_classification_map[validation_doc_id] if classf in sections])\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                           val_docs_list, val_preprocessed_files_prefix, val_preprocessed_docids_files_prefix):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_one_doc(doc_tuple):\n",
    "        #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "        doc_id, doc_tokens = doc_tuple\n",
    "        rep = doc2vec_model.infer_vector(doc_tokens)\n",
    "        return (doc_id, rep)\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_labels = []\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_labels = np.array(validation_labels)\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # Single-threaded inference\n",
    "        # do inference and store results in dict\n",
    "#         i = 0\n",
    "        \n",
    "#         validation_docs_iterator = DocumentBatchGenerator(val_preprocessed_files_prefix, \n",
    "#                                                         val_preprocessed_docids_files_prefix, batch_size=None)\n",
    "#         for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "#             i += 1\n",
    "#             if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "#             validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "        \n",
    "        # Multi-threaded inference\n",
    "        validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                          validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "        generator_func = validation_docs_iterator.__iter__()\n",
    "        pool = ThreadPool(NUM_CORES)\n",
    "        # map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "        validation_documents_reps = {}\n",
    "        mini_batch_size = 1000\n",
    "        while True:\n",
    "            threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "            info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "            if threaded_reps_partial:\n",
    "                #threaded_reps.extend(threaded_reps_partial)\n",
    "                validation_documents_reps.update(threaded_reps_partial)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "                \n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        validation_labels = np.array(validation_labels)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_doc2vec_spark_vectors(validation_vectors_matrix, classification, doc_classification_map):\n",
    "    validation_vectors = []\n",
    "    for (index, doc_id) in enumerate(validation_docs_list):\n",
    "        # converting from memmap to a normal array as spark is unable to convert memmap to a spark Vector\n",
    "        validation_vector = validation_vectors_matrix[index]\n",
    "        validation_vectors.append(get_training_vector(classification, validation_vector, \n",
    "                                                    doc_classification_map[doc_id]))\n",
    "    validation_vectors = sc.parallelize(validation_vectors)\n",
    "    info(\"Finished getting validation vectors\")\n",
    "    return validation_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "\n",
    "def get_training_data(doc2vec_model, classifications):\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for doc_id in training_docs_list:\n",
    "        # converting from memmap to a normal array\n",
    "        normal_array = []\n",
    "        normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "        training_data.append(normal_array)\n",
    "        eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "        training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))\n",
    "    training_labels = np.array(training_labels)\n",
    "    return training_data, training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "                    \n",
    "class DocumentBatchGenerator(object):\n",
    "    def __init__(self, filename_prefix, filename_docids_prefix, batch_size=10000 ):\n",
    "        \"\"\"\n",
    "        batch_size cant be > 10,000 due to a limitation in doc2vec training, \n",
    "        None means no batching (only use for inference)\n",
    "        \"\"\"\n",
    "        assert batch_size <= 10000 or batch_size is None\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.filename_docids_prefix = filename_docids_prefix\n",
    "        self.curr_lines = []\n",
    "        self.curr_docids = []\n",
    "        self.batch_size = batch_size\n",
    "        self.curr_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        self.curr_lines, self.docids = [], []\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_index) )\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    self.curr_lines.append(line.split(\" \"))\n",
    "#                     if i % 1000 == 0:\n",
    "#                         print i\n",
    "            self.curr_docids = pickle.load(open(self.filename_docids_prefix + str(self.curr_index), \"r\"))\n",
    "            self.batch_end = self.curr_index + len(self.curr_lines) -1 \n",
    "            info(\"Finished loading new batch\")\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_index))\n",
    "            raise StopIteration()\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            if self.curr_index > self.batch_end:\n",
    "                self.load_new_batch_in_memory()\n",
    "            for (doc_id, tokens) in zip(self.curr_docids, self.curr_lines):\n",
    "                if self.batch_size is not None:\n",
    "                    curr_batch_iter = 0\n",
    "                    # divide the document to batches according to the batch size\n",
    "                    while curr_batch_iter < len(tokens):\n",
    "                        yield LabeledSentence(words=tokens[curr_batch_iter: curr_batch_iter + self.batch_size], tags=[doc_id])\n",
    "                        curr_batch_iter += self.batch_size\n",
    "                else:\n",
    "                    yield doc_id, tokens\n",
    "                self.curr_index += 1\n",
    "\n",
    "class Word2VecTrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield stemtokenizer(text)\n",
    "                \n",
    "class ValidationDocumentGenerator(object):\n",
    "    def __init__(self, filename, validation_docs_list):\n",
    "        self.filename = filename\n",
    "        self.validation_docs_list = validation_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.validation_docs_list:\n",
    "                    yield doc_id, stemtokenizer(text)\n",
    "                    \n",
    "class StochasticDocumentGenerator(object):\n",
    "    \"\"\"\n",
    "    Randomly shuffle rows while reading them\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, training_docs_list, line_positions):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "        self.line_positions = line_positions\n",
    "        self.lines = set(line_positions.keys())\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            while len(self.lines) > 0:\n",
    "                random_line = random.sample(self.lines,1)[0]\n",
    "                self.lines.remove(random_line)\n",
    "                file_obj.seek(self.line_positions[random_line])\n",
    "                line = file_obj.readline()\n",
    "                if not line.strip(): continue\n",
    "#                 print random_line, self.line_positions[random_line], line[:30]\n",
    "                (doc_id, text) = eval(line)\n",
    "                # print random_line , doc_id\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "#                     yield doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 100\n",
    "DOC2VEC_WINDOW = 5\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 1\n",
    "DOC2VEC_MEAN = 0\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 20\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 10000 # report the progress every x terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_ITERATIONS = 10\n",
    "SVM_CONVERGENCE = 0.001\n",
    "SVM_REG = 0.001\n",
    "SVM_CLASS_WEIGHTS = 'balanced'\n",
    "GLOBAL_VARS.SVM_MODEL_NAME = 'svm_iter_{}_reg_{}_classweights_{}'.format(SVM_ITERATIONS, SVM_REG, str(SVM_CLASS_WEIGHTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_svm_model_path(method, classification, reg=SVM_REG, iterations=SVM_ITERATIONS):\n",
    "    location = os.path.join(save_parent_location, \"models\", method, \n",
    "                            \"iter_\" + str(iterations) + \"_reg_\" + str(reg),\n",
    "                            classification + \"_model.svm\")\n",
    "    ensure_hdfs_location_exists(location)\n",
    "    return location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_{}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "placeholder_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(size=DOC2VEC_SIZE , window=DOC2VEC_WINDOW, min_count=MIN_WORD_COUNT, \n",
    "                max_vocab_size= DOC2VEC_MAX_VOCAB_SIZE,\n",
    "                sample=DOC2VEC_SAMPLE, seed=DOC2VEC_SEED, workers=NUM_CORES,\n",
    "                # doc2vec algorithm dm=1 => PV-DM, dm=2 => PV-DBOW, PV-DM dictates CBOW for words\n",
    "                dm=DOC2VEC_TYPE,\n",
    "                # hs=0 => negative sampling, hs=1 => hierarchical softmax\n",
    "                hs=DOC2VEC_HIERARCHICAL_SAMPLE, negative=DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                dm_concat=DOC2VEC_CONCAT,\n",
    "                # would train words with skip-gram on top of cbow, we don't need that for now\n",
    "                dbow_words=DOC2VEC_TRAIN_WORDS,\n",
    "                iter=DOC2VEC_EPOCHS)\n",
    "\n",
    "GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:44:00,155 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model\n",
      "2017-01-15 02:44:06,464 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.docvecs.* with mmap=None\n",
      "2017-01-15 02:44:06,465 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 02:44:07,600 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 02:44:13,334 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.syn0.npy with mmap=None\n",
      "2017-01-15 02:44:13,684 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 02:44:13,686 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 02:44:14,585 : INFO : using concatenative 1100-dimensional layer1\n",
      "2017-01-15 02:44:14,586 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 3.5 s, total: 26.8 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_docs_iterator = DocumentBatchGenerator(training_preprocessed_files_prefix, \n",
    "                                                        training_preprocessed_docids_files_prefix, batch_size=10000)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX)):\n",
    "    doc2vec_model.build_vocab(sentences=training_docs_iterator, progress_per=REPORT_VOCAB_PROGRESS)\n",
    "    doc2vec_model.save(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX))\n",
    "else:\n",
    "    doc2vec_model_vocab_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX))\n",
    "    doc2vec_model.reset_from(doc2vec_model_vocab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocab_counts = {k:doc2vec_model.vocab[k].count for k in doc2vec_model.vocab.keys()}\n",
    "# dd = sorted(vocab_counts, key=vocab_counts.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training, validation and Metrics Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_model.min_alpha = 0.025\n",
    "epoch_validation_metrics = []\n",
    "epoch_training_metrics = []\n",
    "epoch_word2vec_metrics = []\n",
    "classifications = sections\n",
    "classifications_type = 'sections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'.format(classifications_type)\n",
    "TRAINING_METRICS_FILENAME = '{}_training_metrics.pkl'.format(classifications_type)\n",
    "METRICS_FIG_PNG_FILENAME = '{}_validation_metrics.png'.format(classifications_type)\n",
    "METRICS_FIG_PDF_FILENAME = '{}_validation_metrics.pdf'.format(classifications_type)\n",
    "WORD2VEC_METRICS_FILENAME = 'word2vec_metrics.pkl'\n",
    "\n",
    "# for epoch in range(DOC2VEC_MAX_EPOCHS):\n",
    "#     GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "# fig_save_location = placeholder_model_name.format('run')\n",
    "# plt.savefig(os.path.join(fig_save_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:46:22,121 : INFO : ****************** Epoch 1 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1 *******************\n",
      "2017-01-15 02:46:22,123 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model\n",
      "2017-01-15 02:46:26,763 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.* with mmap=None\n",
      "2017-01-15 02:46:26,764 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 02:46:27,857 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 02:46:31,539 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn0.npy with mmap=None\n",
      "2017-01-15 02:46:31,877 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 02:46:31,879 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 02:46:32,716 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 02:46:32,717 : INFO : Getting training Data\n",
      "2017-01-15 02:46:53,701 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:48:26,534 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 02:48:26,536 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.441, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.542, Top 3: 0.858, Top 5: 0.941, \n",
      "\t\t F1 Micro: 0.565, F1 Macro: 0.476, Total Pos: 2,702,940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:48:40,937 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 1 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 1 1 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/matplotlib/axes/_base.py:2787: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=1, right=1\n",
      "  'left=%s, right=%s') % (left, right))\n",
      "2017-01-15 02:48:50,373 : INFO : ****************** Epoch 2 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2 *******************\n",
      "2017-01-15 02:48:50,374 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.644, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.520, Top 3: 0.837, Top 5: 0.925, \n",
      "\t\t F1 Micro: 0.537, F1 Macro: 0.449, Total Pos: 693,231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:48:58,008 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.* with mmap=None\n",
      "2017-01-15 02:48:58,010 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 02:48:58,502 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 02:48:59,564 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn0.npy with mmap=None\n",
      "2017-01-15 02:48:59,628 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 02:48:59,630 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 02:49:01,074 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 02:49:01,075 : INFO : Getting training Data\n",
      "2017-01-15 02:49:22,985 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:50:56,900 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 02:50:56,901 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.341, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.551, Top 3: 0.868, Top 5: 0.946, \n",
      "\t\t F1 Micro: 0.577, F1 Macro: 0.486, Total Pos: 2,686,085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:51:15,481 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 1 1 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:51:24,933 : INFO : ****************** Epoch 3 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3 *******************\n",
      "2017-01-15 02:51:24,934 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.447, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.545, Top 3: 0.855, Top 5: 0.943, \n",
      "\t\t F1 Micro: 0.556, F1 Macro: 0.466, Total Pos: 701,617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:51:32,612 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.* with mmap=None\n",
      "2017-01-15 02:51:32,613 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 02:51:33,617 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 02:51:35,445 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn0.npy with mmap=None\n",
      "2017-01-15 02:51:35,637 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 02:51:35,638 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 02:51:37,251 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 02:51:37,253 : INFO : Getting training Data\n",
      "2017-01-15 02:52:01,449 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:53:37,639 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 02:53:37,641 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.295, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.555, Top 3: 0.871, Top 5: 0.949, \n",
      "\t\t F1 Micro: 0.582, F1 Macro: 0.490, Total Pos: 2,685,335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:53:51,903 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 1 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:54:01,815 : INFO : ****************** Epoch 4 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4 *******************\n",
      "2017-01-15 02:54:01,817 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.381, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.540, Top 3: 0.860, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.561, F1 Macro: 0.472, Total Pos: 709,202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:54:09,917 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.* with mmap=None\n",
      "2017-01-15 02:54:09,918 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 02:54:10,154 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 02:54:11,240 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn0.npy with mmap=None\n",
      "2017-01-15 02:54:11,303 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 02:54:11,304 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 02:54:12,689 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 02:54:12,690 : INFO : Getting training Data\n",
      "2017-01-15 02:54:36,096 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:56:10,187 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 02:56:10,189 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.272, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.558, Top 3: 0.872, Top 5: 0.950, \n",
      "\t\t F1 Micro: 0.585, F1 Macro: 0.493, Total Pos: 2,685,576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:56:24,357 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:56:34,086 : INFO : ****************** Epoch 5 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5 *******************\n",
      "2017-01-15 02:56:34,087 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.290, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.540, Top 3: 0.860, Top 5: 0.950, \n",
      "\t\t F1 Micro: 0.567, F1 Macro: 0.479, Total Pos: 724,930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:56:42,034 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.* with mmap=None\n",
      "2017-01-15 02:56:42,036 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 02:56:42,548 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 02:56:48,471 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn0.npy with mmap=None\n",
      "2017-01-15 02:56:49,160 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 02:56:49,161 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 02:56:50,765 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 02:56:50,767 : INFO : Getting training Data\n",
      "2017-01-15 02:57:14,357 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:58:49,151 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 02:58:49,153 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.246, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.560, Top 3: 0.875, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.587, F1 Macro: 0.495, Total Pos: 2,685,286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:59:03,447 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:59:12,913 : INFO : ****************** Epoch 6 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6 *******************\n",
      "2017-01-15 02:59:12,914 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.249, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.550, Top 3: 0.866, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.571, F1 Macro: 0.482, Total Pos: 723,052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 02:59:20,557 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.* with mmap=None\n",
      "2017-01-15 02:59:20,558 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 02:59:21,646 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 02:59:26,322 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy with mmap=None\n",
      "2017-01-15 02:59:27,006 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 02:59:27,008 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 02:59:28,587 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 02:59:28,588 : INFO : Getting training Data\n",
      "2017-01-15 02:59:57,509 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:01:38,811 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:01:38,814 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.232, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.562, Top 3: 0.876, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.589, F1 Macro: 0.496, Total Pos: 2,682,419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:01:52,945 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:02:02,307 : INFO : ****************** Epoch 7 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7 *******************\n",
      "2017-01-15 03:02:02,308 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.194, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.548, Top 3: 0.871, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.579, F1 Macro: 0.487, Total Pos: 717,644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:02:05,673 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:02:05,675 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:02:06,248 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:02:13,086 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:02:13,798 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:02:13,799 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:02:15,398 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:02:15,399 : INFO : Getting training Data\n",
      "2017-01-15 03:02:43,961 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:04:18,983 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:04:18,984 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.219, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.564, Top 3: 0.878, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.591, F1 Macro: 0.498, Total Pos: 2,676,855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:04:33,056 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:04:42,712 : INFO : ****************** Epoch 8 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8 *******************\n",
      "2017-01-15 03:04:42,713 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.158, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.556, Top 3: 0.875, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.584, F1 Macro: 0.492, Total Pos: 710,808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:04:51,079 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:04:51,080 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:04:52,171 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:04:56,913 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:04:57,600 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:04:57,601 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:04:59,181 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:04:59,183 : INFO : Getting training Data\n",
      "2017-01-15 03:05:22,749 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:07:05,248 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:07:05,250 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.199, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.567, Top 3: 0.880, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.594, F1 Macro: 0.500, Total Pos: 2,665,948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:07:19,397 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:07:28,872 : INFO : ****************** Epoch 9 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9 *******************\n",
      "2017-01-15 03:07:28,873 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.151, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.555, Top 3: 0.875, Top 5: 0.956, \n",
      "\t\t F1 Micro: 0.584, F1 Macro: 0.491, Total Pos: 715,278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:07:36,879 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:07:36,880 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:07:37,309 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:07:41,705 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:07:42,110 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:07:42,111 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:07:43,622 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:07:43,623 : INFO : Getting training Data\n",
      "2017-01-15 03:08:06,926 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:09:41,606 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:09:41,608 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.191, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.567, Top 3: 0.881, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.594, F1 Macro: 0.501, Total Pos: 2,674,015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:09:55,701 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:10:05,192 : INFO : ****************** Epoch 10 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10 *******************\n",
      "2017-01-15 03:10:05,193 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.132, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.563, Top 3: 0.881, Top 5: 0.958, \n",
      "\t\t F1 Micro: 0.591, F1 Macro: 0.497, Total Pos: 698,706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:10:12,693 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:10:12,695 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:10:13,336 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:10:14,382 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:10:14,736 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:10:14,738 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:10:16,168 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:10:16,169 : INFO : Getting training Data\n",
      "2017-01-15 03:10:43,972 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:12:26,336 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:12:26,340 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.189, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.568, Top 3: 0.880, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.594, F1 Macro: 0.501, Total Pos: 2,679,063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:12:40,607 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:12:50,016 : INFO : ****************** Epoch 11 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11 *******************\n",
      "2017-01-15 03:12:50,018 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.099, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.563, Top 3: 0.880, Top 5: 0.958, \n",
      "\t\t F1 Micro: 0.592, F1 Macro: 0.497, Total Pos: 708,816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:12:58,136 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:12:58,137 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:12:58,381 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:13:02,281 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:13:02,593 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:13:02,594 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:13:03,956 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:13:03,957 : INFO : Getting training Data\n",
      "2017-01-15 03:13:27,336 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:15:02,035 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:15:02,037 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.172, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.570, Top 3: 0.882, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.596, F1 Macro: 0.502, Total Pos: 2,673,534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:15:16,181 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:15:25,822 : INFO : ****************** Epoch 12 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12 *******************\n",
      "2017-01-15 03:15:25,823 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.079, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.565, Top 3: 0.883, Top 5: 0.956, \n",
      "\t\t F1 Micro: 0.597, F1 Macro: 0.501, Total Pos: 697,430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:15:33,909 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:15:33,910 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:15:35,003 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:15:39,969 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:15:40,678 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:15:40,680 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:15:42,248 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:15:42,250 : INFO : Getting training Data\n",
      "2017-01-15 03:16:11,052 : INFO : Training Classifier\n",
      "2017-01-15 03:18:09,359 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:19:51,198 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:19:51,201 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.162, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.570, Top 3: 0.883, Top 5: 0.956, \n",
      "\t\t F1 Micro: 0.597, F1 Macro: 0.503, Total Pos: 2,674,254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:20:05,284 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:20:14,809 : INFO : ****************** Epoch 13 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13 *******************\n",
      "2017-01-15 03:20:14,810 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.072, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.569, Top 3: 0.885, Top 5: 0.957, \n",
      "\t\t F1 Micro: 0.598, F1 Macro: 0.503, Total Pos: 695,872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:20:18,163 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:20:18,164 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:20:19,212 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:20:25,358 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:20:26,037 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:20:26,039 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:20:27,645 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:20:27,647 : INFO : Getting training Data\n",
      "2017-01-15 03:20:56,137 : INFO : Training Classifier\n",
      "2017-01-15 03:22:51,971 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:24:28,404 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:24:28,406 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.157, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.572, Top 3: 0.883, Top 5: 0.956, \n",
      "\t\t F1 Micro: 0.598, F1 Macro: 0.504, Total Pos: 2,672,595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:24:42,603 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:24:52,314 : INFO : ****************** Epoch 14 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14 *******************\n",
      "2017-01-15 03:24:52,316 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.109, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.565, Top 3: 0.880, Top 5: 0.959, \n",
      "\t\t F1 Micro: 0.592, F1 Macro: 0.498, Total Pos: 706,344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:25:00,580 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:25:00,581 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:25:01,670 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:25:06,730 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:25:07,388 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:25:07,389 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:25:08,993 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:25:08,994 : INFO : Getting training Data\n",
      "2017-01-15 03:25:32,849 : INFO : Training Classifier\n",
      "2017-01-15 03:27:36,123 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:29:21,210 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:29:21,212 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.148, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.573, Top 3: 0.884, Top 5: 0.957, \n",
      "\t\t F1 Micro: 0.599, F1 Macro: 0.505, Total Pos: 2,670,232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:29:35,355 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:29:45,197 : INFO : ****************** Epoch 15 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15 *******************\n",
      "2017-01-15 03:29:45,198 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.067, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.564, Top 3: 0.885, Top 5: 0.959, \n",
      "\t\t F1 Micro: 0.598, F1 Macro: 0.505, Total Pos: 697,079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:29:53,337 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:29:53,338 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:29:54,409 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:30:00,497 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:30:01,144 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:30:01,145 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:30:02,523 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:30:02,524 : INFO : Getting training Data\n",
      "2017-01-15 03:30:25,958 : INFO : Training Classifier\n",
      "2017-01-15 03:32:22,406 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:33:58,463 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:33:58,465 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.135, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.574, Top 3: 0.886, Top 5: 0.957, \n",
      "\t\t F1 Micro: 0.601, F1 Macro: 0.506, Total Pos: 2,666,406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:34:17,114 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:34:26,668 : INFO : ****************** Epoch 16 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16 *******************\n",
      "2017-01-15 03:34:26,669 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.089, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.569, Top 3: 0.884, Top 5: 0.957, \n",
      "\t\t F1 Micro: 0.598, F1 Macro: 0.502, Total Pos: 690,410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:34:30,017 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model.docvecs.* with mmap=None\n",
      "2017-01-15 03:34:30,018 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 03:34:31,072 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 03:34:35,530 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model.syn0.npy with mmap=None\n",
      "2017-01-15 03:34:35,972 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 03:34:35,973 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 03:34:37,384 : INFO : Loaded the Doc2vec Model\n",
      "2017-01-15 03:34:37,386 : INFO : Getting training Data\n",
      "2017-01-15 03:35:05,333 : INFO : Training Classifier\n",
      "2017-01-15 03:37:03,785 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:38:45,400 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 03:38:45,401 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-15 03:38:45,408 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.128, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.575, Top 3: 0.886, Top 5: 0.958, \n",
      "\t\t F1 Micro: 0.602, F1 Macro: 0.507, Total Pos: 2,665,766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 03:38:50,649 : INFO : Finished loading new batch\n",
      "2017-01-15 03:39:18,495 : INFO : Finished: 999\n",
      "2017-01-15 03:39:44,064 : INFO : Finished: 1999\n",
      "2017-01-15 03:40:08,437 : INFO : Finished: 2999\n",
      "2017-01-15 03:40:33,004 : INFO : Finished: 3999\n",
      "2017-01-15 03:40:57,387 : INFO : Finished: 4999\n",
      "2017-01-15 03:41:21,068 : INFO : Finished: 5999\n",
      "2017-01-15 03:41:45,713 : INFO : Finished: 6999\n",
      "2017-01-15 03:42:09,850 : INFO : Finished: 7999\n",
      "2017-01-15 03:42:34,223 : INFO : Finished: 8999\n",
      "2017-01-15 03:42:57,078 : INFO : Finished: 9999\n",
      "2017-01-15 03:42:58,322 : INFO : Loading new batch for index: 10000\n",
      "2017-01-15 03:43:03,658 : INFO : Finished loading new batch\n",
      "2017-01-15 03:43:28,699 : INFO : Finished: 10999\n",
      "2017-01-15 03:43:53,323 : INFO : Finished: 11999\n",
      "2017-01-15 03:44:18,429 : INFO : Finished: 12999\n",
      "2017-01-15 03:44:43,429 : INFO : Finished: 13999\n",
      "2017-01-15 03:45:10,414 : INFO : Finished: 14999\n",
      "2017-01-15 03:45:35,601 : INFO : Finished: 15999\n",
      "2017-01-15 03:46:00,448 : INFO : Finished: 16999\n",
      "2017-01-15 03:46:24,023 : INFO : Finished: 17999\n",
      "2017-01-15 03:46:47,964 : INFO : Finished: 18999\n",
      "2017-01-15 03:47:11,230 : INFO : Finished: 19999\n",
      "2017-01-15 03:47:12,532 : INFO : Loading new batch for index: 20000\n",
      "2017-01-15 03:47:17,852 : INFO : Finished loading new batch\n",
      "2017-01-15 03:47:42,455 : INFO : Finished: 20999\n",
      "2017-01-15 03:48:09,283 : INFO : Finished: 21999\n",
      "2017-01-15 03:48:35,304 : INFO : Finished: 22999\n",
      "2017-01-15 03:49:01,903 : INFO : Finished: 23999\n",
      "2017-01-15 03:49:28,744 : INFO : Finished: 24999\n",
      "2017-01-15 03:49:54,083 : INFO : Finished: 25999\n",
      "2017-01-15 03:50:19,628 : INFO : Finished: 26999\n",
      "2017-01-15 03:50:45,376 : INFO : Finished: 27999\n",
      "2017-01-15 03:51:11,011 : INFO : Finished: 28999\n",
      "2017-01-15 03:51:36,826 : INFO : Finished: 29999\n",
      "2017-01-15 03:51:38,014 : INFO : Loading new batch for index: 30000\n",
      "2017-01-15 03:51:43,082 : INFO : Finished loading new batch\n",
      "2017-01-15 03:52:09,916 : INFO : Finished: 30999\n",
      "2017-01-15 03:52:37,452 : INFO : Finished: 31999\n",
      "2017-01-15 03:53:03,874 : INFO : Finished: 32999\n",
      "2017-01-15 03:53:29,811 : INFO : Finished: 33999\n",
      "2017-01-15 03:53:55,890 : INFO : Finished: 34999\n",
      "2017-01-15 03:54:21,488 : INFO : Finished: 35999\n",
      "2017-01-15 03:54:45,490 : INFO : Finished: 36999\n",
      "2017-01-15 03:55:12,668 : INFO : Finished: 37999\n",
      "2017-01-15 03:55:41,545 : INFO : Finished: 38999\n",
      "2017-01-15 03:56:09,964 : INFO : Finished: 39999\n",
      "2017-01-15 03:56:11,209 : INFO : Loading new batch for index: 40000\n",
      "2017-01-15 03:56:17,686 : INFO : Finished loading new batch\n",
      "2017-01-15 03:56:46,788 : INFO : Finished: 40999\n",
      "2017-01-15 03:57:13,768 : INFO : Finished: 41999\n",
      "2017-01-15 03:57:40,927 : INFO : Finished: 42999\n",
      "2017-01-15 03:58:08,906 : INFO : Finished: 43999\n",
      "2017-01-15 03:58:37,929 : INFO : Finished: 44999\n",
      "2017-01-15 03:59:07,447 : INFO : Finished: 45999\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph(len(classifications) +2)\n",
    "# when resuming, resume from an epoch with a previously created doc2vec model to get the learning rate right\n",
    "start_from = 1\n",
    "for epoch in range(start_from, DOC2VEC_MAX_EPOCHS+1):\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    info(\"****************** Epoch {} --- Working on {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "    # if we have the model, just load it, otherwise train the previous model\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "        doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "        info(\"Loaded the Doc2vec Model\")\n",
    "    else:\n",
    "        # train the doc2vec model\n",
    "        training_docs_iterator = DocumentBatchGenerator(training_preprocessed_files_prefix, \n",
    "                                                        training_preprocessed_docids_files_prefix, batch_size=10000)\n",
    "        doc2vec_model.train(sentences=training_docs_iterator, report_delay=REPORT_DELAY)\n",
    "        doc2vec_model.alpha -= 0.001  # decrease the learning rate\n",
    "        doc2vec_model.min_alpha = doc2vec_model.alpha  # fix the learning rate, no decay\n",
    "        ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME))\n",
    "        doc2vec_model.save(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "        \n",
    "        # get the word2vec analogy accuracy score\n",
    "        word2vec_result = doc2vec_model.accuracy(word2vec_questions_file, restrict_vocab=None)\n",
    "        epoch_word2vec_metrics.append(word2vec_result)\n",
    "        pickle.dump(word2vec_result, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME,\n",
    "                                                       WORD2VEC_METRICS_FILENAME), 'w'))\n",
    "\n",
    "\n",
    "    info('Getting training Data')\n",
    "    X, y = get_training_data(doc2vec_model, classifications)\n",
    "    \n",
    "    \n",
    "    ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "    \n",
    "    # try warm start and evaluate after every iter\n",
    "    \n",
    "    if not os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER)):\n",
    "        info('Training Classifier')\n",
    "        clf = OneVsRestClassifier(linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                             #alpha is the 1/C parameter\n",
    "                                                             alpha=SVM_REG, fit_intercept=True, n_iter=SVM_ITERATIONS,\n",
    "                                                             #n_jobs=-1 means use all cpus\n",
    "                                                             shuffle=True, verbose=0, n_jobs=1,\n",
    "                                                             #eta0 is the learning rate when we use constant configuration\n",
    "                                                             random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                             class_weight=SVM_CLASS_WEIGHTS, warm_start=False), n_jobs=1)\n",
    "\n",
    "\n",
    "        # Training of a classifier\n",
    "        clf.fit(X,y)\n",
    "        pickle.dump(clf, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                              GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER), 'w'))\n",
    "    else:\n",
    "        clf = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER), 'r'))\n",
    "    \n",
    "    # Training Metrics\n",
    "    info('Evaluating on Training Data')\n",
    "    yp = clf.predict(X)\n",
    "    print yp\n",
    "    training_metrics = get_metrics(y, yp, yp)\n",
    "    print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "        training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "        training_metrics['f1_micro'], training_metrics['f1_macro'], training_metrics['total_positive'])\n",
    "    \n",
    "    epoch_training_metrics.append(training_metrics)\n",
    "    \n",
    "    \n",
    "    # Validation Metrics\n",
    "    info('Getting Validation Embeddings')\n",
    "    Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                    validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                    validation_preprocessed_docids_files_prefix)\n",
    "    info('Evaluating on Validation Data')\n",
    "    yvp = clf.predict(Xv)\n",
    "    print yvp\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp)\n",
    "    print \"** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "        validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "    \n",
    "    graph.add_metrics_to_graph(validation_metrics, epoch)\n",
    "    \n",
    "    epoch_validation_metrics.append(validation_metrics)\n",
    "    \n",
    "    \n",
    "    # Saving the metrics\n",
    "    pickle.dump(training_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, TRAINING_METRICS_FILENAME), 'w'))\n",
    "    pickle.dump(validation_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, VALIDATION_METRICS_FILENAME), 'w'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-07 08:29:42,629 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model\n",
      "2017-01-07 08:29:56,527 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.* with mmap=None\n",
      "2017-01-07 08:29:56,529 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn1neg.npy with mmap=None\n",
      "2017-01-07 08:30:01,849 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn0.npy with mmap=None\n",
      "2017-01-07 08:30:02,162 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-07 08:30:02,164 : INFO : setting ignored attribute cum_table to None\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(7)\n",
    "\n",
    "# if we have the model, just load it, otherwise train the previous model\n",
    "if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "    doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-09 08:57:31,563 : INFO : saving Doc2Vec object under /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model, separately None\n",
      "2017-01-09 08:57:31,565 : INFO : storing numpy array 'syn1neg' to /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn1neg.npy\n",
      "2017-01-09 08:57:43,811 : INFO : not storing attribute syn0norm\n",
      "2017-01-09 08:57:43,813 : INFO : storing numpy array 'syn0' to /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn0.npy\n",
      "2017-01-09 08:57:44,083 : INFO : not storing attribute cum_table\n",
      "2017-01-09 08:58:16,480 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-09 08:58:34,486 : INFO : capital-common-countries: 0.3% (1/306)\n",
      "2017-01-09 08:58:57,741 : INFO : capital-world: 0.4% (2/453)\n",
      "2017-01-09 08:59:05,483 : INFO : currency: 0.0% (0/152)\n",
      "2017-01-09 09:01:00,546 : INFO : city-in-state: 0.0% (0/2252)\n",
      "2017-01-09 09:01:14,396 : INFO : family: 1.5% (4/272)\n",
      "2017-01-09 09:01:59,006 : INFO : gram1-adjective-to-adverb: 0.7% (6/870)\n",
      "2017-01-09 09:02:32,245 : INFO : gram2-opposite: 0.8% (5/650)\n",
      "2017-01-09 09:03:40,293 : INFO : gram3-comparative: 9.7% (129/1332)\n",
      "2017-01-09 09:04:19,048 : INFO : gram4-superlative: 1.1% (8/756)\n",
      "2017-01-09 09:05:12,945 : INFO : gram5-present-participle: 4.1% (43/1056)\n",
      "2017-01-09 09:06:05,528 : INFO : gram6-nationality-adjective: 0.0% (0/1030)\n",
      "2017-01-09 09:07:17,257 : INFO : gram7-past-tense: 1.9% (27/1406)\n",
      "2017-01-09 09:08:21,564 : INFO : gram8-plural: 4.8% (60/1260)\n",
      "2017-01-09 09:09:03,035 : INFO : gram9-plural-verbs: 3.3% (27/812)\n",
      "2017-01-09 09:09:03,040 : INFO : total: 2.5% (312/12607)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 10s, sys: 2h 7min 46s, total: 2h 51min 56s\n",
      "Wall time: 10min 47s\n",
      "CPU times: user 44min 28s, sys: 2h 7min 55s, total: 2h 52min 23s\n",
      "Wall time: 11min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME))\n",
    "doc2vec_model.save(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "\n",
    "# get the word2vec analogy accuracy score\n",
    "%time word2vec_result = doc2vec_model.accuracy(word2vec_questions_file, restrict_vocab=None)\n",
    "epoch_word2vec_metrics.append(word2vec_result)\n",
    "pickle.dump(word2vec_result, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME,\n",
    "                                               WORD2VEC_METRICS_FILENAME), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
