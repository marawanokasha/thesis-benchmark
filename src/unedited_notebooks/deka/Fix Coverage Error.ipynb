{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Coverage Errors from using y_binary to y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSIFIER_FILE = '{}_classifier.pkl'\n",
    "VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'\n",
    "TRAINING_METRICS_FILENAME = '{}_training_metrics.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_location = \"/big/s/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "svm_location = root_location + \"benchmarking_svm/\"\n",
    "\n",
    "\n",
    "training_file = root_location + \"docs_output.json\"\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Classification Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 1.5 s, total: 31.1 s\n",
      "Wall time: 31.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_subdirectories(d):\n",
    "    #return filter(os.path.isdir, [f for f in os.listdir(d)])\n",
    "    return [f for f in os.listdir(d) if os.path.isdir(os.path.join(d,f))]\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Coverage Error for Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = sections\n",
    "classifications_type = \"sections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# data_types = [\"bm25\", \"tf_idf\", \"sublinear_tf_idf\", \"sublinear_tf\", \"tf\"]\n",
    "data_types = [\"tf_idf\", \"sublinear_tf_idf\", \"sublinear_tf\", \"tf\"]\n",
    "# data_types = [\"tf\"]\n",
    "for data_type in data_types:\n",
    "    preprocessor = data_type\n",
    "    info(\"=============== {} Being Evaluated ================\".format(data_type))\n",
    "    \n",
    "    data_training_location = exports_location + \"{}_training_sparse_data.pkl\".format(data_type)\n",
    "    data_training_docids_location = exports_location + \"{}_training_sparse_docids.pkl\".format(data_type)\n",
    "    data_validation_location = exports_location + \"{}_validation_sparse_data.pkl\".format(data_type)\n",
    "    data_validation_docids_location = exports_location + \"{}_validation_sparse_docids.pkl\".format(data_type)\n",
    "    \n",
    "#     # Get the training data\n",
    "#     info('Getting Training Data')\n",
    "#     %time X = pickle.load(open(data_training_location, \"r\"))\n",
    "#     training_data_docids = pickle.load(open(data_training_docids_location, \"r\"))\n",
    "#     %time y = get_label_data(classifications, training_data_docids, doc_classification_map)\n",
    "\n",
    "#     print y\n",
    "#     print y.shape\n",
    "    \n",
    "    # Get the validation data\n",
    "    info('Getting Valdiation Data')\n",
    "    %time Xv = pickle.load(open(data_validation_location,'r'))\n",
    "    validation_data_docids = pickle.load(open(data_validation_docids_location, \"r\"))\n",
    "    %time yv = get_label_data(classifications, validation_data_docids, doc_classification_map)\n",
    "    \n",
    "    print yv\n",
    "    print yv.shape\n",
    "        \n",
    "    for classifier in natural_sort(get_subdirectories(svm_location)):\n",
    "        print classifier\n",
    "        classifier_path = os.path.join(svm_location, classifier)\n",
    "        preprocessor_path = os.path.join(classifier_path, preprocessor)\n",
    "\n",
    "        if not os.path.exists(preprocessor_path):\n",
    "            info(\"{} doesn't exist, skipping\".format(preprocessor_path)) \n",
    "            continue\n",
    "            \n",
    "        info('Loading Classifier')\n",
    "        clf = pickle.load(open(os.path.join(preprocessor_path, CLASSIFIER_FILE.format(classifications_type)), 'r'))\n",
    "        \n",
    "#         # Training Metrics\n",
    "#         info('Evaluating on Training Data')\n",
    "#         %time yp = clf.predict(X)\n",
    "#         %time yp_score = clf.decision_function(X)\n",
    "#         print yp\n",
    "#         info('Calculating training metrics')\n",
    "#         training_metrics = get_metrics(y, yp_score, yp)\n",
    "#         print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "#             training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "#             training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#             training_metrics['f1_micro'], training_metrics['f1_macro'], training_metrics['total_positive'])\n",
    "\n",
    "        # Validation Metrics\n",
    "        info('Evaluating on Validation Data')\n",
    "        %time yvp = clf.predict(Xv)\n",
    "        %time yvp_score = clf.decision_function(Xv)\n",
    "        print yvp\n",
    "        info('Calculating validation metrics')\n",
    "        validation_metrics = get_metrics(yv, yvp_score, yvp)\n",
    "        print \"** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "            validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "            validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "            validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "\n",
    "        info('Dumping the Metrics')\n",
    "#         pickle.dump(training_metrics, open(os.path.join(preprocessor_path, TRAINING_METRICS_FILENAME.format(classifications_type)), \"w\"))\n",
    "        pickle.dump(validation_metrics, open(os.path.join(preprocessor_path, VALIDATION_METRICS_FILENAME.format(classifications_type)), \"w\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Coverage Error for Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 00:49:47,865 : INFO : Pattern library is not installed, lemmatization won't be available.\n",
      "2017-01-17 00:49:47,903 : INFO : Could not import Theano, will use standard float for default ShardedCorpus dtype.\n",
      "2017-01-17 00:49:48,126 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_RESULTS_LOCATION = '/big/s/shalaby/parameter_search_doc2vec_models_new/full/'\n",
    "\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\"\n",
    "\n",
    "preprocessed_location = root_location + \"preprocessed_data/\"\n",
    "\n",
    "validation_preprocessed_files_prefix = preprocessed_location + \"validation_docs_merged_data_preprocessed-\"\n",
    "validation_preprocessed_docids_files_prefix = preprocessed_location + \"validation_docs_merged_docids_preprocessed-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 22\n",
    "SVM_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = sections\n",
    "classifications_type = \"sections\"\n",
    "VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'.format(classifications_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "\n",
    "    \n",
    "def get_training_data(doc2vec_model, classifications):\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for doc_id in training_docs_list:\n",
    "        # converting from memmap to a normal array\n",
    "        normal_array = []\n",
    "        normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "        training_data.append(normal_array)\n",
    "        eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "        training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))\n",
    "    training_labels = np.array(training_labels)\n",
    "    return training_data, training_labels\n",
    "\n",
    "def get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                           val_docs_list, val_preprocessed_files_prefix, \n",
    "                                           val_preprocessed_docids_files_prefix):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_one_doc(doc_tuple):\n",
    "        #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "        doc_id, doc_tokens = doc_tuple\n",
    "        rep = doc2vec_model.infer_vector(doc_tokens)\n",
    "        return (doc_id, rep)\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    if os.path.exists(os.path.join(GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_labels = []\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_labels = np.array(validation_labels)\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # Multi-threaded inference\n",
    "        validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                          validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "        generator_func = validation_docs_iterator.__iter__()\n",
    "        pool = ThreadPool(NUM_CORES)\n",
    "        # map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "        validation_documents_reps = {}\n",
    "        mini_batch_size = 1000\n",
    "        while True:\n",
    "            threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "            info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "            if threaded_reps_partial:\n",
    "                #threaded_reps.extend(threaded_reps_partial)\n",
    "                validation_documents_reps.update(threaded_reps_partial)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        validation_labels = np.array(validation_labels)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ee = 'svm_iter_100_reg_0.001_classweights_balanced'.split('_')\n",
    "SVM_ITER = ee[2]\n",
    "SVM_REG = ee[4]\n",
    "SVM_CLASSWEIGHTS = ee[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0.001\n",
      "balanced\n"
     ]
    }
   ],
   "source": [
    "print SVM_ITER\n",
    "print SVM_REG\n",
    "print SVM_CLASSWEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finished_doc2vec_methods = ['doc2vec_size_100_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None',\n",
    "                           'doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None',\n",
    "                           'doc2vec_size_200_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None',\n",
    "                           'doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None',\n",
    "                           'doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:33:55,231 : INFO : skipping doc2vec_size_100_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None\n",
      "2017-01-17 20:33:55,233 : INFO : skipping doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None\n",
      "2017-01-17 20:33:55,234 : INFO : skipping doc2vec_size_200_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None\n",
      "2017-01-17 20:33:55,234 : INFO : skipping doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None\n",
      "2017-01-17 20:33:55,236 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None\n",
      "epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:34:24,725 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.* with mmap=None\n",
      "2017-01-17 20:34:24,726 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 20:35:03,827 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 20:35:19,049 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn0.npy with mmap=None\n",
      "2017-01-17 20:35:29,825 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 20:35:29,826 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 20:35:31,295 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 20:35:31,297 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 20:37:47,816 : INFO : Loading Classifier\n",
      "2017-01-17 20:37:47,895 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:39:39,699 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:40:09,343 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 2.073, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.625, Top 3: 0.867, Top 5: 0.949, \n",
      "\t\t F1 Micro: 0.554, F1 Macro: 0.459, Total Pos: 707,179\n",
      "epoch_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:40:16,731 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.* with mmap=None\n",
      "2017-01-17 20:40:16,732 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 20:40:45,519 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 20:40:55,220 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn0.npy with mmap=None\n",
      "2017-01-17 20:41:06,100 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 20:41:06,101 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 20:41:09,359 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 20:41:09,362 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 20:43:26,131 : INFO : Loading Classifier\n",
      "2017-01-17 20:43:26,167 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:44:39,707 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:45:09,326 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.935, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.653, Top 3: 0.890, Top 5: 0.963, \n",
      "\t\t F1 Micro: 0.579, F1 Macro: 0.481, Total Pos: 700,606\n",
      "epoch_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:45:38,010 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.* with mmap=None\n",
      "2017-01-17 20:45:38,011 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 20:46:08,076 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 20:46:19,251 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn0.npy with mmap=None\n",
      "2017-01-17 20:46:28,640 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 20:46:28,641 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 20:46:31,788 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 20:46:31,789 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 20:48:32,781 : INFO : Loading Classifier\n",
      "2017-01-17 20:48:32,821 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:48:49,005 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 1.916, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.662, Top 3: 0.892, Top 5: 0.964, \n",
      "\t\t F1 Micro: 0.580, F1 Macro: 0.485, Total Pos: 706,814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:49:17,758 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:49:44,393 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.* with mmap=None\n",
      "2017-01-17 20:49:44,394 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 20:50:26,363 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 20:50:41,321 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn0.npy with mmap=None\n",
      "2017-01-17 20:50:57,719 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 20:50:57,721 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 20:51:00,300 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 20:51:00,302 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 20:53:01,779 : INFO : Loading Classifier\n",
      "2017-01-17 20:53:01,850 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:53:30,040 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 1.876, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.667, Top 3: 0.901, Top 5: 0.969, \n",
      "\t\t F1 Micro: 0.591, F1 Macro: 0.493, Total Pos: 693,444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:53:59,165 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:54:30,680 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.* with mmap=None\n",
      "2017-01-17 20:54:30,682 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 20:55:21,013 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 20:55:38,123 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn0.npy with mmap=None\n",
      "2017-01-17 20:55:50,929 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 20:55:50,930 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 20:55:53,896 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 20:55:53,898 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 20:57:56,658 : INFO : Loading Classifier\n",
      "2017-01-17 20:57:56,703 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:58:18,586 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 1.897, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.665, Top 3: 0.895, Top 5: 0.966, \n",
      "\t\t F1 Micro: 0.581, F1 Macro: 0.488, Total Pos: 712,044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:58:47,649 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 20:58:57,476 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.* with mmap=None\n",
      "2017-01-17 20:58:57,477 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:00:06,539 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:00:24,373 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:00:39,187 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:00:39,188 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:00:42,307 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:00:42,309 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 21:03:11,371 : INFO : Loading Classifier\n",
      "2017-01-17 21:03:11,467 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:03:43,962 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n",
      "** Validation Metrics: Cov Err: 1.891, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.668, Top 3: 0.897, Top 5: 0.966, \n",
      "\t\t F1 Micro: 0.583, F1 Macro: 0.491, Total Pos: 708,270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:04:12,708 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:04:42,919 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.* with mmap=None\n",
      "2017-01-17 21:04:42,920 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:05:11,527 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:05:23,410 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:05:33,222 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:05:33,224 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:05:36,156 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:05:36,157 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 21:07:28,787 : INFO : Loading Classifier\n",
      "2017-01-17 21:07:28,848 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:07:58,487 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:08:26,086 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.859, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.675, Top 3: 0.903, Top 5: 0.970, \n",
      "\t\t F1 Micro: 0.591, F1 Macro: 0.497, Total Pos: 701,909\n",
      "epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:08:59,852 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.* with mmap=None\n",
      "2017-01-17 21:08:59,853 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:09:29,563 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:09:38,792 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:09:49,461 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:09:49,462 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:09:52,705 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:09:52,707 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-17 21:09:52,707 : INFO : No More Validation Embeddings to load, exiting.....\n",
      "2017-01-17 21:09:52,709 : INFO : Loading Classifier\n",
      "2017-01-17 21:09:52,758 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:10:31,735 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:10:59,519 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.842, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.677, Top 3: 0.906, Top 5: 0.971, \n",
      "\t\t F1 Micro: 0.595, F1 Macro: 0.501, Total Pos: 695,284\n",
      "********************* doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None\n",
      "epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:11:07,675 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.* with mmap=None\n",
      "2017-01-17 21:11:07,676 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:12:15,977 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:12:33,797 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:12:49,662 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:12:49,663 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:12:51,163 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:12:51,165 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 21:16:40,585 : INFO : Loading Classifier\n",
      "2017-01-17 21:16:40,642 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:17:32,685 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 1 0 ..., 1 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 1 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:18:03,454 : INFO : Loading Classifier\n",
      "2017-01-17 21:18:03,514 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 2.118, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.596, Top 3: 0.853, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.516, F1 Macro: 0.448, Total Pos: 825,727\n",
      "svm_iter_10_reg_0.001_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:18:53,209 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ..., 0 0 1]\n",
      " [0 1 0 ..., 1 1 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 1 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:19:27,206 : INFO : Loading Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 2.103, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.598, Top 3: 0.855, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.508, F1 Macro: 0.444, Total Pos: 867,436\n",
      "svm_iter_10_reg_0.1_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:19:27,295 : INFO : Evaluating on Validation Data\n",
      "2017-01-17 21:20:16,955 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:20:48,839 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.595, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.136, Top 3: 0.576, Top 5: 0.869, \n",
      "\t\t F1 Micro: 0.169, F1 Macro: 0.201, Total Pos: 549,226\n",
      "epoch_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:20:58,740 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.* with mmap=None\n",
      "2017-01-17 21:20:58,743 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:21:59,118 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:22:15,454 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:22:30,715 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:22:30,716 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:22:34,064 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:22:34,066 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 21:25:52,680 : INFO : Loading Classifier\n",
      "2017-01-17 21:25:52,724 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:27:45,477 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:28:15,703 : INFO : Loading Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.923, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.660, Top 3: 0.890, Top 5: 0.965, \n",
      "\t\t F1 Micro: 0.560, F1 Macro: 0.482, Total Pos: 778,323\n",
      "svm_iter_10_reg_0.001_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:28:15,789 : INFO : Evaluating on Validation Data\n",
      "2017-01-17 21:31:29,190 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 1 1 1]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:31:57,915 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.877, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.668, Top 3: 0.899, Top 5: 0.970, \n",
      "\t\t F1 Micro: 0.565, F1 Macro: 0.484, Total Pos: 780,478\n",
      "epoch_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:32:31,208 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.* with mmap=None\n",
      "2017-01-17 21:32:31,209 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:33:36,063 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:33:52,257 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:34:08,597 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:34:08,598 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:34:11,438 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:34:11,443 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 21:37:44,056 : INFO : Loading Classifier\n",
      "2017-01-17 21:37:44,129 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:38:48,054 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:39:16,886 : INFO : Loading Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.841, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.678, Top 3: 0.905, Top 5: 0.972, \n",
      "\t\t F1 Micro: 0.582, F1 Macro: 0.498, Total Pos: 746,318\n",
      "svm_iter_10_reg_0.001_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:39:16,976 : INFO : Evaluating on Validation Data\n",
      "2017-01-17 21:40:05,932 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:40:35,069 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.804, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.685, Top 3: 0.913, Top 5: 0.976, \n",
      "\t\t F1 Micro: 0.588, F1 Macro: 0.502, Total Pos: 745,179\n",
      "epoch_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:41:03,935 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.* with mmap=None\n",
      "2017-01-17 21:41:03,936 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:41:59,781 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:42:22,688 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:42:41,189 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:42:41,190 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:42:44,494 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:42:44,497 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 21:46:41,814 : INFO : Loading Classifier\n",
      "2017-01-17 21:46:41,883 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:50:03,946 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n",
      "** Validation Metrics: Cov Err: 1.824, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.682, Top 3: 0.908, Top 5: 0.973, \n",
      "\t\t F1 Micro: 0.589, F1 Macro: 0.502, Total Pos: 731,972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:50:33,685 : INFO : Loading Classifier\n",
      "2017-01-17 21:50:33,746 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_10_reg_0.001_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:53:55,931 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:54:25,794 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.787, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.690, Top 3: 0.915, Top 5: 0.977, \n",
      "\t\t F1 Micro: 0.597, F1 Macro: 0.507, Total Pos: 726,296\n",
      "epoch_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 21:54:59,289 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.* with mmap=None\n",
      "2017-01-17 21:54:59,291 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 21:57:15,675 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 21:57:59,000 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn0.npy with mmap=None\n",
      "2017-01-17 21:58:31,390 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 21:58:31,391 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 21:58:34,687 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 21:58:34,689 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 22:02:20,547 : INFO : Loading Classifier\n",
      "2017-01-17 22:02:20,618 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 22:04:41,581 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n",
      "** Validation Metrics: Cov Err: 1.789, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.692, Top 3: 0.915, Top 5: 0.976, \n",
      "\t\t F1 Micro: 0.603, F1 Macro: 0.514, Total Pos: 706,023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 22:05:10,829 : INFO : Loading Classifier\n",
      "2017-01-17 22:05:10,886 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_10_reg_0.001_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 22:07:19,614 : INFO : Getting Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 22:07:49,943 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 1.747, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.701, Top 3: 0.924, Top 5: 0.980, \n",
      "\t\t F1 Micro: 0.616, F1 Macro: 0.523, Total Pos: 689,910\n",
      "epoch_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 22:08:57,923 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.* with mmap=None\n",
      "2017-01-17 22:08:57,924 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-17 22:10:03,747 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy with mmap=None\n",
      "2017-01-17 22:10:18,610 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy with mmap=None\n",
      "2017-01-17 22:10:34,224 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-17 22:10:34,225 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-17 22:10:37,724 : INFO : Getting Validation Embeddings\n",
      "2017-01-17 22:10:37,726 : INFO : ===== Loading validation vectors\n",
      "2017-01-17 22:14:44,936 : INFO : No Classifier found for svm_iter_100_reg_0.01_classweights_balanced in epoch_6\n",
      "2017-01-17 22:14:44,938 : INFO : Getting training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_iter_100_reg_0.01_classweights_balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-17 22:20:24,187 : INFO : Training Classifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "class_weight must be dict, 'auto', or None, got: 'e'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-16cdb57e7ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;31m# Training of a classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                 \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLASSIFIER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[1;32m--> 287\u001b[1;33m             for i, column in enumerate(columns))\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.n_iter,\n\u001b[1;32m--> 415\u001b[1;33m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;31m# Allocate datastructures from input arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         self._expanded_class_weight = compute_class_weight(self.class_weight,\n\u001b[1;32m--> 355\u001b[1;33m                                                            self.classes_, y)\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/utils/class_weight.pyc\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[1;34m(class_weight, classes, y)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             raise ValueError(\"class_weight must be dict, 'auto', or None,\"\n\u001b[1;32m---> 72\u001b[1;33m                              \" got: %r\" % class_weight)\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: class_weight must be dict, 'auto', or None, got: 'e'"
     ]
    }
   ],
   "source": [
    "for doc2vec_method in natural_sort(get_subdirectories(ROOT_RESULTS_LOCATION)):\n",
    "    if doc2vec_method in finished_doc2vec_methods: \n",
    "        info('skipping {}'.format(doc2vec_method))\n",
    "        continue\n",
    "        \n",
    "    print '********************* {}'.format(doc2vec_method)\n",
    "    epochs_path = os.path.join(ROOT_RESULTS_LOCATION, doc2vec_method)\n",
    "    # this will have the structure dict of classifiers -> dict of metrics -> list of values throughout the epoch\n",
    "    for epoch in natural_sort(get_subdirectories(epochs_path)):\n",
    "        print epoch\n",
    "        epoch_path =  os.path.join(epochs_path, epoch)\n",
    "        \n",
    "        if os.path.exists(os.path.join(epoch_path, MODEL_PREFIX)):\n",
    "            doc2vec_model = Doc2Vec.load(os.path.join(epoch_path, MODEL_PREFIX))\n",
    "        else:\n",
    "            info('No Doc2vec model found for {}. Exiting..'.format(epoch))\n",
    "            break\n",
    "            \n",
    "        GLOBAL_VARS.MODEL_NAME = epoch_path\n",
    "\n",
    "        # Validation Metrics\n",
    "        info('Getting Validation Embeddings')\n",
    "        try:\n",
    "            Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                            validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                            validation_preprocessed_docids_files_prefix)\n",
    "        except:\n",
    "            info('No More Validation Embeddings to load, exiting.....')\n",
    "            \n",
    "        for classifier in get_subdirectories(epoch_path):\n",
    "            print classifier\n",
    "            \n",
    "            classifier_path = os.path.join(epoch_path, classifier)\n",
    "            if(os.path.exists(os.path.join(classifier_path, CLASSIFIER))):\n",
    "                info('Loading Classifier')\n",
    "                clf = pickle.load(open(os.path.join(classifier_path, CLASSIFIER), 'r'))\n",
    "            else:\n",
    "                \n",
    "                info('No Classifier found for {} in {}'.format(classifier, epoch))\n",
    "                info('Getting training Data')\n",
    "                X, y = get_training_data(doc2vec_model, classifications)\n",
    "                info('Training Classifier')\n",
    "                classifier_parts = classifier.split('_')\n",
    "                SVM_ITERATIONS = classifier[2]\n",
    "                SVM_REG = classifier[4]\n",
    "                SVM_CLASS_WEIGHTS = classifier[6] if classifier[6] != 'None' else None\n",
    "                clf = OneVsRestClassifier(linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                                     #alpha is the 1/C parameter\n",
    "                                                                     alpha=SVM_REG, fit_intercept=True, n_iter=SVM_ITERATIONS,\n",
    "                                                                     #n_jobs=-1 means use all cpus\n",
    "                                                                     shuffle=True, verbose=0, n_jobs=1,\n",
    "                                                                     #eta0 is the learning rate when we use constant configuration\n",
    "                                                                     random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                                     class_weight=SVM_CLASS_WEIGHTS, warm_start=False), n_jobs=1)\n",
    "\n",
    "                # Training of a classifier\n",
    "                clf.fit(X,y)\n",
    "                pickle.dump(clf, open(os.path.join(classifier_path, CLASSIFIER), 'w'))\n",
    "\n",
    "            info('Evaluating on Validation Data')\n",
    "            yvp = clf.predict(Xv)\n",
    "            yvp_score = clf.decision_function(Xv)\n",
    "            print yvp\n",
    "            info('Getting Validation Metrics')\n",
    "            validation_metrics = get_metrics(yv, yvp_score, yvp)\n",
    "            print \"** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "                validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "                validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "            \n",
    "            pickle.dump(validation_metrics, open(os.path.join(classifier_path, VALIDATION_METRICS_FILENAME), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
