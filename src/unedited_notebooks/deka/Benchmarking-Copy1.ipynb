{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import coverage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_SIZE = 3\n",
    "MIN_DOCUMENTS = 5\n",
    "TOP_N_FEATURES = 10000\n",
    "\n",
    "TEST_SET_PERCENTAGE = 0.2\n",
    "VALIDATION_IN_TRAINING_PERCENTAGE = 0.2\n",
    "MIN_DOCUMENTS_FOR_TEST = 1\n",
    "MIN_DOCUMENTS_FOR_VALIDATION = 1\n",
    "\n",
    "MIN_DOCUMENTS_FOR_TRAINING_SAMPLE = 10\n",
    "MIN_DOCUMENTS_FOR_TEST_SAMPLE = 1\n",
    "MIN_DOCUMENTS_FOR_VALIDATION_SAMPLE = 1\n",
    "\n",
    "SVM_ITERATIONS = 1000\n",
    "SVM_CONVERGENCE = 0.1\n",
    "SVM_REG = 0.01\n",
    "\n",
    "BM25_K = 1.5  # controls power of tf component\n",
    "BM25_b = 0.75  # controls the BM25 length normalization\n",
    "\n",
    "RANDOM_SEED = 10000\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer().stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text, doc_id):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    previous_unigram = None\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            elif is_stopword(stem):\n",
    "                stem = None\n",
    "            else:\n",
    "                stem = stemmer(token)\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append((stem,{doc_id: 1}))\n",
    "                # extract bi-grams\n",
    "                if previous_unigram: stems.append((previous_unigram + \" \" + stem,{doc_id: 1}))\n",
    "                previous_unigram = stem\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_stopword(word):\n",
    "  return word in STOP_WORDS\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_postings(postings_list1, postings_list2):\n",
    "    # key could be either a doc id or a term\n",
    "    for key in postings_list2:\n",
    "        if postings_list1.get(key):\n",
    "            postings_list1[key] += postings_list2[key]\n",
    "        else:\n",
    "            postings_list1[key] = postings_list2[key]\n",
    "    return postings_list1\n",
    "\n",
    "def get_term_dictionary(terms):\n",
    "    \"\"\"\n",
    "    Maps string terms to indexes in an array\n",
    "    \"\"\"\n",
    "    term_dictionary = {}\n",
    "    term_array = [None] * len(terms)\n",
    "    def put(key):\n",
    "        hashvalue = hashfunction(key, len(term_array))\n",
    "        if term_array[hashvalue] == None:\n",
    "            term_array[hashvalue] = key\n",
    "            return hashvalue\n",
    "        else:\n",
    "            nextslot = rehash(hashvalue, len(term_array))\n",
    "            while term_array[nextslot] != None:\n",
    "                nextslot = rehash(nextslot, len(term_array))\n",
    "            if term_array[nextslot] == None:\n",
    "                term_array[nextslot] = key\n",
    "                return nextslot\n",
    "    def hashfunction(key, size):\n",
    "        return hash(key) % size\n",
    "    def rehash(oldhash, size):\n",
    "        return (oldhash + 1) % size\n",
    "    i = 0\n",
    "    for term in terms:\n",
    "        corresponding_index = put(term)\n",
    "        term_dictionary[term] = corresponding_index\n",
    "        i+=1\n",
    "        if i%10000 == 0: print \"finished \" + str(i)\n",
    "    return term_dictionary\n",
    "\n",
    "def get_doc_index(term, postings_list, term_dictionary):\n",
    "    #return [(doc_id, {term: postings_list[doc_id]}) for doc_id in postings_list]\n",
    "    return [(doc_id, {term_dictionary[term]: postings_list[doc_id]}) for doc_id in postings_list]\n",
    "\n",
    "def get_classes(ipc_classification):\n",
    "    sections = []\n",
    "    classes = []\n",
    "    subclasses = []\n",
    "    for classification in ipc_classification:\n",
    "        # we do the check because some documents have repetitions\n",
    "        section_name = classification['section']\n",
    "        class_name = classification['section'] + \"-\" + classification['class']\n",
    "        subclass_name = classification['section'] + \"-\" + classification['class'] + \"-\" + classification['subclass']\n",
    "        if section_name not in sections:\n",
    "            sections.append(section_name)\n",
    "        if class_name not in classes:\n",
    "            classes.append(class_name)\n",
    "        if subclass_name not in subclasses:\n",
    "            subclasses.append(subclass_name)\n",
    "    return {\"sections\": sections, \"classes\": classes, \"subclasses\": subclasses}\n",
    "\n",
    "\n",
    "def get_training_vector_old(classification, term_list, classifications, classification_key_name, number_of_terms):\n",
    "    clss = 1 if classification in classifications[classification_key_name] else 0\n",
    "    return LabeledPoint(clss, SparseVector(number_of_terms, term_list))\n",
    "\n",
    "def get_training_vector(classification, term_list, classifications, number_of_terms):\n",
    "    clss = 1 if classification in classifications else 0\n",
    "    return LabeledPoint(clss, SparseVector(number_of_terms, term_list))\n",
    "\n",
    "\n",
    "def calculate_sublinear_tf(tf):\n",
    "    # laplace smoothing with +1 in case of term with no documents (useful during testing)\n",
    "    return math.log10(1 + tf)\n",
    "\n",
    "\n",
    "def calculate_tf_idf(tf, df, N):\n",
    "    # laplace smoothing with +1 in case of term with no documents (useful during testing)\n",
    "    return tf * math.log10((N+1) / (df + 1))\n",
    "\n",
    "\n",
    "def calculate_bm25(tf, df, N, d_len, d_avg):\n",
    "    idf = max(0, math.log10((N-df + 0.5)/(df+0.5))) # in rare cases where the df is over 50% of N, this could become -ve, so we guard against that\n",
    "    tf_comp = float(((BM25_K + 1) * tf)) / ( BM25_K * ((1-BM25_b) + BM25_b*(float(d_len)/d_avg)) + tf)\n",
    "    return tf_comp * idf\n",
    "\n",
    "\n",
    "def calculate_rf(df_relevant, df_non_relevant):\n",
    "    return math.log( (2 + (float(df_relevant)/max(1, df_non_relevant))), 2)\n",
    "\n",
    "\n",
    "def calculate_tf_rf(tf, df_relevant, df_non_relevant):\n",
    "    return tf * calculate_rf(df_relevant, df_non_relevant)\n",
    "\n",
    "\n",
    "def compare_classifications(x,y):\n",
    "    len_comp = cmp(len(x), len(y))\n",
    "    if len_comp == 0:\n",
    "        return cmp(x,y)\n",
    "    return len_comp\n",
    "\n",
    "\n",
    "def create_doc_index(term_index, term_dictionary):\n",
    "    return term_index \\\n",
    "        .flatMap(lambda (term, postings_list): get_doc_index(term, postings_list, term_dictionary)) \\\n",
    "        .reduceByKey(lambda x, y: merge_postings(x, y))\n",
    "\n",
    "\n",
    "def get_rf_stats(postings, classification):\n",
    "    a_plus_c = set(postings.keys())\n",
    "    a_plus_b = set(classifications_index[classification])\n",
    "    # first intersection is to get (a), second difference is to get (c) (checkout tf-rf paper for reference)\n",
    "    a = a_plus_c.intersection(a_plus_b)\n",
    "    c = a_plus_c.difference(a_plus_b)\n",
    "    size_a = len(a)\n",
    "    size_c = len(c)\n",
    "    return size_a, size_c\n",
    "\n",
    "\n",
    "def get_rf_postings(classification):\n",
    "    def get_rf_postings_internal(postings):\n",
    "        size_a, size_c = get_rf_stats(postings, classification)\n",
    "        return {docId: calculate_rf(size_a, size_c)\n",
    "                for docId, tf in postings.items()}\n",
    "    return get_rf_postings_internal\n",
    "\n",
    "\n",
    "def get_tf_rf_postings(classification):\n",
    "    def get_tf_rf_postings_internal(postings):\n",
    "        size_a, size_c = get_rf_stats(postings, classification)\n",
    "        return {docId: calculate_tf_rf(tf, size_a, size_c)\n",
    "                for docId, tf in postings.items()}\n",
    "    return get_tf_rf_postings_internal\n",
    "\n",
    "\n",
    "def train_level_old(docs_with_classes, classification, classification_label):\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector_old(classification, term_list, classifications,\n",
    "                                                                           classification_label, number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE)\n",
    "    return training_vectors, svm\n",
    "\n",
    "\n",
    "def train_level(docs_with_classes, classification, number_of_terms):\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector(classification, term_list,\n",
    "                                                                           classifications, number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE, regParam=SVM_REG)\n",
    "    return training_vectors, svm\n",
    "\n",
    "\n",
    "def get_error(svm, test_vectors):\n",
    "    labelsAndPreds = test_vectors.map(lambda p: (p.label, svm.predict(p.features)))\n",
    "    trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(test_vectors.count())\n",
    "    return trainErr\n",
    "\n",
    "\n",
    "def train_all(docs_with_classes):\n",
    "    training_errors = {}\n",
    "    for section in sections:\n",
    "        training_vectors, svm = train_level(docs_with_classes, section, \"sections\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[section] = train_err\n",
    "    #\n",
    "    with open(training_errors_output, 'w') as file:\n",
    "        file.write(json.dumps(training_errors))\n",
    "    #\n",
    "    for clss in classes:\n",
    "        training_vectors, svm = train_level(docs_with_classes, clss, \"classes\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[clss] = train_err\n",
    "    \n",
    "    with open(training_errors_output, 'w') as file:\n",
    "        file.write(json.dumps(training_errors))\n",
    "    \n",
    "    for subclass in subclasses:\n",
    "        training_vectors, svm = train_level(docs_with_classes, subclass, \"subclasses\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[subclass] = train_err\n",
    "    return training_errors\n",
    "\n",
    "\n",
    "def get_labeled_points_from_doc_index(doc_index, doc_classification_map, number_of_terms):\n",
    "    docs_with_classes = doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector(classification, term_list,\n",
    "                                                                           classifications, number_of_terms))\n",
    "    return training_vectors\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    \n",
    "    def __init__(self, labels, scores, threshold=0.5):\n",
    "        self.threshold = 0\n",
    "        self.count = len(self.labels)\n",
    "        \n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tn = 0\n",
    "        \n",
    "        for (l,s) in zip(labels,scores):\n",
    "            if self.is_true(l) and self.is_true(s):\n",
    "                self.tp += 1\n",
    "            if self.is_true(l) and not self.is_true(s):\n",
    "                self.fn += 1\n",
    "            if not self.is_true(l) and self.is_true(s):\n",
    "                self.fp += 1\n",
    "            if not self.is_true(l) and not self.is_true(s):\n",
    "                self.tn += 1\n",
    "        self.precision = self.get_precision()\n",
    "        self.recall = self.get_precision()\n",
    "        self.fa = self.get_f1()\n",
    "        self.error_rate = self.get_error_rate()\n",
    "        \n",
    "    def calculate_contingency(self, label, contingency):\n",
    "        \n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tn = 0\n",
    "        \n",
    "        for (l,s) in zip(labels,scores):\n",
    "            if self.is_true(l) and self.is_true(s):\n",
    "                self.tp += 1\n",
    "            if self.is_true(l) and not self.is_true(s):\n",
    "                self.fn += 1\n",
    "            if not self.is_true(l) and self.is_true(s):\n",
    "                self.fp += 1\n",
    "            if not self.is_true(l) and not self.is_true(s):\n",
    "                self.tn += 1\n",
    "    \n",
    "    def is_true(self, label):\n",
    "        return label > self.threshold\n",
    "    \n",
    "    def get_error_rate(self):\n",
    "        return float(self.tp + self.tn) / len(labels)\n",
    "    \n",
    "    def get_precision(self):\n",
    "        # self.calculate_contingency()\n",
    "        if self.tp == 0: return 0\n",
    "        return float(self.tp) / (self.tp + self.fp)\n",
    "        \n",
    "    def get_recall(self):\n",
    "        # self.calculate_contingency()\n",
    "        if self.tp == 0: return 0\n",
    "        return float(self.tp) / (self.tp + self.fn)\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return 2 * (self.get_precision() * self.get_recall()) / (self.get_precision() + self.get_recall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc = SparkContext(\"\", \"Generate Inverted Index Job\")\n",
    "es_server = \"deka.cip.ifi.lmu.de\"\n",
    "es_port = \"9200\"\n",
    "\n",
    "save_parent_location = \"hdfs://deka.cip.ifi.lmu.de/svm/new/\"\n",
    "if IS_SAMPLE: \n",
    "    save_parent_location = save_parent_location + \"sample/\"\n",
    "\n",
    "file_name = \"sample.json\"\n",
    "test_file_name = \"sample.json\"\n",
    "#url = \"/media/Work/workspace/thesis/benchmark/output/\" + file_name\n",
    "sample_location = save_parent_location + file_name\n",
    "sample_test_location = save_parent_location + test_file_name\n",
    "postings_list_output = save_parent_location + \"postings_list_full.json\"\n",
    "postings_list_chi_selected_output = save_parent_location + \"postings_list_{}.json\"\n",
    "classification_index_output = save_parent_location + \"classification_index.pkl\"\n",
    "doc_classification_map_output = save_parent_location + \"doc_classification_map.pkl\"\n",
    "sections_output = save_parent_location + \"sections.pkl\"\n",
    "classes_output = save_parent_location + \"classes.pkl\"\n",
    "subclasses_output = save_parent_location + \"subclasses.pkl\"\n",
    "classifications_output = save_parent_location + \"classifications.pkl\"\n",
    "# training, validation and test set lists\n",
    "training_docs_list_output = save_parent_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_output = save_parent_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_output = save_parent_location + \"test_docs_list.pkl\"\n",
    "test_postings_list_output = save_parent_location + \"test_postings_list_50000.json\"\n",
    "training_errors_output = save_parent_location + \"training_errors.json\"\n",
    "model_output = save_parent_location + \"models/\" + \"iter_\" + str(SVM_ITERATIONS) + \"_reg_\" + str(SVM_REG) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_name(method, classification, reg=SVM_REG, no_of_features=TOP_N_FEATURES, iterations=SVM_ITERATIONS):\n",
    "    return save_parent_location + \"models/\" + \"iter_\" + str(iterations) + \"_reg_\" + str(reg) + \"/\" + method + \"_\" + classification + \"_model.svm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "read_conf = {\n",
    "    'es.nodes': es_server,\n",
    "    'es.port': es_port,\n",
    "    'es.resource': 'patents3/patent',\n",
    "    'es.query': '{ \"query\" : { \"match_all\" : {} }}',\n",
    "    'es.scroll.keepalive': '120m',\n",
    "    'es.scroll.size': '1000',\n",
    "    'es.http.timeout': '20m'\n",
    "}\n",
    "data = sc.newAPIHadoopRDD(\n",
    "    inputFormatClass = 'org.elasticsearch.hadoop.mr.EsInputFormat',\n",
    "    keyClass = 'org.apache.hadoop.io.NullWritable', \n",
    "    valueClass = 'org.elasticsearch.hadoop.mr.LinkedMapWritable',\n",
    "    conf = read_conf\n",
    ")\n",
    "\n",
    "#data = sc.textFile(sample_location)\n",
    "#doc_count = data.count()\n",
    "#doc_objs = data.persist(pyspark.StorageLevel.MEMORY_AND_DISK_SER)\n",
    "doc_objs = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 6.48 s, total: 34.8 s\n",
      "Wall time: 15min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### doc_objs = data.map(lambda x: json.loads(x))\n",
    "\n",
    "doc_class_map = doc_objs.map(lambda (doc_id, doc): (doc_id, get_classes(doc['classification-ipc']))).cache()\n",
    "doc_classification_map = doc_class_map.map(lambda (doc_id, classification_obj): (doc_id, sorted(reduce(lambda x, lst: x + lst, classification_obj.values(), [])))).collectAsMap()\n",
    "doc_count = len(doc_classification_map)\n",
    "# contains [(classification,  list of docs)]\n",
    "# second list comprehension is to get list of lists [[\"A\", \"B\"],[\"A-01\",\"B-03\"]] to one list [\"A\", \"B\", \"A-01\",\"B-03\"], we could have also used a reduce as in doc_classifications_map\n",
    "classifications_index = doc_class_map.flatMap(lambda (doc_id, classifications_obj): [(classification, doc_id) for classification in [classif for cat in classifications_obj.values() for classif in cat]])\\\n",
    "    .groupByKey().map(lambda (classf, classf_docs): (classf, list(set(classf_docs)))).collectAsMap()\n",
    "\n",
    "sections = sorted(doc_class_map.flatMap(lambda (doc_id, classifications): classifications['sections']).distinct().collect())\n",
    "classes = sorted(doc_class_map.flatMap(lambda (doc_id, classifications): classifications['classes']).distinct().collect())\n",
    "subclasses = sorted(doc_class_map.flatMap(lambda (doc_id, classifications): classifications['subclasses']).distinct().collect())\n",
    "classifications = sorted(classifications_index.keys(), cmp=compare_classifications)\n",
    "# classifications = sorted(set(reduce(lambda x, lst: x + lst, map(lambda doc_id: classifications_index[doc_id], classifications_index), [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save classification objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.2 s, sys: 2.54 s, total: 34.8 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sc.parallelize(doc_classification_map.items()).saveAsPickleFile(doc_classification_map_output)\n",
    "sc.parallelize(classifications_index.items()).saveAsPickleFile(classification_index_output)\n",
    "sc.parallelize(sections).saveAsPickleFile(sections_output)\n",
    "sc.parallelize(classes).saveAsPickleFile(classes_output)\n",
    "sc.parallelize(subclasses).saveAsPickleFile(subclasses_output)\n",
    "sc.parallelize(classifications).saveAsPickleFile(classifications_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Classification Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_classification_map = dict(sc.pickleFile(doc_classification_map_output).collect())\n",
    "doc_count = len(doc_classification_map)\n",
    "classifications_index = dict(sc.pickleFile(classification_index_output).collect())\n",
    "sections = sc.pickleFile(sections_output).collect()\n",
    "classes = sc.pickleFile(classes_output).collect()\n",
    "subclasses = sc.pickleFile(subclasses_output).collect()\n",
    "classifications = sc.pickleFile(classifications_output).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_class_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-aa981fd799b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc_class_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_class_map' is not defined"
     ]
    }
   ],
   "source": [
    "doc_class_map.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009750"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'G-20-B', [u'07433566', u'07896523', u'06985663', u'07116477', u'07218441'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_index.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'07007598', [u'B', u'B-30', u'B-30-B'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_classification_map.items()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'A', u'B', u'C', u'D', u'E', u'F', u'G', u'H']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training, Validation and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(list,\n",
       "             {u'A-02-D': [2],\n",
       "              u'A-04-F': [2],\n",
       "              u'A-04-J': [2],\n",
       "              u'A-04-L': [2],\n",
       "              u'A-04-Q': [2],\n",
       "              u'A-06-B': [2],\n",
       "              u'A-07-H': [2],\n",
       "              u'A-11-B': [2],\n",
       "              u'A-11-F': [2],\n",
       "              u'A-11-K': [2],\n",
       "              u'A-12-N': [2],\n",
       "              u'A-13': [2],\n",
       "              u'A-16-L': [2],\n",
       "              u'A-18': [2],\n",
       "              u'A-18-B': [2],\n",
       "              u'A-22-L': [2],\n",
       "              u'A-25': [2],\n",
       "              u'A-26-D': [2],\n",
       "              u'A-31-F': [2],\n",
       "              u'A-37-D': [2],\n",
       "              u'A-41-J': [2],\n",
       "              u'A-42-F': [2],\n",
       "              u'A-44-D': [2],\n",
       "              u'A-45-G': [2],\n",
       "              u'A-45-H': [2],\n",
       "              u'A-45-K': [2],\n",
       "              u'A-46-H': [2],\n",
       "              u'A-51-B': [2],\n",
       "              u'A-51-F': [2],\n",
       "              u'A-60-B': [2],\n",
       "              u'A-60-C': [2],\n",
       "              u'A-60-F': [2],\n",
       "              u'A-61-O': [2],\n",
       "              u'A-62-G': [2],\n",
       "              u'A-62-L': [2],\n",
       "              u'A-64-B': [2],\n",
       "              u'A-64-F': [2],\n",
       "              u'A-65-F': [2],\n",
       "              u'A-66-F': [2],\n",
       "              u'A-67-K': [2],\n",
       "              u'A-67-M': [2],\n",
       "              u'A-68': [2],\n",
       "              u'A-74': [2],\n",
       "              u'A-81-P': [2],\n",
       "              u'A-83': [2],\n",
       "              u'A-99': [2],\n",
       "              u'A-99-Z': [2],\n",
       "              u'B-01-A': [2],\n",
       "              u'B-01-K': [2],\n",
       "              u'B-01-M': [2],\n",
       "              u'B-01-O': [2],\n",
       "              u'B-01-R': [2],\n",
       "              u'B-03-G': [2],\n",
       "              u'B-04-D': [2],\n",
       "              u'B-04-F': [2],\n",
       "              u'B-05-F': [2],\n",
       "              u'B-05-R': [2],\n",
       "              u'B-06-G': [2],\n",
       "              u'B-06-N': [2],\n",
       "              u'B-07-D': [2],\n",
       "              u'B-07-F': [2],\n",
       "              u'B-08-C': [2],\n",
       "              u'B-08-K': [2],\n",
       "              u'B-08-L': [2],\n",
       "              u'B-10-J': [2],\n",
       "              u'B-10-L': [2],\n",
       "              u'B-13': [2],\n",
       "              u'B-15': [2],\n",
       "              u'B-20': [2],\n",
       "              u'B-21-O': [2],\n",
       "              u'B-21-S': [2],\n",
       "              u'B-22-J': [2],\n",
       "              u'B-23-O': [2],\n",
       "              u'B-24-F': [2],\n",
       "              u'B-24-P': [2],\n",
       "              u'B-24-Q': [2],\n",
       "              u'B-26-C': [2],\n",
       "              u'B-29-F': [2],\n",
       "              u'B-29-O': [2],\n",
       "              u'B-29-P': [2],\n",
       "              u'B-32-C': [2],\n",
       "              u'B-32-Q': [2],\n",
       "              u'B-33-B': [2],\n",
       "              u'B-34-B': [2],\n",
       "              u'B-34-D': [2],\n",
       "              u'B-35-G': [2],\n",
       "              u'B-41-I': [2],\n",
       "              u'B-42-J': [2],\n",
       "              u'B-44-M': [2],\n",
       "              u'B-45': [2],\n",
       "              u'B-46-B': [2],\n",
       "              u'B-50-K': [2],\n",
       "              u'B-53': [2],\n",
       "              u'B-54': [2],\n",
       "              u'B-55': [2],\n",
       "              u'B-55-D': [2],\n",
       "              u'B-56-G': [2],\n",
       "              u'B-56-H': [2],\n",
       "              u'B-62-E': [2],\n",
       "              u'B-62-G': [2],\n",
       "              u'B-62-T': [2],\n",
       "              u'B-63-D': [2],\n",
       "              u'B-63-F': [2],\n",
       "              u'B-64-H': [2],\n",
       "              u'B-69-N': [2],\n",
       "              u'B-95': [2],\n",
       "              u'C-00-C': [2],\n",
       "              u'C-00-D': [2],\n",
       "              u'C-02-E': [2],\n",
       "              u'C-02-H': [2],\n",
       "              u'C-02-P': [2],\n",
       "              u'C-05-K': [2],\n",
       "              u'C-08-Q': [2],\n",
       "              u'C-12-B': [2],\n",
       "              u'C-15': [2],\n",
       "              u'C-15-N': [2],\n",
       "              u'C-16': [2],\n",
       "              u'C-17-H': [2],\n",
       "              u'C-17-K': [2],\n",
       "              u'C-19-P': [2],\n",
       "              u'C-21-N': [2],\n",
       "              u'C-30-C': [2],\n",
       "              u'C-32-B': [2],\n",
       "              u'C-33': [2],\n",
       "              u'C-33-C': [2],\n",
       "              u'C-60': [2],\n",
       "              u'C-90': [2],\n",
       "              u'C-90-K': [2],\n",
       "              u'C-93': [2],\n",
       "              u'C-93-B': [2],\n",
       "              u'C-97-D': [2],\n",
       "              u'C-98': [2],\n",
       "              u'C-98-K': [2],\n",
       "              u'D-00-B': [2],\n",
       "              u'D-03-S': [2],\n",
       "              u'D-12-H': [2],\n",
       "              u'D-23': [2],\n",
       "              u'D-23-C': [2],\n",
       "              u'D-24': [2],\n",
       "              u'D-29': [2],\n",
       "              u'D-30': [2],\n",
       "              u'D-30-D': [2],\n",
       "              u'D-31': [2],\n",
       "              u'D-60-J': [2],\n",
       "              u'E-02-M': [2],\n",
       "              u'E-03-H': [2],\n",
       "              u'E-06-D': [2],\n",
       "              u'E-06-H': [2],\n",
       "              u'E-08': [2],\n",
       "              u'E-09-H': [2],\n",
       "              u'E-09-K': [2],\n",
       "              u'E-23-B': [2],\n",
       "              u'E-36': [2],\n",
       "              u'E-36-B': [2],\n",
       "              u'E-41': [2],\n",
       "              u'E-44-G': [2],\n",
       "              u'E-45': [2],\n",
       "              u'E-45-B': [2],\n",
       "              u'E-55': [2],\n",
       "              u'E-63-C': [2],\n",
       "              u'E-94': [2],\n",
       "              u'E-94-H': [2],\n",
       "              u'F-00-B': [2],\n",
       "              u'F-00-P': [2],\n",
       "              u'F-01-R': [2],\n",
       "              u'F-01-V': [2],\n",
       "              u'F-02-S': [2],\n",
       "              u'F-02-V': [2],\n",
       "              u'F-03-M': [2],\n",
       "              u'F-04-H': [2],\n",
       "              u'F-04-M': [2],\n",
       "              u'F-05-B': [2],\n",
       "              u'F-06-G': [2],\n",
       "              u'F-06-Q': [2],\n",
       "              u'F-09-D': [2],\n",
       "              u'F-09-F': [2],\n",
       "              u'F-10-D': [2],\n",
       "              u'F-10-K': [2],\n",
       "              u'F-10-N': [2],\n",
       "              u'F-11-L': [2],\n",
       "              u'F-14': [2],\n",
       "              u'F-15-H': [2],\n",
       "              u'F-15-L': [2],\n",
       "              u'F-15-M': [2],\n",
       "              u'F-18-H': [2],\n",
       "              u'F-20': [2],\n",
       "              u'F-21-C': [2],\n",
       "              u'F-21-G': [2],\n",
       "              u'F-21-H': [2],\n",
       "              u'F-24-K': [2],\n",
       "              u'F-31': [2],\n",
       "              u'F-31-B': [2],\n",
       "              u'F-35': [2],\n",
       "              u'F-35-B': [2],\n",
       "              u'F-42-G': [2],\n",
       "              u'F-64': [2],\n",
       "              u'G-00-L': [2],\n",
       "              u'G-00-N': [2],\n",
       "              u'G-00-Q': [2],\n",
       "              u'G-00-R': [2],\n",
       "              u'G-01-E': [2],\n",
       "              u'G-01-I': [2],\n",
       "              u'G-01-O': [2],\n",
       "              u'G-02-J': [2],\n",
       "              u'G-03-P': [2],\n",
       "              u'G-03-R': [2],\n",
       "              u'G-03-V': [2],\n",
       "              u'G-05-J': [2],\n",
       "              u'G-05-N': [2],\n",
       "              u'G-07-H': [2],\n",
       "              u'G-08-H': [2],\n",
       "              u'G-08-J': [2],\n",
       "              u'G-11-D': [2],\n",
       "              u'G-11-H': [2],\n",
       "              u'G-11-K': [2],\n",
       "              u'G-11-V': [2],\n",
       "              u'G-12-C': [2],\n",
       "              u'G-12-F': [2],\n",
       "              u'G-12-G': [2],\n",
       "              u'G-12-M': [2],\n",
       "              u'G-12-N': [2],\n",
       "              u'G-16-H': [2],\n",
       "              u'G-17': [2],\n",
       "              u'G-23-K': [2],\n",
       "              u'G-30-F': [2],\n",
       "              u'G-30-G': [2],\n",
       "              u'G-31': [2],\n",
       "              u'G-33-B': [2],\n",
       "              u'G-36': [2],\n",
       "              u'G-41-J': [2],\n",
       "              u'G-50': [2],\n",
       "              u'G-60-B': [2],\n",
       "              u'G-60-C': [2],\n",
       "              u'G-60-W': [2],\n",
       "              u'G-61-K': [2],\n",
       "              u'G-65-F': [2],\n",
       "              u'G-65-H': [2],\n",
       "              u'G-89': [2],\n",
       "              u'G-89-G': [2],\n",
       "              u'G-91': [2],\n",
       "              u'G-91-N': [2],\n",
       "              u'G-94-B': [2],\n",
       "              u'H-00-G': [2],\n",
       "              u'H-01-V': [2],\n",
       "              u'H-02-C': [2],\n",
       "              u'H-02-D': [2],\n",
       "              u'H-02-O': [2],\n",
       "              u'H-02-T': [2],\n",
       "              u'H-03-I': [2],\n",
       "              u'H-03-S': [2],\n",
       "              u'H-05-D': [2],\n",
       "              u'H-05-M': [2],\n",
       "              u'H-05-P': [2],\n",
       "              u'H-06-B': [2],\n",
       "              u'H-06-M': [2],\n",
       "              u'H-07-L': [2],\n",
       "              u'H-07-N': [2],\n",
       "              u'H-08-L': [2],\n",
       "              u'H-09-L': [2],\n",
       "              u'H-09-N': [2],\n",
       "              u'H-10-H': [2],\n",
       "              u'H-10-J': [2],\n",
       "              u'H-10-Q': [2],\n",
       "              u'H-11-C': [2],\n",
       "              u'H-20-J': [2],\n",
       "              u'H-20-M': [2],\n",
       "              u'H-22-K': [2],\n",
       "              u'H-23': [2],\n",
       "              u'H-32': [2],\n",
       "              u'H-32-B': [2],\n",
       "              u'H-44-B': [2],\n",
       "              u'H-44-M': [2],\n",
       "              u'H-47': [2],\n",
       "              u'H-60': [2],\n",
       "              u'H-63-B': [2],\n",
       "              u'H-63-K': [2],\n",
       "              u'H-92': [2],\n",
       "              u'H-93': [2],\n",
       "              u'H-94-B': [2],\n",
       "              u'H-94-M': [2],\n",
       "              u'H-94-N': [2],\n",
       "              u'H-95': [2],\n",
       "              u'H-95-K': [2]}),\n",
       " 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get min number of documents for any classification\n",
    "min = 1000\n",
    "from collections import defaultdict\n",
    "min_classf = defaultdict(list)\n",
    "for (classf, documents) in classifications_index.items():\n",
    "    if len(documents) == 2: \n",
    "        min = len(documents)\n",
    "        min_classf[classf].append(min)\n",
    "min_classf, min\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min_classf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2235"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classifications_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_documents = set()\n",
    "validation_documents = set()\n",
    "test_documents = set()\n",
    "random.seed(RANDOM_SEED)\n",
    "for (classf, documents) in classifications_index.items():\n",
    "    # only worry about subclasses, classes and sections will be already included\n",
    "    if(classf in sections or classf in classes): pass\n",
    "    \n",
    "    # remove any documents that have already been picked before\n",
    "    docs_set = set(documents)\n",
    "    docs_set-=training_documents\n",
    "    docs_set-=validation_documents\n",
    "    docs_set-=test_documents\n",
    "    \n",
    "    base_test_docs_num = int(len(docs_set)* TEST_SET_PERCENTAGE)\n",
    "    num_test_docs = base_test_docs_num if base_test_docs_num > 0 else MIN_DOCUMENTS_FOR_TEST if MIN_DOCUMENTS_FOR_TEST < len(docs_set) else 0\n",
    "    print len(docs_set), num_test_docs\n",
    "    classif_test_docs = random.sample(docs_set, num_test_docs)\n",
    "    \n",
    "    remaining_docs = docs_set.difference(set(classif_test_docs))\n",
    "    base_validation_docs_num = int(len(remaining_docs)* VALIDATION_IN_TRAINING_PERCENTAGE)\n",
    "    num_validation_docs = base_validation_docs_num if base_validation_docs_num > 0 else MIN_DOCUMENTS_FOR_VALIDATION if MIN_DOCUMENTS_FOR_VALIDATION < len(remaining_docs) else 0\n",
    "    classif_validation_docs = random.sample(remaining_docs, num_validation_docs)\n",
    "    \n",
    "    classif_training_docs = set(remaining_docs).difference(set(classif_validation_docs))\n",
    "    \n",
    "    training_documents.update(classif_training_docs)\n",
    "    validation_documents.update(classif_validation_docs)\n",
    "    test_documents.update(classif_test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the training, validation and test document lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.parallelize(training_documents).saveAsPickleFile(training_docs_list_output)\n",
    "sc.parallelize(validation_documents).saveAsPickleFile(validation_docs_list_output)\n",
    "sc.parallelize(test_documents).saveAsPickleFile(test_docs_list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training, validation and test document lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_documents = sc.pickleFile(training_docs_list_output).collect()\n",
    "validation_documents = sc.pickleFile(validation_docs_list_output).collect()\n",
    "test_documents = sc.pickleFile(test_docs_list_output).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928631"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(validation_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for classif in sorted(classifications_index.keys()):\n",
    "    if len(classif) == 1:\n",
    "        print \"%s : %d, %.3f\" % (classif, len(set(classifications_index[classif])), float(len(classifications_index[classif]))/doc_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "overlap_df = pd.DataFrame({section: [0]*len(sections) for section in sections} , index=sections, columns=sections)\n",
    "for doc_id in doc_classification_map:\n",
    "    for classif in doc_classification_map[doc_id]:\n",
    "        if len(classif) == 1:\n",
    "            for classif2 in doc_classification_map[doc_id]:\n",
    "                if len(classif2) == 1:\n",
    "                    overlap_df[classif][classif2] += 1\n",
    "overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.colors.Normalize(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlap_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8), dpi=120)\n",
    "#ax = fig.add_subplot(111, frameon=True, xticks=[], yticks=[])\n",
    "vals = overlap_df.values\n",
    "normal = mpl.colors.Normalize()\n",
    "normal = mpl.colors.Normalize(vals.min()-1, vals.max()+vals.max()/2)\n",
    "formatter = lambda x: \"{:,d}\".format(int(x))\n",
    "\n",
    "the_table=plt.table(cellText=np.vectorize(formatter)(vals), rowLabels=overlap_df.index, colLabels=overlap_df.columns, \n",
    "                    colWidths = [0.1]*(vals.shape[1]+3), loc='center',\n",
    "                    cellColours=plt.cm.YlGn(normal(vals)))\n",
    "the_table.set_fontsize(30)\n",
    "the_table.scale(2, 4)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Create Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 4 ms, total: 24 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Postings List\n",
    "postings_lists = doc_objs.flatMap(lambda (doc_id, doc): stemtokenizer(doc['description'], doc_id)).reduceByKey(lambda x,y: merge_postings(x,y))\n",
    "### postings_lists = doc_objs.flatMap(lambda x: stemtokenizer(x['description'], x['id'])).reduceByKey(lambda x,y: merge_postings(x,y))\n",
    "min_doc_postings_lists = postings_lists.filter(lambda (x,y): len(y) > MIN_DOCUMENTS)\n",
    "#number_of_terms = min_doc_postings_lists.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Postings Lists\n",
    "#min_doc_postings_lists = sc.textFile(postings_list_output).map(lambda json_postings: json.loads(json_postings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save Postings List\n",
    "# min_doc_postings_lists.map(lambda (term, postings_list): \",\".join([term, json.dumps(postings_list)])).repartition(1).saveAsTextFile(postings_list_output)\n",
    "min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(postings_list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_chi_index(term_index, classifications_index, subclasses, number_of_docs):\n",
    "    return term_index.map(lambda (term, postings_list): (term, calculate_chi_squared(postings_list.keys(), classifications_index, subclasses, number_of_docs)))\n",
    "\n",
    "def calculate_chi_squared(document_list, classifications_index, subclasses, number_of_docs):\n",
    "    chi_score = 0\n",
    "    for subclass in subclasses:\n",
    "        Nt1 = len(document_list) # actual collection frequency of having the word\n",
    "        Nt0 = number_of_docs - len(document_list) # actual collection frequency of not having the word\n",
    "        Pt1 = float(len(document_list))/ number_of_docs\n",
    "        Pt0 = float(number_of_docs - len(document_list))/ number_of_docs\n",
    "        Pc1 = float(len(classifications_index[subclass]))/ number_of_docs\n",
    "        Et1c1 = Pt1 * Pc1 * number_of_docs # expected frequency of docs in subclass with term (assuming independence)\n",
    "        Et0c1 = Pt0 * Pc1 * number_of_docs # expected frequency of docs in subclass without term (assuming independence)\n",
    "        chi_score += math.pow( Nt1 - Et1c1, 2) / Et1c1 \n",
    "        chi_score += math.pow( Nt0 - Et0c1, 2) / Et0c1\n",
    "    return chi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "term_accepted_chi_list = get_chi_index(min_doc_postings_lists, classifications_index, subclasses, doc_count).takeOrdered(TOP_N_FEATURES, lambda (term,score): -score)\n",
    "term_accepted_chi_list = map(lambda (x,y): x, term_accepted_chi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "term_accepted_chi_list[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate term dictionary with just the accepted terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gets a bit slower at the end but finishes eventually \n",
    "term_dictionary = get_term_dictionary(term_accepted_chi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_doc_postings_lists = min_doc_postings_lists.filter(lambda (term, postings): term in term_accepted_chi_list).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_terms = min_doc_postings_lists.count()\n",
    "number_of_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Reduced Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save Postings List\n",
    "# min_doc_postings_lists.map(lambda (term, postings_list): \",\".join([term, json.dumps(postings_list)])).repartition(1).saveAsTextFile(postings_list_output)\n",
    "min_doc_postings_lists.map(lambda postings: json.dumps(postings)).repartition(1).saveAsTextFile(postings_list_chi_selected_output.format(str(TOP_N_FEATURES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start creating term weighting postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf_postings = min_doc_postings_lists\n",
    "tf_doc_index = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in training_documents)\n",
    "\n",
    "sublinear_tf_postings = tf_postings.mapValues(lambda postings: {docId:  calculate_sublinear_tf(tf) for docId, tf in postings.items()}).cache()\n",
    "sublinear_tf_doc_index = create_doc_index(sublinear_tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in training_documents)\n",
    "\n",
    "tf_idf_postings = tf_postings.mapValues(lambda postings: {docId:  calculate_tf_idf(tf, len(postings), doc_count) for docId, tf in postings.items()}).cache()\n",
    "tf_id_doc_index = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in training_documents)\n",
    "\n",
    "# need to collect the document lengths since they are used in the BM25 calculation\n",
    "doc_lengths_rdd = tf_doc_index.mapValues(lambda postings_dictionary: reduce(lambda x, term: x + postings_dictionary[term], postings_dictionary, 0))\n",
    "avg_doc_length = doc_lengths_rdd.map(lambda (term, count): count).reduce(lambda count1, count2: count1 + count2) / doc_count\n",
    "doc_lengths_dict = doc_lengths_rdd.collectAsMap()\n",
    "\n",
    "bm25_postings = tf_postings.mapValues(lambda postings: {docId: calculate_bm25(tf, len(postings), doc_count, doc_lengths_dict[docId], avg_doc_length) for docId, tf in postings.items()}).cache()\n",
    "bm25_doc_index = create_doc_index(bm25_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in training_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf_doc_index_val = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "sublinear_tf_doc_index_val = create_doc_index(sublinear_tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "tf_id_doc_index_val = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "bm25_doc_index_val = create_doc_index(bm25_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_evaluations = {}\n",
    "validation_evaluations = {}\n",
    "\n",
    "i=0\n",
    "for section in sections:\n",
    "    classification = section\n",
    "    i+=1\n",
    "    training_evaluations[classification] = {}\n",
    "    validation_evaluations[classification] = {}\n",
    "    representations_to_test = [(\"tf\", tf_doc_index), (\"tf-sublinear\", sublinear_tf_doc_index), (\"tf-idf\", tf_id_doc_index), (\"bm25\", bm25_doc_index)]\n",
    "    \n",
    "    for name, doc_index in representations_to_test:\n",
    "        docs_with_classes = doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "        training_vectors, svm = train_level(docs_with_classes, classification, number_of_terms)\n",
    "        svm.save(sc, get_model_name(name, classification))\n",
    "        labels = training_vectors.map(lambda p: p.label).collect()\n",
    "        predictions = training_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "        training_evaluations[classification][name] = Evaluator(labels, predictions)\n",
    "        # validation\n",
    "        validation_vectors = get_labeled_points_from_doc_index(doc_index, doc_classification_map, number_of_terms)\n",
    "        labels_val = validation_vectors.map(lambda p: p.label).collect()\n",
    "        predictions_val = validation_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "        validation_evaluations[classification][name] = Evaluator(labels_val, predictions_val)\n",
    "    \n",
    "    rf_postings = tf_postings.mapValues(get_rf_postings(classification))\n",
    "    rf_doc_index = create_doc_index(rf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in training_documents)\n",
    "    docs_with_classes = rf_doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "    training_vectors, svm = train_level(docs_with_classes, classification, number_of_terms)\n",
    "    svm.save(sc, get_model_name(\"rf\", classification))\n",
    "    labels = training_vectors.map(lambda p: p.label).collect()\n",
    "    predictions = training_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "    training_evaluations[classification][\"rf\"] = Evaluator(labels, predictions)\n",
    "    # validation\n",
    "    validation_vectors = get_labeled_points_from_doc_index(doc_index, doc_classification_map, number_of_terms)\n",
    "    labels_val = validation_vectors.map(lambda p: p.label).collect()\n",
    "    predictions_val = validation_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "    validation_evaluations[classification][name] = Evaluator(labels_val, predictions_val)\n",
    "    \n",
    "    \n",
    "    tf_rf_postings = tf_postings.mapValues(get_tf_rf_postings(classification))\n",
    "    tf_rf_doc_index = create_doc_index(tf_rf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in training_documents)\n",
    "    docs_with_classes = tf_rf_doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "    training_vectors, svm = train_level(docs_with_classes, classification, number_of_terms)\n",
    "    svm.save(sc, get_model_name(\"tf-rf\", classification))\n",
    "    labels = training_vectors.map(lambda p: p.label).collect()\n",
    "    predictions = training_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "    training_evaluations[classification][\"tf-rf\"] = Evaluator(labels, predictions)\n",
    "    # validation\n",
    "    validation_vectors = get_labeled_points_from_doc_index(doc_index, doc_classification_map, number_of_terms)\n",
    "    labels_val = validation_vectors.map(lambda p: p.label).collect()\n",
    "    predictions_val = validation_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "    validation_evaluations[classification][name] = Evaluator(labels_val, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coverage_error(test_labeled_points, classifications, method):\n",
    "    test_labeled_points.cache()\n",
    "    y_score = np.zeros(test_labeled_points.count(), len(classifications))\n",
    "    y_true = np.zeros(test_labeled_points.count(), len(classifications))\n",
    "    \n",
    "    i = 0\n",
    "    for classification in classifications:\n",
    "        binarySvm = SVMModel.load(sc, get_model_name(method, classification))\n",
    "        binarySvm.clearThreshold()\n",
    "        predictions = test_labeled_points.map(lambda p: binarySvm.predict(p.features))\n",
    "        labels = test_labeled_points.map(lambda p: p.labels)\n",
    "        y_score[:][i] = predictions\n",
    "        y_true[:][i] = labels\n",
    "    return coverage_error(y_score, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf_doc_index_test = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "sublinear_tf_doc_index_test = create_doc_index(sublinear_tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "tf_id_doc_index_test = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "bm25_doc_index_test = create_doc_index(bm25_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method = \"bm25\"\n",
    "test_vectors = get_labeled_points_from_doc_index(bm25_doc_index_test, doc_classification_map, number_of_terms)\n",
    "get_coverage_error(test_vectors, sections, method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
