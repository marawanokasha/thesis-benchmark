{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False\n",
    "TRAINING_SAMPLE_PERCENTAGE = 0.1\n",
    "MIN_TRAINING_SAMPLES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_SIZE = 3\n",
    "MIN_DOCUMENTS = 5\n",
    "TOP_N_FEATURES = 10000\n",
    "\n",
    "TEST_SET_PERCENTAGE = 0.2\n",
    "VALIDATION_IN_TRAINING_PERCENTAGE = 0.2\n",
    "MIN_DOCUMENTS_FOR_TEST = 1\n",
    "MIN_DOCUMENTS_FOR_VALIDATION = 1\n",
    "\n",
    "MIN_DOCUMENTS_FOR_TRAINING_SAMPLE = 10\n",
    "MIN_DOCUMENTS_FOR_TEST_SAMPLE = 1\n",
    "MIN_DOCUMENTS_FOR_VALIDATION_SAMPLE = 1\n",
    "\n",
    "SVM_ITERATIONS = 10000\n",
    "SVM_CONVERGENCE = 0.01\n",
    "SVM_REG = 0.01\n",
    "\n",
    "BM25_K = 1.5  # controls power of tf component\n",
    "BM25_b = 0.75  # controls the BM25 length normalization\n",
    "\n",
    "RANDOM_SEED = 10000\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer().stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text, doc_id):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    previous_unigram = None\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            elif is_stopword(stem):\n",
    "                stem = None\n",
    "            else:\n",
    "                stem = stemmer(token)\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append((stem,{doc_id: 1}))\n",
    "                # extract bi-grams\n",
    "                if previous_unigram: stems.append((previous_unigram + \" \" + stem,{doc_id: 1}))\n",
    "                previous_unigram = stem\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_stopword(word):\n",
    "  return word in STOP_WORDS\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_postings(postings_list1, postings_list2):\n",
    "    # key could be either a doc id or a term\n",
    "    for key in postings_list2:\n",
    "        if postings_list1.get(key):\n",
    "            postings_list1[key] += postings_list2[key]\n",
    "        else:\n",
    "            postings_list1[key] = postings_list2[key]\n",
    "    return postings_list1\n",
    "\n",
    "def get_term_dictionary(terms):\n",
    "    \"\"\"\n",
    "    Maps string terms to indexes in an array\n",
    "    \"\"\"\n",
    "    term_dictionary = {}\n",
    "    term_array = [None] * len(terms)\n",
    "    def put(key):\n",
    "        hashvalue = hashfunction(key, len(term_array))\n",
    "        if term_array[hashvalue] == None:\n",
    "            term_array[hashvalue] = key\n",
    "            return hashvalue\n",
    "        else:\n",
    "            nextslot = rehash(hashvalue, len(term_array))\n",
    "            while term_array[nextslot] != None:\n",
    "                nextslot = rehash(nextslot, len(term_array))\n",
    "            if term_array[nextslot] == None:\n",
    "                term_array[nextslot] = key\n",
    "                return nextslot\n",
    "    def hashfunction(key, size):\n",
    "        return hash(key) % size\n",
    "    def rehash(oldhash, size):\n",
    "        return (oldhash + 1) % size\n",
    "    i = 0\n",
    "    for term in terms:\n",
    "        corresponding_index = put(term)\n",
    "        term_dictionary[term] = corresponding_index\n",
    "        i+=1\n",
    "        if i%10000 == 0: print \"finished \" + str(i)\n",
    "    return term_dictionary\n",
    "\n",
    "def jsonKV2str(x):\n",
    "    \"\"\"\n",
    "    Change string keys to int\n",
    "    \"\"\"\n",
    "    if isinstance(x, dict):\n",
    "            #return {doc_id:{int(term_id):x[doc_id][term_id] for term_id in x[doc_id]} for doc_id in x }\n",
    "        \n",
    "            return {int(k):(int(v) if isinstance(v, unicode) else v) for k,v in x.items()}\n",
    "    return x\n",
    "\n",
    "def get_json(json_postings):\n",
    "    return json.loads(json_postings)\n",
    "\n",
    "def get_json_convert_num(json_postings):\n",
    "    return json.loads(json_postings, object_hook=jsonKV2str)\n",
    "\n",
    "def get_doc_index(term, postings_list, term_dictionary):\n",
    "    #return [(doc_id, {term: postings_list[doc_id]}) for doc_id in postings_list]\n",
    "    return [(doc_id, {term_dictionary[term]: postings_list[doc_id]}) for doc_id in postings_list]\n",
    "\n",
    "def get_classes(ipc_classification):\n",
    "    sections = []\n",
    "    classes = []\n",
    "    subclasses = []\n",
    "    for classification in ipc_classification:\n",
    "        # we do the check because some documents have repetitions\n",
    "        section_name = classification['section']\n",
    "        class_name = classification['section'] + \"-\" + classification['class']\n",
    "        subclass_name = classification['section'] + \"-\" + classification['class'] + \"-\" + classification['subclass']\n",
    "        if section_name not in sections:\n",
    "            sections.append(section_name)\n",
    "        if class_name not in classes:\n",
    "            classes.append(class_name)\n",
    "        if subclass_name not in subclasses:\n",
    "            subclasses.append(subclass_name)\n",
    "    return {\"sections\": sections, \"classes\": classes, \"subclasses\": subclasses}\n",
    "\n",
    "\n",
    "def get_training_vector_old(classification, term_list, classifications, classification_key_name, number_of_terms):\n",
    "    clss = 1 if classification in classifications[classification_key_name] else 0\n",
    "    return LabeledPoint(clss, SparseVector(number_of_terms, term_list))\n",
    "\n",
    "def get_training_vector(classification, term_list, classifications, number_of_terms):\n",
    "    clss = 1 if classification in classifications else 0\n",
    "    return LabeledPoint(clss, SparseVector(number_of_terms, term_list))\n",
    "\n",
    "\n",
    "def calculate_sublinear_tf(tf):\n",
    "    # laplace smoothing with +1 in case of term with no documents (useful during testing)\n",
    "    return math.log10(1 + tf)\n",
    "\n",
    "\n",
    "def calculate_tf_idf(tf, df, N):\n",
    "    # laplace smoothing with +1 in case of term with no documents (useful during testing)\n",
    "    return tf * math.log10((N+1) / (df + 1))\n",
    "\n",
    "\n",
    "def calculate_bm25(tf, df, N, d_len, d_avg):\n",
    "    idf = max(0, math.log10((N-df + 0.5)/(df+0.5))) # in rare cases where the df is over 50% of N, this could become -ve, so we guard against that\n",
    "    tf_comp = float(((BM25_K + 1) * tf)) / ( BM25_K * ((1-BM25_b) + BM25_b*(float(d_len)/d_avg)) + tf)\n",
    "    return tf_comp * idf\n",
    "\n",
    "\n",
    "def calculate_rf(df_relevant, df_non_relevant):\n",
    "    return math.log( (2 + (float(df_relevant)/max(1, df_non_relevant))), 2)\n",
    "\n",
    "\n",
    "def calculate_tf_rf(tf, df_relevant, df_non_relevant):\n",
    "    return tf * calculate_rf(df_relevant, df_non_relevant)\n",
    "\n",
    "\n",
    "def compare_classifications(x,y):\n",
    "    len_comp = cmp(len(x), len(y))\n",
    "    if len_comp == 0:\n",
    "        return cmp(x,y)\n",
    "    return len_comp\n",
    "\n",
    "\n",
    "def create_doc_index(term_index, term_dictionary):\n",
    "    return term_index \\\n",
    "        .flatMap(lambda (term, postings_list): get_doc_index(term, postings_list, term_dictionary)) \\\n",
    "        .reduceByKey(lambda x, y: merge_postings(x, y))\n",
    "\n",
    "\n",
    "def get_rf_stats(postings, classification):\n",
    "    a_plus_c = set(postings.keys())\n",
    "    a_plus_b = set(classifications_index[classification])\n",
    "    # first intersection is to get (a), second difference is to get (c) (checkout tf-rf paper for reference)\n",
    "    a = a_plus_c.intersection(a_plus_b)\n",
    "    c = a_plus_c.difference(a_plus_b)\n",
    "    size_a = len(a)\n",
    "    size_c = len(c)\n",
    "    return size_a, size_c\n",
    "\n",
    "\n",
    "def get_rf_postings(classification):\n",
    "    def get_rf_postings_internal(postings):\n",
    "        size_a, size_c = get_rf_stats(postings, classification)\n",
    "        return {docId: calculate_rf(size_a, size_c)\n",
    "                for docId, tf in postings.items()}\n",
    "    return get_rf_postings_internal\n",
    "\n",
    "\n",
    "def get_tf_rf_postings(classification):\n",
    "    def get_tf_rf_postings_internal(postings):\n",
    "        size_a, size_c = get_rf_stats(postings, classification)\n",
    "        return {docId: calculate_tf_rf(tf, size_a, size_c)\n",
    "                for docId, tf in postings.items()}\n",
    "    return get_tf_rf_postings_internal\n",
    "\n",
    "\n",
    "def train_level_old(docs_with_classes, classification, classification_label):\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector_old(classification, term_list, classifications,\n",
    "                                                                           classification_label, number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE)\n",
    "    return training_vectors, svm\n",
    "\n",
    "\n",
    "def train_level(docs_with_classes, classification, number_of_terms):\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector(classification, term_list,\n",
    "                                                                           classifications, number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=1000, convergenceTol=SVM_CONVERGENCE, regParam=SVM_REG)\n",
    "    return training_vectors, svm\n",
    "\n",
    "\n",
    "def train_level_new(docs_index, classification, doc_classification_map, number_of_terms):\n",
    "    training_vectors = docs_index.map(\n",
    "        lambda (doc_id, postings): get_training_vector(classification, postings,\n",
    "                                                        doc_classification_map[doc_id], number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=1000, convergenceTol=SVM_CONVERGENCE, regParam=SVM_REG)\n",
    "    return training_vectors, svm\n",
    "\n",
    "\n",
    "def get_error(svm, test_vectors):\n",
    "    labelsAndPreds = test_vectors.map(lambda p: (p.label, svm.predict(p.features)))\n",
    "    trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(test_vectors.count())\n",
    "    return trainErr\n",
    "\n",
    "\n",
    "def train_all(docs_with_classes):\n",
    "    training_errors = {}\n",
    "    for section in sections:\n",
    "        training_vectors, svm = train_level(docs_with_classes, section, \"sections\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[section] = train_err\n",
    "    #\n",
    "    with open(training_errors_output, 'w') as file:\n",
    "        file.write(json.dumps(training_errors))\n",
    "    #\n",
    "    for clss in classes:\n",
    "        training_vectors, svm = train_level(docs_with_classes, clss, \"classes\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[clss] = train_err\n",
    "    \n",
    "    with open(training_errors_output, 'w') as file:\n",
    "        file.write(json.dumps(training_errors))\n",
    "    \n",
    "    for subclass in subclasses:\n",
    "        training_vectors, svm = train_level(docs_with_classes, subclass, \"subclasses\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[subclass] = train_err\n",
    "    return training_errors\n",
    "\n",
    "\n",
    "def get_labeled_points_from_doc_index(doc_index, doc_classification_map, number_of_terms):\n",
    "    docs_with_classes = doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector(classification, term_list,\n",
    "                                                                           classifications, number_of_terms))\n",
    "    return training_vectors\n",
    "\n",
    "\n",
    "get_binary = lambda x: 1 if x > 0 else 0\n",
    "get_binary = np.vectorize(get_binary)\n",
    "\n",
    "def get_row_top_N(y_score_row, y_true_row):\n",
    "    desc_score_indices = np.argsort(y_score_row)[::-1]\n",
    "    # print y_score_row\n",
    "    # print y_true_row\n",
    "    true_indices = np.where(y_true_row ==1)[0]\n",
    "    # print desc_score_indices\n",
    "    found = 0\n",
    "    top_N = 0\n",
    "    for i, score in enumerate(desc_score_indices):\n",
    "        if score in true_indices:\n",
    "            found += 1\n",
    "            if found == len(true_indices):\n",
    "                top_N = i + 1\n",
    "    # print top_N\n",
    "    return top_N\n",
    "\n",
    "class Evaluator:\n",
    "    \n",
    "    def __init__(self, labels, scores, threshold=0.5):\n",
    "        self.threshold = 0\n",
    "        self.count = len(labels)\n",
    "        \n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tn = 0\n",
    "        \n",
    "        for (l,s) in zip(labels,scores):\n",
    "            if self.is_true(l) and self.is_true(s):\n",
    "                self.tp += 1\n",
    "            if self.is_true(l) and not self.is_true(s):\n",
    "                self.fn += 1\n",
    "            if not self.is_true(l) and self.is_true(s):\n",
    "                self.fp += 1\n",
    "            if not self.is_true(l) and not self.is_true(s):\n",
    "                self.tn += 1\n",
    "        self.precision = self.get_precision()\n",
    "        self.recall = self.get_precision()\n",
    "        self.f1 = self.get_f1()\n",
    "        self.error_rate = self.get_error_rate()\n",
    "        \n",
    "    def calculate_contingency(self, label, contingency):\n",
    "        \n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tn = 0\n",
    "        \n",
    "        for (l,s) in zip(labels,scores):\n",
    "            if self.is_true(l) and self.is_true(s):\n",
    "                self.tp += 1\n",
    "            if self.is_true(l) and not self.is_true(s):\n",
    "                self.fn += 1\n",
    "            if not self.is_true(l) and self.is_true(s):\n",
    "                self.fp += 1\n",
    "            if not self.is_true(l) and not self.is_true(s):\n",
    "                self.tn += 1\n",
    "    \n",
    "    def is_true(self, label):\n",
    "        return label > self.threshold\n",
    "    \n",
    "    def get_error_rate(self):\n",
    "        return float(self.tp + self.tn) / len(labels)\n",
    "    \n",
    "    def get_precision(self):\n",
    "        # self.calculate_contingency()\n",
    "        if self.tp == 0: return 0\n",
    "        return float(self.tp) / (self.tp + self.fp)\n",
    "        \n",
    "    def get_recall(self):\n",
    "        # self.calculate_contingency()\n",
    "        if self.tp == 0: return 0\n",
    "        return float(self.tp) / (self.tp + self.fn)\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return 2 * (self.get_precision() * self.get_recall()) / (self.get_precision() + self.get_recall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc = SparkContext(\"\", \"Generate Inverted Index Job\")\n",
    "es_server = \"deka.cip.ifi.lmu.de\"\n",
    "es_port = \"9200\"\n",
    "\n",
    "original_parent_save_location = \"hdfs://deka.cip.ifi.lmu.de/svm/new/\"\n",
    "save_parent_location = original_parent_save_location\n",
    "sample_save_parent_location = save_parent_location + \"sample/\"\n",
    "if IS_SAMPLE: \n",
    "    save_parent_location = save_parent_location + \"sample/\"\n",
    "\n",
    "file_name = \"sample.json\"\n",
    "test_file_name = \"sample.json\"\n",
    "#url = \"/media/Work/workspace/thesis/benchmark/output/\" + file_name\n",
    "sample_location = save_parent_location + file_name\n",
    "sample_test_location = save_parent_location + test_file_name\n",
    "docs_output = save_parent_location + \"docs_output\"\n",
    "postings_list_output = save_parent_location + \"postings_list_full.json\"\n",
    "\n",
    "accepted_terms_list_output = original_parent_save_location + \"accepted_terms_list_{}.pkl\"\n",
    "accepted_terms_with_scores_list_output = original_parent_save_location + \"accepted_terms_with_scores_list_{}.pkl\"\n",
    "postings_list_chi_selected_output = original_parent_save_location + \"postings_list_{}.json\"\n",
    "term_df_map_output = original_parent_save_location + \"term_df_map_output_{}.json\"\n",
    "doc_index_chi_selected_output = original_parent_save_location + \"doc_index_for_postings_{}.json\"\n",
    "term_dictionary_output = original_parent_save_location + \"term_dictionary_{}.pkl\"\n",
    "\n",
    "\n",
    "postings_list_training_chi_selected_output = save_parent_location + \"training_postings_list_{}.json\"\n",
    "postings_list_validation_chi_selected_output = save_parent_location + \"validation_postings_list_{}.json\"\n",
    "postings_list_test_chi_selected_output = save_parent_location + \"test_postings_list_{}.json\"\n",
    "\n",
    "# Classification objects, unrelated to sample size\n",
    "classification_index_output = original_parent_save_location + \"classification_index.pkl\"\n",
    "doc_classification_map_output = original_parent_save_location + \"doc_classification_map.pkl\"\n",
    "sections_output = original_parent_save_location + \"sections.pkl\"\n",
    "classes_output = original_parent_save_location + \"classes.pkl\"\n",
    "subclasses_output = original_parent_save_location + \"subclasses.pkl\"\n",
    "classifications_output = original_parent_save_location + \"classifications.pkl\"\n",
    "doc_lengths_map_output = original_parent_save_location + \"doc_lengths_map.pkl\"\n",
    "# training, validation and test set lists\n",
    "training_docs_list_output = original_parent_save_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_output = original_parent_save_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_output = original_parent_save_location + \"test_docs_list.pkl\"\n",
    "sample_training_docs_list_output = sample_save_parent_location + \"training_docs_list.pkl\"\n",
    "\n",
    "\n",
    "training_predictions_sections_output = save_parent_location + \"training_predictions_sections_list.pkl\"\n",
    "training_labels_sections_list_output = save_parent_location + \"training_labels_sections_list.pkl\"\n",
    "valdiation_predictions_sections_output = save_parent_location + \"validation_predictions_sections_list.pkl\"\n",
    "validation_labels_sections_list_output = save_parent_location + \"validation_labels_sections_list.pkl\"\n",
    "\n",
    "\n",
    "test_postings_list_output = save_parent_location + \"test_postings_list_50000.json\"\n",
    "training_errors_output = save_parent_location + \"training_errors.json\"\n",
    "model_output = save_parent_location + \"models/\" + \"iter_\" + str(SVM_ITERATIONS) + \"_reg_\" + str(SVM_REG) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_name(method, classification, reg=SVM_REG, iterations=SVM_ITERATIONS):\n",
    "    return save_parent_location + \"models/\" + \"iter_\" + str(iterations) + \"_reg_\" + str(reg) + \"/\" + method + \"_\" + classification + \"_model.svm\"\n",
    "def get_data_output_name(method, no_of_features=TOP_N_FEATURES, data_type=\"training\"):\n",
    "    return save_parent_location + \"models/\" + data_type + \"_data/\" + method  + \"_data.json\"\n",
    "def get_data_classification_output_name(method, classification, data_type=\"training\"):\n",
    "    return save_parent_location + \"models/\" + data_type + \"_data/\" + method + \"_\" + classification + \"_data.json\"\n",
    "def get_prediction_output_name(method, data_type=\"training\", subset=\"sections\", reg=SVM_REG, iterations=SVM_ITERATIONS):\n",
    "    return save_parent_location + \"models/\" + \"iter_\" + str(iterations) + \"_reg_\" + str(reg) + \"/\" + method + \"_\" + data_type + \"_\" + subset + \"_predictions.svm\"\n",
    "def get_labels_output_name(data_type=\"training\", subset=\"sections\", reg=SVM_REG, iterations=SVM_ITERATIONS):\n",
    "    return save_parent_location + \"models/\" + \"iter_\" + str(iterations) + \"_reg_\" + str(reg) + \"/\" + data_type + \"_\" + subset + \"_labels.svm\"\n",
    "def get_metrics_output_name(method, data_type=\"training\", subset=\"sections\", reg=SVM_REG, iterations=SVM_ITERATIONS):\n",
    "    return save_parent_location + \"models/\" + \"iter_\" + str(iterations) + \"_reg_\" + str(reg) + \"/\" + method + \"_\" + data_type + \"_\" + subset + \"_metrics.pkl\"\n",
    "def get_save_location(location, sample=False):\n",
    "    if sample:\n",
    "        return location.replace(save_parent_location, sample_save_parent_location)\n",
    "    return location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading document texts from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_text_objs = sc.textFile(docs_output).map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 6.48 s, total: 34.8 s\n",
      "Wall time: 15min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### doc_objs = data.map(lambda x: json.loads(x))\n",
    "\n",
    "doc_class_map = doc_objs.map(lambda (doc_id, doc): (doc_id, get_classes(doc['classification-ipc']))).cache()\n",
    "doc_classification_map = doc_class_map.map(lambda (doc_id, classification_obj): (doc_id, sorted(reduce(lambda x, lst: x + lst, classification_obj.values(), [])))).collectAsMap()\n",
    "doc_count = len(doc_classification_map)\n",
    "# contains [(classification,  list of docs)]\n",
    "# second list comprehension is to get list of lists [[\"A\", \"B\"],[\"A-01\",\"B-03\"]] to one list [\"A\", \"B\", \"A-01\",\"B-03\"], we could have also used a reduce as in doc_classifications_map\n",
    "classifications_index = doc_class_map.flatMap(lambda (doc_id, classifications_obj): [(classification, doc_id) for classification in [classif for cat in classifications_obj.values() for classif in cat]])\\\n",
    "    .groupByKey().map(lambda (classf, classf_docs): (classf, list(set(classf_docs)))).collectAsMap()\n",
    "\n",
    "sections = sorted(doc_class_map.flatMap(lambda (doc_id, classifications): classifications['sections']).distinct().collect())\n",
    "classes = sorted(doc_class_map.flatMap(lambda (doc_id, classifications): classifications['classes']).distinct().collect())\n",
    "subclasses = sorted(doc_class_map.flatMap(lambda (doc_id, classifications): classifications['subclasses']).distinct().collect())\n",
    "classifications = sorted(classifications_index.keys(), cmp=compare_classifications)\n",
    "# classifications = sorted(set(reduce(lambda x, lst: x + lst, map(lambda doc_id: classifications_index[doc_id], classifications_index), [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save classification objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.2 s, sys: 2.54 s, total: 34.8 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sc.parallelize(doc_classification_map.items()).repartition(1).saveAsPickleFile(doc_classification_map_output)\n",
    "sc.parallelize(classifications_index.items()).repartition(1).saveAsPickleFile(classification_index_output)\n",
    "sc.parallelize(sections).repartition(1).saveAsPickleFile(sections_output)\n",
    "sc.parallelize(classes).repartition(1).saveAsPickleFile(classes_output)\n",
    "sc.parallelize(subclasses).repartition(1).saveAsPickleFile(subclasses_output)\n",
    "sc.parallelize(classifications).repartition(1).saveAsPickleFile(classifications_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Classification Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_classification_map = dict(sc.pickleFile(doc_classification_map_output).collect())\n",
    "doc_count = len(doc_classification_map)\n",
    "classifications_index = dict(sc.pickleFile(classification_index_output).collect())\n",
    "sections = sc.pickleFile(sections_output).collect()\n",
    "classes = sc.pickleFile(classes_output).collect()\n",
    "subclasses = sc.pickleFile(subclasses_output).collect()\n",
    "classifications = sc.pickleFile(classifications_output).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accelerates the chi squared calculation a lot\n",
    "classifications_index_set = {k:set(docs) for k,docs in classifications_index.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009750"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'G-20-B', [u'07433566', u'07896523', u'06985663', u'07116477', u'07218441'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_index.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'07007598', [u'B', u'B-30', u'B-30-B'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_classification_map.items()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'A', u'B', u'C', u'D', u'E', u'F', u'G', u'H']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training, Validation and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get min number of documents for any classification\n",
    "min = 1000\n",
    "from collections import defaultdict\n",
    "min_classf = defaultdict(list)\n",
    "for (classf, documents) in classifications_index.items():\n",
    "    if len(documents) == 2: \n",
    "        min = len(documents)\n",
    "        min_classf[classf].append(min)\n",
    "min_classf, min\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min_classf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2235"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classifications_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_documents = set()\n",
    "validation_documents = set()\n",
    "test_documents = set()\n",
    "for (classf, documents) in classifications_index.items():\n",
    "    # only worry about subclasses, classes and sections will be already included\n",
    "    if(classf in sections or classf in classes): pass\n",
    "    \n",
    "    # remove any documents that have already been picked before\n",
    "    docs_set = set(documents)\n",
    "    docs_set-=training_documents\n",
    "    docs_set-=validation_documents\n",
    "    docs_set-=test_documents\n",
    "    \n",
    "    base_test_docs_num = int(len(docs_set)* TEST_SET_PERCENTAGE)\n",
    "    num_test_docs = base_test_docs_num if base_test_docs_num > 0 else MIN_DOCUMENTS_FOR_TEST if MIN_DOCUMENTS_FOR_TEST < len(docs_set) else 0\n",
    "    print len(docs_set), num_test_docs\n",
    "    classif_test_docs = random.sample(docs_set, num_test_docs)\n",
    "    \n",
    "    remaining_docs = docs_set.difference(set(classif_test_docs))\n",
    "    base_validation_docs_num = int(len(remaining_docs)* VALIDATION_IN_TRAINING_PERCENTAGE)\n",
    "    num_validation_docs = base_validation_docs_num if base_validation_docs_num > 0 else MIN_DOCUMENTS_FOR_VALIDATION if MIN_DOCUMENTS_FOR_VALIDATION < len(remaining_docs) else 0\n",
    "    classif_validation_docs = random.sample(remaining_docs, num_validation_docs)\n",
    "    \n",
    "    classif_training_docs = set(remaining_docs).difference(set(classif_validation_docs))\n",
    "    \n",
    "    training_documents.update(classif_training_docs)\n",
    "    validation_documents.update(classif_validation_docs)\n",
    "    test_documents.update(classif_test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the training, validation and test document lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.parallelize(training_documents).saveAsPickleFile(training_docs_list_output)\n",
    "sc.parallelize(validation_documents).saveAsPickleFile(validation_docs_list_output)\n",
    "sc.parallelize(test_documents).saveAsPickleFile(test_docs_list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training, validation and test document lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_documents = sc.pickleFile(training_docs_list_output).collect()\n",
    "validation_documents = sc.pickleFile(validation_docs_list_output).collect()\n",
    "test_documents = sc.pickleFile(test_docs_list_output).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401877"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SAMPLE_PERCENTAGE = 0.03\n",
    "sample_training_documents = set()\n",
    "i = 0\n",
    "for (classf, documents) in classifications_index.items():\n",
    "    if len(documents) > MIN_TRAINING_SAMPLES:\n",
    "        base_sample_docs_len = int(len(documents)* TRAINING_SAMPLE_PERCENTAGE)\n",
    "        num_sample_docs = base_sample_docs_len if base_sample_docs_len > 0 else MIN_TRAINING_SAMPLES\n",
    "        #print \"%s: Total %d, sample: %d\" % (classf, len(documents), num_sample_docs)\n",
    "        classif_training_docs = random.sample(documents, num_sample_docs)\n",
    "        \n",
    "        sample_training_documents.update(set(classif_training_docs))\n",
    "    else:\n",
    "        sample_training_documents.update(documents)\n",
    "    i+=1\n",
    "    \n",
    "    #if i > 100: break\n",
    "len(sample_training_documents)\n",
    "sc.parallelize(sample_training_documents).saveAsPickleFile(sample_training_docs_list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_training_documents = sc.pickleFile(sample_training_docs_list_output).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_documents = sample_training_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for classif in sorted(classifications_index.keys()):\n",
    "    if len(classif) == 1:\n",
    "        print \"%s : %d, %.3f\" % (classif, len(set(classifications_index[classif])), float(len(classifications_index[classif]))/doc_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "overlap_df = pd.DataFrame({section: [0]*len(sections) for section in sections} , index=sections, columns=sections)\n",
    "for doc_id in doc_classification_map:\n",
    "    for classif in doc_classification_map[doc_id]:\n",
    "        if len(classif) == 1:\n",
    "            for classif2 in doc_classification_map[doc_id]:\n",
    "                if len(classif2) == 1:\n",
    "                    overlap_df[classif][classif2] += 1\n",
    "overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.colors.Normalize(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlap_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8), dpi=120)\n",
    "#ax = fig.add_subplot(111, frameon=True, xticks=[], yticks=[])\n",
    "vals = overlap_df.values\n",
    "normal = mpl.colors.Normalize()\n",
    "normal = mpl.colors.Normalize(vals.min()-1, vals.max()+vals.max()/2)\n",
    "formatter = lambda x: \"{:,d}\".format(int(x))\n",
    "\n",
    "the_table=plt.table(cellText=np.vectorize(formatter)(vals), rowLabels=overlap_df.index, colLabels=overlap_df.columns, \n",
    "                    colWidths = [0.1]*(vals.shape[1]+3), loc='center',\n",
    "                    cellColours=plt.cm.YlGn(normal(vals)))\n",
    "the_table.set_fontsize(30)\n",
    "the_table.scale(2, 4)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Create Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# Create Postings List (old one)\n",
    "#postings_lists = doc_text_objs.flatMap(lambda (doc_id, doc): stemtokenizer(doc['description'], doc_id)).reduceByKey(lambda x,y: merge_postings(x,y))\n",
    "### postings_lists = doc_objs.flatMap(lambda x: stemtokenizer(x['description'], x['id'])).reduceByKey(lambda x,y: merge_postings(x,y))\n",
    "#min_doc_postings_lists = postings_lists.filter(lambda (x,y): len(y) > MIN_DOCUMENTS)\n",
    "#number_of_terms = min_doc_postings_lists.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create Postings List\n",
    "postings_lists = doc_text_objs.flatMap(lambda (doc_id, doc): stemtokenizer(doc, doc_id)).reduceByKey(lambda x,y: merge_postings(x,y))\n",
    "### postings_lists = doc_objs.flatMap(lambda x: stemtokenizer(x['description'], x['id'])).reduceByKey(lambda x,y: merge_postings(x,y))\n",
    "min_doc_postings_lists = postings_lists.filter(lambda (x,y): len(y) > MIN_DOCUMENTS)\n",
    "#number_of_terms = min_doc_postings_lists.count()\n",
    "\n",
    "# min_doc_postings_lists.map(lambda (term, postings_list): \",\".join([term, json.dumps(postings_list)])).repartition(1).saveAsTextFile(postings_list_output)\n",
    "min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(postings_list_output)\n",
    "\n",
    "def get_chi_index(term_index, classifications_index, subclasses, number_of_docs):\n",
    "    return term_index.map(lambda (term, postings_list): (term, calculate_chi_squared(postings_list.keys(), classifications_index, subclasses, number_of_docs)))\n",
    "\n",
    "def calculate_chi_squared(document_list, classifications_index, subclasses, number_of_docs):\n",
    "    chi_score = 0\n",
    "    for subclass in subclasses:\n",
    "        Nt1 = len(document_list) # actual collection frequency of having the word\n",
    "        Nt0 = number_of_docs - len(document_list) # actual collection frequency of not having the word\n",
    "        Pt1 = float(len(document_list))/ number_of_docs\n",
    "        Pt0 = float(number_of_docs - len(document_list))/ number_of_docs\n",
    "        Pc1 = float(len(classifications_index[subclass]))/ number_of_docs\n",
    "        Et1c1 = Pt1 * Pc1 * number_of_docs # expected frequency of docs in subclass with term (assuming independence)\n",
    "        Et0c1 = Pt0 * Pc1 * number_of_docs # expected frequency of docs in subclass without term (assuming independence)\n",
    "        chi_score += math.pow( Nt1 - Et1c1, 2) / Et1c1 \n",
    "        chi_score += math.pow( Nt0 - Et0c1, 2) / Et0c1\n",
    "    return chi_score\n",
    "\n",
    "term_accepted_chi_list = get_chi_index(min_doc_postings_lists, classifications_index, subclasses, doc_count).takeOrdered(TOP_N_FEATURES, lambda (term,score): -score)\n",
    "term_accepted_chi_list = map(lambda (x,y): x, term_accepted_chi_list)\n",
    "\n",
    "# gets a bit slower at the end but finishes eventually \n",
    "term_dictionary = get_term_dictionary(term_accepted_chi_list)\n",
    "\n",
    "min_doc_postings_lists = min_doc_postings_lists.filter(lambda (term, postings): term in term_accepted_chi_list).cache()\n",
    "\n",
    "number_of_terms = min_doc_postings_lists.count()\n",
    "number_of_terms\n",
    "\n",
    "min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(postings_list_chi_selected_output.format(str(TOP_N_FEATURES)))\n",
    "sc.parallelize(term_dictionary.items()).saveAsPickleFile(term_dictionary_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Document Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_lengths_dict = doc_text_objs.map(lambda (doc_id, document_text): (doc_id, len(document_text))).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_doc_length = sum(doc_lengths_dict.values())/len(doc_lengths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'08369259', 85861)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_lengths_dict.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46477"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_doc_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save Postings List\n",
    "# min_doc_postings_lists.map(lambda (term, postings_list): \",\".join([term, json.dumps(postings_list)])).repartition(1).saveAsTextFile(postings_list_output)\n",
    "min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(postings_list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Postings Lists\n",
    "min_doc_postings_lists = sc.textFile(postings_list_output).map(lambda json_postings: json.loads(json_postings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_chi_index(term_index, classifications_index_set, subclasses, number_of_docs):\n",
    "    return term_index.map(lambda (term, postings_list): (term, calculate_chi_squared(postings_list.keys(), classifications_index_set, subclasses, number_of_docs)))\n",
    "\n",
    "def calculate_chi_squared(document_list, classifications_index_set, subclasses, number_of_docs):\n",
    "    \"\"\"\n",
    "    Chi squared is the ratio of the difference between actual frequency and expected frequency of a term relative to the expected frequency\n",
    "    summed up across all classes and whether the term appears or not\n",
    "    Here we calculate the average chi squared score which is one of two options in multi-lable classification (the other being max)\n",
    "    \"\"\"\n",
    "#     chi_score = 0\n",
    "#     Nt1 = len(document_list) # actual collection frequency of having the word\n",
    "#     Nt0 = number_of_docs - len(document_list) # actual collection frequency of not having the word\n",
    "#     Pt1 = float(len(document_list))/ number_of_docs # probability of the term happening\n",
    "#     Pt0 = float(number_of_docs - len(document_list))/ number_of_docs # probablility of the term not happening\n",
    "#     print \"Docs Stats: Term present in %d (%.7f), Not Present in %d (%.7f) \" % (Nt1, Pt1, Nt0, Pt0)\n",
    "#     for subclass in subclasses:\n",
    "#         Pc1 = float(len(classifications_index[subclass]))/ number_of_docs # probability of the class happening\n",
    "#         Et1c1 = Pt1 * Pc1 * number_of_docs # expected frequency of docs in subclass with term (assuming independence)\n",
    "#         Et0c1 = Pt0 * Pc1 * number_of_docs # expected frequency of docs in subclass without term (assuming independence)\n",
    "#         chi_score += float(math.pow( Nt1 - Et1c1, 2)) / Et1c1\n",
    "#         chi_score += float(math.pow( Nt0 - Et0c1, 2)) / Et0c1\n",
    "#         print \"subclass %s: %.7f, %d, %d, %.7f\" % (subclass, Pc1, Et1c1, Et0c1, chi_score)\n",
    "#     return chi_score\n",
    "    chi_score = 0\n",
    "    N = len(document_list)\n",
    "    doc_set = set(document_list)\n",
    "    Nt1 = N # actual collection frequency of having the word\n",
    "    Nt0 = number_of_docs - N # actual collection frequency of not having the word\n",
    "    Pt1 = float(N)/ number_of_docs # probability of the term happening\n",
    "    Pt0 = float(number_of_docs - N)/ number_of_docs # probablility of the term not happening\n",
    "    #print \"Docs Stats: Term present in %d (%.7f), Not Present in %d (%.7f) \" % (Nt1, Pt1, Nt0, Pt0)\n",
    "    for subclass in subclasses:\n",
    "        Pc1 = float(len(classifications_index_set[subclass]))/ number_of_docs # probability of the class happening\n",
    "        Pc0 = 1 - Pc1\n",
    "        Pt1c1 = float(len(doc_set & classifications_index_set[subclass])) / number_of_docs\n",
    "        Pt1c0 = Pt1 - Pt1c1\n",
    "        Pt0c1 = Pc1 - Pt1c1\n",
    "        Pt0c0 = 1 - Pt1c0 - Pt0c1 - Pt1c1\n",
    "        \n",
    "        cat_chi_score = (number_of_docs * math.pow(Pt1c1 * Pt0c0 - Pt1c0 * Pt0c1, 2))/(Pt1 * Pt0 * Pc1 * Pc0)\n",
    "        # calculate average chi score\n",
    "        chi_score += Pc1 * cat_chi_score\n",
    "        #print \"subclass %s: %.7f, %.7f, %.7f, %.7f, %.7f, %.7f\" % (subclass, Pc1, Pt1c1, Pt1c0, Pt0c1, Pt0c0, chi_score)\n",
    "    return chi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44846888"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_doc_postings_lists.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min_doc_postings_lists = sc.parallelize(min_doc_postings_lists.take(10000))\n",
    "\n",
    "# term_accepted_chi_list_with_scores = get_chi_index(min_doc_postings_lists, classifications_index, subclasses, doc_count).takeOrdered(TOP_N_FEATURES, lambda (term,score): -score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order by Chi Squared and get Top features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate term dictionary with just the accepted terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 10000\n"
     ]
    }
   ],
   "source": [
    "# gets a bit slower at the end but finishes eventually \n",
    "term_dictionary = get_term_dictionary(term_accepted_chi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_doc_postings_lists = min_doc_postings_lists.filter(lambda (term, postings): term in term_accepted_chi_list).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_terms = min_doc_postings_lists.count()\n",
    "number_of_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Reduced Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save Postings List\n",
    "## min_doc_postings_lists.map(lambda (term, postings_list): \",\".join([term, json.dumps(postings_list)])).repartition(1).saveAsTextFile(postings_list_output)\n",
    "min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(postings_list_chi_selected_output.format(str(TOP_N_FEATURES)))\n",
    "#sc.parallelize(term_dictionary.items()).saveAsPickleFile(term_dictionary_output)\n",
    "#sc.parallelize(term_accepted_chi_list).saveAsPickleFile(accepted_terms_list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Reduced Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-89dbcbd1ab08>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-89dbcbd1ab08>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    term_dictionary = dict(sc.pickleFile(term_dictionary_output).collect())\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "min_doc_postings_lists = sc.textFile(postings_list_chi_selected_output.format(str(TOP_N_FEATURES)).map(lambda json_postings: json.loads(json_postings)).cache()\n",
    "term_dictionary = dict(sc.pickleFile(term_dictionary_output).collect())\n",
    "number_of_terms = min_doc_postings_lists.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect document lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to collect the document lengths since they are used in the BM25 calculation\n",
    "all_doc_index = create_doc_index(min_doc_postings_lists, term_dictionary)\n",
    "\n",
    "doc_lengths_rdd = all_doc_index.mapValues(lambda postings_dictionary: reduce(lambda x, term: x + postings_dictionary[term], postings_dictionary, 0))\n",
    "avg_doc_length = doc_lengths_rdd.map(lambda (term, count): count).reduce(lambda count1, count2: count1 + count2) / doc_count\n",
    "doc_lengths_dict = doc_lengths_rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_doc_index.map(lambda postings: json.dumps(postings)).saveAsTextFile(doc_index_chi_selected_output.format(str(TOP_N_FEATURES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Document Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.parallelize(doc_lengths_dict.items()).saveAsPickleFile(doc_lengths_map_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_doc_index.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_doc_index.saveAsPickleFile(doc_index_chi_selected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Document Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_lengths_dict = dict(sc.pickleFile(doc_lengths_map_output).collect())\n",
    "avg_doc_length = sum(doc_lengths_dict.values())/len(doc_lengths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'08226314', 3466)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_lengths_dict.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009750"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_lengths_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load everything for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_doc_postings_lists = sc.textFile(postings_list_chi_selected_output.format(str(TOP_N_FEATURES))).map(lambda json_postings: json.loads(json_postings)).cache()\n",
    "term_dictionary = dict(sc.pickleFile(term_dictionary_output.format(str(TOP_N_FEATURES))).collect())\n",
    "term_df_map = dict(sc.pickleFile(term_df_map_output.format(str(TOP_N_FEATURES))).collect())\n",
    "number_of_terms = len(term_dictionary)\n",
    "doc_lengths_dict = dict(sc.pickleFile(doc_lengths_map_output).collect())\n",
    "avg_doc_length = sum(doc_lengths_dict.values())/len(doc_lengths_dict)\n",
    "#all_doc_index = sc.textFile(doc_index_chi_selected_output.format(str(TOP_N_FEATURES))).map(lambda json_postings: json.loads(json_postings)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_doc_index = all_doc_index.map(lambda (doc_id, postings): (doc_id, {int(key): postings[key] for key in postings})).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get min_doc_postings_lists for the sample only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_docs_set = set(training_documents)\n",
    "validation_docs_set = set(validation_documents)\n",
    "test_docs_set = set(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_doc_postings_lists = sc.textFile(postings_list_chi_selected_output.format(str(TOP_N_FEATURES))).map(lambda json_postings: json.loads(json_postings)).cache()\n",
    "min_doc_postings_lists = min_doc_postings_lists.map(lambda (term, postings): (term, {doc_id:postings[doc_id] for doc_id in postings if doc_id in training_docs_set or doc_id in validation_docs_set or doc_id in test_docs_set}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(get_save_location(postings_list_chi_selected_output.format(str(TOP_N_FEATURES)), sample=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_postings_output = get_save_location(postings_list_training_chi_selected_output.format(str(TOP_N_FEATURES)), sample=IS_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_min_doc_postings_lists = min_doc_postings_lists.map(lambda (term, postings): (term, {doc_id:postings[doc_id] for doc_id in postings if doc_id in training_docs_set}))\n",
    "training_min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(training_postings_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_min_doc_postings_lists = sc.textFile(training_postings_output).map(get_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_postings_output = get_save_location(postings_list_validation_chi_selected_output.format(str(TOP_N_FEATURES)), sample=IS_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hdfs://deka.cip.ifi.lmu.de/svm/new/validation_postings_list_10000.json'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_postings_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_min_doc_postings_lists = min_doc_postings_lists.map(lambda (term, postings): (term, {doc_id:postings[doc_id] for doc_id in postings if doc_id in validation_docs_set}))\n",
    "validation_min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(validation_postings_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_min_doc_postings_lists = sc.textFile(validation_postings_output).map(get_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_postings_output = get_save_location(postings_list_test_chi_selected_output.format(str(TOP_N_FEATURES)), sample=IS_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_min_doc_postings_lists = min_doc_postings_lists.map(lambda (term, postings): (term, {doc_id:postings[doc_id] for doc_id in postings if doc_id in test_docs_set}))\n",
    "test_min_doc_postings_lists.map(lambda postings: json.dumps(postings)).saveAsTextFile(test_postings_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_min_doc_postings_lists = sc.textFile(test_postings_output).map(get_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start creating term weighting postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_written_doc_index(term_index, name, data_type=\"training\"):\n",
    "    doc_index = create_doc_index(term_index, term_dictionary)\n",
    "    output_name = get_data_output_name(name, data_type=data_type).replace(\"training_data\", \"training_data_corrected\")\n",
    "    doc_index.map(lambda postings: json.dumps(postings)).repartition(100).saveAsTextFile(output_name)\n",
    "    doc_index = sc.textFile(output_name).map(get_json_convert_num).cache()\n",
    "    return doc_index\n",
    "\n",
    "def read_written_doc_index(name, data_type=\"training\"):\n",
    "    output_name = get_data_output_name(name, data_type=data_type)\n",
    "    doc_index = sc.textFile(output_name).map(get_json_convert_num)\n",
    "    return doc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hdfs://deka.cip.ifi.lmu.de/svm/new/models/training_data_corrected/tf_data.json'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name = get_data_output_name(\"tf\", data_type=\"training\").replace(\"training_data\", \"training_data_corrected\")\n",
    "output_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create TrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.5 s, sys: 1.37 s, total: 31.8 s\n",
      "Wall time: 11h 16min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf_postings = training_min_doc_postings_lists\n",
    "tf_doc_index_training = create_written_doc_index(tf_postings, \"tf\")\n",
    "\n",
    "sublinear_tf_postings = tf_postings.mapValues(lambda postings: {docId:  calculate_sublinear_tf(tf) for docId, tf in postings.items()})\n",
    "sublinear_tf_doc_index_training = create_written_doc_index(sublinear_tf_postings, \"tf-sublinear\")\n",
    "\n",
    "tf_idf_postings = tf_postings.mapValues(lambda postings: {docId:  calculate_tf_idf(tf, len(postings), doc_count) for docId, tf in postings.items()})\n",
    "tf_idf_doc_index_training = create_written_doc_index(tf_idf_postings, \"tf-idf\")\n",
    "\n",
    "bm25_postings = tf_postings.mapValues(lambda postings: {docId: calculate_bm25(tf, len(postings), doc_count, doc_lengths_dict[docId], avg_doc_length) for docId, tf in postings.items()})\n",
    "bm25_doc_index_training = create_written_doc_index(bm25_postings, \"bm25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_doc_index_training = read_written_doc_index(\"tf\")\n",
    "sublinear_tf_doc_index_training = read_written_doc_index(\"tf-sublinear\")\n",
    "tf_idf_doc_index_training = read_written_doc_index(\"tf-idf\")\n",
    "bm25_doc_index_training = read_written_doc_index(\"bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hdfs://deka.cip.ifi.lmu.de/svm/new/models/training_data_repartitioned/tf_data.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_output_name(\"tf\").replace(\"training_data\", \"training_data_repartitioned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sublinear_tf_doc_index_training.map(lambda postings: json.dumps(postings)).repartition(100).saveAsTextFile(get_data_output_name(\"tf-sublinear\").replace(\"training_data\", \"training_data_repartitioned\"))\n",
    "tf_idf_doc_index_training.map(lambda postings: json.dumps(postings)).repartition(100).saveAsTextFile(get_data_output_name(\"tf-idf\").replace(\"training_data\", \"training_data_repartitioned\"))\n",
    "bm25_doc_index_training.map(lambda postings: json.dumps(postings)).repartition(100).saveAsTextFile(get_data_output_name(\"bm25\").replace(\"training_data\", \"training_data_repartitioned\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 1.93 s, total: 28.9 s\n",
      "Wall time: 4h 56min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf_postings_validation = validation_min_doc_postings_lists\n",
    "tf_doc_index_validation = create_written_doc_index(tf_postings_validation, \"tf\", data_type=\"validation\")\n",
    "\n",
    "sublinear_tf_postings_validation = tf_postings_validation.mapValues(lambda postings: {docId:  calculate_sublinear_tf(tf) for docId, tf in postings.items()})\n",
    "sublinear_tf_doc_index_validation = create_written_doc_index(sublinear_tf_postings_validation, \"tf-sublinear\", data_type=\"validation\")\n",
    "\n",
    "tf_idf_postings_validation = tf_postings_validation.mapValues(lambda postings: {docId:  calculate_tf_idf(tf, len(postings), doc_count) for docId, tf in postings.items()})\n",
    "tf_idf_doc_index_validation = create_written_doc_index(tf_idf_postings_validation, \"tf-idf\", data_type=\"validation\")\n",
    "\n",
    "bm25_postings_validation = tf_postings_validation.mapValues(lambda postings: {docId: calculate_bm25(tf, len(postings), doc_count, doc_lengths_dict[docId], avg_doc_length) for docId, tf in postings.items()})\n",
    "bm25_doc_index_validation = create_written_doc_index(bm25_postings_validation, \"bm25\", data_type=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_doc_index_validation = read_written_doc_index(\"tf\", data_type=\"validation\")\n",
    "sublinear_tf_doc_index_validation = read_written_doc_index(\"tf-sublinear\", data_type=\"validation\")\n",
    "tf_idf_doc_index_validation = read_written_doc_index(\"tf-idf\", data_type=\"validation\")\n",
    "bm25_doc_index_validation = read_written_doc_index(\"bm25\", data_type=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'oooidii', {3: 4}], [u'232323', {3: 2}]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jsonKV2str(x):\n",
    "    if isinstance(x, dict):\n",
    "            return {int(k):(int(v) if isinstance(v, unicode) else v) for k,v in x.items()}\n",
    "    return x\n",
    "\n",
    "output_namee = \"hdfs://deka.cip.ifi.lmu.de/svm/new/lskd4.json\"\n",
    "dd = {\"232323\":{3:2},\"oooidii\": {3:4}}\n",
    "#sc.parallelize(dd.items()).take(1)\n",
    "#sc.parallelize(dd.items()).map(lambda postings: json.dumps(postings)).saveAsTextFile(output_namee)\n",
    "sc.parallelize(dd.items()).map(lambda postings: json.dumps(postings)).take(1)\n",
    "sc.parallelize(dd.items()).map(lambda postings: json.dumps(postings)).map(lambda postings: json.loads(postings, object_hook=jsonKV2str)).collect()\n",
    "\n",
    "#map(json.dumps,dd.items() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf_doc_index_validation.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(doc_classification_map, open('/big/s/shalaby/exported_data_non_spark_format/doc_classification_map.pkl','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(sections, open('/big/s/shalaby/exported_data_non_spark_format/sections.pkl','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_evaluations = {}\n",
    "validation_evaluations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_exists(path):\n",
    "    try:\n",
    "        model = SVMModel.load(sc, path)\n",
    "        return True;\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Trying: tf\n",
      "Model Exists\n",
      "Trying: tf-sublinear\n",
      "Model Exists\n",
      "Trying: tf-idf\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for section in sections:\n",
    "    classification = section\n",
    "    print classification\n",
    "    #if classification == \"A\" or classification == \"B\" or classification == \"C\" or classification == \"D\": continue\n",
    "    i+=1\n",
    "    training_evaluations[classification] = {}\n",
    "    validation_evaluations[classification] = {}\n",
    "    representations_to_test = [\n",
    "                               (\"tf\", tf_doc_index_training, tf_doc_index_validation), \n",
    "                               (\"tf-sublinear\", sublinear_tf_doc_index_training, sublinear_tf_doc_index_validation), \n",
    "                               (\"tf-idf\", tf_idf_doc_index_training, tf_idf_doc_index_validation), \n",
    "                               (\"bm25\", bm25_doc_index_training, bm25_doc_index_validation)]\n",
    "    #representations_to_test = [(\"tf\", tf_doc_index), (\"tf-sublinear\", sublinear_tf_doc_index), (\"tf-idf\", tf_id_doc_index), (\"bm25\", bm25_doc_index)]\n",
    "    \n",
    "    for name, doc_index, val_doc_index in representations_to_test:\n",
    "        try:\n",
    "            print \"Trying: \" + name\n",
    "            model_path = get_model_name(name, classification)\n",
    "            if not model_exists(model_path):\n",
    "                training_vectors, svm = train_level_new(doc_index, classification, doc_classification_map, number_of_terms)\n",
    "                svm.save(sc, model_path)\n",
    "            else:\n",
    "                print \"Model Exists\"\n",
    "        except:\n",
    "            print \"Problem creating: %s: %s\" % (classification, name)\n",
    "            continue\n",
    "#         print \"Trying: \" + name\n",
    "#         docs_with_classes = doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "#         training_vectors, svm = train_level(docs_with_classes, classification, number_of_terms)\n",
    "#         svm.save(sc, get_model_name(name, classification))\n",
    "#         labels = training_vectors.map(lambda p: p.label).collect()\n",
    "#         predictions = training_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "#         training_evaluations[classification][name] = Evaluator(labels, predictions)\n",
    "#         # validation\n",
    "#         print \"Validating\"\n",
    "#         validation_vectors = get_labeled_points_from_doc_index(val_doc_index, doc_classification_map, number_of_terms)\n",
    "#         labels_val = validation_vectors.map(lambda p: p.label).collect()\n",
    "#         predictions_val = validation_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "#         validation_evaluations[classification][name] = Evaluator(labels_val, predictions_val)\n",
    "    \n",
    "#     rf_postings = tf_postings.mapValues(get_rf_postings(classification))\n",
    "#     rf_doc_index = create_doc_index(rf_postings, term_dictionary)\n",
    "#     # save the doc index so we don't have to create it again\n",
    "#     rf_doc_index.map(lambda postings: json.dumps(postings)).saveAsTextFile(get_data_classification_output_name(\"rf\", classification))\n",
    "#     rf_doc_index_training = rf_doc_index.filter(lambda (doc_id, postings): doc_id in training_documents)\n",
    "#     rf_doc_index_val = rf_doc_index.filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "#     docs_with_classes = rf_doc_index_training.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "#     training_vectors, svm = train_level(docs_with_classes, classification, number_of_terms)\n",
    "#     svm.save(sc, get_model_name(\"rf\", classification))\n",
    "#     labels = training_vectors.map(lambda p: p.label).collect()\n",
    "#     predictions = training_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "#     training_evaluations[classification][\"rf\"] = Evaluator(labels, predictions)\n",
    "#     # validation\n",
    "#     validation_vectors = get_labeled_points_from_doc_index(rf_doc_index_val, doc_classification_map, number_of_terms)\n",
    "#     labels_val = validation_vectors.map(lambda p: p.label).collect()\n",
    "#     predictions_val = validation_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "#     validation_evaluations[classification][name] = Evaluator(labels_val, predictions_val)\n",
    "    \n",
    "    \n",
    "#     tf_rf_postings = tf_postings.mapValues(get_tf_rf_postings(classification))\n",
    "#     tf_rf_doc_index = create_doc_index(tf_rf_postings, term_dictionary)\n",
    "#     # save the doc index so we don't have to create it again\n",
    "#     tf_rf_doc_index.map(lambda postings: json.dumps(postings)).saveAsTextFile(get_data_classification_output_name(\"tf-rf\", classification))\n",
    "#     tf_rf_doc_index_training = tf_rf_doc_index.filter(lambda (doc_id, postings): doc_id in training_documents)\n",
    "#     tf_rf_doc_index_val = tf_rf_doc_index.filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "#     docs_with_classes = tf_rf_doc_index_training.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "#     training_vectors, svm = train_level(docs_with_classes, classification, number_of_terms)\n",
    "#     svm.save(sc, get_model_name(\"tf-rf\", classification))\n",
    "#     labels = training_vectors.map(lambda p: p.label).collect()\n",
    "#     predictions = training_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "#     training_evaluations[classification][\"tf-rf\"] = Evaluator(labels, predictions)\n",
    "#     # validation\n",
    "#     validation_vectors = get_labeled_points_from_doc_index(tf_rf_doc_index_val, doc_classification_map, number_of_terms)\n",
    "#     labels_val = validation_vectors.map(lambda p: p.label).collect()\n",
    "#     predictions_val = validation_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "#     validation_evaluations[classification][name] = Evaluator(labels_val, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_exists(get_model_name(\"tf\", \"A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_evaluations = {}\n",
    "validation_evaluations = {}\n",
    "\n",
    "classification = \"A-01\"\n",
    "\n",
    "training_evaluations[classification] = {}\n",
    "validation_evaluations[classification] = {}\n",
    "representations_to_test = [\n",
    "    (\"tf\", tf_doc_index_training, tf_doc_index_validation),\n",
    "#     (\"tf-sublinear\", sublinear_tf_doc_index_training, sublinear_tf_doc_index_validation), \n",
    "#     (\"bm25\", bm25_doc_index_training, bm25_doc_index_validation),\n",
    "#     (\"tf-idf\", tf_idf_doc_index_training, tf_idf_doc_index_validation)\n",
    "]\n",
    "name, doc_index, val_doc_index = representations_to_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#doc_index.map(lambda postings: json.dumps(postings)).saveAsTextFile(get_data_output_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying: tf\n"
     ]
    }
   ],
   "source": [
    "print \"Trying: \" + name\n",
    "docs_with_classes = doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "training_vectors, svm = train_level(docs_with_classes, classification, number_of_terms)\n",
    "svm.save(sc, get_model_name(name, classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector(classification, term_list,\n",
    "                                                                           classifications, number_of_terms))\n",
    "svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE, regParam=SVM_REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = training_vectors.map(lambda p: p.label).collect()\n",
    "predictions = training_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "training_evaluations[classification][name] = Evaluator(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "print \"Validating\"\n",
    "validation_vectors = get_labeled_points_from_doc_index(val_doc_index, doc_classification_map, number_of_terms)\n",
    "labels_val = validation_vectors.map(lambda p: p.label).collect()\n",
    "predictions_val = validation_vectors.map(lambda p: svm.predict(p.features)).collect()\n",
    "validation_evaluations[classification][name] = Evaluator(labels_val, predictions_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321473\n",
      "A\n",
      "Loaded the model\n",
      "B\n",
      "Loaded the model\n",
      "C\n",
      "Loaded the model\n",
      "D\n",
      "Loaded the model\n",
      "E\n",
      "Loaded the model\n",
      "F\n",
      "Loaded the model\n",
      "G\n",
      "Loaded the model\n",
      "H\n",
      "Loaded the model\n"
     ]
    }
   ],
   "source": [
    "representations_to_test = [\n",
    "#    (\"tf\", tf_doc_index_validation), \n",
    "#    (\"tf-sublinear\", sublinear_tf_doc_index_validation), \n",
    "#    (\"tf-idf\", tf_idf_doc_index_validation), \n",
    "   (\"bm25\", bm25_doc_index_validation)\n",
    "]\n",
    "method = representations_to_test[0][0]\n",
    "val_doc_set = representations_to_test[0][1]\n",
    "val_doc_set.cache()\n",
    "doc_count = len(validation_documents)\n",
    "print doc_count\n",
    "y_score = np.zeros((doc_count, len(sections)))\n",
    "y_true = np.zeros((doc_count, len(sections)))\n",
    "i=0\n",
    "\n",
    "for section in sections:\n",
    "    print section\n",
    "    classification = section\n",
    "    val_doc_set_vectors = val_doc_set.map(lambda (doc_id, postings): \n",
    "                                          get_training_vector(classification, postings, doc_classification_map[doc_id], \n",
    "                                                              number_of_terms) )\n",
    "    \n",
    "    binarySvm = SVMModel.load(sc, get_model_name(method, classification))\n",
    "    print \"Loaded the model\"\n",
    "    binarySvm.clearThreshold()\n",
    "    labels_predictions = val_doc_set_vectors.map(lambda p: (p.label, binarySvm.predict(p.features))).collect()\n",
    "    #labels = test_labeled_points.map(lambda p: p.labels)\n",
    "    y_true[:,i] = [label_pred[0] for label_pred in labels_predictions]\n",
    "    y_score[:,i] = [label_pred[1] for label_pred in labels_predictions]\n",
    "    i+=1\n",
    "y_binary_score = get_binary(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.parallelize(y_true).repartition(1).saveAsPickleFile(get_labels_output_name(data_type=\"validation\", subset=\"sections\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.parallelize(y_score).repartition(1).saveAsPickleFile(get_prediction_output_name(method=method, data_type=\"validation\", subset=\"sections\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true_loaded = sc.pickleFile(get_labels_output_name(data_type=\"validation\", subset=\"sections\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true_loaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d8fd36733672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true_loaded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true_loaded' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(np.array(y_true_loaded)[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(y_binary_score)[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321473,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321473, 8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_binary_score):\n",
    "    metrics = {}\n",
    "    metrics['coverage_error'] = coverage_error(y_binary_score, y_true)\n",
    "    metrics['average_num_of_labels'] = np.sum(np.sum(y_true, axis=1))/y_true.shape[0]\n",
    "    metrics['average_precision_micro'] = sklearn.metrics.average_precision_score(y_true, y_binary_score, average='micro')\n",
    "    metrics['average_precision_macro'] = sklearn.metrics.average_precision_score(y_true, y_binary_score, average='macro')\n",
    "    metrics['precision_micro'] = sklearn.metrics.precision_score(y_true, y_binary_score, average='micro')\n",
    "    metrics['precision_macro'] = sklearn.metrics.precision_score(y_true, y_binary_score, average='macro')\n",
    "    metrics['recall_micro'] = sklearn.metrics.recall_score(y_true, y_binary_score, average='micro')\n",
    "    metrics['recall_macro'] = sklearn.metrics.recall_score(y_true, y_binary_score, average='macro')\n",
    "    metrics['f1_micro'] = sklearn.metrics.f1_score(y_true, y_binary_score, average='micro')\n",
    "    metrics['f1_macro'] = sklearn.metrics.f1_score(y_true, y_binary_score, average='macro')\n",
    "\n",
    "    precision_scores = np.zeros(y_true.shape[1])\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        precision_scores[i] = sklearn.metrics.precision_score(y_true[:,i], y_binary_score[:,i])\n",
    "    metrics['precision_scores_array'] = precision_scores.tolist()\n",
    "\n",
    "    recall_scores = np.zeros(y_true.shape[1])\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        recall_scores[i] = sklearn.metrics.recall_score(y_true[:,i], y_binary_score[:,i])\n",
    "    metrics['recall_scores_array'] = recall_scores.tolist()\n",
    "\n",
    "    f1_scores = np.zeros(y_true.shape[1])\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        f1_scores[i] = sklearn.metrics.f1_score(y_true[:,i], y_binary_score[:,i])\n",
    "    metrics['f1_scores_array'] = f1_scores.tolist()\n",
    "\n",
    "    tops = []\n",
    "    for i in xrange(y_score.shape[0]):\n",
    "        tops.append(get_row_top_N(y_score[i,:], y_true[i,:]))\n",
    "    metrics['topN_list'] = np.array(tops).tolist()\n",
    "    metrics['topN_avg'] = np.mean(tops)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_num_of_labels': 1.1485630208446744,\n",
       " 'average_precision_macro': 0.61977339811967314,\n",
       " 'average_precision_micro': 0.70698467993040581,\n",
       " 'coverage_error': 2.061488834210027,\n",
       " 'f1_macro': 0.43082556994376509,\n",
       " 'f1_micro': 0.65704275498813458,\n",
       " 'f1_scores_array': [0.6668153785592441,\n",
       "  0.4488631841455973,\n",
       "  0.5635695834678721,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2688478452066843,\n",
       "  0.7625937711546343,\n",
       "  0.7359147970160885],\n",
       " 'precision_macro': 0.56466354610048419,\n",
       " 'precision_micro': 0.78778287224416077,\n",
       " 'precision_scores_array': [0.8737019462210301,\n",
       "  0.5839373231172775,\n",
       "  0.8467042629312959,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.59815278647464,\n",
       "  0.8098731379050638,\n",
       "  0.8049389121545665],\n",
       " 'recall_macro': 0.36221780078541721,\n",
       " 'recall_micro': 0.56352103826320576,\n",
       " 'recall_scores_array': [0.5391487014089289,\n",
       "  0.3645393432732914,\n",
       "  0.4223405220652733,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.1733902073784998,\n",
       "  0.7205301355796508,\n",
       "  0.6777934965776936],\n",
       " 'topN_avg': 1.8634846472332047,\n",
       " 'topN_list': [2,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  2,\n",
       "  7,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  7,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  7,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  7,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  8,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  6,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  7,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  5,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  8,\n",
       "  3,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  ...]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = get_metrics(y_true, y_binary_score)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.parallelize((\"metrics\", json.dumps(metrics))).saveAsTextFile(get_metrics_output_name(method=method, data_type=\"validation\", subset=\"sections\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_metrics = json.loads(sc.textFile(get_metrics_output_name(method=method, data_type=\"validation\", subset=\"sections\")).collect()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coverage_error(test_labeled_points, classifications, method):\n",
    "    test_labeled_points.cache()\n",
    "    y_score = np.zeros(test_labeled_points.count(), len(classifications))\n",
    "    y_true = np.zeros(test_labeled_points.count(), len(classifications))\n",
    "    \n",
    "    i = 0\n",
    "    for classification in classifications:\n",
    "        binarySvm = SVMModel.load(sc, get_model_name(method, classification))\n",
    "        binarySvm.clearThreshold()\n",
    "        predictions = test_labeled_points.map(lambda p: binarySvm.predict(p.features))\n",
    "        labels = test_labeled_points.map(lambda p: p.labels)\n",
    "        y_score[:][i] = predictions\n",
    "        y_true[:][i] = labels\n",
    "        i += 1\n",
    "    return coverage_error(y_score, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf_doc_index_test = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "sublinear_tf_doc_index_test = create_doc_index(sublinear_tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "tf_id_doc_index_test = create_doc_index(tf_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)\n",
    "bm25_doc_index_test = create_doc_index(bm25_postings, term_dictionary).filter(lambda (doc_id, postings): doc_id in validation_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method = \"bm25\"\n",
    "test_vectors = get_labeled_points_from_doc_index(bm25_doc_index_test, doc_classification_map, number_of_terms)\n",
    "get_coverage_error(test_vectors, sections, method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
