{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_WORD_COUNT = 100\n",
    "MIN_SIZE = 0\n",
    "NUM_CORES = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training_file = \"/home/local/shalaby/docs_output_sample_100.json\"\n",
    "\n",
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "doc2vec_model_save_location = os.path.join(root_location, \"parameter_search_doc2vec_models_new\", \"full\")\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_parameter_search\")\n",
    "if not os.path.exists(doc2vec_model_save_location):\n",
    "    os.makedirs(doc2vec_model_save_location)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL)):\n",
    "    os.makedirs(os.path.join(doc2vec_model_save_location, VOCAB_MODEL))\n",
    "\n",
    "training_file = root_location + \"docs_output.json\"\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "classification_index_file = exports_location + \"classification_index.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\"\n",
    "\n",
    "preprocessed_location = root_location + \"preprocessed_data/\"\n",
    "\n",
    "training_preprocessed_files_prefix = preprocessed_location + \"training_docs_merged_data_preprocessed-\"\n",
    "training_preprocessed_docids_files_prefix = preprocessed_location + \"training_docs_merged_docids_preprocessed-\"\n",
    "validation_preprocessed_files_prefix = preprocessed_location + \"validation_docs_merged_data_preprocessed-\"\n",
    "validation_preprocessed_docids_files_prefix = preprocessed_location + \"validation_docs_merged_docids_preprocessed-\"\n",
    "\n",
    "word2vec_questions_file = result = root_location + 'tensorflow/word2vec/questions-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 2.94 s, total: 33.3 s\n",
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "classifications_index = pickle.load(open(classification_index_file))\n",
    "#test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ensure_hdfs_location_exists(location):\n",
    "    parent = os.path.dirname(location)\n",
    "    os.system(\"hdfs dfs -mkdir -p \" + location)\n",
    "\n",
    "def ensure_disk_location_exists(location):\n",
    "    if not os.path.exists(location):\n",
    "        os.makedirs(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference(doc2vec_model, doc_classification_map):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # do inference and store results in dict\n",
    "        i = 0\n",
    "        for (doc_id, doc_contents_array) in ValidationDocumentGenerator(training_file, validation_docs_list):\n",
    "            i += 1\n",
    "            if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "            validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "\n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in validation_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            validation_labels.append([classf for classf in doc_classification_map[validation_doc_id] if classf in sections])\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                           val_docs_list, val_preprocessed_files_prefix, val_preprocessed_docids_files_prefix):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_one_doc(doc_tuple):\n",
    "        #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "        doc_id, doc_tokens = doc_tuple\n",
    "        rep = doc2vec_model.infer_vector(doc_tokens)\n",
    "        return (doc_id, rep)\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_labels = []\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_labels = np.array(validation_labels)\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # Single-threaded inference\n",
    "        # do inference and store results in dict\n",
    "#         i = 0\n",
    "        \n",
    "#         validation_docs_iterator = DocumentBatchGenerator(val_preprocessed_files_prefix, \n",
    "#                                                         val_preprocessed_docids_files_prefix, batch_size=None)\n",
    "#         for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "#             i += 1\n",
    "#             if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "#             validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "        \n",
    "        # Multi-threaded inference\n",
    "        validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                          validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "        generator_func = validation_docs_iterator.__iter__()\n",
    "        pool = ThreadPool(NUM_CORES)\n",
    "        # map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "        validation_documents_reps = {}\n",
    "        mini_batch_size = 1000\n",
    "        while True:\n",
    "            threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "            info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "            if threaded_reps_partial:\n",
    "                #threaded_reps.extend(threaded_reps_partial)\n",
    "                validation_documents_reps.update(threaded_reps_partial)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "                \n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        validation_labels = np.array(validation_labels)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "\n",
    "def get_training_data(doc2vec_model, classifications):\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for doc_id in training_docs_list:\n",
    "        # converting from memmap to a normal array\n",
    "        normal_array = []\n",
    "        normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "        training_data.append(normal_array)\n",
    "        eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "        training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))\n",
    "    training_labels = np.array(training_labels)\n",
    "    training_data = np.array(training_data)\n",
    "    return training_data, training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "                    \n",
    "class DocumentBatchGenerator(object):\n",
    "    def __init__(self, filename_prefix, filename_docids_prefix, batch_size=10000 ):\n",
    "        \"\"\"\n",
    "        batch_size cant be > 10,000 due to a limitation in doc2vec training, \n",
    "        None means no batching (only use for inference)\n",
    "        \"\"\"\n",
    "        assert batch_size <= 10000 or batch_size is None\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.filename_docids_prefix = filename_docids_prefix\n",
    "        self.curr_lines = []\n",
    "        self.curr_docids = []\n",
    "        self.batch_size = batch_size\n",
    "        self.curr_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        del self.curr_lines, self.curr_docids\n",
    "        self.curr_lines, self.docids = [], []\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_index) )\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    self.curr_lines.append(line.split(\" \"))\n",
    "#                     if i % 1000 == 0:\n",
    "#                         print i\n",
    "            self.curr_docids = pickle.load(open(self.filename_docids_prefix + str(self.curr_index), \"r\"))\n",
    "            self.batch_end = self.curr_index + len(self.curr_lines) -1 \n",
    "            info(\"Finished loading new batch\")\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_index))\n",
    "            raise StopIteration()\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            if self.curr_index > self.batch_end:\n",
    "                self.load_new_batch_in_memory()\n",
    "            for (doc_id, tokens) in zip(self.curr_docids, self.curr_lines):\n",
    "                if self.batch_size is not None:\n",
    "                    curr_batch_iter = 0\n",
    "                    # divide the document to batches according to the batch size\n",
    "                    while curr_batch_iter < len(tokens):\n",
    "                        yield LabeledSentence(words=tokens[curr_batch_iter: curr_batch_iter + self.batch_size], tags=[doc_id])\n",
    "                        curr_batch_iter += self.batch_size\n",
    "                else:\n",
    "                    yield doc_id, tokens\n",
    "                self.curr_index += 1\n",
    "\n",
    "class Word2VecTrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield stemtokenizer(text)\n",
    "                \n",
    "class ValidationDocumentGenerator(object):\n",
    "    def __init__(self, filename, validation_docs_list):\n",
    "        self.filename = filename\n",
    "        self.validation_docs_list = validation_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.validation_docs_list:\n",
    "                    yield doc_id, stemtokenizer(text)\n",
    "                    \n",
    "class StochasticDocumentGenerator(object):\n",
    "    \"\"\"\n",
    "    Randomly shuffle rows while reading them\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, training_docs_list, line_positions):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "        self.line_positions = line_positions\n",
    "        self.lines = set(line_positions.keys())\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            while len(self.lines) > 0:\n",
    "                random_line = random.sample(self.lines,1)[0]\n",
    "                self.lines.remove(random_line)\n",
    "                file_obj.seek(self.line_positions[random_line])\n",
    "                line = file_obj.readline()\n",
    "                if not line.strip(): continue\n",
    "#                 print random_line, self.line_positions[random_line], line[:30]\n",
    "                (doc_id, text) = eval(line)\n",
    "                # print random_line , doc_id\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "#                     yield doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Specific Doc2vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 1000\n",
    "DOC2VEC_WINDOW = 8\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 0\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 1\n",
    "DOC2VEC_MEAN = 0\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 20\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 10000 # report vocab progress every x documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2vec_size_1000_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_{}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "placeholder_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_epochs = {\n",
    "    'doc2vec_size_50_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 8,\n",
    "    'doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 14,\n",
    "    'doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vocab_counts = {k:doc2vec_model.vocab[k].count for k in doc2vec_model.vocab.keys()}\n",
    "# dd = sorted(vocab_counts, key=vocab_counts.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifications = sections\n",
    "classifications_type = 'sections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 21:58:29,865 : INFO : ****************** Epoch 6 --- Loading doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6 *******************\n",
      "2017-01-31 21:58:29,868 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model\n",
      "2017-01-31 21:58:35,926 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.* with mmap=None\n",
      "2017-01-31 21:58:35,928 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-31 21:58:37,843 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy with mmap=None\n",
      "2017-01-31 21:58:38,428 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy with mmap=None\n",
      "2017-01-31 21:58:39,025 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-31 21:58:39,027 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-31 21:58:40,730 : INFO : Getting training Data\n",
      "2017-01-31 21:59:29,189 : INFO : Getting Validation Embeddings\n",
      "2017-01-31 21:59:29,192 : INFO : ===== Loading validation vectors\n"
     ]
    }
   ],
   "source": [
    "epoch = 6\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "info(\"****************** Epoch {} --- Loading {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "# if we have the model, just load it, otherwise train the previous model\n",
    "if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "    doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "\n",
    "info('Getting training Data')\n",
    "X, y = get_training_data(doc2vec_model, classifications)\n",
    "\n",
    "info('Getting Validation Embeddings')\n",
    "Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                validation_preprocessed_docids_files_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create nn parameter search directory\n",
    "if not os.path.exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME)):\n",
    "    os.makedirs(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_keras_nn_model(input_size, output_size, \n",
    "                          first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                          second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                          input_dropout_do, hidden_dropout_do):\n",
    "    \n",
    "    doc_input = Input(shape=(DOC2VEC_SIZE,), name='doc_input')\n",
    "    if input_dropout_do:\n",
    "        hidden = Dropout(0.7)(doc_input)\n",
    "    hidden = Dense(first_hidden_layer_size, activation=first_hidden_layer_activation, \n",
    "                   name='hidden_layer_{}'.format(first_hidden_layer_activation))(doc_input if not input_dropout_do else hidden)\n",
    "    if hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    if second_hidden_layer_size is not None:\n",
    "        hidden = Dense(second_hidden_layer_size, activation=second_hidden_layer_activation, \n",
    "                       name='hidden_layer2_{}'.format(second_hidden_layer_activation))(hidden)\n",
    "    softmax_output = Dense(output_size, activation='sigmoid', name='softmax_output')(hidden)\n",
    "\n",
    "    model = Model(input=doc_input, output=softmax_output)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'.format(classifications_type)\n",
    "TRAINING_METRICS_FILENAME = '{}_training_metrics.pkl'.format(classifications_type)\n",
    "METRICS_FIG_PNG_FILENAME = '{}_validation_metrics.png'.format(classifications_type)\n",
    "METRICS_FIG_PDF_FILENAME = '{}_validation_metrics.pdf'.format(classifications_type)\n",
    "WORD2VEC_METRICS_FILENAME = 'word2vec_metrics.pkl'\n",
    "\n",
    "# for epoch in range(DOC2VEC_MAX_EPOCHS):\n",
    "#     GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "# fig_save_location = placeholder_model_name.format('run')\n",
    "# plt.savefig(os.path.join(fig_save_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_binary_0_5 = lambda x: 1 if x > 0.5 else 0\n",
    "get_binary_0_5 = np.vectorize(get_binary_0_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "NN_MAX_EPOCHS = 100\n",
    "NN_BATCH_SIZE = 1024\n",
    "NN_RANDOM_SEARCH_BUDGET = 20\n",
    "NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "first_hidden_layer_sizes = [200,500]\n",
    "second_hidden_layer_sizes = [None,50,200,500,1000]\n",
    "first_hidden_layer_activations = ['relu','sigmoid', 'tanh', 'softmax']\n",
    "second_hidden_layer_activations = ['relu','sigmoid', 'tanh', 'softmax']\n",
    "# first_hidden_layer_activations = ['relu']\n",
    "# second_hidden_layer_activations = ['relu']\n",
    "input_dropout_options = [False, True]\n",
    "hidden_dropout_options = [False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Batch Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:18:08,422 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 749s - loss: 0.2799 - val_loss: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:30:46,709 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 22s, sys: 52.7 s, total: 2min 15s\n",
      "Wall time: 12min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:30:56,551 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:31:14,674 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.709, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.705, Top 3: 0.932, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.633, F1 Macro: 0.416, Total Pos: 266,589\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 109s - loss: 0.2730 - val_loss: 0.2065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:33:03,732 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 5s, sys: 38.6 s, total: 1min 44s\n",
      "Wall time: 1min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:33:10,364 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:33:26,903 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.664, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.943, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.627, F1 Macro: 0.455, Total Pos: 245,299\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 109s - loss: 0.2724 - val_loss: 0.2082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:35:16,033 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 4s, sys: 38.4 s, total: 1min 42s\n",
      "Wall time: 1min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:35:23,493 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:35:39,934 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.684, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.707, Top 3: 0.938, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.634, F1 Macro: 0.436, Total Pos: 269,296\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 93s - loss: 0.2721 - val_loss: 0.2077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:37:13,820 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 58.6 s, sys: 34.1 s, total: 1min 32s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:37:19,295 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:37:28,746 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.688, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.710, Top 3: 0.936, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.631, F1 Macro: 0.433, Total Pos: 261,761\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2719 - val_loss: 0.2030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:38:29,795 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.5 s, sys: 28 s, total: 1min 12s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:38:34,949 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:38:45,755 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.675, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.722, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.647, F1 Macro: 0.446, Total Pos: 260,299\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 64s - loss: 0.2720 - val_loss: 0.2034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:39:50,345 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 47 s, sys: 29.7 s, total: 1min 16s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:39:55,424 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:40:06,470 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.726, Top 3: 0.935, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.648, F1 Macro: 0.434, Total Pos: 255,847\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2721 - val_loss: 0.2062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:41:07,572 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.4 s, sys: 28.2 s, total: 1min 12s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:41:12,301 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:41:20,732 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.708, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.712, Top 3: 0.930, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.641, F1 Macro: 0.439, Total Pos: 259,504\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 63s - loss: 0.2721 - val_loss: 0.2062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:42:24,126 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.9 s, sys: 31.9 s, total: 1min 16s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:42:29,017 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:42:37,494 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.728, Top 3: 0.935, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.460, Total Pos: 259,484\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 63s - loss: 0.2720 - val_loss: 0.2038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:43:40,568 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 45.9 s, sys: 30.4 s, total: 1min 16s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:43:45,346 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:43:56,554 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.724, Top 3: 0.941, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.642, F1 Macro: 0.459, Total Pos: 261,635\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 62s - loss: 0.2722 - val_loss: 0.2044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:44:58,610 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.8 s, sys: 30.2 s, total: 1min 14s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:45:03,627 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:45:13,198 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.665, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.940, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.658, F1 Macro: 0.435, Total Pos: 277,230\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 124s - loss: 0.2722 - val_loss: 0.2054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:47:17,397 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 26s, sys: 47.6 s, total: 2min 13s\n",
      "Wall time: 2min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:47:28,524 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:47:43,417 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.669, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.939, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.482, Total Pos: 266,918\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 212s - loss: 0.2721 - val_loss: 0.2075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:51:16,274 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 32s, sys: 1min 18s, total: 3min 51s\n",
      "Wall time: 3min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:51:32,942 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:51:55,045 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.691, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.934, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.632, F1 Macro: 0.423, Total Pos: 255,122\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 263s - loss: 0.2722 - val_loss: 0.2097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:56:18,726 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 5s, sys: 1min 53s, total: 4min 59s\n",
      "Wall time: 4min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:56:36,108 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:56:59,743 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.711, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.720, Top 3: 0.927, Top 5: 0.981, \n",
      "\t\t F1 Micro: 0.605, F1 Macro: 0.421, Total Pos: 219,893\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 226s - loss: 0.2724 - val_loss: 0.2049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:00:46,496 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 39s, sys: 1min 35s, total: 4min 14s\n",
      "Wall time: 3min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:01:03,139 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:01:26,373 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.938, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.637, F1 Macro: 0.451, Total Pos: 253,115\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 267s - loss: 0.2724 - val_loss: 0.2065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:05:54,353 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 6s, sys: 1min 51s, total: 4min 57s\n",
      "Wall time: 4min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:06:03,468 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.700, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.932, Top 5: 0.982, \n",
      "\t\t F1 Micro: 0.663, F1 Macro: 0.458, Total Pos: 286,271\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:06:28,943 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 165s - loss: 0.2801 - val_loss: 0.2087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:09:21,241 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 56s, sys: 1min 14s, total: 3min 10s\n",
      "Wall time: 2min 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:09:40,226 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:10:05,799 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.686, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.935, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.630, F1 Macro: 0.424, Total Pos: 249,069\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 160s - loss: 0.2710 - val_loss: 0.2030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:12:45,850 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 41s, sys: 1min, total: 2min 42s\n",
      "Wall time: 2min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:13:03,894 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:13:23,840 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.647, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.729, Top 3: 0.943, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.645, F1 Macro: 0.444, Total Pos: 259,649\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 135s - loss: 0.2697 - val_loss: 0.2030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:15:39,372 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 29s, sys: 53.3 s, total: 2min 22s\n",
      "Wall time: 2min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:15:54,793 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:16:10,639 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.665, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.939, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.643, F1 Macro: 0.448, Total Pos: 257,832\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 165s - loss: 0.2692 - val_loss: 0.2024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:18:55,909 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 48s, sys: 1min 3s, total: 2min 51s\n",
      "Wall time: 2min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:19:03,646 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:19:29,019 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.668, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.720, Top 3: 0.938, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.641, F1 Macro: 0.450, Total Pos: 264,452\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 155s - loss: 0.2691 - val_loss: 0.2019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:22:04,072 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 42s, sys: 1min, total: 2min 42s\n",
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:22:21,785 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:22:45,764 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.668, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.726, Top 3: 0.938, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.660, F1 Macro: 0.445, Total Pos: 275,878\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 157s - loss: 0.2686 - val_loss: 0.2033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:25:23,683 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 44s, sys: 1min 1s, total: 2min 45s\n",
      "Wall time: 2min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:25:41,829 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:25:59,425 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.649, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.940, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.648, F1 Macro: 0.505, Total Pos: 258,654\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 154s - loss: 0.2684 - val_loss: 0.2029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:28:33,752 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 40s, sys: 1min 2s, total: 2min 42s\n",
      "Wall time: 2min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:28:38,341 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:28:50,079 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.691, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.709, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.645, F1 Macro: 0.416, Total Pos: 274,392\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 160s - loss: 0.2684 - val_loss: 0.2083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:31:30,955 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 41s, sys: 1min, total: 2min 41s\n",
      "Wall time: 2min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:31:40,319 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:32:02,290 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.745, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.695, Top 3: 0.924, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.645, F1 Macro: 0.410, Total Pos: 288,486\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 158s - loss: 0.2684 - val_loss: 0.2008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:34:41,296 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 44s, sys: 1min 3s, total: 2min 48s\n",
      "Wall time: 2min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:34:59,535 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:35:24,281 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.722, Top 3: 0.942, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.635, F1 Macro: 0.441, Total Pos: 246,453\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 163s - loss: 0.2682 - val_loss: 0.2007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:38:08,185 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 47s, sys: 1min 2s, total: 2min 49s\n",
      "Wall time: 2min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:38:25,722 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:38:47,390 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.628, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.742, Top 3: 0.944, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.507, Total Pos: 252,998\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 162s - loss: 0.2681 - val_loss: 0.1976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:41:30,379 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 46s, sys: 1min 2s, total: 2min 49s\n",
      "Wall time: 2min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:41:40,981 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:42:02,913 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.646, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.666, F1 Macro: 0.499, Total Pos: 277,265\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 139s - loss: 0.2681 - val_loss: 0.1998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:44:22,267 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 31s, sys: 55 s, total: 2min 26s\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:44:36,492 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:44:56,939 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.634, F1 Macro: 0.442, Total Pos: 240,993\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 153s - loss: 0.2680 - val_loss: 0.1981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:47:30,293 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 41s, sys: 1min, total: 2min 42s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:47:48,031 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:48:12,449 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.643, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.667, F1 Macro: 0.494, Total Pos: 274,374\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 152s - loss: 0.2684 - val_loss: 0.1994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:50:45,372 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 36s, sys: 58.5 s, total: 2min 35s\n",
      "Wall time: 2min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:51:03,675 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:51:28,183 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.650, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.734, Top 3: 0.942, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.672, F1 Macro: 0.465, Total Pos: 286,275\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 150s - loss: 0.2679 - val_loss: 0.2027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:53:59,101 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 40s, sys: 59.4 s, total: 2min 39s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:54:16,237 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.728, Top 3: 0.939, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.677, F1 Macro: 0.506, Total Pos: 304,618\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:54:39,255 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 94s - loss: 0.2822 - val_loss: 0.2092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:07:49,442 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 17s, sys: 54.8 s, total: 2min 12s\n",
      "Wall time: 13min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:08:10,668 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:08:35,401 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.677, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.718, Top 3: 0.938, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.630, F1 Macro: 0.413, Total Pos: 251,200\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 90s - loss: 0.2702 - val_loss: 0.2063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:10:05,911 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 55.7 s, sys: 38.1 s, total: 1min 33s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:10:25,051 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:10:49,649 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.685, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.723, Top 3: 0.936, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.640, F1 Macro: 0.404, Total Pos: 258,544\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 60s - loss: 0.2681 - val_loss: 0.2027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:11:50,271 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 38.6 s, sys: 27.4 s, total: 1min 6s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:12:07,764 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:12:31,861 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.658, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.940, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.662, F1 Macro: 0.461, Total Pos: 279,292\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 91s - loss: 0.2674 - val_loss: 0.1999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:14:03,790 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 57.3 s, sys: 39.8 s, total: 1min 37s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:14:10,741 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:14:34,977 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.629, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.947, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.479, Total Pos: 262,190\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 90s - loss: 0.2668 - val_loss: 0.2006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:16:05,388 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 55 s, sys: 38.1 s, total: 1min 33s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:16:22,853 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:16:40,009 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.739, Top 3: 0.947, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.468, Total Pos: 257,948\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 93s - loss: 0.2665 - val_loss: 0.2032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:18:13,399 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 58.3 s, sys: 38.5 s, total: 1min 36s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:18:30,724 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:18:54,928 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.685, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.714, Top 3: 0.935, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.405, Total Pos: 277,088\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 90s - loss: 0.2662 - val_loss: 0.1993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:20:25,444 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 56.7 s, sys: 37.4 s, total: 1min 34s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:20:40,609 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:20:56,343 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.637, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.943, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.656, F1 Macro: 0.489, Total Pos: 266,847\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 95s - loss: 0.2662 - val_loss: 0.2008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:22:32,201 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min, sys: 39 s, total: 1min 39s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:22:50,243 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:23:14,582 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.639, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.654, F1 Macro: 0.465, Total Pos: 269,813\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 95s - loss: 0.2661 - val_loss: 0.1995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:24:50,411 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 59.6 s, sys: 39.2 s, total: 1min 38s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:24:56,108 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:25:04,870 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.640, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.943, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.447, Total Pos: 256,639\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 91s - loss: 0.2658 - val_loss: 0.1980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:26:36,664 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 57.2 s, sys: 37.9 s, total: 1min 35s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:26:54,972 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:27:19,805 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.625, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.740, Top 3: 0.946, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.484, Total Pos: 282,533\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 98s - loss: 0.2658 - val_loss: 0.1975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:28:58,246 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 2s, sys: 39.8 s, total: 1min 42s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:29:05,446 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:29:30,099 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.631, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.946, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.661, F1 Macro: 0.471, Total Pos: 276,097\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 96s - loss: 0.2657 - val_loss: 0.1985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:31:06,169 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 57.7 s, sys: 39.9 s, total: 1min 37s\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:31:25,112 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:31:48,517 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.732, Top 3: 0.938, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.672, F1 Macro: 0.449, Total Pos: 295,226\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 97s - loss: 0.2655 - val_loss: 0.1960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:33:26,108 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 1s, sys: 46.9 s, total: 1min 48s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:33:45,391 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:34:09,936 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.612, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.749, Top 3: 0.947, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.673, F1 Macro: 0.510, Total Pos: 269,819\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 99s - loss: 0.2651 - val_loss: 0.1957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:35:49,897 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 2s, sys: 46 s, total: 1min 48s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:36:08,525 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:36:27,175 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.620, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.744, Top 3: 0.945, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.676, F1 Macro: 0.518, Total Pos: 281,954\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 97s - loss: 0.2653 - val_loss: 0.1963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:38:04,205 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 2s, sys: 45.6 s, total: 1min 47s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:38:22,405 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.641, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.945, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.487, Total Pos: 286,206\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:38:48,043 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 45s - loss: 0.2864 - val_loss: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:39:39,214 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 31.6 s, sys: 23.6 s, total: 55.2 s\n",
      "Wall time: 51.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:39:58,108 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:40:23,756 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.782, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.686, Top 3: 0.917, Top 5: 0.980, \n",
      "\t\t F1 Micro: 0.638, F1 Macro: 0.367, Total Pos: 286,361\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 59s - loss: 0.2709 - val_loss: 0.2045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:41:23,096 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35.2 s, sys: 28.9 s, total: 1min 4s\n",
      "Wall time: 59.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:41:41,620 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:42:06,420 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.637, F1 Macro: 0.432, Total Pos: 249,573\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2681 - val_loss: 0.2051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:43:07,921 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 36.5 s, sys: 29.7 s, total: 1min 6s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:43:25,772 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:43:45,194 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.657, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.724, Top 3: 0.942, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.647, F1 Macro: 0.475, Total Pos: 268,660\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 60s - loss: 0.2666 - val_loss: 0.2021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:44:45,645 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35.2 s, sys: 28.7 s, total: 1min 3s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:44:59,910 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:45:23,521 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.667, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.941, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.647, F1 Macro: 0.415, Total Pos: 274,404\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 54s - loss: 0.2658 - val_loss: 0.2002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:46:18,473 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 32 s, sys: 26.5 s, total: 58.5 s\n",
      "Wall time: 54.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:46:36,167 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:47:00,643 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.625, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.740, Top 3: 0.946, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.664, F1 Macro: 0.498, Total Pos: 276,415\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2652 - val_loss: 0.2020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:48:02,497 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 36.2 s, sys: 29.3 s, total: 1min 5s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:48:20,189 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:48:43,755 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.677, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.663, F1 Macro: 0.436, Total Pos: 286,090\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 60s - loss: 0.2649 - val_loss: 0.1969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:49:44,177 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35 s, sys: 28.7 s, total: 1min 3s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:50:02,758 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:50:23,157 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.741, Top 3: 0.945, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.685, F1 Macro: 0.507, Total Pos: 299,021\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 66s - loss: 0.2646 - val_loss: 0.1982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:51:30,141 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 37.1 s, sys: 28.6 s, total: 1min 5s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:51:41,871 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:52:06,573 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.741, Top 3: 0.946, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.653, F1 Macro: 0.473, Total Pos: 261,249\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 58s - loss: 0.2643 - val_loss: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:53:05,190 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 33.5 s, sys: 26.5 s, total: 1min\n",
      "Wall time: 58.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:53:09,850 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:53:25,166 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.638, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.732, Top 3: 0.945, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.664, F1 Macro: 0.449, Total Pos: 283,275\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 64s - loss: 0.2643 - val_loss: 0.1968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:54:30,013 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 36.7 s, sys: 28.8 s, total: 1min 5s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:54:38,033 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:55:02,352 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.629, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.740, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.665, F1 Macro: 0.481, Total Pos: 268,183\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 58s - loss: 0.2641 - val_loss: 0.2022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:56:01,005 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 33.5 s, sys: 26.8 s, total: 1min\n",
      "Wall time: 58.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:56:18,842 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:56:43,028 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.674, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.937, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.454, Total Pos: 301,568\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 53s - loss: 0.2639 - val_loss: 0.1963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:57:36,894 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 31.8 s, sys: 24.9 s, total: 56.7 s\n",
      "Wall time: 53.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:57:55,832 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:58:20,534 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.622, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.737, Top 3: 0.948, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.646, F1 Macro: 0.457, Total Pos: 252,998\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 55s - loss: 0.2639 - val_loss: 0.2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:59:15,712 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 32.1 s, sys: 25.2 s, total: 57.3 s\n",
      "Wall time: 55.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:59:34,166 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:59:58,807 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.659, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.940, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.659, F1 Macro: 0.441, Total Pos: 276,067\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 59s - loss: 0.2640 - val_loss: 0.1978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:00:58,178 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35.2 s, sys: 26.1 s, total: 1min 1s\n",
      "Wall time: 59.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:01:16,349 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:01:32,056 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.643, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.654, F1 Macro: 0.457, Total Pos: 276,519\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 65s - loss: 0.2638 - val_loss: 0.1969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:02:37,802 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 38 s, sys: 28.6 s, total: 1min 6s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:02:49,256 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.643, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.736, Top 3: 0.942, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.671, F1 Macro: 0.455, Total Pos: 290,945\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:03:14,123 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 43s - loss: 0.2922 - val_loss: 0.2192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:04:03,649 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 29.6 s, sys: 20.5 s, total: 50.1 s\n",
      "Wall time: 49.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:04:15,782 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:04:37,479 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.748, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.684, Top 3: 0.928, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.600, F1 Macro: 0.359, Total Pos: 244,661\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 41s - loss: 0.2726 - val_loss: 0.2115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:05:19,100 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 23 s, sys: 19.5 s, total: 42.5 s\n",
      "Wall time: 41.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:05:32,660 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:05:51,639 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.689, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.718, Top 3: 0.935, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.623, F1 Macro: 0.412, Total Pos: 245,614\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 41s - loss: 0.2689 - val_loss: 0.2092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:06:33,550 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 23.3 s, sys: 19.1 s, total: 42.4 s\n",
      "Wall time: 41.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:06:50,593 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:07:00,402 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.711, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.700, Top 3: 0.933, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.629, F1 Macro: 0.400, Total Pos: 274,559\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.2670 - val_loss: 0.2063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:07:32,519 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 17.3 s, sys: 16.5 s, total: 33.8 s\n",
      "Wall time: 32.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:07:49,688 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:08:13,042 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.690, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.717, Top 3: 0.932, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.636, F1 Macro: 0.413, Total Pos: 253,934\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 33s - loss: 0.2660 - val_loss: 0.2010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:08:46,644 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 18.8 s, sys: 17 s, total: 35.8 s\n",
      "Wall time: 33.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:09:03,835 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:09:27,080 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.654, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.729, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.646, F1 Macro: 0.438, Total Pos: 260,230\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.2652 - val_loss: 0.1971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:09:56,737 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 16.3 s, sys: 15.8 s, total: 32 s\n",
      "Wall time: 29.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:10:06,870 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:10:20,406 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.619, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.746, Top 3: 0.946, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.469, Total Pos: 273,493\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.2645 - val_loss: 0.1986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:10:45,235 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 14.1 s, sys: 13.9 s, total: 28 s\n",
      "Wall time: 24.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:10:54,238 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:11:11,006 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.722, Top 3: 0.940, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.652, F1 Macro: 0.445, Total Pos: 269,235\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 38s - loss: 0.2643 - val_loss: 0.1965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:11:49,853 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 21 s, sys: 18.1 s, total: 39.1 s\n",
      "Wall time: 38.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:12:01,856 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:12:19,188 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.641, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.942, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.667, F1 Macro: 0.462, Total Pos: 278,876\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 38s - loss: 0.2640 - val_loss: 0.1968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:12:57,716 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 21.1 s, sys: 17.9 s, total: 39 s\n",
      "Wall time: 38.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:13:13,181 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:13:28,550 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.638, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.475, Total Pos: 288,099\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 37s - loss: 0.2638 - val_loss: 0.1963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:14:06,369 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 21 s, sys: 17.5 s, total: 38.6 s\n",
      "Wall time: 37.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:14:22,775 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:14:36,397 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.619, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.738, Top 3: 0.948, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.654, F1 Macro: 0.464, Total Pos: 260,415\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 37s - loss: 0.2634 - val_loss: 0.2001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:15:13,795 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 20.9 s, sys: 18 s, total: 38.9 s\n",
      "Wall time: 37.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:15:29,749 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:15:44,320 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.641, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.731, Top 3: 0.944, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.659, F1 Macro: 0.462, Total Pos: 282,548\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2635 - val_loss: 0.1935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:16:19,948 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 18.9 s, sys: 17.5 s, total: 36.4 s\n",
      "Wall time: 35.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:16:35,021 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:16:52,729 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.602, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.747, Top 3: 0.950, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.678, F1 Macro: 0.502, Total Pos: 290,620\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.2632 - val_loss: 0.1947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:17:23,331 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 16.2 s, sys: 16 s, total: 32.3 s\n",
      "Wall time: 30.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:17:38,766 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:18:01,393 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.621, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.738, Top 3: 0.947, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.658, F1 Macro: 0.469, Total Pos: 266,806\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.2630 - val_loss: 0.1956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:18:31,849 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 15.7 s, sys: 16.5 s, total: 32.3 s\n",
      "Wall time: 30.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:18:47,231 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:19:09,777 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.610, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.742, Top 3: 0.950, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.502, Total Pos: 255,701\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2629 - val_loss: 0.1984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:19:30,602 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.1 s, sys: 13.1 s, total: 24.1 s\n",
      "Wall time: 20.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:19:45,517 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.612, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.744, Top 3: 0.948, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.661, F1 Macro: 0.518, Total Pos: 264,403\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:20:09,190 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.3015 - val_loss: 0.2350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:20:31,995 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 13.9 s, sys: 10.2 s, total: 24.1 s\n",
      "Wall time: 22.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:20:41,434 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:21:04,015 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.797, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.676, Top 3: 0.917, Top 5: 0.980, \n",
      "\t\t F1 Micro: 0.527, F1 Macro: 0.246, Total Pos: 209,201\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2775 - val_loss: 0.2228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:21:25,732 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 12 s, sys: 10.8 s, total: 22.8 s\n",
      "Wall time: 21.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:21:37,779 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:21:55,280 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.774, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.658, Top 3: 0.929, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.590, F1 Macro: 0.364, Total Pos: 262,715\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2717 - val_loss: 0.2108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:22:16,570 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.4 s, sys: 11.1 s, total: 22.4 s\n",
      "Wall time: 21.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:22:30,670 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:22:49,712 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.708, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.712, Top 3: 0.931, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.643, F1 Macro: 0.376, Total Pos: 280,861\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.2692 - val_loss: 0.2108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:23:06,700 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 8.64 s, sys: 9.77 s, total: 18.4 s\n",
      "Wall time: 17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:23:20,964 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:23:43,813 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.706, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.697, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.627, F1 Macro: 0.393, Total Pos: 273,790\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.2673 - val_loss: 0.2031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:24:00,878 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 9.3 s, sys: 9.83 s, total: 19.1 s\n",
      "Wall time: 17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:24:15,105 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:24:37,815 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.726, Top 3: 0.943, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.652, F1 Macro: 0.459, Total Pos: 275,756\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2661 - val_loss: 0.2020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:24:58,839 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.2 s, sys: 11.2 s, total: 22.4 s\n",
      "Wall time: 21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:25:06,465 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:25:26,638 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.652, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.732, Top 3: 0.941, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.644, F1 Macro: 0.429, Total Pos: 260,530\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2653 - val_loss: 0.2043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:25:48,177 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.2 s, sys: 11 s, total: 22.2 s\n",
      "Wall time: 21.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:26:02,180 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:26:16,608 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.673, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.714, Top 3: 0.941, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.640, F1 Macro: 0.422, Total Pos: 270,169\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.2649 - val_loss: 0.1973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:26:35,772 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 10.2 s, sys: 10.3 s, total: 20.5 s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:26:49,889 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:27:12,696 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.737, Top 3: 0.948, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.658, F1 Macro: 0.473, Total Pos: 268,516\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.2642 - val_loss: 0.2025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:27:30,309 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 9.38 s, sys: 10.3 s, total: 19.7 s\n",
      "Wall time: 17.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:27:43,264 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:28:05,710 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.665, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.939, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.666, F1 Macro: 0.479, Total Pos: 296,239\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2638 - val_loss: 0.1985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:28:26,167 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.1 s, sys: 11.3 s, total: 22.3 s\n",
      "Wall time: 20.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:28:35,890 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:28:55,270 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.661, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.940, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.656, F1 Macro: 0.445, Total Pos: 285,264\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2638 - val_loss: 0.1965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:29:15,812 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.2 s, sys: 11.3 s, total: 22.5 s\n",
      "Wall time: 20.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:29:29,942 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:29:45,537 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.640, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.731, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.664, F1 Macro: 0.443, Total Pos: 285,562\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.2635 - val_loss: 0.1988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:03,898 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 9.66 s, sys: 10.1 s, total: 19.8 s\n",
      "Wall time: 18.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:11,597 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:30:24,512 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.642, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.943, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.671, F1 Macro: 0.466, Total Pos: 303,967\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 13s - loss: 0.2631 - val_loss: 0.1949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:38,081 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 7.46 s, sys: 7.78 s, total: 15.2 s\n",
      "Wall time: 13.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:49,630 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:30:59,570 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.607, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.746, Top 3: 0.949, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.661, F1 Macro: 0.488, Total Pos: 265,989\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.2632 - val_loss: 0.1991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:31:13,962 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 7.29 s, sys: 8.3 s, total: 15.6 s\n",
      "Wall time: 14.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:31:28,660 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:31:51,300 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.625, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.738, Top 3: 0.948, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.464, Total Pos: 267,543\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2630 - val_loss: 0.1998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:32:11,581 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.4 s, sys: 9.79 s, total: 21.2 s\n",
      "Wall time: 20.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:32:18,510 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.731, Top 3: 0.935, Top 5: 0.983, \n",
      "\t\t F1 Micro: 0.677, F1 Macro: 0.433, Total Pos: 308,801\n"
     ]
    }
   ],
   "source": [
    "batch_dict = {}\n",
    "for batch_sz in [64,128,256,512,1024,2048]:\n",
    "# for batch_sz in [2048]:\n",
    "    NN_BATCH_SIZE = batch_sz\n",
    "    batch_dict[batch_sz] = {}\n",
    "    start_time = time.time()\n",
    "    param_sampler = ParameterSampler({\n",
    "            'first_hidden_layer_size':first_hidden_layer_sizes,\n",
    "            'first_hidden_layer_activation':first_hidden_layer_activations,\n",
    "            'second_hidden_layer_size':second_hidden_layer_sizes,\n",
    "            'second_hidden_layer_activation':second_hidden_layer_activations,\n",
    "            'input_dropout':input_dropout_options,\n",
    "            'hidden_dropout':hidden_dropout_options\n",
    "        }, n_iter=NN_RANDOM_SEARCH_BUDGET, random_state=NN_PARAM_SAMPLE_SEED)\n",
    "    for parameters in param_sampler:\n",
    "        first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "        first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "        second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "        second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "        input_dropout_do = parameters['input_dropout']\n",
    "        hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "        print (\"===================================================================================\\n\" + \\\n",
    "              \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "              \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "              \"==========================\").format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                                    second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                                    input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "        GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "            first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "            second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "        )\n",
    "\n",
    "        model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                      first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                      second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                      input_dropout_do, hidden_dropout_do)\n",
    "        model.summary()\n",
    "        \n",
    "        batch_dict[batch_sz]['metrics'] = []\n",
    "        batch_dict[batch_sz]['history'] = []\n",
    "\n",
    "        for nn_epoch in range(1, NN_MAX_EPOCHS+1):\n",
    "            info('======= NN Epoch: {} =========='.format(nn_epoch)) \n",
    "            %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, nb_epoch=1, verbose=1, callbacks=[early_stopper])\n",
    "    #         info('Evaluating on Training Data')\n",
    "    #         yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "    #         yp_binary = get_binary_0_5(yp)\n",
    "    #         #print yp\n",
    "    #         info('Generating Training Metrics')\n",
    "    #         training_metrics = get_metrics(y, yp, yp_binary)\n",
    "    #         print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    #             training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "    #             training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "    #             training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "            info('Evaluating on Validation Data')\n",
    "            yvp = model.predict(Xv)\n",
    "            yvp_binary = get_binary_0_5(yvp)\n",
    "            #print yvp\n",
    "            info('Generating Validation Metrics')\n",
    "            validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "            print \"****** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "                validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "                validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "            \n",
    "            batch_dict[batch_sz]['metrics'].append(validation_metrics)\n",
    "            batch_dict[batch_sz]['history'].append(history)\n",
    "            \n",
    "        break\n",
    "    duration = time.time() - start_time\n",
    "    batch_dict[batch_sz]['duration'] =  duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Batch Size: 64\n",
      "Duration => 2902.9390409\n",
      "Loss History => [0.28, 0.273, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272]\n",
      "Val Loss Hist => [0.211, 0.207, 0.208, 0.208, 0.203, 0.203, 0.206, 0.206, 0.204, 0.204, 0.205, 0.207, 0.21, 0.205, 0.206]\n",
      "Cov Erro Hist=> [1.709, 1.664, 1.684, 1.688, 1.675, 1.676, 1.708, 1.676, 1.66, 1.665, 1.669, 1.691, 1.711, 1.676, 1.7]\n",
      "F1 Micro Hist=> [0.633, 0.627, 0.634, 0.631, 0.647, 0.648, 0.641, 0.65, 0.642, 0.658, 0.65, 0.632, 0.605, 0.637, 0.663]\n",
      "F1 Macro Hist=> [0.416, 0.455, 0.436, 0.433, 0.446, 0.434, 0.439, 0.46, 0.459, 0.435, 0.482, 0.423, 0.421, 0.451, 0.458]\n",
      "Coverage Error Max: 8 => 1.66 | F1 Micro Max: 14 => 0.663 | F1 Macro Max: 10 => 0.482\n",
      "========== Batch Size: 128\n",
      "Duration => 2890.55074692\n",
      "Loss History => [0.28, 0.271, 0.27, 0.269, 0.269, 0.269, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268]\n",
      "Val Loss Hist => [0.209, 0.203, 0.203, 0.202, 0.202, 0.203, 0.203, 0.208, 0.201, 0.201, 0.198, 0.2, 0.198, 0.199, 0.203]\n",
      "Cov Erro Hist=> [1.686, 1.647, 1.665, 1.668, 1.668, 1.649, 1.691, 1.745, 1.656, 1.628, 1.646, 1.656, 1.643, 1.65, 1.66]\n",
      "F1 Micro Hist=> [0.63, 0.645, 0.643, 0.641, 0.66, 0.648, 0.645, 0.645, 0.635, 0.651, 0.666, 0.634, 0.667, 0.672, 0.677]\n",
      "F1 Macro Hist=> [0.424, 0.444, 0.448, 0.45, 0.445, 0.505, 0.416, 0.41, 0.441, 0.507, 0.499, 0.442, 0.494, 0.465, 0.506]\n",
      "Coverage Error Max: 9 => 1.628 | F1 Micro Max: 14 => 0.677 | F1 Macro Max: 9 => 0.507\n",
      "========== Batch Size: 256\n",
      "Duration => 2648.8733201\n",
      "Loss History => [0.282, 0.27, 0.268, 0.267, 0.267, 0.267, 0.266, 0.266, 0.266, 0.266, 0.266, 0.266, 0.265, 0.265, 0.265]\n",
      "Val Loss Hist => [0.209, 0.206, 0.203, 0.2, 0.201, 0.203, 0.199, 0.201, 0.2, 0.198, 0.198, 0.199, 0.196, 0.196, 0.196]\n",
      "Cov Erro Hist=> [1.677, 1.685, 1.658, 1.629, 1.626, 1.685, 1.637, 1.639, 1.64, 1.625, 1.631, 1.66, 1.612, 1.62, 1.641]\n",
      "F1 Micro Hist=> [0.63, 0.64, 0.662, 0.651, 0.651, 0.651, 0.656, 0.654, 0.65, 0.668, 0.661, 0.672, 0.673, 0.676, 0.668]\n",
      "F1 Macro Hist=> [0.413, 0.404, 0.461, 0.479, 0.468, 0.405, 0.489, 0.465, 0.447, 0.484, 0.471, 0.449, 0.51, 0.518, 0.487]\n",
      "Coverage Error Max: 12 => 1.612 | F1 Micro Max: 13 => 0.676 | F1 Macro Max: 13 => 0.518\n",
      "========== Batch Size: 512\n",
      "Duration => 1466.01992393\n",
      "Loss History => [0.286, 0.271, 0.268, 0.267, 0.266, 0.265, 0.265, 0.265, 0.264, 0.264, 0.264, 0.264, 0.264, 0.264, 0.264]\n",
      "Val Loss Hist => [0.219, 0.205, 0.205, 0.202, 0.2, 0.202, 0.197, 0.198, 0.197, 0.197, 0.202, 0.196, 0.2, 0.198, 0.197]\n",
      "Cov Erro Hist=> [1.782, 1.656, 1.657, 1.667, 1.625, 1.677, 1.626, 1.626, 1.638, 1.629, 1.674, 1.622, 1.659, 1.643, 1.643]\n",
      "F1 Micro Hist=> [0.638, 0.637, 0.647, 0.647, 0.664, 0.663, 0.685, 0.653, 0.664, 0.665, 0.668, 0.646, 0.659, 0.654, 0.671]\n",
      "F1 Macro Hist=> [0.367, 0.432, 0.475, 0.415, 0.498, 0.436, 0.507, 0.473, 0.449, 0.481, 0.454, 0.457, 0.441, 0.457, 0.455]\n",
      "Coverage Error Max: 11 => 1.622 | F1 Micro Max: 6 => 0.685 | F1 Macro Max: 6 => 0.507\n",
      "========== Batch Size: 1024\n",
      "Duration => 1015.32090187\n",
      "Loss History => [0.292, 0.273, 0.269, 0.267, 0.266, 0.265, 0.265, 0.264, 0.264, 0.264, 0.263, 0.264, 0.263, 0.263, 0.263]\n",
      "Val Loss Hist => [0.219, 0.211, 0.209, 0.206, 0.201, 0.197, 0.199, 0.197, 0.197, 0.196, 0.2, 0.194, 0.195, 0.196, 0.198]\n",
      "Cov Erro Hist=> [1.748, 1.689, 1.711, 1.69, 1.654, 1.619, 1.66, 1.641, 1.638, 1.619, 1.641, 1.602, 1.621, 1.61, 1.612]\n",
      "F1 Micro Hist=> [0.6, 0.623, 0.629, 0.636, 0.646, 0.668, 0.652, 0.667, 0.668, 0.654, 0.659, 0.678, 0.658, 0.65, 0.661]\n",
      "F1 Macro Hist=> [0.359, 0.412, 0.4, 0.413, 0.438, 0.469, 0.445, 0.462, 0.475, 0.464, 0.462, 0.502, 0.469, 0.502, 0.518]\n",
      "Coverage Error Max: 11 => 1.602 | F1 Micro Max: 11 => 0.678 | F1 Macro Max: 14 => 0.518\n",
      "========== Batch Size: 2048\n",
      "Duration => 753.347830057\n",
      "Loss History => [0.301, 0.277, 0.272, 0.269, 0.267, 0.266, 0.265, 0.265, 0.264, 0.264, 0.264, 0.263, 0.263, 0.263, 0.263]\n",
      "Val Loss Hist => [0.235, 0.223, 0.211, 0.211, 0.203, 0.202, 0.204, 0.197, 0.202, 0.198, 0.196, 0.199, 0.195, 0.199, 0.2]\n",
      "Cov Erro Hist=> [1.797, 1.774, 1.708, 1.706, 1.656, 1.652, 1.673, 1.626, 1.665, 1.661, 1.64, 1.642, 1.607, 1.625, 1.676]\n",
      "F1 Micro Hist=> [0.527, 0.59, 0.643, 0.627, 0.652, 0.644, 0.64, 0.658, 0.666, 0.656, 0.664, 0.671, 0.661, 0.651, 0.677]\n",
      "F1 Macro Hist=> [0.246, 0.364, 0.376, 0.393, 0.459, 0.429, 0.422, 0.473, 0.479, 0.445, 0.443, 0.466, 0.488, 0.464, 0.433]\n",
      "Coverage Error Max: 12 => 1.607 | F1 Micro Max: 14 => 0.677 | F1 Macro Max: 12 => 0.488\n"
     ]
    }
   ],
   "source": [
    "for sz in sorted(batch_dict.keys()):\n",
    "    print '========== Batch Size: {}'.format(sz)\n",
    "    print 'Duration => {}'.format(batch_dict[sz]['duration'])\n",
    "    print 'Loss History => {}'.format([round(hist.history['loss'][0],3) for hist in batch_dict[sz]['history']])\n",
    "    print 'Val Loss Hist => {}'.format([round(hist.history['val_loss'][0],3) for hist in batch_dict[sz]['history']])\n",
    "    cov_error_history = [round(metrics['coverage_error'],3) for metrics in batch_dict[sz]['metrics']]\n",
    "    f1_micro_history = [round(metrics['f1_micro'],3) for metrics in batch_dict[sz]['metrics']]\n",
    "    f1_macro_history = [round(metrics['f1_macro'],3) for metrics in batch_dict[sz]['metrics']]\n",
    "    print 'Cov Erro Hist=> {}'.format(cov_error_history)\n",
    "    print 'F1 Micro Hist=> {}'.format(f1_micro_history)\n",
    "    print 'F1 Macro Hist=> {}'.format(f1_macro_history)\n",
    "    print 'Coverage Error Max: {} => {} | F1 Micro Max: {} => {} | F1 Macro Max: {} => {}'.format(np.argmin(cov_error_history),\n",
    "                                                                                                np.min(cov_error_history),\n",
    "                                                                                                np.argmax(f1_micro_history),\n",
    "                                                                                                np.max(f1_micro_history), \n",
    "                                                                                                np.argmax(f1_macro_history),\n",
    "                                                                                                np.max(f1_macro_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(batch_dict, open('/mnt/data2/shalaby/exported_data/nn_batch_sizes.pkl','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Parameter searches for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopper_deltas = {\n",
    "    'sections': 0.0001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "early_stopper_patience = {\n",
    "    'sections': 5,\n",
    "    'classes': 10,\n",
    "    'subclasses': 10\n",
    "}\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 50,\n",
    "    'subclasses': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            time.sleep(0.2)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                yvp = self.model.predict(Xv)\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_sampler = ParameterSampler({\n",
    "        'first_hidden_layer_size':first_hidden_layer_sizes,\n",
    "        'first_hidden_layer_activation':first_hidden_layer_activations,\n",
    "        'second_hidden_layer_size':second_hidden_layer_sizes,\n",
    "        'second_hidden_layer_activation':second_hidden_layer_activations,\n",
    "        'input_dropout':input_dropout_options,\n",
    "        'hidden_dropout':hidden_dropout_options\n",
    "    }, n_iter=NN_RANDOM_SEARCH_BUDGET, random_state=NN_PARAM_SAMPLE_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_200_2nd-act_softmax_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_1000_2nd-act_tanh_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_1000_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_200_2nd-act_tanh_in-drop_True_hid-drop_False\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_200_2nd-act_tanh_in-drop_False_hid-drop_False\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_500_2nd-act_softmax_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_relu_2nd-size_1000_2nd-act_sigmoid_in-drop_True_hid-drop_True\n"
     ]
    }
   ],
   "source": [
    "for parameters in param_sampler:\n",
    "    start_time = time.time()\n",
    "    first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "    first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "    second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "    second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "    input_dropout_do = parameters['input_dropout']\n",
    "    hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "    dd = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "        first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "        second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "    )\n",
    "    print dd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_results_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load param results if needed to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_results_dict = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_skip = []\n",
    "to_skip = ['nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:30:23,291 : INFO : ***************************************************************************************\n",
      "2017-01-31 16:30:23,292 : INFO : nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True due to input dropout\n",
      "skipping: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "skipping: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True due to input dropout\n",
      "skipping: nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "skipping: nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_False due to input dropout\n",
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True due to input dropout\n",
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           100500      doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           470940      hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 571440\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:30:54,102 : INFO : Found lower val loss for epoch 1 => 0.41663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.5433 - val_loss: 0.4166\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:31:18,789 : INFO : Found lower val loss for epoch 2 => 0.24105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.3220 - val_loss: 0.2410\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:31:42,942 : INFO : Found lower val loss for epoch 3 => 0.13767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.1853 - val_loss: 0.1377\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:32:07,699 : INFO : Found lower val loss for epoch 4 => 0.07834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.1054 - val_loss: 0.0783\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:32:32,919 : INFO : Found lower val loss for epoch 5 => 0.04537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0603 - val_loss: 0.0454\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:32:58,110 : INFO : Found lower val loss for epoch 6 => 0.02747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0355 - val_loss: 0.0275\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:33:21,933 : INFO : Found lower val loss for epoch 7 => 0.01797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 23s - loss: 0.0222 - val_loss: 0.0180\n",
      "Epoch 8/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:33:47,220 : INFO : Found lower val loss for epoch 8 => 0.01304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0152 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:34:12,374 : INFO : Found lower val loss for epoch 9 => 0.01053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:34:37,619 : INFO : Found lower val loss for epoch 10 => 0.00928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:35:02,274 : INFO : Found lower val loss for epoch 11 => 0.00867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 12/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:35:26,834 : INFO : Found lower val loss for epoch 12 => 0.00838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:35:51,288 : INFO : Found lower val loss for epoch 13 => 0.00824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:36:16,023 : INFO : Found lower val loss for epoch 14 => 0.00817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 15/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:36:41,214 : INFO : Found lower val loss for epoch 15 => 0.00814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:37:06,312 : INFO : Found lower val loss for epoch 16 => 0.00812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 17/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:37:31,333 : INFO : Found lower val loss for epoch 17 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 18/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:37:56,477 : INFO : Found lower val loss for epoch 18 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 19/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:38:21,529 : INFO : Found lower val loss for epoch 19 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 20/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:38:46,671 : INFO : Found lower val loss for epoch 20 => 0.0081\n",
      "2017-01-31 16:38:46,673 : INFO : Validation Loss Reduced 20 times\n",
      "2017-01-31 16:38:46,674 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 16:39:52,959 : INFO : Generating Validation Metrics\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.110 | Top 3: 0.186 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n",
      "1286325/1286325 [==============================] - 486s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 21/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:46:53,197 : INFO : Found lower val loss for epoch 21 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 22/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:47:19,752 : INFO : Found lower val loss for epoch 22 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 23/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:47:44,396 : INFO : Found lower val loss for epoch 23 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 24/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:48:08,421 : INFO : Found lower val loss for epoch 24 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 25/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:48:32,268 : INFO : Found lower val loss for epoch 25 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 23s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 26/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:48:56,822 : INFO : Found lower val loss for epoch 26 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 24s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 27/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:49:20,402 : INFO : Found lower val loss for epoch 27 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 23s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 28/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0081 - val_loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:50:07,558 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: early stopping\n",
      "CPU times: user 13min 10s, sys: 6min 57s, total: 20min 7s\n",
      "Wall time: 19min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:51:08,970 : INFO : Generating Validation Metrics\n",
      "2017-01-31 16:57:31,299 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.086 | Top 3: 0.187 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 16:58:27,675 : INFO : Generating Validation Metrics\n",
      "2017-01-31 17:04:48,228 : INFO : ***************************************************************************************\n",
      "2017-01-31 17:04:48,230 : INFO : nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.082 | Top 3: 0.187 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           40200       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_softmax (Dense)    (None, 500)           100500      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           470940      hidden_layer2_softmax[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 611640\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:05:18,922 : INFO : Found lower val loss for epoch 1 => 0.4126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 28s - loss: 0.5347 - val_loss: 0.4126\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:05:48,620 : INFO : Found lower val loss for epoch 2 => 0.24363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 29s - loss: 0.3222 - val_loss: 0.2436\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:06:15,603 : INFO : Found lower val loss for epoch 3 => 0.13995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.1876 - val_loss: 0.1399\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:06:42,020 : INFO : Found lower val loss for epoch 4 => 0.07977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.1072 - val_loss: 0.0798\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:07:08,290 : INFO : Found lower val loss for epoch 5 => 0.04616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0614 - val_loss: 0.0462\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:07:34,954 : INFO : Found lower val loss for epoch 6 => 0.02789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0361 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:08:01,319 : INFO : Found lower val loss for epoch 7 => 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0226 - val_loss: 0.0182\n",
      "Epoch 8/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:08:27,504 : INFO : Found lower val loss for epoch 8 => 0.01315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0154 - val_loss: 0.0132\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:08:53,737 : INFO : Found lower val loss for epoch 9 => 0.01059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:09:20,633 : INFO : Found lower val loss for epoch 10 => 0.00931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:09:47,341 : INFO : Found lower val loss for epoch 11 => 0.00868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 12/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:10:13,569 : INFO : Found lower val loss for epoch 12 => 0.00838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:10:39,007 : INFO : Found lower val loss for epoch 13 => 0.00824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:11:05,337 : INFO : Found lower val loss for epoch 14 => 0.00817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 15/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:11:31,866 : INFO : Found lower val loss for epoch 15 => 0.00814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:11:58,433 : INFO : Found lower val loss for epoch 16 => 0.00812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 17/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:12:24,962 : INFO : Found lower val loss for epoch 17 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 18/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:12:51,487 : INFO : Found lower val loss for epoch 18 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 19/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:13:17,440 : INFO : Found lower val loss for epoch 19 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 25s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 20/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:13:44,208 : INFO : Found lower val loss for epoch 20 => 0.0081\n",
      "2017-01-31 17:13:44,210 : INFO : Validation Loss Reduced 20 times\n",
      "2017-01-31 17:13:44,211 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 17:14:45,496 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.101 | Top 3: 0.187 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n",
      "1286325/1286325 [==============================] - 480s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 21/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:21:45,172 : INFO : Found lower val loss for epoch 21 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 27s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 22/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:22:13,217 : INFO : Found lower val loss for epoch 22 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 28s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 23/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:22:39,862 : INFO : Found lower val loss for epoch 23 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 24/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:23:06,529 : INFO : Found lower val loss for epoch 24 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 25/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:23:33,284 : INFO : Found lower val loss for epoch 25 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 26/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:24:00,511 : INFO : Found lower val loss for epoch 26 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 27/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:24:27,302 : INFO : Found lower val loss for epoch 27 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 28/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:24:54,153 : INFO : Found lower val loss for epoch 28 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:25:20,522 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: early stopping\n",
      "CPU times: user 13min 27s, sys: 7min 30s, total: 20min 57s\n",
      "Wall time: 20min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:26:24,136 : INFO : Generating Validation Metrics\n",
      "2017-01-31 17:32:48,984 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.096 | Top 3: 0.186 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:33:41,248 : INFO : Generating Validation Metrics\n",
      "2017-01-31 17:39:59,992 : INFO : ***************************************************************************************\n",
      "2017-01-31 17:39:59,994 : INFO : nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.084 | Top 3: 0.187 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           100500      doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_relu (Dense)       (None, 200)           100200      hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           188940      hidden_layer2_relu[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 389640\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:40:24,260 : INFO : Found lower val loss for epoch 1 => 0.00509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 22s - loss: 0.0148 - val_loss: 0.0051\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:40:47,101 : INFO : Found lower val loss for epoch 2 => 0.00419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 22s - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:41:09,290 : INFO : Found lower val loss for epoch 3 => 0.00392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 22s - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:41:30,001 : INFO : Found lower val loss for epoch 4 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:41:50,134 : INFO : Found lower val loss for epoch 5 => 0.00376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:42:09,955 : INFO : Found lower val loss for epoch 6 => 0.00373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:42:29,867 : INFO : Found lower val loss for epoch 7 => 0.00367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 8/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:43:09,790 : INFO : Found lower val loss for epoch 9 => 0.00363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 10/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 11/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 12/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:44:27,934 : INFO : Found lower val loss for epoch 13 => 0.00361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 14/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:44:47,325 : INFO : Found lower val loss for epoch 14 => 0.00359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 16/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 18/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:46:06,108 : INFO : Found lower val loss for epoch 18 => 0.00358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 21/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 22/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 23/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 24/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 25/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:48:23,610 : INFO : Found lower val loss for epoch 25 => 0.00355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 26/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 27/100\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 28/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:49:23,752 : INFO : Found lower val loss for epoch 28 => 0.00354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 30/100\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 31/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 32/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 33/100\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 34/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 35/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 37/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 38/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 39/100\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.0032 - val_loss: 0.0036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:52:59,864 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: early stopping\n",
      "CPU times: user 7min 12s, sys: 6min 24s, total: 13min 37s\n",
      "Wall time: 12min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 17:53:57,587 : INFO : Generating Validation Metrics\n",
      "2017-01-31 18:00:52,189 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 7.414 | Top 3: 0.724 | Top 5: 0.808 | F1 Micro: 0.493 | F1 Macro: 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:01:47,254 : INFO : Generating Validation Metrics\n",
      "2017-01-31 18:08:33,636 : INFO : ***************************************************************************************\n",
      "2017-01-31 18:08:33,638 : INFO : nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 7.396 | Top 3: 0.725 | Top 5: 0.808 | F1 Micro: 0.501 | F1 Macro: 0.131\n",
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True due to input dropout\n",
      "skipping: nn_1st-size_500_1st-act_relu_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True due to input dropout\n",
      "skipping: nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_sigmoid_in-drop_True_hid-drop_True due to input dropout\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 200)           40200       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 200)           0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_softmax (Dense)    (None, 500)           100500      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           470940      hidden_layer2_softmax[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 611640\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:09:04,029 : INFO : Found lower val loss for epoch 1 => 0.41353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 28s - loss: 0.5356 - val_loss: 0.4135\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:09:34,068 : INFO : Found lower val loss for epoch 2 => 0.24421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 30s - loss: 0.3230 - val_loss: 0.2442\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:10:01,188 : INFO : Found lower val loss for epoch 3 => 0.14029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.1881 - val_loss: 0.1403\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:10:27,780 : INFO : Found lower val loss for epoch 4 => 0.07996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.1075 - val_loss: 0.0800\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:10:53,820 : INFO : Found lower val loss for epoch 5 => 0.04626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0615 - val_loss: 0.0463\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:11:20,840 : INFO : Found lower val loss for epoch 6 => 0.02795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0362 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:11:48,266 : INFO : Found lower val loss for epoch 7 => 0.01822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0226 - val_loss: 0.0182\n",
      "Epoch 8/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:12:15,251 : INFO : Found lower val loss for epoch 8 => 0.01317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0154 - val_loss: 0.0132\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:12:41,764 : INFO : Found lower val loss for epoch 9 => 0.01059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:13:08,673 : INFO : Found lower val loss for epoch 10 => 0.00931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:13:35,276 : INFO : Found lower val loss for epoch 11 => 0.00868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 12/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:14:02,740 : INFO : Found lower val loss for epoch 12 => 0.00838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:14:30,488 : INFO : Found lower val loss for epoch 13 => 0.00824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:14:57,300 : INFO : Found lower val loss for epoch 14 => 0.00817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 15/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:15:24,293 : INFO : Found lower val loss for epoch 15 => 0.00814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:15:51,381 : INFO : Found lower val loss for epoch 16 => 0.00812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 17/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:16:18,335 : INFO : Found lower val loss for epoch 17 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 18/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:16:45,186 : INFO : Found lower val loss for epoch 18 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 19/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:17:11,588 : INFO : Found lower val loss for epoch 19 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 20/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:17:38,490 : INFO : Found lower val loss for epoch 20 => 0.0081\n",
      "2017-01-31 18:17:38,492 : INFO : Validation Loss Reduced 20 times\n",
      "2017-01-31 18:17:38,492 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 18:18:41,194 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.088 | Top 3: 0.187 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n",
      "1286325/1286325 [==============================] - 486s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 21/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:25:46,911 : INFO : Found lower val loss for epoch 21 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 28s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 22/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:26:16,852 : INFO : Found lower val loss for epoch 22 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 29s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 23/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:26:44,421 : INFO : Found lower val loss for epoch 23 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 24/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:27:10,895 : INFO : Found lower val loss for epoch 24 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 25/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:27:37,599 : INFO : Found lower val loss for epoch 25 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 26/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:28:04,553 : INFO : Found lower val loss for epoch 26 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 27/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:28:32,278 : INFO : Found lower val loss for epoch 27 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 27s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 28/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:28:58,952 : INFO : Found lower val loss for epoch 28 => 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 26s - loss: 0.0081 - val_loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:29:25,248 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: early stopping\n",
      "CPU times: user 13min 29s, sys: 7min 43s, total: 21min 13s\n",
      "Wall time: 20min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:30:30,549 : INFO : Generating Validation Metrics\n",
      "2017-01-31 18:36:56,583 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.092 | Top 3: 0.187 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:37:48,881 : INFO : Generating Validation Metrics\n",
      "2017-01-31 18:44:08,939 : INFO : ***************************************************************************************\n",
      "2017-01-31 18:44:08,940 : INFO : nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 75.112 | Top 3: 0.186 | Top 5: 0.238 | F1 Micro: 0.000 | F1 Macro: 0.000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           40200       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_relu (Dense)       (None, 50)            10050       hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           47940       hidden_layer2_relu[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 98190\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:44:30,805 : INFO : Found lower val loss for epoch 1 => 0.00588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0247 - val_loss: 0.0059\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:44:51,418 : INFO : Found lower val loss for epoch 2 => 0.00472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:45:11,070 : INFO : Found lower val loss for epoch 3 => 0.00431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:45:29,099 : INFO : Found lower val loss for epoch 4 => 0.00421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:45:47,441 : INFO : Found lower val loss for epoch 5 => 0.00407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:46:04,671 : INFO : Found lower val loss for epoch 6 => 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:46:23,315 : INFO : Found lower val loss for epoch 7 => 0.00397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 8/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:46:41,045 : INFO : Found lower val loss for epoch 8 => 0.00393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:46:58,818 : INFO : Found lower val loss for epoch 9 => 0.00389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:47:17,104 : INFO : Found lower val loss for epoch 10 => 0.00388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:47:34,273 : INFO : Found lower val loss for epoch 11 => 0.00386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 12/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:47:51,907 : INFO : Found lower val loss for epoch 12 => 0.00385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:48:09,259 : INFO : Found lower val loss for epoch 13 => 0.00382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 14/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 16/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:49:01,413 : INFO : Found lower val loss for epoch 16 => 0.00381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 17/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:49:19,126 : INFO : Found lower val loss for epoch 17 => 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 18/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:49:36,719 : INFO : Found lower val loss for epoch 18 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 19/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:49:54,414 : INFO : Found lower val loss for epoch 19 => 0.00377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 21/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 22/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 23/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:51:04,118 : INFO : Found lower val loss for epoch 23 => 0.00373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 24/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 25/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 26/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 27/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:52:13,149 : INFO : Found lower val loss for epoch 27 => 0.00372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 28/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 30/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 31/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 18:53:23,932 : INFO : Found lower val loss for epoch 31 => 0.00371\n",
      "2017-01-31 18:53:23,935 : INFO : Validation Loss Reduced 20 times\n",
      "2017-01-31 18:53:23,936 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 18:54:31,985 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.269 | Top 3: 0.703 | Top 5: 0.788 | F1 Micro: 0.482 | F1 Macro: 0.099\n",
      "1286325/1286325 [==============================] - 511s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 32/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:01:55,424 : INFO : Found lower val loss for epoch 32 => 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 34/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 35/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 36/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 37/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:03:24,916 : INFO : Found lower val loss for epoch 37 => 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 38/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 39/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:03:59,832 : INFO : Found lower val loss for epoch 39 => 0.00369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 40/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 41/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 42/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 43/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 44/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:05:27,028 : INFO : Found lower val loss for epoch 44 => 0.00368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 45/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 46/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 47/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 48/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 49/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 50/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:07:13,407 : INFO : Found lower val loss for epoch 50 => 0.00368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1286325/1286325 [==============================] - 16s - loss: 0.0035 - val_loss: 0.0037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:07:13,412 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00049: early stopping\n",
      "CPU times: user 16min 9s, sys: 7min 43s, total: 23min 52s\n",
      "Wall time: 23min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:08:25,189 : INFO : Generating Validation Metrics\n",
      "2017-01-31 19:15:16,377 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.153 | Top 3: 0.707 | Top 5: 0.792 | F1 Micro: 0.469 | F1 Macro: 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:16:12,029 : INFO : Generating Validation Metrics\n",
      "2017-01-31 19:22:59,553 : INFO : ***************************************************************************************\n",
      "2017-01-31 19:22:59,555 : INFO : nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.153 | Top 3: 0.707 | Top 5: 0.792 | F1 Micro: 0.469 | F1 Macro: 0.093\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 200)           40200       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 200)           0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_sigmoid (Dense)    (None, 50)            10050       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           47940       hidden_layer2_sigmoid[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 98190\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:23:21,154 : INFO : Found lower val loss for epoch 1 => 0.00812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0549 - val_loss: 0.0081\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:23:41,099 : INFO : Found lower val loss for epoch 2 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:24:00,344 : INFO : Found lower val loss for epoch 3 => 0.00799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:24:18,707 : INFO : Found lower val loss for epoch 4 => 0.00731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:24:38,049 : INFO : Found lower val loss for epoch 5 => 0.00669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:24:56,670 : INFO : Found lower val loss for epoch 6 => 0.00622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:25:15,235 : INFO : Found lower val loss for epoch 7 => 0.00572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 8/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:25:34,615 : INFO : Found lower val loss for epoch 8 => 0.00533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:25:53,625 : INFO : Found lower val loss for epoch 9 => 0.00506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:26:11,969 : INFO : Found lower val loss for epoch 10 => 0.00487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:26:30,735 : INFO : Found lower val loss for epoch 11 => 0.00471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 12/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:26:49,258 : INFO : Found lower val loss for epoch 12 => 0.00458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:27:08,134 : INFO : Found lower val loss for epoch 13 => 0.00449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:27:27,073 : INFO : Found lower val loss for epoch 14 => 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 15/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:27:45,653 : INFO : Found lower val loss for epoch 15 => 0.00434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:28:04,975 : INFO : Found lower val loss for epoch 16 => 0.00428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:28:23,534 : INFO : Found lower val loss for epoch 17 => 0.00423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:28:42,368 : INFO : Found lower val loss for epoch 18 => 0.00419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:29:01,152 : INFO : Found lower val loss for epoch 19 => 0.00415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:29:20,837 : INFO : Found lower val loss for epoch 20 => 0.00412\n",
      "2017-01-31 19:29:20,838 : INFO : Validation Loss Reduced 20 times\n",
      "2017-01-31 19:29:20,839 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 19:30:31,118 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 11.305 | Top 3: 0.638 | Top 5: 0.727 | F1 Micro: 0.410 | F1 Macro: 0.029\n",
      "1286325/1286325 [==============================] - 502s - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 21/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:37:41,259 : INFO : Found lower val loss for epoch 21 => 0.00409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 22/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:38:00,079 : INFO : Found lower val loss for epoch 22 => 0.00407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 23/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:38:20,985 : INFO : Found lower val loss for epoch 23 => 0.00405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 20s - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 24/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:38:39,828 : INFO : Found lower val loss for epoch 24 => 0.00403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 25/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:38:59,088 : INFO : Found lower val loss for epoch 25 => 0.00401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 26/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:39:17,782 : INFO : Found lower val loss for epoch 26 => 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 27/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:39:36,744 : INFO : Found lower val loss for epoch 27 => 0.00398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:39:55,046 : INFO : Found lower val loss for epoch 28 => 0.00397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 29/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:40:13,655 : INFO : Found lower val loss for epoch 29 => 0.00396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 30/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:40:31,973 : INFO : Found lower val loss for epoch 30 => 0.00394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 31/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:40:50,127 : INFO : Found lower val loss for epoch 31 => 0.00393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 32/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:41:08,782 : INFO : Found lower val loss for epoch 32 => 0.00393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 33/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:41:27,337 : INFO : Found lower val loss for epoch 33 => 0.00392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 34/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:41:46,224 : INFO : Found lower val loss for epoch 34 => 0.00391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 35/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:42:05,471 : INFO : Found lower val loss for epoch 35 => 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 19s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 36/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:42:23,870 : INFO : Found lower val loss for epoch 36 => 0.00389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 37/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:42:42,275 : INFO : Found lower val loss for epoch 37 => 0.00389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 38/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:43:00,714 : INFO : Found lower val loss for epoch 38 => 0.00388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 39/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:43:19,639 : INFO : Found lower val loss for epoch 39 => 0.00388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 18s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 40/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:43:37,847 : INFO : Found lower val loss for epoch 40 => 0.00387\n",
      "2017-01-31 19:43:37,849 : INFO : Validation Loss Reduced 40 times\n",
      "2017-01-31 19:43:37,850 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 19:44:49,978 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 9.313 | Top 3: 0.673 | Top 5: 0.761 | F1 Micro: 0.450 | F1 Macro: 0.046\n",
      "1286325/1286325 [==============================] - 504s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 41/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:52:01,444 : INFO : Found lower val loss for epoch 41 => 0.00386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 42/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:52:21,501 : INFO : Found lower val loss for epoch 42 => 0.00386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 20s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 43/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:52:36,991 : INFO : Found lower val loss for epoch 43 => 0.00386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 44/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:52:51,684 : INFO : Found lower val loss for epoch 44 => 0.00385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 45/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:53:05,791 : INFO : Found lower val loss for epoch 45 => 0.00385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 46/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:53:19,541 : INFO : Found lower val loss for epoch 46 => 0.00384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 13s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 47/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:53:33,916 : INFO : Found lower val loss for epoch 47 => 0.00384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 48/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:53:48,128 : INFO : Found lower val loss for epoch 48 => 0.00384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 49/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:54:01,858 : INFO : Found lower val loss for epoch 49 => 0.00383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 13s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 50/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:54:17,985 : INFO : Found lower val loss for epoch 50 => 0.00383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 51/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:54:34,285 : INFO : Found lower val loss for epoch 51 => 0.00383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 52/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:54:50,387 : INFO : Found lower val loss for epoch 52 => 0.00382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 53/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:55:05,037 : INFO : Found lower val loss for epoch 53 => 0.00382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 54/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 55/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:55:33,832 : INFO : Found lower val loss for epoch 55 => 0.00382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 56/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:55:48,753 : INFO : Found lower val loss for epoch 56 => 0.00381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 57/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 58/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:56:20,396 : INFO : Found lower val loss for epoch 58 => 0.00381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 59/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:56:35,991 : INFO : Found lower val loss for epoch 59 => 0.00381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 60/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:56:51,867 : INFO : Found lower val loss for epoch 60 => 0.00381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 61/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:57:07,544 : INFO : Found lower val loss for epoch 61 => 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 62/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 19:57:24,182 : INFO : Found lower val loss for epoch 62 => 0.0038\n",
      "2017-01-31 19:57:24,184 : INFO : Validation Loss Reduced 60 times\n",
      "2017-01-31 19:57:24,185 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 19:58:36,327 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.818 | Top 3: 0.683 | Top 5: 0.770 | F1 Micro: 0.459 | F1 Macro: 0.055\n",
      "1286325/1286325 [==============================] - 651s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 63/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 64/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:08:32,135 : INFO : Found lower val loss for epoch 64 => 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 65/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:08:47,349 : INFO : Found lower val loss for epoch 65 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 66/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:09:02,819 : INFO : Found lower val loss for epoch 66 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 67/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:09:17,932 : INFO : Found lower val loss for epoch 67 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 68/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:09:32,408 : INFO : Found lower val loss for epoch 68 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 69/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:09:46,705 : INFO : Found lower val loss for epoch 69 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 70/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:10:01,479 : INFO : Found lower val loss for epoch 70 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 71/100\n",
      "1286325/1286325 [==============================] - 13s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 72/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:10:28,849 : INFO : Found lower val loss for epoch 72 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 13s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 73/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 74/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:10:58,272 : INFO : Found lower val loss for epoch 74 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 75/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:11:15,310 : INFO : Found lower val loss for epoch 75 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 17s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 76/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:11:31,724 : INFO : Found lower val loss for epoch 76 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 77/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:11:47,328 : INFO : Found lower val loss for epoch 77 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 78/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:12:04,193 : INFO : Found lower val loss for epoch 78 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 79/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 80/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:12:36,523 : INFO : Found lower val loss for epoch 80 => 0.00378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 81/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:12:52,329 : INFO : Found lower val loss for epoch 81 => 0.00377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 82/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 83/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 84/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 85/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:13:52,619 : INFO : Found lower val loss for epoch 85 => 0.00377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 86/100\n",
      "1286325/1286325 [==============================] - 13s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 87/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 88/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 89/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:14:51,796 : INFO : Found lower val loss for epoch 89 => 0.00377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 90/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:15:07,962 : INFO : Found lower val loss for epoch 90 => 0.00376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 91/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 92/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:15:40,613 : INFO : Found lower val loss for epoch 92 => 0.00376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 93/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 94/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 95/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 96/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 20:16:47,191 : INFO : Found lower val loss for epoch 96 => 0.00376\n",
      "2017-01-31 20:16:47,193 : INFO : Validation Loss Reduced 80 times\n",
      "2017-01-31 20:16:47,194 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 20:18:40,124 : INFO : Generating Validation Metrics\n"
     ]
    }
   ],
   "source": [
    "for parameters in param_sampler:\n",
    "    start_time = time.time()\n",
    "    first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "    first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "    second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "    second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "    input_dropout_do = parameters['input_dropout']\n",
    "    hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "#     print \"===================================================================================\\n\" + \\\n",
    "#           \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "#           \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "#           \"==========================\".format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "#                                                 second_hidden_layer_size, second_hidden_layer_activation, \n",
    "#                                                 input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "        first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "        second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "    )\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "    if input_dropout_do:\n",
    "        print \"skipping: {} due to input dropout\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "    \n",
    "    info('***************************************************************************************')\n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    \n",
    "    model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                  second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                  input_dropout_do, hidden_dropout_do)\n",
    "    model.summary()\n",
    "    \n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=4096, \\\n",
    "                              nb_epoch=NN_MAX_EPOCHS, verbose=1, callbacks=[early_stopper, metrics_callback])\n",
    "    \n",
    "#     info('Evaluating on Training Data')\n",
    "#     yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "#     yp_binary = get_binary_0_5(yp)\n",
    "#     #print yp\n",
    "#     info('Generating Training Metrics')\n",
    "#     training_metrics = get_metrics(y, yp, yp_binary)\n",
    "#     print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "#         training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "#         training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#         training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "    info('Evaluating on Validation Data using last weights')\n",
    "    yvp = model.predict(Xv)\n",
    "    yvp_binary = get_binary_0_5(yvp)\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    last_validation_metrics = validation_metrics\n",
    "\n",
    "    # using the recorded weights of the best recorded validation loss\n",
    "    last_model_weights = model.get_weights()\n",
    "    info('Evaluating on Validation Data using saved best weights')\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    yvp = model.predict(Xv)\n",
    "    yvp_binary = get_binary_0_5(yvp)\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    best_validation_metrics = validation_metrics\n",
    "\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "#     param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_metrics'] = training_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_validation_metrics'] = last_validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "#     param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['history'] = history\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_weights'] = last_model_weights\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "    \n",
    "    # setting the model weights to the best weights\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    \n",
    "    ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.NN_MODEL_NAME))\n",
    "    \n",
    "#     pickle.dump(model, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                             GLOBAL_VARS.NN_MODEL_NAME, CLASSIFIER), 'w'))\n",
    "    \n",
    "    pickle.dump(best_validation_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.NN_MODEL_NAME, VALIDATION_METRICS_FILENAME), 'w'))\n",
    "\n",
    "    del history, last_model_weights\n",
    "    \n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print len(param_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix old param_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications_type = 'subclasses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 6\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_results_dict = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if this is an old param_results_dict (it would have history and metrics_callback in that case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict:\n",
    "    print param_results_dict[key].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "CPU times: user 30.6 s, sys: 1.72 s, total: 32.3 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key in param_results_dict:\n",
    "    print param_results_dict[key].keys()\n",
    "    if param_results_dict[key].get('history') is not None:\n",
    "        val = param_results_dict[key]\n",
    "        param_results_dict[key]['epochs'] = len(val['history'].history['val_loss'])\n",
    "        param_results_dict[key]['best_weights'] = val['metrics_callback'].best_weights\n",
    "        del param_results_dict[key]['metrics_callback']\n",
    "        del param_results_dict[key]['history']\n",
    "    # delete last_weights to save more disk space\n",
    "    if param_results_dict[key].get('last_weights') is not None:\n",
    "        del param_results_dict[key]['last_weights']\n",
    "\n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "Epochs => 94\n",
      "Best Val Loss => 0.00629693473944\n",
      "Last Val: Coverage Error => 36.5203 | F1 Micro => 0.1340 | F1 Macro => 0.0016 | Top 3 => 0.3576\n",
      "Best Val: Coverage Error => 36.4996 | F1 Micro => 0.1360 | F1 Macro => 0.0016 | Top 3 => 0.3572\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.00362682105919\n",
      "Last Val: Coverage Error => 8.3420 | F1 Micro => 0.4929 | F1 Macro => 0.0873 | Top 3 => 0.7135\n",
      "Best Val: Coverage Error => 8.2455 | F1 Micro => 0.4931 | F1 Macro => 0.0844 | Top 3 => 0.7162\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "Epochs => 59\n",
      "Best Val Loss => 0.00416292175067\n",
      "Last Val: Coverage Error => 11.2393 | F1 Micro => 0.3981 | F1 Macro => 0.0350 | Top 3 => 0.6518\n",
      "Best Val: Coverage Error => 11.1370 | F1 Micro => 0.3986 | F1 Macro => 0.0325 | Top 3 => 0.6550\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict.keys():\n",
    "    print('========== NN: {}'.format(key))\n",
    "    val = param_results_dict[key]\n",
    "    val_metrics = val['last_validation_metrics']\n",
    "    val_metrics2 =  val['best_validation_metrics']\n",
    "    \n",
    "    print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "    print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Last Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Best Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run network for specific configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:02:19,885 : INFO : ***************************************************************************************\n",
      "2017-01-31 22:02:19,887 : INFO : nn_1st-size_500_1st-act_sigmoid_2nd-size_1000_2nd-act_tanh_in-drop_False_hid-drop_False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           100500      doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 1000)          501000      hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             8008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 609508\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:02:36,516 : INFO : Found lower val loss for epoch 1 => 0.21835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.2409 - val_loss: 0.2183\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:02:51,456 : INFO : Found lower val loss for epoch 2 => 0.19774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1972 - val_loss: 0.1977\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:03:06,350 : INFO : Found lower val loss for epoch 3 => 0.18749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1848 - val_loss: 0.1875\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:03:21,162 : INFO : Found lower val loss for epoch 4 => 0.17758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1749 - val_loss: 0.1776\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:03:35,974 : INFO : Found lower val loss for epoch 5 => 0.17404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1670 - val_loss: 0.1740\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:03:50,633 : INFO : Found lower val loss for epoch 6 => 0.17084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1605 - val_loss: 0.1708\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:04:05,453 : INFO : Found lower val loss for epoch 7 => 0.15889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1553 - val_loss: 0.1589\n",
      "Epoch 8/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:04:20,392 : INFO : Found lower val loss for epoch 8 => 0.15429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1513 - val_loss: 0.1543\n",
      "Epoch 9/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1481 - val_loss: 0.1544\n",
      "Epoch 10/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1454 - val_loss: 0.1558\n",
      "Epoch 11/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1432 - val_loss: 0.1583\n",
      "Epoch 12/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1412 - val_loss: 0.1545\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:05:34,756 : INFO : Found lower val loss for epoch 13 => 0.14946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 15s - loss: 0.1396 - val_loss: 0.1495\n",
      "Epoch 14/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1380 - val_loss: 0.1508\n",
      "Epoch 15/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:06:04,659 : INFO : Found lower val loss for epoch 15 => 0.14932\n",
      "2017-01-31 22:06:04,661 : INFO : Validation Loss Reduced 10 times\n",
      "2017-01-31 22:06:04,662 : INFO : Evaluating on Validation Data\n",
      "2017-01-31 22:06:09,773 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.451 | Top 3: 0.970 | Top 5: 0.995 | F1 Micro: 0.781 | F1 Macro: 0.724\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.1367 - val_loss: 0.1493\n",
      "Epoch 16/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:06:34,769 : INFO : Found lower val loss for epoch 16 => 0.1439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 14s - loss: 0.1354 - val_loss: 0.1439\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1342 - val_loss: 0.1488\n",
      "Epoch 18/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1330 - val_loss: 0.1471\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1321 - val_loss: 0.1477\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1311 - val_loss: 0.1468\n",
      "Epoch 21/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1301 - val_loss: 0.1461\n",
      "Epoch 22/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.1292 - val_loss: 0.1465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:08:01,761 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: early stopping\n",
      "CPU times: user 2min 42s, sys: 4min 26s, total: 7min 9s\n",
      "Wall time: 5min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:08:06,462 : INFO : Generating Validation Metrics\n",
      "2017-01-31 22:08:14,404 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.444 | Top 3: 0.970 | Top 5: 0.995 | F1 Micro: 0.785 | F1 Macro: 0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-31 22:08:19,091 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.437 | Top 3: 0.971 | Top 5: 0.995 | F1 Micro: 0.782 | F1 Macro: 0.702\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "first_hidden_layer_size = 500\n",
    "first_hidden_layer_activation = 'sigmoid'\n",
    "second_hidden_layer_size = 1000\n",
    "second_hidden_layer_activation = 'tanh'\n",
    "input_dropout_do = False\n",
    "hidden_dropout_do = False\n",
    "\n",
    "#     print \"===================================================================================\\n\" + \\\n",
    "#           \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "#           \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "#           \"==========================\".format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "#                                                 second_hidden_layer_size, second_hidden_layer_activation, \n",
    "#                                                 input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "    first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "    second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    ")\n",
    "if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys():\n",
    "    print \"Should be skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "info('***************************************************************************************')\n",
    "info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                              first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                              second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                              input_dropout_do, hidden_dropout_do)\n",
    "model.summary()\n",
    "\n",
    "early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                              patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "metrics_callback = MetricsCallback()\n",
    "\n",
    "# Model Fitting\n",
    "%time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                          nb_epoch=NN_MAX_EPOCHS, verbose=1, callbacks=[early_stopper, metrics_callback])\n",
    "\n",
    "#     info('Evaluating on Training Data')\n",
    "#     yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "#     yp_binary = get_binary_0_5(yp)\n",
    "#     #print yp\n",
    "#     info('Generating Training Metrics')\n",
    "#     training_metrics = get_metrics(y, yp, yp_binary)\n",
    "#     print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "#         training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "#         training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#         training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "info('Evaluating on Validation Data using last weights')\n",
    "yvp = model.predict(Xv)\n",
    "yvp_binary = get_binary_0_5(yvp)\n",
    "#print yvp\n",
    "info('Generating Validation Metrics')\n",
    "validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "last_validation_metrics = validation_metrics\n",
    "\n",
    "# using the recorded weights of the best recorded validation loss\n",
    "last_model_weights = model.get_weights()\n",
    "info('Evaluating on Validation Data using saved best weights')\n",
    "model.set_weights(metrics_callback.best_weights)\n",
    "yvp = model.predict(Xv)\n",
    "yvp_binary = get_binary_0_5(yvp)\n",
    "#print yvp\n",
    "info('Generating Validation Metrics')\n",
    "validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "best_validation_metrics = validation_metrics\n",
    "\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "#     param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_metrics'] = training_metrics\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_validation_metrics'] = last_validation_metrics\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_weights'] = last_model_weights\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['history'] = history\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'] = metrics_callback\n",
    "\n",
    "    \n",
    "duration = time.time() - start_time\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "# pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                        NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                       NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "Epochs => 100\n",
      "Best Val Loss => 0.166829405505\n",
      "Last Val: Coverage Error => 1.4960 | F1 Micro => 0.7434 | F1 Macro => 0.6293 | Top 3 => 0.9637\n",
      "Best Val: Coverage Error => 1.4960 | F1 Micro => 0.7434 | F1 Macro => 0.6293 | Top 3 => 0.9637\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 47\n",
      "Best Val Loss => 0.147426413828\n",
      "Last Val: Coverage Error => 1.4576 | F1 Micro => 0.7738 | F1 Macro => 0.7021 | Top 3 => 0.9697\n",
      "Best Val: Coverage Error => 1.4576 | F1 Micro => 0.7738 | F1 Macro => 0.7021 | Top 3 => 0.9697\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.192695072037\n",
      "Last Val: Coverage Error => 1.6299 | F1 Micro => 0.6631 | F1 Macro => 0.4731 | Top 3 => 0.9455\n",
      "Best Val: Coverage Error => 1.6299 | F1 Micro => 0.6631 | F1 Macro => 0.4731 | Top 3 => 0.9455\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict.keys():\n",
    "    print('========== NN: {}'.format(key))\n",
    "    val = param_results_dict[key]\n",
    "    val_metrics = val['last_validation_metrics']\n",
    "    val_metrics2 =  val['best_validation_metrics']\n",
    "    \n",
    "    print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "    print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Last Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Best Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 52\n",
      "Best Val Loss => 0.209273911595\n",
      "Coverage Error => 1.6301 | F1 Micro => 0.6278 | F1 Macro => 0.4057 | Top 3 => 0.9440\n",
      "Coverage Error => 1.6337 | F1 Micro => 0.6286 | F1 Macro => 0.4065 | Top 3 => 0.9448\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 35\n",
      "Best Val Loss => 0.218694725994\n",
      "Coverage Error => 1.6793 | F1 Micro => 0.5939 | F1 Macro => 0.3668 | Top 3 => 0.9360\n",
      "Coverage Error => 1.6744 | F1 Micro => 0.5924 | F1 Macro => 0.3680 | Top 3 => 0.9370\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 79\n",
      "Best Val Loss => 0.161037461469\n",
      "Coverage Error => 1.5147 | F1 Micro => 0.7480 | F1 Macro => 0.6480 | Top 3 => 0.9605\n",
      "Coverage Error => 1.5151 | F1 Micro => 0.7483 | F1 Macro => 0.6455 | Top 3 => 0.9606\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.19296394765\n",
      "Coverage Error => 1.6255 | F1 Micro => 0.6765 | F1 Macro => 0.4847 | Top 3 => 0.9473\n",
      "Coverage Error => 1.6164 | F1 Micro => 0.6772 | F1 Macro => 0.4822 | Top 3 => 0.9479\n",
      "========== NN: nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 62\n",
      "Best Val Loss => 0.153030478399\n",
      "Coverage Error => 1.4792 | F1 Micro => 0.7659 | F1 Macro => 0.6745 | Top 3 => 0.9663\n",
      "Coverage Error => 1.4793 | F1 Micro => 0.7658 | F1 Macro => 0.6767 | Top 3 => 0.9661\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "Epochs => 74\n",
      "Best Val Loss => 0.152595937912\n",
      "Coverage Error => 1.4762 | F1 Micro => 0.7662 | F1 Macro => 0.6849 | Top 3 => 0.9669\n",
      "Coverage Error => 1.4755 | F1 Micro => 0.7665 | F1 Macro => 0.6822 | Top 3 => 0.9669\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 23\n",
      "Best Val Loss => 0.146622256775\n",
      "Coverage Error => 1.4371 | F1 Micro => 0.7814 | F1 Macro => 0.7202 | Top 3 => 0.9718\n",
      "Coverage Error => 1.4397 | F1 Micro => 0.7802 | F1 Macro => 0.7099 | Top 3 => 0.9716\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.150167715843\n",
      "Coverage Error => 1.4643 | F1 Micro => 0.7701 | F1 Macro => 0.6994 | Top 3 => 0.9683\n",
      "Coverage Error => 1.4615 | F1 Micro => 0.7701 | F1 Macro => 0.6962 | Top 3 => 0.9685\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "Epochs => 45\n",
      "Best Val Loss => 0.144718239361\n",
      "Coverage Error => 1.4385 | F1 Micro => 0.7851 | F1 Macro => 0.7142 | Top 3 => 0.9709\n",
      "Coverage Error => 1.4387 | F1 Micro => 0.7850 | F1 Macro => 0.7155 | Top 3 => 0.9709\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "Epochs => 69\n",
      "Best Val Loss => 0.152811881308\n",
      "Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "Epochs => 31\n",
      "Best Val Loss => 0.188622105058\n",
      "Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.177211825736\n",
      "Coverage Error => 1.5612 | F1 Micro => 0.7096 | F1 Macro => 0.5282 | Top 3 => 0.9537\n",
      "Coverage Error => 1.5519 | F1 Micro => 0.7001 | F1 Macro => 0.5391 | Top 3 => 0.9564\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 37\n",
      "Best Val Loss => 0.182871406887\n",
      "Coverage Error => 1.5657 | F1 Micro => 0.6919 | F1 Macro => 0.4956 | Top 3 => 0.9543\n",
      "Coverage Error => 1.5669 | F1 Micro => 0.6938 | F1 Macro => 0.5057 | Top 3 => 0.9543\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 40\n",
      "Best Val Loss => 0.14467293148\n",
      "Coverage Error => 1.4431 | F1 Micro => 0.7800 | F1 Macro => 0.7153 | Top 3 => 0.9714\n",
      "Coverage Error => 1.4431 | F1 Micro => 0.7821 | F1 Macro => 0.7181 | Top 3 => 0.9713\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.19802413061\n",
      "Coverage Error => 1.6223 | F1 Micro => 0.6572 | F1 Macro => 0.4326 | Top 3 => 0.9455\n",
      "Coverage Error => 1.6197 | F1 Micro => 0.6594 | F1 Macro => 0.4412 | Top 3 => 0.9467\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 50\n",
      "Best Val Loss => 0.154267980102\n",
      "Coverage Error => 1.4724 | F1 Micro => 0.7650 | F1 Macro => 0.6873 | Top 3 => 0.9668\n",
      "Coverage Error => 1.4724 | F1 Micro => 0.7629 | F1 Macro => 0.6759 | Top 3 => 0.9670\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.142855885915\n",
      "Coverage Error => 1.4374 | F1 Micro => 0.7837 | F1 Macro => 0.7206 | Top 3 => 0.9723\n",
      "Coverage Error => 1.4351 | F1 Micro => 0.7844 | F1 Macro => 0.7225 | Top 3 => 0.9724\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.166171306583\n",
      "Coverage Error => 1.4945 | F1 Micro => 0.7443 | F1 Macro => 0.6440 | Top 3 => 0.9635\n",
      "Coverage Error => 1.4932 | F1 Micro => 0.7445 | F1 Macro => 0.6436 | Top 3 => 0.9636\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 30\n",
      "Best Val Loss => 0.179389482992\n",
      "Coverage Error => 1.5448 | F1 Micro => 0.7084 | F1 Macro => 0.5527 | Top 3 => 0.9560\n",
      "Coverage Error => 1.5430 | F1 Micro => 0.7015 | F1 Macro => 0.5343 | Top 3 => 0.9566\n",
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "Epochs => 25\n",
      "Best Val Loss => 0.166892905616\n",
      "Coverage Error => 1.5206 | F1 Micro => 0.7352 | F1 Macro => 0.6247 | Top 3 => 0.9605\n",
      "Coverage Error => 1.5179 | F1 Micro => 0.7295 | F1 Macro => 0.6038 | Top 3 => 0.9610\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict.keys():\n",
    "    print('========== NN: {}'.format(key))\n",
    "    val = param_results_dict[key]\n",
    "    val_metrics = val['validation_metrics']\n",
    "    val_metrics2 =  val['metrics_callback'].metrics_dict[sorted(val['metrics_callback'].metrics_dict.keys())[-1]]\n",
    "    \n",
    "    print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "    print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_results_dict = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, 1024))), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 52\n",
      "Best Val Loss => 0.209273911595\n",
      "Last Val: Coverage Error => 1.6301 | F1 Micro => 0.6278 | F1 Macro => 0.4057 | Top 3 => 0.9440\n",
      "Best Val: Coverage Error => 1.6337 | F1 Micro => 0.6286 | F1 Macro => 0.4065 | Top 3 => 0.9448\n",
      "Epochs => 44\n",
      "Best Val Loss => 0.210580854079\n",
      "Last Val: Coverage Error => 1.6304 | F1 Micro => 0.6271 | F1 Macro => 0.4056 | Top 3 => 0.9441\n",
      "Best Val: Coverage Error => 1.6304 | F1 Micro => 0.6271 | F1 Macro => 0.4056 | Top 3 => 0.9441\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 35\n",
      "Best Val Loss => 0.218694725994\n",
      "Last Val: Coverage Error => 1.6793 | F1 Micro => 0.5939 | F1 Macro => 0.3668 | Top 3 => 0.9360\n",
      "Best Val: Coverage Error => 1.6744 | F1 Micro => 0.5924 | F1 Macro => 0.3680 | Top 3 => 0.9370\n",
      "Epochs => 27\n",
      "Best Val Loss => 0.218751933207\n",
      "Last Val: Coverage Error => 1.6814 | F1 Micro => 0.5933 | F1 Macro => 0.3621 | Top 3 => 0.9354\n",
      "Best Val: Coverage Error => 1.6650 | F1 Micro => 0.5930 | F1 Macro => 0.3696 | Top 3 => 0.9376\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 79\n",
      "Best Val Loss => 0.161037461469\n",
      "Last Val: Coverage Error => 1.5147 | F1 Micro => 0.7480 | F1 Macro => 0.6480 | Top 3 => 0.9605\n",
      "Best Val: Coverage Error => 1.5151 | F1 Micro => 0.7483 | F1 Macro => 0.6455 | Top 3 => 0.9606\n",
      "Epochs => 56\n",
      "Best Val Loss => 0.147194364789\n",
      "Last Val: Coverage Error => 1.4567 | F1 Micro => 0.7771 | F1 Macro => 0.7070 | Top 3 => 0.9688\n",
      "Best Val: Coverage Error => 1.4568 | F1 Micro => 0.7773 | F1 Macro => 0.7074 | Top 3 => 0.9689\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.19296394765\n",
      "Last Val: Coverage Error => 1.6255 | F1 Micro => 0.6765 | F1 Macro => 0.4847 | Top 3 => 0.9473\n",
      "Best Val: Coverage Error => 1.6164 | F1 Micro => 0.6772 | F1 Macro => 0.4822 | Top 3 => 0.9479\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.193241113904\n",
      "Last Val: Coverage Error => 1.6170 | F1 Micro => 0.6712 | F1 Macro => 0.4914 | Top 3 => 0.9469\n",
      "Best Val: Coverage Error => 1.6062 | F1 Micro => 0.6640 | F1 Macro => 0.5023 | Top 3 => 0.9496\n",
      "========== NN: nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 62\n",
      "Best Val Loss => 0.153030478399\n",
      "Last Val: Coverage Error => 1.4792 | F1 Micro => 0.7659 | F1 Macro => 0.6745 | Top 3 => 0.9663\n",
      "Best Val: Coverage Error => 1.4793 | F1 Micro => 0.7658 | F1 Macro => 0.6767 | Top 3 => 0.9661\n",
      "Epochs => 44\n",
      "Best Val Loss => 0.153852276883\n",
      "Last Val: Coverage Error => 1.4837 | F1 Micro => 0.7659 | F1 Macro => 0.6799 | Top 3 => 0.9651\n",
      "Best Val: Coverage Error => 1.4827 | F1 Micro => 0.7662 | F1 Macro => 0.6794 | Top 3 => 0.9654\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "Epochs => 74\n",
      "Best Val Loss => 0.152595937912\n",
      "Last Val: Coverage Error => 1.4762 | F1 Micro => 0.7662 | F1 Macro => 0.6849 | Top 3 => 0.9669\n",
      "Best Val: Coverage Error => 1.4755 | F1 Micro => 0.7665 | F1 Macro => 0.6822 | Top 3 => 0.9669\n",
      "Epochs => 46\n",
      "Best Val Loss => 0.153923276142\n",
      "Last Val: Coverage Error => 1.4816 | F1 Micro => 0.7628 | F1 Macro => 0.6860 | Top 3 => 0.9657\n",
      "Best Val: Coverage Error => 1.4820 | F1 Micro => 0.7638 | F1 Macro => 0.6902 | Top 3 => 0.9660\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 23\n",
      "Best Val Loss => 0.146622256775\n",
      "Last Val: Coverage Error => 1.4371 | F1 Micro => 0.7814 | F1 Macro => 0.7202 | Top 3 => 0.9718\n",
      "Best Val: Coverage Error => 1.4397 | F1 Micro => 0.7802 | F1 Macro => 0.7099 | Top 3 => 0.9716\n",
      "Epochs => 15\n",
      "Best Val Loss => 0.148500504008\n",
      "Last Val: Coverage Error => 1.4443 | F1 Micro => 0.7803 | F1 Macro => 0.7072 | Top 3 => 0.9705\n",
      "Best Val: Coverage Error => 1.4468 | F1 Micro => 0.7789 | F1 Macro => 0.7036 | Top 3 => 0.9702\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.150167715843\n",
      "Last Val: Coverage Error => 1.4643 | F1 Micro => 0.7701 | F1 Macro => 0.6994 | Top 3 => 0.9683\n",
      "Best Val: Coverage Error => 1.4615 | F1 Micro => 0.7701 | F1 Macro => 0.6962 | Top 3 => 0.9685\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.149573759319\n",
      "Last Val: Coverage Error => 1.4595 | F1 Micro => 0.7725 | F1 Macro => 0.6973 | Top 3 => 0.9687\n",
      "Best Val: Coverage Error => 1.4587 | F1 Micro => 0.7742 | F1 Macro => 0.7010 | Top 3 => 0.9689\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "Epochs => 45\n",
      "Best Val Loss => 0.144718239361\n",
      "Last Val: Coverage Error => 1.4385 | F1 Micro => 0.7851 | F1 Macro => 0.7142 | Top 3 => 0.9709\n",
      "Best Val: Coverage Error => 1.4387 | F1 Micro => 0.7850 | F1 Macro => 0.7155 | Top 3 => 0.9709\n",
      "Epochs => 27\n",
      "Best Val Loss => 0.1450360377\n",
      "Last Val: Coverage Error => 1.4380 | F1 Micro => 0.7865 | F1 Macro => 0.7186 | Top 3 => 0.9710\n",
      "Best Val: Coverage Error => 1.4387 | F1 Micro => 0.7860 | F1 Macro => 0.7172 | Top 3 => 0.9710\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "Epochs => 69\n",
      "Best Val Loss => 0.152811881308\n",
      "Last Val: Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "Best Val: Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "Epochs => 68\n",
      "Best Val Loss => 0.152235407092\n",
      "Last Val: Coverage Error => 1.4780 | F1 Micro => 0.7664 | F1 Macro => 0.6801 | Top 3 => 0.9665\n",
      "Best Val: Coverage Error => 1.4761 | F1 Micro => 0.7653 | F1 Macro => 0.6861 | Top 3 => 0.9671\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "Epochs => 31\n",
      "Best Val Loss => 0.188622105058\n",
      "Last Val: Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "Best Val: Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "Epochs => 31\n",
      "Best Val Loss => 0.185910411101\n",
      "Last Val: Coverage Error => 1.6197 | F1 Micro => 0.7108 | F1 Macro => 0.4772 | Top 3 => 0.9383\n",
      "Best Val: Coverage Error => 1.6074 | F1 Micro => 0.7170 | F1 Macro => 0.5003 | Top 3 => 0.9405\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.177211825736\n",
      "Last Val: Coverage Error => 1.5612 | F1 Micro => 0.7096 | F1 Macro => 0.5282 | Top 3 => 0.9537\n",
      "Best Val: Coverage Error => 1.5519 | F1 Micro => 0.7001 | F1 Macro => 0.5391 | Top 3 => 0.9564\n",
      "Epochs => 20\n",
      "Best Val Loss => 0.178523907068\n",
      "Last Val: Coverage Error => 1.5559 | F1 Micro => 0.6967 | F1 Macro => 0.5266 | Top 3 => 0.9557\n",
      "Best Val: Coverage Error => 1.5498 | F1 Micro => 0.7073 | F1 Macro => 0.5485 | Top 3 => 0.9567\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 37\n",
      "Best Val Loss => 0.182871406887\n",
      "Last Val: Coverage Error => 1.5657 | F1 Micro => 0.6919 | F1 Macro => 0.4956 | Top 3 => 0.9543\n",
      "Best Val: Coverage Error => 1.5669 | F1 Micro => 0.6938 | F1 Macro => 0.5057 | Top 3 => 0.9543\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.185281427776\n",
      "Last Val: Coverage Error => 1.5724 | F1 Micro => 0.6860 | F1 Macro => 0.4913 | Top 3 => 0.9532\n",
      "Best Val: Coverage Error => 1.5723 | F1 Micro => 0.6857 | F1 Macro => 0.4896 | Top 3 => 0.9535\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 40\n",
      "Best Val Loss => 0.14467293148\n",
      "Last Val: Coverage Error => 1.4431 | F1 Micro => 0.7800 | F1 Macro => 0.7153 | Top 3 => 0.9714\n",
      "Best Val: Coverage Error => 1.4431 | F1 Micro => 0.7821 | F1 Macro => 0.7181 | Top 3 => 0.9713\n",
      "Epochs => 21\n",
      "Best Val Loss => 0.14781301107\n",
      "Last Val: Coverage Error => 1.4545 | F1 Micro => 0.7763 | F1 Macro => 0.7045 | Top 3 => 0.9694\n",
      "Best Val: Coverage Error => 1.4535 | F1 Micro => 0.7755 | F1 Macro => 0.7076 | Top 3 => 0.9699\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.19802413061\n",
      "Last Val: Coverage Error => 1.6223 | F1 Micro => 0.6572 | F1 Macro => 0.4326 | Top 3 => 0.9455\n",
      "Best Val: Coverage Error => 1.6197 | F1 Micro => 0.6594 | F1 Macro => 0.4412 | Top 3 => 0.9467\n",
      "Epochs => 38\n",
      "Best Val Loss => 0.200216266256\n",
      "Last Val: Coverage Error => 1.6320 | F1 Micro => 0.6561 | F1 Macro => 0.4338 | Top 3 => 0.9444\n",
      "Best Val: Coverage Error => 1.6231 | F1 Micro => 0.6513 | F1 Macro => 0.4264 | Top 3 => 0.9458\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 50\n",
      "Best Val Loss => 0.154267980102\n",
      "Last Val: Coverage Error => 1.4724 | F1 Micro => 0.7650 | F1 Macro => 0.6873 | Top 3 => 0.9668\n",
      "Best Val: Coverage Error => 1.4724 | F1 Micro => 0.7629 | F1 Macro => 0.6759 | Top 3 => 0.9670\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.154700267607\n",
      "Last Val: Coverage Error => 1.4750 | F1 Micro => 0.7592 | F1 Macro => 0.6718 | Top 3 => 0.9665\n",
      "Best Val: Coverage Error => 1.4733 | F1 Micro => 0.7616 | F1 Macro => 0.6797 | Top 3 => 0.9668\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.142855885915\n",
      "Last Val: Coverage Error => 1.4374 | F1 Micro => 0.7837 | F1 Macro => 0.7206 | Top 3 => 0.9723\n",
      "Best Val: Coverage Error => 1.4351 | F1 Micro => 0.7844 | F1 Macro => 0.7225 | Top 3 => 0.9724\n",
      "Epochs => 17\n",
      "Best Val Loss => 0.147080744336\n",
      "Last Val: Coverage Error => 1.4501 | F1 Micro => 0.7759 | F1 Macro => 0.7089 | Top 3 => 0.9703\n",
      "Best Val: Coverage Error => 1.4492 | F1 Micro => 0.7765 | F1 Macro => 0.7112 | Top 3 => 0.9706\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.166171306583\n",
      "Last Val: Coverage Error => 1.4945 | F1 Micro => 0.7443 | F1 Macro => 0.6440 | Top 3 => 0.9635\n",
      "Best Val: Coverage Error => 1.4932 | F1 Micro => 0.7445 | F1 Macro => 0.6436 | Top 3 => 0.9636\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.167615778877\n",
      "Last Val: Coverage Error => 1.5069 | F1 Micro => 0.7373 | F1 Macro => 0.6381 | Top 3 => 0.9609\n",
      "Best Val: Coverage Error => 1.5037 | F1 Micro => 0.7392 | F1 Macro => 0.6410 | Top 3 => 0.9614\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 30\n",
      "Best Val Loss => 0.179389482992\n",
      "Last Val: Coverage Error => 1.5448 | F1 Micro => 0.7084 | F1 Macro => 0.5527 | Top 3 => 0.9560\n",
      "Best Val: Coverage Error => 1.5430 | F1 Micro => 0.7015 | F1 Macro => 0.5343 | Top 3 => 0.9566\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.179591152206\n",
      "Last Val: Coverage Error => 1.5438 | F1 Micro => 0.6930 | F1 Macro => 0.5099 | Top 3 => 0.9566\n",
      "Best Val: Coverage Error => 1.5346 | F1 Micro => 0.6969 | F1 Macro => 0.5243 | Top 3 => 0.9579\n",
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "Epochs => 25\n",
      "Best Val Loss => 0.166892905616\n",
      "Last Val: Coverage Error => 1.5206 | F1 Micro => 0.7352 | F1 Macro => 0.6247 | Top 3 => 0.9605\n",
      "Best Val: Coverage Error => 1.5179 | F1 Micro => 0.7295 | F1 Macro => 0.6038 | Top 3 => 0.9610\n",
      "Epochs => 29\n",
      "Best Val Loss => 0.165255952613\n",
      "Last Val: Coverage Error => 1.5259 | F1 Micro => 0.7263 | F1 Macro => 0.6177 | Top 3 => 0.9594\n",
      "Best Val: Coverage Error => 1.5097 | F1 Micro => 0.7366 | F1 Macro => 0.6207 | Top 3 => 0.9614\n"
     ]
    }
   ],
   "source": [
    "param_results_dict_512 = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, 512))), 'r'))\n",
    "param_results_dict_1024 = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, 1024))), 'r'))mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 52\n",
      "Best Val Loss => 0.209273911595\n",
      "Last Val: Coverage Error => 1.6301 | F1 Micro => 0.6278 | F1 Macro => 0.4057 | Top 3 => 0.9440\n",
      "Best Val: Coverage Error => 1.6337 | F1 Micro => 0.6286 | F1 Macro => 0.4065 | Top 3 => 0.9448\n",
      "**** 1024 ********\n",
      "Epochs => 44\n",
      "Best Val Loss => 0.210580854079\n",
      "Last Val: Coverage Error => 1.6304 | F1 Micro => 0.6271 | F1 Macro => 0.4056 | Top 3 => 0.9441\n",
      "Best Val: Coverage Error => 1.6304 | F1 Micro => 0.6271 | F1 Macro => 0.4056 | Top 3 => 0.9441\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 35\n",
      "Best Val Loss => 0.218694725994\n",
      "Last Val: Coverage Error => 1.6793 | F1 Micro => 0.5939 | F1 Macro => 0.3668 | Top 3 => 0.9360\n",
      "Best Val: Coverage Error => 1.6744 | F1 Micro => 0.5924 | F1 Macro => 0.3680 | Top 3 => 0.9370\n",
      "**** 1024 ********\n",
      "Epochs => 27\n",
      "Best Val Loss => 0.218751933207\n",
      "Last Val: Coverage Error => 1.6814 | F1 Micro => 0.5933 | F1 Macro => 0.3621 | Top 3 => 0.9354\n",
      "Best Val: Coverage Error => 1.6650 | F1 Micro => 0.5930 | F1 Macro => 0.3696 | Top 3 => 0.9376\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 79\n",
      "Best Val Loss => 0.161037461469\n",
      "Last Val: Coverage Error => 1.5147 | F1 Micro => 0.7480 | F1 Macro => 0.6480 | Top 3 => 0.9605\n",
      "Best Val: Coverage Error => 1.5151 | F1 Micro => 0.7483 | F1 Macro => 0.6455 | Top 3 => 0.9606\n",
      "**** 1024 ********\n",
      "Epochs => 56\n",
      "Best Val Loss => 0.147194364789\n",
      "Last Val: Coverage Error => 1.4567 | F1 Micro => 0.7771 | F1 Macro => 0.7070 | Top 3 => 0.9688\n",
      "Best Val: Coverage Error => 1.4568 | F1 Micro => 0.7773 | F1 Macro => 0.7074 | Top 3 => 0.9689\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.19296394765\n",
      "Last Val: Coverage Error => 1.6255 | F1 Micro => 0.6765 | F1 Macro => 0.4847 | Top 3 => 0.9473\n",
      "Best Val: Coverage Error => 1.6164 | F1 Micro => 0.6772 | F1 Macro => 0.4822 | Top 3 => 0.9479\n",
      "**** 1024 ********\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.193241113904\n",
      "Last Val: Coverage Error => 1.6170 | F1 Micro => 0.6712 | F1 Macro => 0.4914 | Top 3 => 0.9469\n",
      "Best Val: Coverage Error => 1.6062 | F1 Micro => 0.6640 | F1 Macro => 0.5023 | Top 3 => 0.9496\n",
      "========== NN: nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 62\n",
      "Best Val Loss => 0.153030478399\n",
      "Last Val: Coverage Error => 1.4792 | F1 Micro => 0.7659 | F1 Macro => 0.6745 | Top 3 => 0.9663\n",
      "Best Val: Coverage Error => 1.4793 | F1 Micro => 0.7658 | F1 Macro => 0.6767 | Top 3 => 0.9661\n",
      "**** 1024 ********\n",
      "Epochs => 44\n",
      "Best Val Loss => 0.153852276883\n",
      "Last Val: Coverage Error => 1.4837 | F1 Micro => 0.7659 | F1 Macro => 0.6799 | Top 3 => 0.9651\n",
      "Best Val: Coverage Error => 1.4827 | F1 Micro => 0.7662 | F1 Macro => 0.6794 | Top 3 => 0.9654\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 74\n",
      "Best Val Loss => 0.152595937912\n",
      "Last Val: Coverage Error => 1.4762 | F1 Micro => 0.7662 | F1 Macro => 0.6849 | Top 3 => 0.9669\n",
      "Best Val: Coverage Error => 1.4755 | F1 Micro => 0.7665 | F1 Macro => 0.6822 | Top 3 => 0.9669\n",
      "**** 1024 ********\n",
      "Epochs => 46\n",
      "Best Val Loss => 0.153923276142\n",
      "Last Val: Coverage Error => 1.4816 | F1 Micro => 0.7628 | F1 Macro => 0.6860 | Top 3 => 0.9657\n",
      "Best Val: Coverage Error => 1.4820 | F1 Micro => 0.7638 | F1 Macro => 0.6902 | Top 3 => 0.9660\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "**** 512 ********\n",
      "Epochs => 23\n",
      "Best Val Loss => 0.146622256775\n",
      "Last Val: Coverage Error => 1.4371 | F1 Micro => 0.7814 | F1 Macro => 0.7202 | Top 3 => 0.9718\n",
      "Best Val: Coverage Error => 1.4397 | F1 Micro => 0.7802 | F1 Macro => 0.7099 | Top 3 => 0.9716\n",
      "**** 1024 ********\n",
      "Epochs => 15\n",
      "Best Val Loss => 0.148500504008\n",
      "Last Val: Coverage Error => 1.4443 | F1 Micro => 0.7803 | F1 Macro => 0.7072 | Top 3 => 0.9705\n",
      "Best Val: Coverage Error => 1.4468 | F1 Micro => 0.7789 | F1 Macro => 0.7036 | Top 3 => 0.9702\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "**** 512 ********\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.150167715843\n",
      "Last Val: Coverage Error => 1.4643 | F1 Micro => 0.7701 | F1 Macro => 0.6994 | Top 3 => 0.9683\n",
      "Best Val: Coverage Error => 1.4615 | F1 Micro => 0.7701 | F1 Macro => 0.6962 | Top 3 => 0.9685\n",
      "**** 1024 ********\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.149573759319\n",
      "Last Val: Coverage Error => 1.4595 | F1 Micro => 0.7725 | F1 Macro => 0.6973 | Top 3 => 0.9687\n",
      "Best Val: Coverage Error => 1.4587 | F1 Micro => 0.7742 | F1 Macro => 0.7010 | Top 3 => 0.9689\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "**** 512 ********\n",
      "Epochs => 45\n",
      "Best Val Loss => 0.144718239361\n",
      "Last Val: Coverage Error => 1.4385 | F1 Micro => 0.7851 | F1 Macro => 0.7142 | Top 3 => 0.9709\n",
      "Best Val: Coverage Error => 1.4387 | F1 Micro => 0.7850 | F1 Macro => 0.7155 | Top 3 => 0.9709\n",
      "**** 1024 ********\n",
      "Epochs => 27\n",
      "Best Val Loss => 0.1450360377\n",
      "Last Val: Coverage Error => 1.4380 | F1 Micro => 0.7865 | F1 Macro => 0.7186 | Top 3 => 0.9710\n",
      "Best Val: Coverage Error => 1.4387 | F1 Micro => 0.7860 | F1 Macro => 0.7172 | Top 3 => 0.9710\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 69\n",
      "Best Val Loss => 0.152811881308\n",
      "Last Val: Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "Best Val: Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "**** 1024 ********\n",
      "Epochs => 68\n",
      "Best Val Loss => 0.152235407092\n",
      "Last Val: Coverage Error => 1.4780 | F1 Micro => 0.7664 | F1 Macro => 0.6801 | Top 3 => 0.9665\n",
      "Best Val: Coverage Error => 1.4761 | F1 Micro => 0.7653 | F1 Macro => 0.6861 | Top 3 => 0.9671\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "**** 512 ********\n",
      "Epochs => 31\n",
      "Best Val Loss => 0.188622105058\n",
      "Last Val: Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "Best Val: Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "**** 1024 ********\n",
      "Epochs => 31\n",
      "Best Val Loss => 0.185910411101\n",
      "Last Val: Coverage Error => 1.6197 | F1 Micro => 0.7108 | F1 Macro => 0.4772 | Top 3 => 0.9383\n",
      "Best Val: Coverage Error => 1.6074 | F1 Micro => 0.7170 | F1 Macro => 0.5003 | Top 3 => 0.9405\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.177211825736\n",
      "Last Val: Coverage Error => 1.5612 | F1 Micro => 0.7096 | F1 Macro => 0.5282 | Top 3 => 0.9537\n",
      "Best Val: Coverage Error => 1.5519 | F1 Micro => 0.7001 | F1 Macro => 0.5391 | Top 3 => 0.9564\n",
      "**** 1024 ********\n",
      "Epochs => 20\n",
      "Best Val Loss => 0.178523907068\n",
      "Last Val: Coverage Error => 1.5559 | F1 Micro => 0.6967 | F1 Macro => 0.5266 | Top 3 => 0.9557\n",
      "Best Val: Coverage Error => 1.5498 | F1 Micro => 0.7073 | F1 Macro => 0.5485 | Top 3 => 0.9567\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 37\n",
      "Best Val Loss => 0.182871406887\n",
      "Last Val: Coverage Error => 1.5657 | F1 Micro => 0.6919 | F1 Macro => 0.4956 | Top 3 => 0.9543\n",
      "Best Val: Coverage Error => 1.5669 | F1 Micro => 0.6938 | F1 Macro => 0.5057 | Top 3 => 0.9543\n",
      "**** 1024 ********\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.185281427776\n",
      "Last Val: Coverage Error => 1.5724 | F1 Micro => 0.6860 | F1 Macro => 0.4913 | Top 3 => 0.9532\n",
      "Best Val: Coverage Error => 1.5723 | F1 Micro => 0.6857 | F1 Macro => 0.4896 | Top 3 => 0.9535\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 40\n",
      "Best Val Loss => 0.14467293148\n",
      "Last Val: Coverage Error => 1.4431 | F1 Micro => 0.7800 | F1 Macro => 0.7153 | Top 3 => 0.9714\n",
      "Best Val: Coverage Error => 1.4431 | F1 Micro => 0.7821 | F1 Macro => 0.7181 | Top 3 => 0.9713\n",
      "**** 1024 ********\n",
      "Epochs => 21\n",
      "Best Val Loss => 0.14781301107\n",
      "Last Val: Coverage Error => 1.4545 | F1 Micro => 0.7763 | F1 Macro => 0.7045 | Top 3 => 0.9694\n",
      "Best Val: Coverage Error => 1.4535 | F1 Micro => 0.7755 | F1 Macro => 0.7076 | Top 3 => 0.9699\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.19802413061\n",
      "Last Val: Coverage Error => 1.6223 | F1 Micro => 0.6572 | F1 Macro => 0.4326 | Top 3 => 0.9455\n",
      "Best Val: Coverage Error => 1.6197 | F1 Micro => 0.6594 | F1 Macro => 0.4412 | Top 3 => 0.9467\n",
      "**** 1024 ********\n",
      "Epochs => 38\n",
      "Best Val Loss => 0.200216266256\n",
      "Last Val: Coverage Error => 1.6320 | F1 Micro => 0.6561 | F1 Macro => 0.4338 | Top 3 => 0.9444\n",
      "Best Val: Coverage Error => 1.6231 | F1 Micro => 0.6513 | F1 Macro => 0.4264 | Top 3 => 0.9458\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "**** 512 ********\n",
      "Epochs => 50\n",
      "Best Val Loss => 0.154267980102\n",
      "Last Val: Coverage Error => 1.4724 | F1 Micro => 0.7650 | F1 Macro => 0.6873 | Top 3 => 0.9668\n",
      "Best Val: Coverage Error => 1.4724 | F1 Micro => 0.7629 | F1 Macro => 0.6759 | Top 3 => 0.9670\n",
      "**** 1024 ********\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.154700267607\n",
      "Last Val: Coverage Error => 1.4750 | F1 Micro => 0.7592 | F1 Macro => 0.6718 | Top 3 => 0.9665\n",
      "Best Val: Coverage Error => 1.4733 | F1 Micro => 0.7616 | F1 Macro => 0.6797 | Top 3 => 0.9668\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.142855885915\n",
      "Last Val: Coverage Error => 1.4374 | F1 Micro => 0.7837 | F1 Macro => 0.7206 | Top 3 => 0.9723\n",
      "Best Val: Coverage Error => 1.4351 | F1 Micro => 0.7844 | F1 Macro => 0.7225 | Top 3 => 0.9724\n",
      "**** 1024 ********\n",
      "Epochs => 17\n",
      "Best Val Loss => 0.147080744336\n",
      "Last Val: Coverage Error => 1.4501 | F1 Micro => 0.7759 | F1 Macro => 0.7089 | Top 3 => 0.9703\n",
      "Best Val: Coverage Error => 1.4492 | F1 Micro => 0.7765 | F1 Macro => 0.7112 | Top 3 => 0.9706\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "**** 512 ********\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.166171306583\n",
      "Last Val: Coverage Error => 1.4945 | F1 Micro => 0.7443 | F1 Macro => 0.6440 | Top 3 => 0.9635\n",
      "Best Val: Coverage Error => 1.4932 | F1 Micro => 0.7445 | F1 Macro => 0.6436 | Top 3 => 0.9636\n",
      "**** 1024 ********\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.167615778877\n",
      "Last Val: Coverage Error => 1.5069 | F1 Micro => 0.7373 | F1 Macro => 0.6381 | Top 3 => 0.9609\n",
      "Best Val: Coverage Error => 1.5037 | F1 Micro => 0.7392 | F1 Macro => 0.6410 | Top 3 => 0.9614\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "**** 512 ********\n",
      "Epochs => 30\n",
      "Best Val Loss => 0.179389482992\n",
      "Last Val: Coverage Error => 1.5448 | F1 Micro => 0.7084 | F1 Macro => 0.5527 | Top 3 => 0.9560\n",
      "Best Val: Coverage Error => 1.5430 | F1 Micro => 0.7015 | F1 Macro => 0.5343 | Top 3 => 0.9566\n",
      "**** 1024 ********\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.179591152206\n",
      "Last Val: Coverage Error => 1.5438 | F1 Micro => 0.6930 | F1 Macro => 0.5099 | Top 3 => 0.9566\n",
      "Best Val: Coverage Error => 1.5346 | F1 Micro => 0.6969 | F1 Macro => 0.5243 | Top 3 => 0.9579\n",
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "**** 512 ********\n",
      "Epochs => 25\n",
      "Best Val Loss => 0.166892905616\n",
      "Last Val: Coverage Error => 1.5206 | F1 Micro => 0.7352 | F1 Macro => 0.6247 | Top 3 => 0.9605\n",
      "Best Val: Coverage Error => 1.5179 | F1 Micro => 0.7295 | F1 Macro => 0.6038 | Top 3 => 0.9610\n",
      "**** 1024 ********\n",
      "Epochs => 29\n",
      "Best Val Loss => 0.165255952613\n",
      "Last Val: Coverage Error => 1.5259 | F1 Micro => 0.7263 | F1 Macro => 0.6177 | Top 3 => 0.9594\n",
      "Best Val: Coverage Error => 1.5097 | F1 Micro => 0.7366 | F1 Macro => 0.6207 | Top 3 => 0.9614\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict_512.keys():\n",
    "    print('========== NN: {}'.format(key))\n",
    "    print '**** 512 ********'\n",
    "    val = param_results_dict_1024[key]\n",
    "    val_metrics = val['validation_metrics']\n",
    "    val_metrics2 =  val['metrics_callback'].metrics_dict[sorted(val['metrics_callback'].metrics_dict.keys())[-1]]\n",
    "    \n",
    "    print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "    print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Last Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Best Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))\n",
    "    val = param_results_dict_512[key]\n",
    "    val_metrics = val['last_validation_metrics']\n",
    "    val_metrics2 =  val['best_validation_metrics']\n",
    "    \n",
    "    print '**** 1024 ********'\n",
    "    print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "    print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Last Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Best Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:21:16,530 : INFO : nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286325/1286325 [==============================] - 33s - loss: 0.2821 - val_loss: 0.2110\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:22:31,938 : INFO : Found lower val loss for epoch 2 => 0.203628581978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 51s - loss: 0.2703 - val_loss: 0.2036\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:23:22,809 : INFO : Found lower val loss for epoch 3 => 0.201484667301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 52s - loss: 0.2681 - val_loss: 0.2015\n",
      "Epoch 4/100\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2672 - val_loss: 0.2029\n",
      "Epoch 5/100\n",
      "1286325/1286325 [==============================] - 33s - loss: 0.2667 - val_loss: 0.2026\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:25:23,439 : INFO : Found lower val loss for epoch 6 => 0.199616165483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 51s - loss: 0.2664 - val_loss: 0.1996\n",
      "Epoch 7/100\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2663 - val_loss: 0.2002\n",
      "Epoch 8/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.2660 - val_loss: 0.2019\n",
      "Epoch 9/100\n",
      "1286325/1286325 [==============================] - 34s - loss: 0.2659 - val_loss: 0.2001\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:28:00,290 : INFO : Found lower val loss for epoch 10 => 0.199289376226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 51s - loss: 0.2658 - val_loss: 0.1993\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:28:49,316 : INFO : Found lower val loss for epoch 11 => 0.195961182039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 49s - loss: 0.2657 - val_loss: 0.1960\n",
      "Epoch 12/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.2654 - val_loss: 0.1971\n",
      "Epoch 13/100\n",
      "1286325/1286325 [==============================] - 34s - loss: 0.2653 - val_loss: 0.1975\n",
      "Epoch 14/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:30:41,675 : INFO : Found lower val loss for epoch 14 => 0.19504755833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 45s - loss: 0.2653 - val_loss: 0.1950\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.2653 - val_loss: 0.1961\n",
      "Epoch 16/100\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2653 - val_loss: 0.1978\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.2652 - val_loss: 0.1956\n",
      "Epoch 18/100\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2650 - val_loss: 0.1976\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.2650 - val_loss: 0.1967\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2652 - val_loss: 0.1994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:34:16,045 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: early stopping\n",
      "CPU times: user 8min 31s, sys: 6min 56s, total: 15min 28s\n",
      "Wall time: 12min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:34:21,000 : INFO : Generating Validation Metrics\n",
      "2017-01-24 19:34:29,627 : INFO : nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.655, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.941, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.656, F1 Macro: 0.460, Total Pos: 279,726\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           50500       dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 54508\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286325/1286325 [==============================] - 39s - loss: 0.3160 - val_loss: 0.2088\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:35:59,346 : INFO : Found lower val loss for epoch 2 => 0.192288219558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 53s - loss: 0.2567 - val_loss: 0.1923\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:36:52,451 : INFO : Found lower val loss for epoch 3 => 0.186144922012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 53s - loss: 0.2511 - val_loss: 0.1861\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:37:46,218 : INFO : Found lower val loss for epoch 4 => 0.182256995962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 52s - loss: 0.2481 - val_loss: 0.1823\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:38:38,934 : INFO : Found lower val loss for epoch 5 => 0.179341568726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 53s - loss: 0.2464 - val_loss: 0.1793\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:39:32,240 : INFO : Found lower val loss for epoch 6 => 0.176923097311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 54s - loss: 0.2454 - val_loss: 0.1769\n",
      "Epoch 7/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:40:28,051 : INFO : Found lower val loss for epoch 7 => 0.175086520936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 52s - loss: 0.2447 - val_loss: 0.1751\n",
      "Epoch 8/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:41:13,101 : INFO : Found lower val loss for epoch 8 => 0.173581494644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 46s - loss: 0.2443 - val_loss: 0.1736\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:42:09,090 : INFO : Found lower val loss for epoch 9 => 0.172278660867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 54s - loss: 0.2439 - val_loss: 0.1723\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:43:03,300 : INFO : Found lower val loss for epoch 10 => 0.170981978252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 54s - loss: 0.2440 - val_loss: 0.1710\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:43:57,987 : INFO : Found lower val loss for epoch 11 => 0.170295062794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 56s - loss: 0.2441 - val_loss: 0.1703\n",
      "Epoch 12/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:44:52,647 : INFO : Found lower val loss for epoch 12 => 0.169493416986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 55s - loss: 0.2440 - val_loss: 0.1695\n",
      "Epoch 13/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:46:04,579 : INFO : Found lower val loss for epoch 13 => 0.169158573616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 72s - loss: 0.2446 - val_loss: 0.1692\n",
      "Epoch 14/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:47:02,000 : INFO : Found lower val loss for epoch 14 => 0.168888930534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 56s - loss: 0.2451 - val_loss: 0.1689\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 40s - loss: 0.2458 - val_loss: 0.1693\n",
      "Epoch 16/100\n",
      "1286325/1286325 [==============================] - 38s - loss: 0.2460 - val_loss: 0.1696\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 39s - loss: 0.2468 - val_loss: 0.1696\n",
      "Epoch 18/100\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2478 - val_loss: 0.1706\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 38s - loss: 0.2487 - val_loss: 0.1717\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 40s - loss: 0.2499 - val_loss: 0.1729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:51:08,105 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: early stopping\n",
      "CPU times: user 10min 54s, sys: 8min 18s, total: 19min 13s\n",
      "Wall time: 16min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 19:51:13,088 : INFO : Generating Validation Metrics\n",
      "2017-01-24 19:51:25,791 : INFO : nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.540, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.785, Top 3: 0.956, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.722, F1 Macro: 0.596, Total Pos: 289,289\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_relu (Dense)       (None, 500)           100500      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_relu[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      " 923648/1286325 [====================>.........] - ETA: 10s - loss: 0.1874"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-eccfa7a2ce05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Model Fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE,                               nb_epoch=100, verbose=1, callbacks=[early_stopper, metrics_callback])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#     info('Evaluating on Training Data')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for parameters in param_sampler:\n",
    "    start_time = time.time()\n",
    "    first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "    first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "    second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "    second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "    input_dropout_do = parameters['input_dropout']\n",
    "    hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "#     print \"===================================================================================\\n\" + \\\n",
    "#           \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "#           \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "#           \"==========================\".format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "#                                                 second_hidden_layer_size, second_hidden_layer_activation, \n",
    "#                                                 input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "        first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "        second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "    )\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys():\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "        \n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    \n",
    "    model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                  second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                  input_dropout_do, hidden_dropout_do)\n",
    "    model.summary()\n",
    "    \n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPOER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                              nb_epoch=100, verbose=1, callbacks=[early_stopper, metrics_callback])\n",
    "    \n",
    "#     info('Evaluating on Training Data')\n",
    "#     yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "#     yp_binary = get_binary_0_5(yp)\n",
    "#     #print yp\n",
    "#     info('Generating Training Metrics')\n",
    "#     training_metrics = get_metrics(y, yp, yp_binary)\n",
    "#     print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "#         training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "#         training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#         training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "    info('Evaluating on Validation Data')\n",
    "    yvp = model.predict(Xv)\n",
    "    yvp_binary = get_binary_0_5(yvp)\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "\n",
    "\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "#     param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_metrics'] = training_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_metrics'] = validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['history'] = history\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'] = metrics_callback\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = valid_classes\n",
    "NN_OUTPUT_NEURONS = len(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:15:01,583 : INFO : Getting training Data\n",
      "2017-01-24 03:29:46,498 : INFO : Getting Validation Embeddings\n",
      "2017-01-24 03:29:46,501 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 28.6 s, total: 2min 25s\n",
      "Wall time: 15min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "info('Getting training Data')\n",
    "X, y = get_training_data(doc2vec_model, classifications)\n",
    "\n",
    "# Validation Metrics\n",
    "info('Getting Validation Embeddings')\n",
    "Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                validation_preprocessed_docids_files_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "========== 1st Layer Size: {}, 1st Layer Activation: {}, \n",
      " 2nd Layer Size: {}, 2nd Layer Activation: {}, \n",
      "Input Dropout: {}, Hidden Dropout: {} \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           50500       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 244)           122244      hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 172744\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:32:36,557 : INFO : Found lower val loss for epoch 1 => 0.0105074494745\n",
      "2017-01-24 03:32:36,558 : INFO : Generating Validation Metrics\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.567, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.638, Top 3: 0.808, Top 5: 0.883, \n",
      "\t\t F1 Micro: 0.592, F1 Macro: 0.147, Total Pos: 289,304\n",
      "1286325/1286325 [==============================] - 213s - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:36:14,809 : INFO : Found lower val loss for epoch 2 => 0.0100261151577\n",
      "2017-01-24 03:36:14,811 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.412, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.660, Top 3: 0.823, Top 5: 0.891, \n",
      "\t\t F1 Micro: 0.615, F1 Macro: 0.155, Total Pos: 294,583\n",
      "1286325/1286325 [==============================] - 245s - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 3/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:40:19,699 : INFO : Found lower val loss for epoch 3 => 0.00984834508472\n",
      "2017-01-24 03:40:19,701 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.335, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.671, Top 3: 0.829, Top 5: 0.896, \n",
      "\t\t F1 Micro: 0.629, F1 Macro: 0.169, Total Pos: 305,891\n",
      "1286325/1286325 [==============================] - 232s - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 4/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:44:10,594 : INFO : Found lower val loss for epoch 4 => 0.00971982242917\n",
      "2017-01-24 03:44:10,595 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.289, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.674, Top 3: 0.832, Top 5: 0.897, \n",
      "\t\t F1 Micro: 0.632, F1 Macro: 0.166, Total Pos: 304,306\n",
      "1286325/1286325 [==============================] - 201s - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 5/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:47:27,072 : INFO : Found lower val loss for epoch 5 => 0.00958075336049\n",
      "2017-01-24 03:47:27,073 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.261, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.677, Top 3: 0.834, Top 5: 0.899, \n",
      "\t\t F1 Micro: 0.631, F1 Macro: 0.163, Total Pos: 294,545\n",
      "1286325/1286325 [==============================] - 182s - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 6/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:50:28,322 : INFO : Found lower val loss for epoch 6 => 0.0094630262306\n",
      "2017-01-24 03:50:28,324 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.235, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.679, Top 3: 0.836, Top 5: 0.900, \n",
      "\t\t F1 Micro: 0.626, F1 Macro: 0.156, Total Pos: 277,577\n",
      "1286325/1286325 [==============================] - 180s - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 7/100\n",
      "1286325/1286325 [==============================] - 34s - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 8/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 9/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:54:37,973 : INFO : Found lower val loss for epoch 9 => 0.00945049781655\n",
      "2017-01-24 03:54:37,975 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.217, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.681, Top 3: 0.838, Top 5: 0.901, \n",
      "\t\t F1 Micro: 0.637, F1 Macro: 0.169, Total Pos: 298,259\n",
      "1286325/1286325 [==============================] - 179s - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 10/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 03:57:41,035 : INFO : Found lower val loss for epoch 10 => 0.00941921028729\n",
      "2017-01-24 03:57:41,036 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.226, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.682, Top 3: 0.837, Top 5: 0.901, \n",
      "\t\t F1 Micro: 0.631, F1 Macro: 0.160, Total Pos: 284,120\n",
      "1286325/1286325 [==============================] - 196s - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 11/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 04:01:16,284 : INFO : Found lower val loss for epoch 11 => 0.00940488452284\n",
      "2017-01-24 04:01:16,285 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.215, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.682, Top 3: 0.837, Top 5: 0.902, \n",
      "\t\t F1 Micro: 0.636, F1 Macro: 0.165, Total Pos: 291,478\n",
      "1286325/1286325 [==============================] - 331s - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 04:06:43,413 : INFO : Found lower val loss for epoch 12 => 0.00939198008005\n",
      "2017-01-24 04:06:43,425 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 3.220, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.682, Top 3: 0.837, Top 5: 0.901, \n",
      "\t\t F1 Micro: 0.632, F1 Macro: 0.162, Total Pos: 283,967\n",
      "1286325/1286325 [==============================] - 240s - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 00011: early stopping\n",
      "CPU times: user 27min 8s, sys: 10min 52s, total: 38min 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 04:09:31,760 : INFO : Evaluating on Training Data\n",
      "2017-01-24 04:18:09,445 : INFO : Generating Training Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 37min 52s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-d5eea77ea72d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#print yp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Generating Training Metrics'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mtraining_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myp_binary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m print (\"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n\u001b[0;32m     37\u001b[0m     \u001b[0mtraining_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coverage_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'average_num_of_labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/thesis/thesis-benchmark/src/thesis/utils/metrics.pyc\u001b[0m in \u001b[0;36mget_metrics\u001b[1;34m(y_true, y_score, y_binary_score)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mprecision_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mprecision_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_binary_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precision_scores_array'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1240\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m             true_sum = bincount(y_true, weights=sample_weight,\n\u001b[1;32m-> 1091\u001b[1;33m                                 minlength=len(labels))\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m         \u001b[1;31m# Retain only selected labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "first_hidden_layer_size = 500\n",
    "first_hidden_layer_activation = 'tanh'\n",
    "second_hidden_layer_size = None\n",
    "second_hidden_layer_activation = 'tanh'\n",
    "input_dropout_do = False\n",
    "hidden_dropout_do = False\n",
    "\n",
    "print (\"===================================================================================\\n\" + \\\n",
    "      \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "      \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "      \"==========================\".format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                            second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                            input_dropout_do, hidden_dropout_do))\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "    first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "    second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    ")\n",
    "\n",
    "model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                              first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                              second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                              input_dropout_do, hidden_dropout_do)\n",
    "model.summary()\n",
    "\n",
    "early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00001, \\\n",
    "                                              patience=5, verbose=1, mode='auto')\n",
    "metrics_callback = MetricsCallback()\n",
    "\n",
    "# Model Fitting\n",
    "%time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                          nb_epoch=100, verbose=1, callbacks=[early_stopper, metrics_callback])\n",
    "\n",
    "info('Evaluating on Training Data')\n",
    "yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "yp_binary = get_binary_0_5(yp)\n",
    "#print yp\n",
    "info('Generating Training Metrics')\n",
    "training_metrics = get_metrics(y, yp, yp_binary)\n",
    "print (\"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "    training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "    training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive']))\n",
    "\n",
    "info('Evaluating on Validation Data')\n",
    "yvp = model.predict(Xv)\n",
    "yvp_binary = get_binary_0_5(yvp)\n",
    "#print yvp\n",
    "info('Generating Validation Metrics')\n",
    "validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "print(\"****** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "    validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "    validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive']))\n",
    "\n",
    "\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_metrics'] = training_metrics\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_metrics'] = validation_metrics\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['history'] = history\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'] = metrics_callback\n",
    "\n",
    "duration = time.time() - start_time\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:34:57,532 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.2860 - val_loss: 0.2146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:35:17,175 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 9.38 s, sys: 14.2 s, total: 23.5 s\n",
      "Wall time: 19.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:35:23,471 : INFO : Generating Training Metrics\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2017-01-22 00:35:57,556 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 1.706, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.707, Top 3: 0.935, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.600, F1 Macro: 0.386, Total Pos: 914,613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:36:01,866 : INFO : Generating Validation Metrics\n",
      "2017-01-22 00:36:10,031 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.700, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.711, Top 3: 0.935, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.613, F1 Macro: 0.396, Total Pos: 236,405\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.2708 - val_loss: 0.2054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:36:28,796 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 8.3 s, sys: 14 s, total: 22.3 s\n",
      "Wall time: 18.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:36:36,076 : INFO : Generating Training Metrics\n",
      "2017-01-22 00:37:14,305 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 1.653, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.724, Top 3: 0.944, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.598, F1 Macro: 0.403, Total Pos: 881,900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:37:19,389 : INFO : Generating Validation Metrics\n",
      "2017-01-22 00:37:29,588 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.645, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.728, Top 3: 0.945, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.616, F1 Macro: 0.415, Total Pos: 230,060\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 25s - loss: 0.2680 - val_loss: 0.2016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:37:55,372 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 13.3 s, sys: 18.1 s, total: 31.3 s\n",
      "Wall time: 25.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:38:03,499 : INFO : Generating Training Metrics\n",
      "2017-01-22 00:38:47,572 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 1.653, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.726, Top 3: 0.944, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.640, F1 Macro: 0.442, Total Pos: 1,051,494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:38:52,884 : INFO : Generating Validation Metrics\n",
      "2017-01-22 00:39:03,518 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.646, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.729, Top 3: 0.944, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.652, F1 Macro: 0.454, Total Pos: 268,702\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 25s - loss: 0.2667 - val_loss: 0.2025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:39:28,806 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 13.2 s, sys: 18.6 s, total: 31.8 s\n",
      "Wall time: 25.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:39:37,471 : INFO : Generating Training Metrics\n",
      "2017-01-22 00:40:22,736 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 1.663, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.715, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.657, F1 Macro: 0.481, Total Pos: 1,177,676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:40:28,288 : INFO : Generating Validation Metrics\n",
      "2017-01-22 00:40:39,891 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.644, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.945, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.495, Total Pos: 296,876\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 52s - loss: 0.2659 - val_loss: 0.2002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:41:32,590 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 12.2 s, sys: 18.1 s, total: 30.4 s\n",
      "Wall time: 52.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:41:48,031 : INFO : Generating Training Metrics\n",
      "2017-01-22 00:42:36,222 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 1.658, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.728, Top 3: 0.941, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.641, F1 Macro: 0.427, Total Pos: 1,051,233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:42:41,915 : INFO : Generating Validation Metrics\n",
      "2017-01-22 00:42:53,699 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.648, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.942, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.655, F1 Macro: 0.441, Total Pos: 269,826\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 56s - loss: 0.2652 - val_loss: 0.1994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:43:50,392 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 13.7 s, sys: 19.3 s, total: 32.9 s\n",
      "Wall time: 56.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:44:06,761 : INFO : Generating Training Metrics\n",
      "2017-01-22 00:44:54,399 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 1.643, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.944, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.640, F1 Macro: 0.485, Total Pos: 1,002,814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 00:44:59,829 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.629, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.739, Top 3: 0.946, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.653, F1 Macro: 0.496, Total Pos: 257,936\n"
     ]
    }
   ],
   "source": [
    "for parameters in param_sampler:\n",
    "    first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "    first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "    second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "    second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "    input_dropout_do = parameters['input_dropout']\n",
    "    hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "    print (\"===================================================================================\\n\" + \\\n",
    "          \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "          \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "          \"==========================\").format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                                second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                                input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "        first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "        second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "    )\n",
    "    \n",
    "    model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                  second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                  input_dropout_do, hidden_dropout_do)\n",
    "    model.summary()\n",
    "    \n",
    "    for nn_epoch in range(1, NN_MAX_EPOCHS+1):\n",
    "        info('======= NN Epoch: {} =========='.format(nn_epoch)) \n",
    "        %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, nb_epoch=100, verbose=1)\n",
    "        info('Evaluating on Training Data')\n",
    "        yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "        yp_binary = get_binary_0_5(yp)\n",
    "        #print yp\n",
    "        info('Generating Training Metrics')\n",
    "        training_metrics = get_metrics(y, yp, yp_binary)\n",
    "        print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "            training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "            training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "            training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "        info('Evaluating on Validation Data')\n",
    "        yvp = model.predict(Xv)\n",
    "        yvp_binary = get_binary_0_5(yvp)\n",
    "        #print yvp\n",
    "        info('Generating Validation Metrics')\n",
    "        validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "        print \"****** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "            validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "            validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "            validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "\n",
    "        if nn_epoch > 5:\n",
    "            break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286325, 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nn_epoch in range(1, NN_MAX_EPOCHS+1):\n",
    "    %time history = model.fit(x=X, y=y, batch_size=NN_BATCH_SIZE, nb_epoch=1, verbose=0)\n",
    "    info('Evaluating on Training Data')\n",
    "    yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "    yp_binary = get_binary_0_5(yp)\n",
    "    #print yp\n",
    "    info('Generating Training Metrics')\n",
    "    training_metrics = get_metrics(y, yp, yp_binary)\n",
    "    print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "        training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "        training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "    info('Evaluating on Validation Data')\n",
    "    yvp = model.predict(Xv)\n",
    "    yvp_binary = get_binary_0_5(yvp)\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "        validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-20 20:18:46,752 : INFO : ****************** Epoch 1 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1 *******************\n",
      "2017-01-20 20:18:46,761 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model\n",
      "2017-01-20 20:19:07,886 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.* with mmap=None\n",
      "2017-01-20 20:19:07,897 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-20 20:19:11,000 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn1neg.npy with mmap=None\n",
      "2017-01-20 20:19:23,502 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn0.npy with mmap=None\n",
      "2017-01-20 20:19:24,830 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-20 20:19:24,840 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-20 20:19:27,000 : INFO : Getting training Data\n",
      "2017-01-20 20:20:18,862 : INFO : Training Classifier\n",
      "2017-01-20 20:44:16,699 : INFO : Getting Validation Embeddings\n",
      "2017-01-20 20:44:16,712 : INFO : ===== Loading validation vectors\n",
      "2017-01-20 20:44:37,693 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 1 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.634, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.521, Top 3: 0.839, Top 5: 0.924, \n",
      "\t\t F1 Micro: 0.539, F1 Macro: 0.450, Total Pos: 689,413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/matplotlib/axes/_base.py:2787: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=1, right=1\n",
      "  'left=%s, right=%s') % (left, right))\n",
      "2017-01-20 20:44:53,611 : INFO : ****************** Epoch 2 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2 *******************\n",
      "2017-01-20 20:44:53,613 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model\n",
      "2017-01-20 20:45:18,499 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.* with mmap=None\n",
      "2017-01-20 20:45:18,502 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-20 20:45:19,671 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn1neg.npy with mmap=None\n",
      "2017-01-20 20:45:29,596 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn0.npy with mmap=None\n",
      "2017-01-20 20:45:29,955 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-20 20:45:29,965 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-20 20:45:34,726 : INFO : Getting training Data\n",
      "2017-01-20 20:46:19,798 : INFO : Training Classifier\n",
      "2017-01-20 21:09:56,391 : INFO : Getting Validation Embeddings\n",
      "2017-01-20 21:09:56,393 : INFO : ===== Loading validation vectors\n",
      "2017-01-20 21:10:30,233 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.437, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.545, Top 3: 0.856, Top 5: 0.944, \n",
      "\t\t F1 Micro: 0.558, F1 Macro: 0.467, Total Pos: 700,050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-20 21:10:57,231 : INFO : ****************** Epoch 3 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3 *******************\n",
      "2017-01-20 21:10:57,232 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model\n",
      "2017-01-20 21:11:16,975 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.* with mmap=None\n",
      "2017-01-20 21:11:16,986 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-20 21:11:19,050 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn1neg.npy with mmap=None\n",
      "2017-01-20 21:11:28,687 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn0.npy with mmap=None\n",
      "2017-01-20 21:11:29,035 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-20 21:11:29,036 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-20 21:11:30,795 : INFO : Getting training Data\n",
      "2017-01-20 21:12:32,852 : INFO : Training Classifier\n",
      "2017-01-20 21:34:02,114 : INFO : Getting Validation Embeddings\n",
      "2017-01-20 21:34:02,142 : INFO : ===== Loading validation vectors\n",
      "2017-01-20 21:34:26,819 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 1 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-20 21:34:40,248 : INFO : ****************** Epoch 4 --- Working on doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4 *******************\n",
      "2017-01-20 21:34:40,249 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation Metrics: Cov Err: 3.374, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.541, Top 3: 0.861, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.562, F1 Macro: 0.473, Total Pos: 707,978\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph(len(classifications) +2)\n",
    "# when resuming, resume from an epoch with a previously created doc2vec model to get the learning rate right\n",
    "start_from = 1\n",
    "for epoch in range(start_from, DOC2VEC_MAX_EPOCHS+1):\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    info(\"****************** Epoch {} --- Working on {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "    # if we have the model, just load it, otherwise train the previous model\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "        doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    info('Getting training Data')\n",
    "    X, y = get_training_data(doc2vec_model, classifications)\n",
    "    \n",
    "    \n",
    "    ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "    \n",
    "    # try warm start and evaluate after every iter\n",
    "    \n",
    "    if not os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER)):\n",
    "        info('Training Classifier')\n",
    "        clf = OneVsRestClassifier(linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                             #alpha is the 1/C parameter\n",
    "                                                             alpha=SVM_REG, fit_intercept=True, n_iter=SVM_ITERATIONS,\n",
    "                                                             #n_jobs=-1 means use all cpus\n",
    "                                                             shuffle=True, verbose=0, n_jobs=1,\n",
    "                                                             #eta0 is the learning rate when we use constant configuration\n",
    "                                                             random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                             class_weight=SVM_CLASS_WEIGHTS, warm_start=False), n_jobs=1)\n",
    "\n",
    "\n",
    "        # Training of a classifier\n",
    "        clf.fit(X,y)\n",
    "        pickle.dump(clf, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                              GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER), 'w'))\n",
    "    else:\n",
    "        info('Loading Classifier')\n",
    "        clf = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER), 'r'))\n",
    "    \n",
    "#     # Training Metrics\n",
    "#     info('Evaluating on Training Data')\n",
    "#     yp = clf.predict(X)\n",
    "#     yp_score = clf.decision_function(X)\n",
    "#     print yp\n",
    "#     training_metrics = get_metrics(y, yp, yp)\n",
    "#     print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "#         training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "#         training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#         training_metrics['f1_micro'], training_metrics['f1_macro'], training_metrics['total_positive'])\n",
    "    \n",
    "#     epoch_training_metrics.append(training_metrics)\n",
    "    \n",
    "    del X,y\n",
    "    \n",
    "    # Validation Metrics\n",
    "    info('Getting Validation Embeddings')\n",
    "    Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                    validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                    validation_preprocessed_docids_files_prefix)\n",
    "    info('Evaluating on Validation Data')\n",
    "    yvp = clf.predict(Xv)\n",
    "    yvp_score = clf.decision_function(Xv)\n",
    "    print yvp\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp)\n",
    "    print \"** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "        validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "    \n",
    "    graph.add_metrics_to_graph(validation_metrics, epoch)\n",
    "    \n",
    "    epoch_validation_metrics.append(validation_metrics)\n",
    "    \n",
    "    \n",
    "    # Saving the metrics\n",
    "#     pickle.dump(training_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                                           GLOBAL_VARS.SVM_MODEL_NAME, TRAINING_METRICS_FILENAME), 'w'))\n",
    "    pickle.dump(validation_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, VALIDATION_METRICS_FILENAME), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import thesis.utils.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 22:22:21,536 : INFO : Loading new batch\n",
      "2016-12-28 22:22:27,109 : INFO : Finished loading new batch\n"
     ]
    }
   ],
   "source": [
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "i=0\n",
    "doc_contents = []\n",
    "for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "    i += 1\n",
    "    doc_contents.append((doc_id, doc_contents_array))\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def infer_one_doc(doc):\n",
    "    #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "    rep = doc2vec_model.infer_vector(doc[1])\n",
    "    return (doc[0], rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threaded Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 620 ms, total: 1min 41s\n",
      "Wall time: 9.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = ThreadPool(16)\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "threaded_reps = pool.map(infer_one_doc, doc_contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Threaded Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 44 ms, total: 14.1 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reps = []\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "for doc in doc_contents:\n",
    "    reps.append((doc[0], doc2vec_model.infer_vector(doc[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal([d[0] for d in reps], [d[0] for d in threaded_reps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nothing_func(doc):\n",
    "    1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12412"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threaded_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 520 ms, total: 2.13 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifications = sections\n",
    "\n",
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "one_hot_encoder = OneHotEncoder(classifications)\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for doc_id in training_docs_list:\n",
    "    # converting from memmap to a normal array\n",
    "    normal_array = []\n",
    "    normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "    training_data.append(normal_array)\n",
    "    eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "    training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(history_list, open('/mnt/data2/shalaby/history_list_sample_0.0001.pickle','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_input = Input(shape=(DOC2VEC_SIZE,), name='doc_input')\n",
    "hidden = Dense(NN_HIDDEN_NEURONS, activation='relu', name='hidden_layer')(doc_input)\n",
    "softmax_output = Dense(NN_OUTPUT_NEURONS, activation='sigmoid', name='softmax_output')(hidden)\n",
    "model = Model(input=doc_input, output=softmax_output)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', 'fbeta_score', theano_coverage_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer (Dense)             (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8979 samples, validate on 1969 samples\n",
      "Epoch 1/1\n",
      "8979/8979 [==============================] - 4s - loss: 0.0427 - acc: 0.9835 - fbeta_score: 0.9504 - coverage error: 1.4936 - val_loss: 2.1309 - val_acc: 0.8531 - val_fbeta_score: 0.4738 - val_coverage error: 3.4474\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=training_data, y=training_labels, \n",
    "          validation_data=(validation_data, validation_labels), \n",
    "          nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_prediction = model.predict(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.70263344e-01,   3.49998474e-02,   3.13610617e-05,\n",
       "          1.08150870e-03,   3.11665332e-07,   7.09001958e-01,\n",
       "          4.97711152e-02,   2.63609409e-01],\n",
       "       [  1.70166213e-02,   5.36046147e-01,   2.61311390e-04,\n",
       "          4.87348643e-06,   1.27638310e-01,   9.57404263e-03,\n",
       "          3.39831635e-02,   2.13784515e-03]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
