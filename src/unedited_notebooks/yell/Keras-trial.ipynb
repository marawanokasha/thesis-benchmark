{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 2: Tesla K40m (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import theano.sandbox.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.919699 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n",
      "CPU times: user 292 ms, sys: 668 ms, total: 960 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s - loss: 0.6826 - acc: 0.6328     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.6590 - acc: 0.6510     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.6475 - acc: 0.6549     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.6416 - acc: 0.6615     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.6216 - acc: 0.6745     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.6128 - acc: 0.6680     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.6018 - acc: 0.6927     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.5962 - acc: 0.6927     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.5991 - acc: 0.6953     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.5920 - acc: 0.6927     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.5905 - acc: 0.6979     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.5883 - acc: 0.6901     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.5870 - acc: 0.6953     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.5869 - acc: 0.6836     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.5815 - acc: 0.6953     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.5779 - acc: 0.6966     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.5809 - acc: 0.6849     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.5818 - acc: 0.6953     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.5814 - acc: 0.6901     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.5748 - acc: 0.7096     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.5758 - acc: 0.7005     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.5739 - acc: 0.7135     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.5736 - acc: 0.6927     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.5750 - acc: 0.6940     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s - loss: 0.5734 - acc: 0.7031     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.5683 - acc: 0.7083     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.5688 - acc: 0.7018     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.5714 - acc: 0.7070     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.5621 - acc: 0.7188     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.5647 - acc: 0.7122     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.5630 - acc: 0.7135     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.5613 - acc: 0.7214     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.5594 - acc: 0.7188     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.5598 - acc: 0.7187     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.5624 - acc: 0.7187     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.5615 - acc: 0.7201     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.5544 - acc: 0.7214     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.5529 - acc: 0.7135     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.5550 - acc: 0.7227     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.5574 - acc: 0.7331     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.5561 - acc: 0.7357     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.5459 - acc: 0.7370     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.5481 - acc: 0.7240     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.5409 - acc: 0.7331     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.5438 - acc: 0.7422     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.5360 - acc: 0.7344     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.5393 - acc: 0.7357     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.5360 - acc: 0.7435     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.5407 - acc: 0.7370     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.5473 - acc: 0.7344     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.5287 - acc: 0.7448     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.5283 - acc: 0.7539     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.5308 - acc: 0.7396     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.5274 - acc: 0.7448     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.5241 - acc: 0.7539     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.5262 - acc: 0.7526     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.5272 - acc: 0.7422     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.5262 - acc: 0.7539     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.5224 - acc: 0.7604     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.5200 - acc: 0.7513     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.5158 - acc: 0.7578     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.5162 - acc: 0.7513     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.5097 - acc: 0.7552     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.5134 - acc: 0.7487     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.5112 - acc: 0.7435     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.5141 - acc: 0.7656     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.5082 - acc: 0.7539     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.5101 - acc: 0.7643     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.5136 - acc: 0.7409     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.5182 - acc: 0.7474     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.5185 - acc: 0.7370     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.5073 - acc: 0.7539     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.4982 - acc: 0.7682     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.4967 - acc: 0.7591     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.5070 - acc: 0.7617     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.5025 - acc: 0.7526     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.4991 - acc: 0.7604     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.4923 - acc: 0.7656     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.4998 - acc: 0.7695     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.5004 - acc: 0.7526     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.5043 - acc: 0.7552     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.5002 - acc: 0.7656     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.4932 - acc: 0.7617     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.4971 - acc: 0.7604     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.5007 - acc: 0.7513     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.4889 - acc: 0.7656     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.4953 - acc: 0.7591     \n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s - loss: 0.4910 - acc: 0.7669     \n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s - loss: 0.4897 - acc: 0.7604     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.4867 - acc: 0.7643     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.4915 - acc: 0.7669     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.4907 - acc: 0.7630     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.4912 - acc: 0.7604     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.4851 - acc: 0.7630     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.4821 - acc: 0.7682     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.4835 - acc: 0.7669     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.4738 - acc: 0.7773     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.5008 - acc: 0.7474     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.4841 - acc: 0.7682     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.4816 - acc: 0.7669     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.4843 - acc: 0.7695     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.4753 - acc: 0.7891     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.4841 - acc: 0.7630     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.4836 - acc: 0.7786     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.4809 - acc: 0.7708     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.4792 - acc: 0.7786     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.4831 - acc: 0.7734     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.4783 - acc: 0.7852     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.4784 - acc: 0.7708     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.4803 - acc: 0.7682     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.4704 - acc: 0.7734     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.4752 - acc: 0.7878     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.4776 - acc: 0.7760     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.4849 - acc: 0.7604     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.4773 - acc: 0.7682     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.4712 - acc: 0.7773     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.4675 - acc: 0.7786     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.4660 - acc: 0.7839     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.4702 - acc: 0.7891     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.4699 - acc: 0.7852     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.4786 - acc: 0.7852     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.4745 - acc: 0.7786     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.4684 - acc: 0.7839     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.4709 - acc: 0.7760     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.4699 - acc: 0.7747     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.4649 - acc: 0.7747     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.4710 - acc: 0.7708     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.4574 - acc: 0.7956     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.4645 - acc: 0.7930     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.4761 - acc: 0.7734     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.4606 - acc: 0.7812     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.4619 - acc: 0.7878     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.4742 - acc: 0.7773     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.4714 - acc: 0.7786     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.4635 - acc: 0.7891     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.4571 - acc: 0.7995     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.4614 - acc: 0.7930     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.4677 - acc: 0.7799     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.4615 - acc: 0.7852     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.4593 - acc: 0.7852     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.4626 - acc: 0.7799     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.4614 - acc: 0.7786     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.4627 - acc: 0.7865     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.4538 - acc: 0.8034     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.4597 - acc: 0.7852     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.4646 - acc: 0.7930     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.4540 - acc: 0.7904     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.4656 - acc: 0.7799     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.4589 - acc: 0.7826     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.4611 - acc: 0.7773     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a56d45f50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544/768 [====================>.........] - ETA: 0sacc: 78.91%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82117373],\n",
       "       [ 0.10473503],\n",
       "       [ 0.9090184 ],\n",
       "       [ 0.10512042],\n",
       "       [ 0.78090107],\n",
       "       [ 0.26003391],\n",
       "       [ 0.16429627],\n",
       "       [ 0.43324727],\n",
       "       [ 0.94769281],\n",
       "       [ 0.14849883],\n",
       "       [ 0.21905506],\n",
       "       [ 0.93988955],\n",
       "       [ 0.5941481 ],\n",
       "       [ 0.944345  ],\n",
       "       [ 0.77902597],\n",
       "       [ 0.31717807],\n",
       "       [ 0.61684436],\n",
       "       [ 0.32911414],\n",
       "       [ 0.36678585],\n",
       "       [ 0.22693451],\n",
       "       [ 0.51870084],\n",
       "       [ 0.43885848],\n",
       "       [ 0.94429654],\n",
       "       [ 0.34876618],\n",
       "       [ 0.67694926],\n",
       "       [ 0.54456681],\n",
       "       [ 0.85718262],\n",
       "       [ 0.09663744],\n",
       "       [ 0.33522213],\n",
       "       [ 0.28970671],\n",
       "       [ 0.46944129],\n",
       "       [ 0.67228943],\n",
       "       [ 0.0961894 ],\n",
       "       [ 0.02473637],\n",
       "       [ 0.57788187],\n",
       "       [ 0.47445977],\n",
       "       [ 0.77614415],\n",
       "       [ 0.6019994 ],\n",
       "       [ 0.27857256],\n",
       "       [ 0.69152761],\n",
       "       [ 0.6963852 ],\n",
       "       [ 0.74253017],\n",
       "       [ 0.1207545 ],\n",
       "       [ 0.81510013],\n",
       "       [ 0.84786874],\n",
       "       [ 0.95875186],\n",
       "       [ 0.74810088],\n",
       "       [ 0.07186981],\n",
       "       [ 0.58771729],\n",
       "       [ 0.06745848],\n",
       "       [ 0.04526624],\n",
       "       [ 0.16006069],\n",
       "       [ 0.07521161],\n",
       "       [ 0.90410578],\n",
       "       [ 0.88898551],\n",
       "       [ 0.0971714 ],\n",
       "       [ 0.92643583],\n",
       "       [ 0.31949258],\n",
       "       [ 0.85613757],\n",
       "       [ 0.31203571],\n",
       "       [ 0.03655434],\n",
       "       [ 0.72036731],\n",
       "       [ 0.1311979 ],\n",
       "       [ 0.54077548],\n",
       "       [ 0.63791782],\n",
       "       [ 0.18447915],\n",
       "       [ 0.17384833],\n",
       "       [ 0.51742667],\n",
       "       [ 0.08086821],\n",
       "       [ 0.33181804],\n",
       "       [ 0.1832408 ],\n",
       "       [ 0.56676817],\n",
       "       [ 0.82083845],\n",
       "       [ 0.15604205],\n",
       "       [ 0.08436352],\n",
       "       [ 0.09340575],\n",
       "       [ 0.16741587],\n",
       "       [ 0.3187103 ],\n",
       "       [ 0.96654516],\n",
       "       [ 0.19365533],\n",
       "       [ 0.39594215],\n",
       "       [ 0.03320163],\n",
       "       [ 0.15075165],\n",
       "       [ 0.10301826],\n",
       "       [ 0.53468311],\n",
       "       [ 0.25215027],\n",
       "       [ 0.74664408],\n",
       "       [ 0.12395939],\n",
       "       [ 0.75440758],\n",
       "       [ 0.14763102],\n",
       "       [ 0.07202218],\n",
       "       [ 0.25755435],\n",
       "       [ 0.13929519],\n",
       "       [ 0.37733969],\n",
       "       [ 0.23605236],\n",
       "       [ 0.6709196 ],\n",
       "       [ 0.18594821],\n",
       "       [ 0.08741678],\n",
       "       [ 0.21322599],\n",
       "       [ 0.6369487 ],\n",
       "       [ 0.8995648 ],\n",
       "       [ 0.56539845],\n",
       "       [ 0.02133301],\n",
       "       [ 0.05428443],\n",
       "       [ 0.41940662],\n",
       "       [ 0.4213621 ],\n",
       "       [ 0.00435052],\n",
       "       [ 0.61828381],\n",
       "       [ 0.07443107],\n",
       "       [ 0.06024989],\n",
       "       [ 0.66762453],\n",
       "       [ 0.91111171],\n",
       "       [ 0.05754405],\n",
       "       [ 0.23793249],\n",
       "       [ 0.8357771 ],\n",
       "       [ 0.63410348],\n",
       "       [ 0.55714285],\n",
       "       [ 0.4793379 ],\n",
       "       [ 0.25156873],\n",
       "       [ 0.06982659],\n",
       "       [ 0.52294654],\n",
       "       [ 0.45663029],\n",
       "       [ 0.16267441],\n",
       "       [ 0.12141705],\n",
       "       [ 0.17951274],\n",
       "       [ 0.35703528],\n",
       "       [ 0.36279455],\n",
       "       [ 0.25244042],\n",
       "       [ 0.28573996],\n",
       "       [ 0.26702744],\n",
       "       [ 0.75975776],\n",
       "       [ 0.84414923],\n",
       "       [ 0.7753154 ],\n",
       "       [ 0.48269919],\n",
       "       [ 0.10274494],\n",
       "       [ 0.3870959 ],\n",
       "       [ 0.09093279],\n",
       "       [ 0.14100875],\n",
       "       [ 0.33663309],\n",
       "       [ 0.3851707 ],\n",
       "       [ 0.33529902],\n",
       "       [ 0.37022308],\n",
       "       [ 0.2003185 ],\n",
       "       [ 0.60440171],\n",
       "       [ 0.59222847],\n",
       "       [ 0.04345106],\n",
       "       [ 0.28506899],\n",
       "       [ 0.40160945],\n",
       "       [ 0.72599739],\n",
       "       [ 0.08622971],\n",
       "       [ 0.59512347],\n",
       "       [ 0.32942158],\n",
       "       [ 0.78806728],\n",
       "       [ 0.48184913],\n",
       "       [ 0.97993737],\n",
       "       [ 0.85212392],\n",
       "       [ 0.21188843],\n",
       "       [ 0.28518242],\n",
       "       [ 0.06610413],\n",
       "       [ 0.92260265],\n",
       "       [ 0.37398812],\n",
       "       [ 0.35142577],\n",
       "       [ 0.30839863],\n",
       "       [ 0.20254894],\n",
       "       [ 0.27608511],\n",
       "       [ 0.36562043],\n",
       "       [ 0.61726975],\n",
       "       [ 0.52840996],\n",
       "       [ 0.44445291],\n",
       "       [ 0.07987094],\n",
       "       [ 0.22788027],\n",
       "       [ 0.48715827],\n",
       "       [ 0.38843536],\n",
       "       [ 0.10862596],\n",
       "       [ 0.08066881],\n",
       "       [ 0.84737062],\n",
       "       [ 0.22373234],\n",
       "       [ 0.26265395],\n",
       "       [ 0.86966068],\n",
       "       [ 0.71373349],\n",
       "       [ 0.07659729],\n",
       "       [ 0.26794401],\n",
       "       [ 0.02923529],\n",
       "       [ 0.15293829],\n",
       "       [ 0.55204439],\n",
       "       [ 0.97253191],\n",
       "       [ 0.98340595],\n",
       "       [ 0.1600083 ],\n",
       "       [ 0.39560801],\n",
       "       [ 0.49625847],\n",
       "       [ 0.20300341],\n",
       "       [ 0.53309423],\n",
       "       [ 0.86022824],\n",
       "       [ 0.72517085],\n",
       "       [ 0.20350599],\n",
       "       [ 0.70215362],\n",
       "       [ 0.19776684],\n",
       "       [ 0.16681595],\n",
       "       [ 0.35640988],\n",
       "       [ 0.55044848],\n",
       "       [ 0.18200555],\n",
       "       [ 0.5231635 ],\n",
       "       [ 0.24593109],\n",
       "       [ 0.08812845],\n",
       "       [ 0.5419966 ],\n",
       "       [ 0.191204  ],\n",
       "       [ 0.94619352],\n",
       "       [ 0.65089226],\n",
       "       [ 0.12862132],\n",
       "       [ 0.88358784],\n",
       "       [ 0.12870178],\n",
       "       [ 0.47665578],\n",
       "       [ 0.83214718],\n",
       "       [ 0.46672785],\n",
       "       [ 0.48926219],\n",
       "       [ 0.90679628],\n",
       "       [ 0.41755074],\n",
       "       [ 0.45097804],\n",
       "       [ 0.23415038],\n",
       "       [ 0.66868633],\n",
       "       [ 0.45153481],\n",
       "       [ 0.76993394],\n",
       "       [ 0.2872723 ],\n",
       "       [ 0.2517916 ],\n",
       "       [ 0.1239029 ],\n",
       "       [ 0.05077025],\n",
       "       [ 0.17413734],\n",
       "       [ 0.91289067],\n",
       "       [ 0.88673395],\n",
       "       [ 0.10998958],\n",
       "       [ 0.68718827],\n",
       "       [ 0.84869033],\n",
       "       [ 0.04682035],\n",
       "       [ 0.57657331],\n",
       "       [ 0.06399622],\n",
       "       [ 0.92527747],\n",
       "       [ 0.84456533],\n",
       "       [ 0.77715307],\n",
       "       [ 0.78291911],\n",
       "       [ 0.04985502],\n",
       "       [ 0.12342168],\n",
       "       [ 0.15244181],\n",
       "       [ 0.62185973],\n",
       "       [ 0.62791246],\n",
       "       [ 0.53581959],\n",
       "       [ 0.93414003],\n",
       "       [ 0.68776363],\n",
       "       [ 0.28135794],\n",
       "       [ 0.74127543],\n",
       "       [ 0.09035853],\n",
       "       [ 0.42157084],\n",
       "       [ 0.19421272],\n",
       "       [ 0.04493851],\n",
       "       [ 0.1515162 ],\n",
       "       [ 0.69500691],\n",
       "       [ 0.33900547],\n",
       "       [ 0.46251237],\n",
       "       [ 0.22324656],\n",
       "       [ 0.60809952],\n",
       "       [ 0.87529933],\n",
       "       [ 0.85028213],\n",
       "       [ 0.89685041],\n",
       "       [ 0.22217947],\n",
       "       [ 0.66418922],\n",
       "       [ 0.61474538],\n",
       "       [ 0.19221409],\n",
       "       [ 0.96838802],\n",
       "       [ 0.71723586],\n",
       "       [ 0.2155544 ],\n",
       "       [ 0.88984162],\n",
       "       [ 0.78025371],\n",
       "       [ 0.12959629],\n",
       "       [ 0.23559265],\n",
       "       [ 0.08130512],\n",
       "       [ 0.13745961],\n",
       "       [ 0.15980949],\n",
       "       [ 0.37895057],\n",
       "       [ 0.18023905],\n",
       "       [ 0.27716106],\n",
       "       [ 0.09693921],\n",
       "       [ 0.68408483],\n",
       "       [ 0.55437374],\n",
       "       [ 0.41200528],\n",
       "       [ 0.72936654],\n",
       "       [ 0.23827924],\n",
       "       [ 0.64823079],\n",
       "       [ 0.76198864],\n",
       "       [ 0.49446777],\n",
       "       [ 0.13485797],\n",
       "       [ 0.23176607],\n",
       "       [ 0.04324741],\n",
       "       [ 0.18337151],\n",
       "       [ 0.53840065],\n",
       "       [ 0.60284394],\n",
       "       [ 0.1989425 ],\n",
       "       [ 0.65689832],\n",
       "       [ 0.54855078],\n",
       "       [ 0.18314581],\n",
       "       [ 0.61443394],\n",
       "       [ 0.07124263],\n",
       "       [ 0.98238927],\n",
       "       [ 0.56536007],\n",
       "       [ 0.09128086],\n",
       "       [ 0.50145769],\n",
       "       [ 0.40082598],\n",
       "       [ 0.22148155],\n",
       "       [ 0.79984349],\n",
       "       [ 0.20526069],\n",
       "       [ 0.28750861],\n",
       "       [ 0.45343778],\n",
       "       [ 0.26209629],\n",
       "       [ 0.32876906],\n",
       "       [ 0.4842672 ],\n",
       "       [ 0.33374515],\n",
       "       [ 0.61548018],\n",
       "       [ 0.20017827],\n",
       "       [ 0.0706998 ],\n",
       "       [ 0.81896174],\n",
       "       [ 0.35969868],\n",
       "       [ 0.88871956],\n",
       "       [ 0.35318634],\n",
       "       [ 0.22009046],\n",
       "       [ 0.28929511],\n",
       "       [ 0.49705851],\n",
       "       [ 0.22582181],\n",
       "       [ 0.42580807],\n",
       "       [ 0.41247556],\n",
       "       [ 0.95044452],\n",
       "       [ 0.19837599],\n",
       "       [ 0.20587935],\n",
       "       [ 0.57446367],\n",
       "       [ 0.09030379],\n",
       "       [ 0.97383928],\n",
       "       [ 0.32322848],\n",
       "       [ 0.10187984],\n",
       "       [ 0.67204016],\n",
       "       [ 0.30564332],\n",
       "       [ 0.45533237],\n",
       "       [ 0.77844757],\n",
       "       [ 0.92153352],\n",
       "       [ 0.22137798],\n",
       "       [ 0.11602724],\n",
       "       [ 0.104898  ],\n",
       "       [ 0.37125441],\n",
       "       [ 0.1537381 ],\n",
       "       [ 0.4460488 ],\n",
       "       [ 0.52286661],\n",
       "       [ 0.58385336],\n",
       "       [ 0.13968107],\n",
       "       [ 0.27089521],\n",
       "       [ 0.30280098],\n",
       "       [ 0.39189398],\n",
       "       [ 0.16114599],\n",
       "       [ 0.09048916],\n",
       "       [ 0.27759713],\n",
       "       [ 0.80116987],\n",
       "       [ 0.5732432 ],\n",
       "       [ 0.64448351],\n",
       "       [ 0.35445496],\n",
       "       [ 0.86668998],\n",
       "       [ 0.87974006],\n",
       "       [ 0.68606782],\n",
       "       [ 0.26981279],\n",
       "       [ 0.81507105],\n",
       "       [ 0.4461267 ],\n",
       "       [ 0.27496392],\n",
       "       [ 0.42741877],\n",
       "       [ 0.08610015],\n",
       "       [ 0.03372821],\n",
       "       [ 0.29318115],\n",
       "       [ 0.80873984],\n",
       "       [ 0.21488039],\n",
       "       [ 0.09271483],\n",
       "       [ 0.22336014],\n",
       "       [ 0.57281888],\n",
       "       [ 0.90162218],\n",
       "       [ 0.04472881],\n",
       "       [ 0.13599814],\n",
       "       [ 0.90691328],\n",
       "       [ 0.12444541],\n",
       "       [ 0.15409203],\n",
       "       [ 0.07240104],\n",
       "       [ 0.10179149],\n",
       "       [ 0.12729529],\n",
       "       [ 0.25854412],\n",
       "       [ 0.22604713],\n",
       "       [ 0.44212857],\n",
       "       [ 0.39615464],\n",
       "       [ 0.73559785],\n",
       "       [ 0.17759262],\n",
       "       [ 0.41464204],\n",
       "       [ 0.91413599],\n",
       "       [ 0.09350752],\n",
       "       [ 0.25077391],\n",
       "       [ 0.75981826],\n",
       "       [ 0.41627875],\n",
       "       [ 0.38233432],\n",
       "       [ 0.391166  ],\n",
       "       [ 0.06047815],\n",
       "       [ 0.88684535],\n",
       "       [ 0.31696576],\n",
       "       [ 0.31357926],\n",
       "       [ 0.32258272],\n",
       "       [ 0.24460994],\n",
       "       [ 0.90216005],\n",
       "       [ 0.49923122],\n",
       "       [ 0.4504801 ],\n",
       "       [ 0.13440819],\n",
       "       [ 0.95373982],\n",
       "       [ 0.80556732],\n",
       "       [ 0.23038869],\n",
       "       [ 0.29938743],\n",
       "       [ 0.21512362],\n",
       "       [ 0.27019492],\n",
       "       [ 0.48704234],\n",
       "       [ 0.36832356],\n",
       "       [ 0.18235764],\n",
       "       [ 0.67012578],\n",
       "       [ 0.05139163],\n",
       "       [ 0.36206517],\n",
       "       [ 0.42598751],\n",
       "       [ 0.09568189],\n",
       "       [ 0.16508338],\n",
       "       [ 0.32911736],\n",
       "       [ 0.7563175 ],\n",
       "       [ 0.83632004],\n",
       "       [ 0.0343325 ],\n",
       "       [ 0.82848519],\n",
       "       [ 0.32706675],\n",
       "       [ 0.33668923],\n",
       "       [ 0.31419525],\n",
       "       [ 0.12279834],\n",
       "       [ 0.04424528],\n",
       "       [ 0.33343896],\n",
       "       [ 0.19263136],\n",
       "       [ 0.9728598 ],\n",
       "       [ 0.78203732],\n",
       "       [ 0.60977083],\n",
       "       [ 0.04984998],\n",
       "       [ 0.34847358],\n",
       "       [ 0.58697832],\n",
       "       [ 0.07128333],\n",
       "       [ 0.30126059],\n",
       "       [ 0.56206864],\n",
       "       [ 0.47770301],\n",
       "       [ 0.95401978],\n",
       "       [ 0.1101013 ],\n",
       "       [ 0.15931395],\n",
       "       [ 0.12586664],\n",
       "       [ 0.16073957],\n",
       "       [ 0.07012957],\n",
       "       [ 0.44195956],\n",
       "       [ 0.2830382 ],\n",
       "       [ 0.22875258],\n",
       "       [ 0.23560171],\n",
       "       [ 0.9492628 ],\n",
       "       [ 0.18266466],\n",
       "       [ 0.1158559 ],\n",
       "       [ 0.8966912 ],\n",
       "       [ 0.03673918],\n",
       "       [ 0.3589097 ],\n",
       "       [ 0.06209715],\n",
       "       [ 0.1961526 ],\n",
       "       [ 0.12848642],\n",
       "       [ 0.2137614 ],\n",
       "       [ 0.28160462],\n",
       "       [ 0.05797713],\n",
       "       [ 0.19049771],\n",
       "       [ 0.35618734],\n",
       "       [ 0.64335984],\n",
       "       [ 0.58102375],\n",
       "       [ 0.36580724],\n",
       "       [ 0.42349997],\n",
       "       [ 0.49693948],\n",
       "       [ 0.34974578],\n",
       "       [ 0.35382524],\n",
       "       [ 0.51868737],\n",
       "       [ 0.2810216 ],\n",
       "       [ 0.37328938],\n",
       "       [ 0.4591895 ],\n",
       "       [ 0.63716125],\n",
       "       [ 0.16917852],\n",
       "       [ 0.10030126],\n",
       "       [ 0.11770365],\n",
       "       [ 0.98161077],\n",
       "       [ 0.57233262],\n",
       "       [ 0.54814231],\n",
       "       [ 0.84450293],\n",
       "       [ 0.14537984],\n",
       "       [ 0.87388289],\n",
       "       [ 0.10472827],\n",
       "       [ 0.1040452 ],\n",
       "       [ 0.277237  ],\n",
       "       [ 0.49066895],\n",
       "       [ 0.03739519],\n",
       "       [ 0.54628372],\n",
       "       [ 0.30287221],\n",
       "       [ 0.07735357],\n",
       "       [ 0.90939039],\n",
       "       [ 0.75804174],\n",
       "       [ 0.05755149],\n",
       "       [ 0.18321472],\n",
       "       [ 0.41484135],\n",
       "       [ 0.29572916],\n",
       "       [ 0.2627202 ],\n",
       "       [ 0.20276672],\n",
       "       [ 0.56141615],\n",
       "       [ 0.35292119],\n",
       "       [ 0.15528147],\n",
       "       [ 0.05981224],\n",
       "       [ 0.48720139],\n",
       "       [ 0.1916438 ],\n",
       "       [ 0.04674357],\n",
       "       [ 0.18722127],\n",
       "       [ 0.17532066],\n",
       "       [ 0.60266   ],\n",
       "       [ 0.77210754],\n",
       "       [ 0.64619297],\n",
       "       [ 0.1390955 ],\n",
       "       [ 0.50554812],\n",
       "       [ 0.08203091],\n",
       "       [ 0.2720702 ],\n",
       "       [ 0.06520178],\n",
       "       [ 0.79343671],\n",
       "       [ 0.55691081],\n",
       "       [ 0.10852806],\n",
       "       [ 0.09085653],\n",
       "       [ 0.14918797],\n",
       "       [ 0.27648377],\n",
       "       [ 0.25971442],\n",
       "       [ 0.34856614],\n",
       "       [ 0.46913233],\n",
       "       [ 0.18561089],\n",
       "       [ 0.28355181],\n",
       "       [ 0.1141941 ],\n",
       "       [ 0.93486476],\n",
       "       [ 0.11765334],\n",
       "       [ 0.0383516 ],\n",
       "       [ 0.35132781],\n",
       "       [ 0.49575818],\n",
       "       [ 0.64817911],\n",
       "       [ 0.35987249],\n",
       "       [ 0.51189256],\n",
       "       [ 0.06129728],\n",
       "       [ 0.10016919],\n",
       "       [ 0.8600738 ],\n",
       "       [ 0.90153885],\n",
       "       [ 0.41100675],\n",
       "       [ 0.49461785],\n",
       "       [ 0.48737222],\n",
       "       [ 0.16702069],\n",
       "       [ 0.18808421],\n",
       "       [ 0.15870152],\n",
       "       [ 0.07621875],\n",
       "       [ 0.18041815],\n",
       "       [ 0.58564126],\n",
       "       [ 0.24452426],\n",
       "       [ 0.1307237 ],\n",
       "       [ 0.79086995],\n",
       "       [ 0.30327606],\n",
       "       [ 0.6323759 ],\n",
       "       [ 0.8664251 ],\n",
       "       [ 0.12065219],\n",
       "       [ 0.18349479],\n",
       "       [ 0.09129808],\n",
       "       [ 0.18567865],\n",
       "       [ 0.06583523],\n",
       "       [ 0.36516577],\n",
       "       [ 0.59793353],\n",
       "       [ 0.35172656],\n",
       "       [ 0.19234674],\n",
       "       [ 0.03385247],\n",
       "       [ 0.17345959],\n",
       "       [ 0.18420771],\n",
       "       [ 0.22857751],\n",
       "       [ 0.30130279],\n",
       "       [ 0.49534884],\n",
       "       [ 0.47907791],\n",
       "       [ 0.67980623],\n",
       "       [ 0.95761085],\n",
       "       [ 0.42195484],\n",
       "       [ 0.31464201],\n",
       "       [ 0.10714363],\n",
       "       [ 0.53655928],\n",
       "       [ 0.87116361],\n",
       "       [ 0.14493492],\n",
       "       [ 0.84812093],\n",
       "       [ 0.25627178],\n",
       "       [ 0.81985343],\n",
       "       [ 0.11336501],\n",
       "       [ 0.85773104],\n",
       "       [ 0.35197508],\n",
       "       [ 0.57268631],\n",
       "       [ 0.25735986],\n",
       "       [ 0.69032705],\n",
       "       [ 0.52682292],\n",
       "       [ 0.27838832],\n",
       "       [ 0.19106357],\n",
       "       [ 0.83711892],\n",
       "       [ 0.3381353 ],\n",
       "       [ 0.06981242],\n",
       "       [ 0.21560532],\n",
       "       [ 0.2015806 ],\n",
       "       [ 0.70800501],\n",
       "       [ 0.88587856],\n",
       "       [ 0.53213704],\n",
       "       [ 0.7315982 ],\n",
       "       [ 0.08397882],\n",
       "       [ 0.48636773],\n",
       "       [ 0.11390261],\n",
       "       [ 0.28676847],\n",
       "       [ 0.8233552 ],\n",
       "       [ 0.88369328],\n",
       "       [ 0.2844283 ],\n",
       "       [ 0.75953406],\n",
       "       [ 0.17180741],\n",
       "       [ 0.12759918],\n",
       "       [ 0.03438558],\n",
       "       [ 0.58104402],\n",
       "       [ 0.89200211],\n",
       "       [ 0.38051432],\n",
       "       [ 0.15736806],\n",
       "       [ 0.94914651],\n",
       "       [ 0.17046478],\n",
       "       [ 0.27919164],\n",
       "       [ 0.11483046],\n",
       "       [ 0.18321534],\n",
       "       [ 0.24881832],\n",
       "       [ 0.56356776],\n",
       "       [ 0.12015719],\n",
       "       [ 0.56844336],\n",
       "       [ 0.14023525],\n",
       "       [ 0.29764414],\n",
       "       [ 0.10714782],\n",
       "       [ 0.34628984],\n",
       "       [ 0.57616258],\n",
       "       [ 0.33838186],\n",
       "       [ 0.08777471],\n",
       "       [ 0.26762015],\n",
       "       [ 0.07015797],\n",
       "       [ 0.07843339],\n",
       "       [ 0.53416735],\n",
       "       [ 0.67663878],\n",
       "       [ 0.24053557],\n",
       "       [ 0.33263806],\n",
       "       [ 0.55176735],\n",
       "       [ 0.67114639],\n",
       "       [ 0.82906818],\n",
       "       [ 0.62106317],\n",
       "       [ 0.17633672],\n",
       "       [ 0.1461014 ],\n",
       "       [ 0.29703176],\n",
       "       [ 0.258389  ],\n",
       "       [ 0.50535595],\n",
       "       [ 0.20146547],\n",
       "       [ 0.51253384],\n",
       "       [ 0.16504294],\n",
       "       [ 0.64976323],\n",
       "       [ 0.52198642],\n",
       "       [ 0.12789224],\n",
       "       [ 0.79609251],\n",
       "       [ 0.95276272],\n",
       "       [ 0.79707628],\n",
       "       [ 0.72016543],\n",
       "       [ 0.65503991],\n",
       "       [ 0.27991715],\n",
       "       [ 0.52953857],\n",
       "       [ 0.48985818],\n",
       "       [ 0.50861973],\n",
       "       [ 0.60920459],\n",
       "       [ 0.80718029],\n",
       "       [ 0.2057312 ],\n",
       "       [ 0.09700064],\n",
       "       [ 0.35513359],\n",
       "       [ 0.06211391],\n",
       "       [ 0.93030196],\n",
       "       [ 0.68208098],\n",
       "       [ 0.29246357],\n",
       "       [ 0.69437653],\n",
       "       [ 0.14973427],\n",
       "       [ 0.06070874],\n",
       "       [ 0.84727681],\n",
       "       [ 0.19810234],\n",
       "       [ 0.3912667 ],\n",
       "       [ 0.01993607],\n",
       "       [ 0.2943294 ],\n",
       "       [ 0.34683406],\n",
       "       [ 0.38631707],\n",
       "       [ 0.30425733],\n",
       "       [ 0.61654174],\n",
       "       [ 0.29199579],\n",
       "       [ 0.74619037],\n",
       "       [ 0.27330032],\n",
       "       [ 0.65669841],\n",
       "       [ 0.13425204],\n",
       "       [ 0.5310601 ],\n",
       "       [ 0.66665435],\n",
       "       [ 0.64697677],\n",
       "       [ 0.17070359],\n",
       "       [ 0.76059771],\n",
       "       [ 0.29741991],\n",
       "       [ 0.47302678],\n",
       "       [ 0.78031051],\n",
       "       [ 0.3861405 ],\n",
       "       [ 0.1638654 ],\n",
       "       [ 0.22646114],\n",
       "       [ 0.09812474],\n",
       "       [ 0.32822376],\n",
       "       [ 0.86902791],\n",
       "       [ 0.33336967],\n",
       "       [ 0.21190333],\n",
       "       [ 0.19795477],\n",
       "       [ 0.88444734],\n",
       "       [ 0.17384353],\n",
       "       [ 0.19837017],\n",
       "       [ 0.95688313],\n",
       "       [ 0.77671182],\n",
       "       [ 0.10793517],\n",
       "       [ 0.46906042],\n",
       "       [ 0.42242557],\n",
       "       [ 0.07272821],\n",
       "       [ 0.38525185],\n",
       "       [ 0.57174927],\n",
       "       [ 0.25609279],\n",
       "       [ 0.16630955],\n",
       "       [ 0.41681015],\n",
       "       [ 0.26046425],\n",
       "       [ 0.27509421],\n",
       "       [ 0.30025232],\n",
       "       [ 0.28968814],\n",
       "       [ 0.25952798],\n",
       "       [ 0.23665699],\n",
       "       [ 0.59318447],\n",
       "       [ 0.30223796],\n",
       "       [ 0.25003043],\n",
       "       [ 0.37380943],\n",
       "       [ 0.12356289],\n",
       "       [ 0.35744423],\n",
       "       [ 0.17131199],\n",
       "       [ 0.42140061],\n",
       "       [ 0.72553498],\n",
       "       [ 0.28339463],\n",
       "       [ 0.22707863],\n",
       "       [ 0.64058012],\n",
       "       [ 0.83429158],\n",
       "       [ 0.42063966],\n",
       "       [ 0.57329965],\n",
       "       [ 0.1368947 ],\n",
       "       [ 0.84781224],\n",
       "       [ 0.81955743],\n",
       "       [ 0.65796047],\n",
       "       [ 0.16270961],\n",
       "       [ 0.23330671],\n",
       "       [ 0.54451329],\n",
       "       [ 0.7917695 ],\n",
       "       [ 0.29756349],\n",
       "       [ 0.42326707],\n",
       "       [ 0.5969184 ],\n",
       "       [ 0.26812786],\n",
       "       [ 0.92403746],\n",
       "       [ 0.07989902],\n",
       "       [ 0.95818186],\n",
       "       [ 0.24780583],\n",
       "       [ 0.14126803],\n",
       "       [ 0.45648447],\n",
       "       [ 0.28699684],\n",
       "       [ 0.64857447],\n",
       "       [ 0.11667049]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rounded = [round(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Keras Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name Dense",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bd7c115bdc50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name Dense"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(1000, 64, input_length=10))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
