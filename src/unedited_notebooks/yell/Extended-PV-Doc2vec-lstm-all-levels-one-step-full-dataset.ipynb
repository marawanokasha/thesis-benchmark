{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of fixed size paragraph vectors using LSTM\n",
    "should be able to deal with all levels using the PARTS_LEVEL param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: Tesla K40m (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple, defaultdict\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "import seaborn\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Masking\n",
    "from keras.layers.convolutional import MaxPooling1D, Convolution1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from thesis.utils.metrics import *\n",
    "from thesis.utils.file import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables used throughout the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234\n",
    "NN_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "VALIDATION_DICT = \"validation_dict.pkl\"\n",
    "TEST_MATRIX = \"test_matrix.pkl\"\n",
    "TEST_DICT = \"test_dict.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\"\n",
    "TYPE_CLASSIFIER= \"{}_classifier.pkl\"\n",
    "\n",
    "TRAINING_DATA_MATRIX = \"X_level_{}.npy\"\n",
    "TRAINING_LABELS_MATRIX = \"y_{}.npy\"\n",
    "VALIDATION_DATA_MATRIX = \"Xv_level_{}.npy\"\n",
    "VALIDATION_LABELS_MATRIX = \"yv_{}.npy\"\n",
    "TEST_DATA_MATRIX = \"Xt_level_{}.npy\"\n",
    "TEST_LABELS_MATRIX = \"yt_{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"lstm_{}_level_{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "big_data_location = \"/mnt/data/shalaby/\"\n",
    "\n",
    "matrices_save_location = big_data_location + \"extended_pv_matrices/\"\n",
    "# matrices_save_location = big_data_location + \"extended_pv_matrices/one_model/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_parameter_search_extended_abs_desc_claims_full_chunks\")\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load general data required for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 s, sys: 116 ms, total: 2.28 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401877"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_data(classifications_type, level):\n",
    "    info(\"Loading Training Data from file\")\n",
    "    training_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                              TRAINING_DATA_MATRIX.format(level))))\n",
    "    training_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                TRAINING_LABELS_MATRIX.format(classifications_type))))\n",
    "    return training_data, training_labels\n",
    "\n",
    "def get_validation_data(classifications_type, level):\n",
    "    info(\"Loading Validation Data from file\")\n",
    "    validation_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                VALIDATION_DATA_MATRIX.format(level))))\n",
    "    validation_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  VALIDATION_LABELS_MATRIX.format(classifications_type))))\n",
    "    return validation_data, validation_labels\n",
    "\n",
    "def get_test_data(classifications_type, level):\n",
    "    info(\"Loading Test Data from file\")\n",
    "    test_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                TEST_DATA_MATRIX.format(level))))\n",
    "    test_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  TEST_LABELS_MATRIX.format(classifications_type))))\n",
    "    return test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the \n",
    "    validation metrics\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        MetricsCallback.EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "        MetricsCallback.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
    "        MetricsCallback.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
    "        self.ax = plt.subplot(111)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
    "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
    "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
    "        self.ax.set_ylim((MetricsCallback.GRAPH_MIN, MetricsCallback.GRAPH_MAX))\n",
    "        self.fig.canvas.draw()\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            #time.sleep(0.1)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                yvp = self.model.predict(Xv)\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_keras_rnn_model(input_size, output_size, lstm_output_size, w_dropout_do, u_dropout_do, \n",
    "                           stack_layers=1, conv_size=None, conv_filter_length=3, max_pooling_length=None):\n",
    "    \n",
    "    model= Sequential()\n",
    "#     model.add(Masking(mask_value=0., input_shape=(MAX_SIZE, input_size)))\n",
    "    if conv_size:\n",
    "        model.add(Convolution1D(nb_filter=conv_size, input_shape=(MAX_SIZE, input_size), filter_length=conv_filter_length, \n",
    "                                border_mode='same', activation='relu'))\n",
    "        if max_pooling_length is not None:\n",
    "            model.add(MaxPooling1D(pool_length=max_pooling_length))\n",
    "    for i in range(stack_layers):\n",
    "        model.add(LSTM(lstm_output_size, input_dim=input_size, dropout_W=w_dropout_do, dropout_U=u_dropout_do,\n",
    "                       return_sequences=False if i+1 == stack_layers else True,\n",
    "                  name='lstm_{}_w-drop_{}_u-drop_{}_layer_{}'.format(lstm_output_size, str(u_dropout_do), str(w_dropout_do), str(i+1))))\n",
    "    model.add(Dense(output_size, activation='sigmoid', name='sigmoid_output'))\n",
    "    model.compile(optimizer=NN_OPTIMIZER, loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Param Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum change in val_loss from previous epoch to register as a decrease\n",
    "early_stopper_deltas = {\n",
    "    'sections': 0.00001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "# how many epochs to wait when there is no decrease in val_loss before early stopping\n",
    "early_stopper_patience = {\n",
    "    'sections': 15,\n",
    "    'classes': 15,\n",
    "    'subclasses': 15\n",
    "}\n",
    "# number of epochs after which we do periodic evaluation of validation metrics\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 20,\n",
    "    'subclasses': 20\n",
    "}\n",
    "\n",
    "# ranges for learning graph shown\n",
    "metrics_graph_ranges = {\n",
    "    'sections': {'min':0, 'max': 0.3},\n",
    "    'classes': {'min':0, 'max': 0.05},\n",
    "    'subclasses': {'min':0, 'max': 0.05}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEVEL_DOC = 1\n",
    "LEVEL_DIVISIONS = 2\n",
    "LEVEL_CHUNKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_EPOCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_PARMS_TO_RUN = [\n",
    "    {\n",
    "        'doc2vec_epoch': 1,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_DIVISIONS,\n",
    "        'nn_batch_size': 4096,\n",
    "        'lstm_output_size': 1000,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 1,\n",
    "        'lstm_conv_size': None,\n",
    "        'lstm_conv_filter_length': None,\n",
    "        'lstm_max_pooling_length': None\n",
    "    },\n",
    "    {\n",
    "        'doc2vec_epoch': 3,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_DIVISIONS,\n",
    "        'nn_batch_size': 4096,\n",
    "        'lstm_output_size': 1000,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 1,\n",
    "        'lstm_conv_size': None,\n",
    "        'lstm_conv_filter_length': None,\n",
    "        'lstm_max_pooling_length': None\n",
    "    },\n",
    "    {\n",
    "        'doc2vec_epoch': 5,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_DIVISIONS,\n",
    "        'nn_batch_size': 4096,\n",
    "        'lstm_output_size': 1000,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 1,\n",
    "        'lstm_conv_size': None,\n",
    "        'lstm_conv_filter_length': None,\n",
    "        'lstm_max_pooling_length': None\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== NEW PARAM SET ============================================\n",
      "{'lstm_conv_filter_length': None, 'lstm_stack_layers': 1, 'nn_batch_size': 4096, 'classifications_type': 'sections', 'lstm_w_dropout': 0.5, 'lstm_max_pooling_length': None, 'lstm_u_dropout': 0.5, 'parts_level': 2, 'lstm_output_size': 1000, 'doc2vec_epoch': 1, 'lstm_conv_size': None}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 22:34:08,903 : INFO : Loading Training Documents\n",
      "2017-04-18 22:34:08,905 : INFO : Loading Training Data from file\n",
      "2017-04-18 22:34:10,487 : INFO : Loading Validation Documents\n",
      "2017-04-18 22:34:10,489 : INFO : Loading Validation Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1286325, 4, 200)\n",
      "(1286325, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 22:34:10,832 : INFO : No Previous results exist in /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_full_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/lstm_sections_level_2_batch_4096_nn_parameter_searches.pkl\n",
      "2017-04-18 22:34:10,833 : INFO : ***************************************************************************************\n",
      "2017-04-18 22:34:10,834 : INFO : lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(321473, 4, 200)\n",
      "(321473, 8)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, 1000)          4804000     lstm_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 8)             8008        lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "====================================================================================================\n",
      "Total params: 4,812,008\n",
      "Trainable params: 4,812,008\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.2082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 22:38:10,311 : INFO : Found lower val loss for epoch 1 => 0.18146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 220s - loss: 0.2082 - val_loss: 0.1815\n",
      "Epoch 2/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 22:41:52,838 : INFO : Found lower val loss for epoch 2 => 0.1633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 222s - loss: 0.1713 - val_loss: 0.1633\n",
      "Epoch 3/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 22:45:38,634 : INFO : Found lower val loss for epoch 3 => 0.16186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1617 - val_loss: 0.1619\n",
      "Epoch 4/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 22:49:22,919 : INFO : Found lower val loss for epoch 4 => 0.15164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1564 - val_loss: 0.1516\n",
      "Epoch 5/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1529 - val_loss: 0.1532\n",
      "Epoch 6/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1503"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 22:56:53,440 : INFO : Found lower val loss for epoch 6 => 0.15015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1503 - val_loss: 0.1502\n",
      "Epoch 7/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 23:00:37,172 : INFO : Found lower val loss for epoch 7 => 0.1493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1484 - val_loss: 0.1493\n",
      "Epoch 8/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 23:04:22,264 : INFO : Found lower val loss for epoch 8 => 0.14892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1467 - val_loss: 0.1489\n",
      "Epoch 9/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 23:08:06,251 : INFO : Found lower val loss for epoch 9 => 0.14618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1453 - val_loss: 0.1462\n",
      "Epoch 10/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1440 - val_loss: 0.1477\n",
      "Epoch 11/200\n",
      "1286325/1286325 [==============================] - 218s - loss: 0.1430 - val_loss: 0.1465\n",
      "Epoch 12/200\n",
      "1286325/1286325 [==============================] - 222s - loss: 0.1421 - val_loss: 0.1469\n",
      "Epoch 13/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 23:22:59,015 : INFO : Found lower val loss for epoch 13 => 0.14526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 227s - loss: 0.1413 - val_loss: 0.1453\n",
      "Epoch 14/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1406 - val_loss: 0.1457\n",
      "Epoch 15/200\n",
      "1286325/1286325 [==============================] - 226s - loss: 0.1399 - val_loss: 0.1454\n",
      "Epoch 16/200\n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1393 - val_loss: 0.1456\n",
      "Epoch 17/200\n",
      "1286325/1286325 [==============================] - 227s - loss: 0.1387 - val_loss: 0.1454\n",
      "Epoch 18/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 23:41:49,792 : INFO : Found lower val loss for epoch 18 => 0.14427\n",
      "2017-04-18 23:41:49,793 : INFO : Validation Loss Reduced 10 times\n",
      "2017-04-18 23:41:49,794 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 23:44:51,962 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.429 | Top 3: 0.972 | Top 5: 0.995 | F1 Micro: 0.789 | F1 Macro: 0.733\n",
      "1286325/1286325 [==============================] - 417s - loss: 0.1383 - val_loss: 0.1443\n",
      "Epoch 19/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1377 - val_loss: 0.1443\n",
      "Epoch 20/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1372 - val_loss: 0.1456\n",
      "Epoch 21/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 23:56:17,310 : INFO : Found lower val loss for epoch 21 => 0.14401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 226s - loss: 0.1369 - val_loss: 0.1440\n",
      "Epoch 22/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1365 - val_loss: 0.1441\n",
      "Epoch 23/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1362 - val_loss: 0.1460\n",
      "Epoch 24/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1358 - val_loss: 0.1446\n",
      "Epoch 25/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1354 - val_loss: 0.1443\n",
      "Epoch 26/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1353 - val_loss: 0.1443\n",
      "Epoch 27/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 00:18:46,948 : INFO : Found lower val loss for epoch 27 => 0.1434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1350 - val_loss: 0.1434\n",
      "Epoch 28/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1346 - val_loss: 0.1444\n",
      "Epoch 29/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1344 - val_loss: 0.1442\n",
      "Epoch 30/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 00:30:02,046 : INFO : Found lower val loss for epoch 30 => 0.14275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1341 - val_loss: 0.1427\n",
      "Epoch 31/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1339 - val_loss: 0.1445\n",
      "Epoch 32/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1337 - val_loss: 0.1454\n",
      "Epoch 33/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 00:41:20,309 : INFO : Found lower val loss for epoch 33 => 0.14243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 227s - loss: 0.1336 - val_loss: 0.1424\n",
      "Epoch 34/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1333 - val_loss: 0.1437\n",
      "Epoch 35/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1331 - val_loss: 0.1447\n",
      "Epoch 36/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1329 - val_loss: 0.1461\n",
      "Epoch 37/200\n",
      "1286325/1286325 [==============================] - 222s - loss: 0.1327 - val_loss: 0.1440\n",
      "Epoch 38/200\n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1326 - val_loss: 0.1446\n",
      "Epoch 39/200\n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1324 - val_loss: 0.1445\n",
      "Epoch 40/200\n",
      "1286325/1286325 [==============================] - 225s - loss: 0.1323 - val_loss: 0.1435\n",
      "Epoch 41/200\n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1322 - val_loss: 0.1429\n",
      "Epoch 42/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1320 - val_loss: 0.1441\n",
      "Epoch 43/200\n",
      "1286325/1286325 [==============================] - 220s - loss: 0.1319 - val_loss: 0.1436\n",
      "Epoch 44/200\n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1316 - val_loss: 0.1445\n",
      "Epoch 45/200\n",
      "1286325/1286325 [==============================] - 223s - loss: 0.1316 - val_loss: 0.1431\n",
      "Epoch 46/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1314 - val_loss: 0.1434\n",
      "Epoch 47/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1313 - val_loss: 0.1431\n",
      "Epoch 48/200\n",
      "1286325/1286325 [==============================] - 224s - loss: 0.1313 - val_loss: 0.1445\n",
      "Epoch 49/200\n",
      "1286325/1286325 [==============================] - 220s - loss: 0.1311 - val_loss: 0.1430\n",
      "Epoch 00048: early stopping\n",
      "CPU times: user 1h 9min 50s, sys: 1h 48min 3s, total: 2h 57min 54s\n",
      "Wall time: 3h 6min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 01:41:01,375 : INFO : Evaluating on Training Data\n",
      "2017-04-19 01:50:23,439 : INFO : Generating Training Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Training Metrics: Cov Err: 1.344 | Top 3: 0.984 | Top 5: 0.998 | F1 Micro: 0.831 | F1 Macro: 0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 01:51:00,163 : INFO : Evaluating on Validation Data using saved best weights\n",
      "2017-04-19 01:53:21,109 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.420 | Top 3: 0.973 | Top 5: 0.995 | F1 Micro: 0.795 | F1 Macro: 0.741\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-68250b7be4d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mparam_results_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_param_results_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_results_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_results_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "for GLOBAL_PARAMS in GLOBAL_PARMS_TO_RUN:\n",
    "    \n",
    "    print '==================================== NEW PARAM SET ============================================'\n",
    "    print {k:v for k,v in GLOBAL_PARAMS.items() if k != 'classifications'}\n",
    "    \n",
    "    classifications = GLOBAL_PARAMS['classifications']\n",
    "    classifications_type = GLOBAL_PARAMS['classifications_type']\n",
    "    classifier_file = TYPE_CLASSIFIER.format(classifications_type)\n",
    "    \n",
    "    PARTS_LEVEL = GLOBAL_PARAMS['parts_level']\n",
    "    \n",
    "    \n",
    "    placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "    placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "    epoch = GLOBAL_PARAMS['doc2vec_epoch']\n",
    "\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    print GLOBAL_VARS.MODEL_NAME\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    info(\"Loading Training Documents\")\n",
    "    X, y = get_training_data(classifications_type, PARTS_LEVEL)\n",
    "    print X.shape\n",
    "    print y.shape\n",
    "    \n",
    "    info(\"Loading Validation Documents\")\n",
    "    Xv, yv = get_validation_data(classifications_type, PARTS_LEVEL)\n",
    "    print Xv.shape\n",
    "    print yv.shape\n",
    "    \n",
    "    \n",
    "    NN_OUTPUT_NEURONS = len(classifications)\n",
    "    EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "    EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "\n",
    "    NN_MAX_EPOCHS = 200\n",
    "    NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "    NN_BATCH_SIZE = GLOBAL_PARAMS['nn_batch_size']\n",
    "\n",
    "    MODEL_VERBOSITY = 1\n",
    "\n",
    "    NN_OPTIMIZER = 'rmsprop'\n",
    "    # NN_OPTIMIZER = 'adam'\n",
    "\n",
    "    to_skip = []\n",
    "\n",
    "    load_existing_results = True\n",
    "    save_results = True\n",
    "\n",
    "\n",
    "    np.random.seed(NN_SEED)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    ############### Actual Training\n",
    "\n",
    "\n",
    "    # load previous finshed results so we dont redo them\n",
    "    param_results_dict = {}\n",
    "    \n",
    "    param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                   NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "        \n",
    "    if load_existing_results:\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results from {}'.format(param_results_path))\n",
    "            param_results_dict = pickle.load(open(param_results_path))\n",
    "        else:\n",
    "            info('No Previous results exist in {}'.format(param_results_path))\n",
    "\n",
    "    ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "    start_time = time.time()\n",
    "    lstm_output_size = GLOBAL_PARAMS['lstm_output_size']\n",
    "    w_dropout_do = GLOBAL_PARAMS['lstm_w_dropout']\n",
    "    u_dropout_do = GLOBAL_PARAMS['lstm_u_dropout']\n",
    "    stack_layers = GLOBAL_PARAMS['lstm_stack_layers']\n",
    "    conv_size = GLOBAL_PARAMS['lstm_conv_size']\n",
    "    conv_filter_length = GLOBAL_PARAMS['lstm_conv_filter_length']\n",
    "    conv_max_pooling_length = GLOBAL_PARAMS['lstm_max_pooling_length']\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "        lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    "    )\n",
    "    if conv_size:\n",
    "        GLOBAL_VARS.NN_MODEL_NAME += '_conv-filter-length_{}_max-pooling-size_{}'.format(conv_filter_length, \n",
    "                                                                                         conv_max_pooling_length)\n",
    "\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "\n",
    "    info('***************************************************************************************')\n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "    # creating the actual keras model\n",
    "    model = create_keras_rnn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size, \n",
    "                                   conv_filter_length, conv_max_pooling_length)\n",
    "    model.summary()\n",
    "\n",
    "    # callbacks for early stopping and for generating validation metrics\n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                              nb_epoch=NN_MAX_EPOCHS, verbose=MODEL_VERBOSITY, \\\n",
    "                              callbacks=[early_stopper, metrics_callback])\n",
    "    \n",
    "    \n",
    "#     time.sleep(0.2)\n",
    "#     info('Evaluating on Training Data')\n",
    "#     yp = model.predict(X) # get raw probability for predicted labels\n",
    "#     yp_binary = get_binary_0_5(yp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "#     #print yvp\n",
    "#     info('Generating Training Metrics')\n",
    "#     training_metrics = get_metrics(y, yp, yp_binary)\n",
    "#     print \"****** Training Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "#     training_metrics['coverage_error'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#     training_metrics['f1_micro'], training_metrics['f1_macro'])\n",
    "    \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Validation Data using saved best weights')\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    yvp = model.predict(Xv) # get raw probability for predicted labels\n",
    "    yvp_binary = get_binary_0_5(yvp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    best_validation_metrics = validation_metrics\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "    del history, metrics_callback, model\n",
    "\n",
    "    if save_results:\n",
    "        if load_existing_results:\n",
    "            if os.path.exists(param_results_path):\n",
    "                info('Loading Previous results from {}'.format(param_results_path))\n",
    "                loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "                param_results_dict.update(loaded_param_results_dict)\n",
    "\n",
    "        pickle.dump(param_results_dict, open(param_results_path, 'w'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-13 19:29:00,369 : INFO : Evaluating on Validation Data using saved best weights\n",
      "2017-04-13 19:34:08,795 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.357 | Top 3: 0.982 | Top 5: 0.997 | F1 Micro: 0.827 | F1 Macro: 0.784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time.sleep(0.2)\n",
    "info('Evaluating on Validation Data using saved best weights')\n",
    "model.set_weights(metrics_callback.best_weights)\n",
    "yvp = model.predict(Xv) # get raw probability for predicted labels\n",
    "yvp_binary = get_binary_0_5(yvp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "#print yvp\n",
    "info('Generating Validation Metrics')\n",
    "validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "best_validation_metrics = validation_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(param_results_dict, open('/mnt/data/shalaby/sections_lstm.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = sections\n",
    "classifications_type = 'sections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_METRICS_FILENAME = '{}_level_{}_lstm_test_metrics_dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DOC2VEC_EPOCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = DOC2VEC_EPOCH\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "print GLOBAL_VARS.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 4096\n",
    "NN_OPTIMIZER = 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARTS_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "param_results_dict = pickle.load(open(param_results_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 21:28:07,313 : INFO : Loading Test Data from file\n"
     ]
    }
   ],
   "source": [
    "Xt, yt = get_test_data(classifications_type, PARTS_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "NN_INPUT_NEURONS = Xt.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_2_conv_None',\n",
       " 'lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_3_conv_None',\n",
       " 'lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 21:28:14,579 : INFO : ***************************************************************************************\n",
      "2017-04-18 21:28:14,580 : INFO : lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_3_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, None, 1000)    4804000     lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, None, 1000)    8004000     lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "____________________________________________________________________________________________________\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, 1000)          8004000     lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 8)             8008        lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 21:28:18,468 : INFO : Evaluating on Test Data using best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 20,820,008\n",
      "Trainable params: 20,820,008\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 21:39:42,230 : INFO : Generating Test Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test Metrics: Cov Err: 1.360, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.862, Top 3: 0.981, Top 5: 0.997, \n",
      "\t\t F1 Micro: 0.824, F1 Macro: 0.781, Total Pos: 441,003\n"
     ]
    }
   ],
   "source": [
    "lstm_output_size = 1000\n",
    "w_dropout_do = 0.5\n",
    "u_dropout_do = 0.5\n",
    "stack_layers = 3\n",
    "conv_size = None\n",
    "conv_filter_length = None\n",
    "conv_max_pooling_length = None\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "    lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    ")\n",
    "if conv_size:\n",
    "    GLOBAL_VARS.NN_MODEL_NAME += '_conv-filter-length_{}_max-pooling-size_{}'.format(conv_filter_length, \n",
    "                                                                                     conv_max_pooling_length)\n",
    "                                                                                     \n",
    "if GLOBAL_VARS.NN_MODEL_NAME not in param_results_dict.keys():\n",
    "    print \"Can't find model: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    raise Exception()\n",
    "\n",
    "test_metrics_dict = {}\n",
    "test_metrics_path = os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                            TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL))\n",
    "if os.path.exists(test_metrics_path):\n",
    "    test_metrics_dict =  pickle.load(open(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                            TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL))))\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in test_metrics_dict.keys():\n",
    "        print \"Test metrics already exist for: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        test_metrics = test_metrics_dict[GLOBAL_VARS.NN_MODEL_NAME]\n",
    "        print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "            test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "            test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "            test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "        raise Exception()\n",
    "        \n",
    "info('***************************************************************************************')\n",
    "info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "# creating the actual keras model\n",
    "model = create_keras_rnn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                              lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size, \n",
    "                               conv_filter_length, conv_max_pooling_length)\n",
    "model.summary()\n",
    "\n",
    "# get model best weights\n",
    "# weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'].best_weights\n",
    "weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights']\n",
    "model.set_weights(weights)\n",
    "\n",
    "info('Evaluating on Test Data using best weights')\n",
    "ytp = model.predict(Xt)\n",
    "ytp_binary = get_binary_0_5(ytp)\n",
    "#print yvp\n",
    "info('Generating Test Metrics')\n",
    "test_metrics = get_metrics(yt, ytp, ytp_binary)\n",
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "\n",
    "ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "test_metrics_dict[GLOBAL_VARS.NN_MODEL_NAME] = test_metrics\n",
    "pickle.dump(test_metrics_dict, open(test_metrics_path, 'w'))\n",
    "\n",
    "# pickle.dump(test_metrics, open(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                             TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL)), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test Metrics: Cov Err: 6.531, Avg Labels: 1.340, \n",
      "\t\t Top 1: 0.606, Top 3: 0.749, Top 5: 0.830, \n",
      "\t\t F1 Micro: 0.559, F1 Macro: 0.186, Total Pos: 370,180\n"
     ]
    }
   ],
   "source": [
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
