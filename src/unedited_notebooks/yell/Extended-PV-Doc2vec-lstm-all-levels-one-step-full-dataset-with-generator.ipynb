{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of fixed size paragraph vectors using LSTM\n",
    "should be able to deal with all levels using the PARTS_LEVEL param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: TITAN X (Pascal) (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple, defaultdict\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "import seaborn\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Masking\n",
    "from keras.layers.convolutional import MaxPooling1D, Convolution1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from thesis.utils.metrics import *\n",
    "from thesis.utils.file import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables used throughout the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234\n",
    "NN_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUEUE_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "VALIDATION_DICT = \"validation_dict.pkl\"\n",
    "TEST_MATRIX = \"test_matrix.pkl\"\n",
    "TEST_DICT = \"test_dict.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\"\n",
    "TYPE_CLASSIFIER= \"{}_classifier.pkl\"\n",
    "\n",
    "TRAINING_DATA_MATRIX = \"X_level_{}.npy\"\n",
    "TRAINING_LABELS_MATRIX = \"y_{}.npy\"\n",
    "VALIDATION_DATA_MATRIX = \"Xv_level_{}.npy\"\n",
    "VALIDATION_LABELS_MATRIX = \"yv_{}.npy\"\n",
    "TEST_DATA_MATRIX = \"Xt_level_{}.npy\"\n",
    "TEST_LABELS_MATRIX = \"yt_{}.npy\"\n",
    "\n",
    "TRAINING_DATA_MATRIX_PART = \"X_level_{}-{}.npy\"\n",
    "TRAINING_LABELS_MATRIX_PART = \"y_{}-{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"lstm_{}_level_{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "big_data_location = \"/mnt/data/shalaby/\"\n",
    "\n",
    "matrices_save_location = big_data_location + \"extended_pv_matrices/\"\n",
    "# matrices_save_location = big_data_location + \"extended_pv_matrices/one_model/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_parameter_search_extended_abs_desc_claims_full_chunks\")\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load general data required for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 120 ms, total: 2.44 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sections = pickle.load(open(sections_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401877"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type_file_dict ={\n",
    "    \"training\": TRAINING_DATA_MATRIX,\n",
    "    \"validation\": VALIDATION_DATA_MATRIX,\n",
    "    \"test\": TEST_DATA_MATRIX,\n",
    "}\n",
    "labels_type_file_dict ={\n",
    "    \"training\": TRAINING_LABELS_MATRIX,\n",
    "    \"validation\": VALIDATION_LABELS_MATRIX,\n",
    "    \"test\": TEST_LABELS_MATRIX,\n",
    "}\n",
    "\n",
    "def get_data_dirs(classifications_type, level, data_type):\n",
    "    data_dir = os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                data_type_file_dict[data_type].format(level))\n",
    "    labels_dir = os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                labels_type_file_dict[data_type].format(classifications_type))\n",
    "    return data_dir, labels_dir\n",
    "\n",
    "def get_data(data_file, labels_file, mmap=False):\n",
    "    mmap_mode = None\n",
    "    if mmap == True:\n",
    "        mmap_mode = \"r\"\n",
    "    X_data = np.load(data_file, mmap_mode=mmap_mode)\n",
    "    y_data = np.load(labels_file, mmap_mode=mmap_mode)\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the \n",
    "    validation metrics\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        MetricsCallback.EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "        MetricsCallback.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
    "        MetricsCallback.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
    "        self.ax = plt.subplot(111)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
    "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
    "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
    "        self.ax.set_ylim((MetricsCallback.GRAPH_MIN, MetricsCallback.GRAPH_MAX))\n",
    "        self.fig.canvas.draw()\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            #time.sleep(0.1)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                Xv_file, yv_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'validation')\n",
    "                Xv, yv = get_data(Xv_file, yv_file, mmap=True)\n",
    "                yvp = self.model.predict_generator(generator=batch_generator(Xv_file, yv_file, NN_BATCH_SIZE, is_mlp=False, validate=True),\\\n",
    "                                       max_q_size=QUEUE_SIZE,\\\n",
    "                                       val_samples=len(validation_docs_list))\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_keras_rnn_model(input_size, output_size, lstm_output_size, w_dropout_do, u_dropout_do, \n",
    "                           stack_layers=1, conv_size=None, conv_filter_length=3, max_pooling_length=None):\n",
    "    \n",
    "    model= Sequential()\n",
    "#     model.add(Masking(mask_value=0., input_shape=(MAX_SIZE, input_size)))\n",
    "    if conv_size:\n",
    "        model.add(Convolution1D(nb_filter=conv_size, input_shape=(MAX_SIZE, input_size), filter_length=conv_filter_length, \n",
    "                                border_mode='same', activation='relu'))\n",
    "        if max_pooling_length is not None:\n",
    "            model.add(MaxPooling1D(pool_length=max_pooling_length))\n",
    "    for i in range(stack_layers):\n",
    "        model.add(LSTM(lstm_output_size, input_dim=input_size, dropout_W=w_dropout_do, dropout_U=u_dropout_do,\n",
    "                       return_sequences=False if i+1 == stack_layers else True,\n",
    "                  name='lstm_{}_w-drop_{}_u-drop_{}_layer_{}'.format(lstm_output_size, str(u_dropout_do), str(w_dropout_do), str(i+1))))\n",
    "    model.add(Dense(output_size, activation='sigmoid', name='sigmoid_output'))\n",
    "    model.compile(optimizer=NN_OPTIMIZER, loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ArrayReader(Process):\n",
    "    def __init__(self, input_file, label_file, out_queue, batch_size, is_mlp=False, validate=False):\n",
    "        super(ArrayReader, self).__init__()\n",
    "        self.is_mlp = is_mlp\n",
    "        self.validate = validate\n",
    "        self.q = out_queue\n",
    "        self.batch_size = batch_size\n",
    "        self.input_file = input_file\n",
    "        self.label_file = label_file\n",
    "\n",
    "    def run(self):\n",
    "        x_file = np.load(self.input_file, mmap_mode='r')\n",
    "        y_file = np.load(self.label_file, mmap_mode='r')\n",
    "        start_item = 0\n",
    "        num_iter = 0\n",
    "#         shuffled_indices = np.arange(y_file.shape[0])\n",
    "#         np.random.shuffle(shuffled_indices)\n",
    "        while True:\n",
    "            if start_item > y_file.shape[0]:\n",
    "                info('in new epoch for {}'.format(os.path.basename(self.input_file)))\n",
    "#                 np.random.seed(42 + num_iter)\n",
    "#                 np.random.shuffle(shuffled_indices)\n",
    "                start_item = 0\n",
    "#             start_time = time.time()\n",
    "            x_file[0:200000]\n",
    "#             y_batch = np.copy(y_file[start_item: start_item + self.batch_size])\n",
    "#             x_batch = np.copy(x_file[start_item: start_item + self.batch_size])\n",
    "            y_batch = y_file[start_item: start_item + self.batch_size]\n",
    "            x_batch = x_file[start_item: start_item + self.batch_size]\n",
    "#             batch_indices = shuffled_indices[start_item: start_item + self.batch_size]\n",
    "#             x_batch = x_file[batch_indices]\n",
    "#             y_batch = y_file[batch_indices]\n",
    "#             print 'Duration: {}'.format(str(time.time() - start_time))\n",
    "            # because we use MLP\n",
    "            if self.is_mlp:\n",
    "                x_batch = np.reshape(x_batch, (x_batch.shape[0], x_batch.shape[1] * x_batch.shape[2]))\n",
    "            start_item += self.batch_size\n",
    "            num_iter += 1\n",
    "            try:\n",
    "                #print 'adding new batch'\n",
    "                self.q.put((x_batch, y_batch), block=True)\n",
    "            except:\n",
    "                return\n",
    "\n",
    "            \n",
    "def batch_generator(input_file, label_file, batch_size, is_mlp=False, validate=False):\n",
    "    q = Queue(maxsize=QUEUE_SIZE)\n",
    "    p = ArrayReader(input_file, label_file, q, batch_size, is_mlp, validate)\n",
    "    p.start()\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if not item:\n",
    "            p.terminate()\n",
    "            raise StopIteration()\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Param Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum change in val_loss from previous epoch to register as a decrease\n",
    "early_stopper_deltas = {\n",
    "    'sections': 0.00001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "# how many epochs to wait when there is no decrease in val_loss before early stopping\n",
    "early_stopper_patience = {\n",
    "    'sections': 15,\n",
    "    'classes': 15,\n",
    "    'subclasses': 15\n",
    "}\n",
    "# number of epochs after which we do periodic evaluation of validation metrics\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 20,\n",
    "    'subclasses': 20\n",
    "}\n",
    "\n",
    "# ranges for learning graph shown\n",
    "metrics_graph_ranges = {\n",
    "    'sections': {'min':0, 'max': 0.3},\n",
    "    'classes': {'min':0, 'max': 0.05},\n",
    "    'subclasses': {'min':0, 'max': 0.05}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEVEL_DOC = 1\n",
    "LEVEL_DIVISIONS = 2\n",
    "LEVEL_CHUNKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_EPOCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_PARMS_TO_RUN = [\n",
    "    {\n",
    "        'doc2vec_epoch': DOC2VEC_EPOCH,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_CHUNKS,\n",
    "        'nn_batch_size': 1024,\n",
    "        'lstm_output_size': 1000,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 2,\n",
    "        'lstm_conv_size': None,\n",
    "        'lstm_conv_filter_length': None,\n",
    "        'lstm_max_pooling_length': None\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== NEW PARAM SET ============================================\n",
      "{'lstm_conv_filter_length': None, 'lstm_stack_layers': 2, 'nn_batch_size': 1024, 'classifications_type': 'sections', 'lstm_w_dropout': 0.5, 'lstm_max_pooling_length': None, 'lstm_u_dropout': 0.5, 'parts_level': 3, 'lstm_output_size': 1000, 'doc2vec_epoch': 8, 'lstm_conv_size': None}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 13:25:36,826 : INFO : No Previous results exist in /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_full_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_3_batch_1024_nn_parameter_searches.pkl\n",
      "2017-04-19 13:25:36,827 : INFO : ***************************************************************************************\n",
      "2017-04-19 13:25:36,829 : INFO : lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_2_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, None, 1000)    4804000     lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, 1000)          8004000     lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 8)             8008        lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "====================================================================================================\n",
      "Total params: 12,816,008\n",
      "Trainable params: 12,816,008\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 13:50:12,685 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 13:53:56,824 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 13:54:43,173 : INFO : Found lower val loss for epoch 1 => 0.15238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1709s - loss: 0.1881 - val_loss: 0.1524\n",
      "Epoch 2/200\n",
      "1183744/1286325 [==========================>...] - ETA: 129s - loss: 0.1517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 14:19:33,658 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 14:22:56,651 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 14:24:02,855 : INFO : Found lower val loss for epoch 2 => 0.13864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1759s - loss: 0.1517 - val_loss: 0.1386\n",
      "Epoch 3/200\n",
      "1183744/1286325 [==========================>...] - ETA: 128s - loss: 0.1427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 14:48:47,804 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 14:51:48,280 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 14:53:15,097 : INFO : Found lower val loss for epoch 3 => 0.13374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1752s - loss: 0.1429 - val_loss: 0.1337\n",
      "Epoch 4/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 15:17:27,298 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 15:20:02,192 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 15:21:55,407 : INFO : Found lower val loss for epoch 4 => 0.13143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1720s - loss: 0.1385 - val_loss: 0.1314\n",
      "Epoch 5/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 15:45:53,671 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 15:48:05,060 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 15:50:17,577 : INFO : Found lower val loss for epoch 5 => 0.13017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1702s - loss: 0.1359 - val_loss: 0.1302\n",
      "Epoch 6/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 16:14:14,281 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 16:16:19,534 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 16:18:23,154 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 16:18:39,927 : INFO : Found lower val loss for epoch 6 => 0.12833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1702s - loss: 0.1339 - val_loss: 0.1283\n",
      "Epoch 7/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 16:42:33,782 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 16:46:24,171 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 16:47:04,746 : INFO : Found lower val loss for epoch 7 => 0.12826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1704s - loss: 0.1325 - val_loss: 0.1283\n",
      "Epoch 8/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 17:11:01,599 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 17:14:26,355 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 17:15:27,238 : INFO : Found lower val loss for epoch 8 => 0.12662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1702s - loss: 0.1317 - val_loss: 0.1266\n",
      "Epoch 9/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1307"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 17:39:26,163 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 17:42:27,484 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1702s - loss: 0.1310 - val_loss: 0.1275\n",
      "Epoch 10/200\n",
      "1183744/1286325 [==========================>...] - ETA: 123s - loss: 0.1301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 18:07:34,550 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 18:10:12,444 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 18:11:53,296 : INFO : Found lower val loss for epoch 10 => 0.1264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1683s - loss: 0.1304 - val_loss: 0.1264\n",
      "Epoch 11/200\n",
      "1183744/1286325 [==========================>...] - ETA: 123s - loss: 0.1296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 18:35:38,735 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 18:37:54,794 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 18:39:59,274 : INFO : Found lower val loss for epoch 11 => 0.12623\n",
      "2017-04-19 18:39:59,276 : INFO : Validation Loss Reduced 10 times\n",
      "2017-04-19 18:39:59,277 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 18:41:45,701 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 18:42:32,962 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.372 | Top 3: 0.980 | Top 5: 0.997 | F1 Micro: 0.819 | F1 Macro: 0.774\n",
      "1286325/1286325 [==============================] - 1851s - loss: 0.1299 - val_loss: 0.1262\n",
      "Epoch 12/200\n",
      "1183744/1286325 [==========================>...] - ETA: 129s - loss: 0.1293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 19:07:37,940 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 19:09:46,665 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 19:11:59,858 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 19:12:10,862 : INFO : Found lower val loss for epoch 12 => 0.12585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 1765s - loss: 0.1296 - val_loss: 0.1258\n",
      "Epoch 13/200\n",
      "1183744/1286325 [==========================>...] - ETA: 126s - loss: 0.1290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 19:36:27,095 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 19:40:23,543 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1727s - loss: 0.1293 - val_loss: 0.1260\n",
      "Epoch 14/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 20:05:05,339 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 20:08:34,626 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1711s - loss: 0.1292 - val_loss: 0.1265\n",
      "Epoch 15/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 20:33:33,088 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 20:36:43,798 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1714s - loss: 0.1291 - val_loss: 0.1270\n",
      "Epoch 16/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 21:02:07,094 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 21:04:51,187 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1703s - loss: 0.1290 - val_loss: 0.1283\n",
      "Epoch 17/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 21:30:31,991 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 21:32:57,876 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1717s - loss: 0.1288 - val_loss: 0.1270\n",
      "Epoch 18/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 21:59:06,677 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 22:01:13,821 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-19 22:03:25,722 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1705s - loss: 0.1289 - val_loss: 0.1268\n",
      "Epoch 19/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 22:27:31,277 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 22:31:32,985 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1711s - loss: 0.1289 - val_loss: 0.1273\n",
      "Epoch 20/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 22:56:05,771 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 22:59:39,893 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1706s - loss: 0.1289 - val_loss: 0.1276\n",
      "Epoch 21/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 23:24:30,886 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 23:27:48,165 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1713s - loss: 0.1289 - val_loss: 0.1266\n",
      "Epoch 22/200\n",
      "1183744/1286325 [==========================>...] - ETA: 124s - loss: 0.1288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 23:53:02,594 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-19 23:55:53,285 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1703s - loss: 0.1291 - val_loss: 0.1267\n",
      "Epoch 23/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 00:21:30,480 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 00:24:02,495 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1716s - loss: 0.1291 - val_loss: 0.1281\n",
      "Epoch 24/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 00:50:04,973 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 00:52:12,251 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1706s - loss: 0.1291 - val_loss: 0.1261\n",
      "Epoch 25/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 01:18:38,460 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 01:20:43,330 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-20 01:22:45,261 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1717s - loss: 0.1290 - val_loss: 0.1261\n",
      "Epoch 26/200\n",
      "1183744/1286325 [==========================>...] - ETA: 125s - loss: 0.1286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 01:47:11,052 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 01:50:50,772 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1706s - loss: 0.1289 - val_loss: 0.1272\n",
      "Epoch 27/200\n",
      "1183744/1286325 [==========================>...] - ETA: 123s - loss: 0.1287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 02:15:20,704 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 02:18:34,036 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1686s - loss: 0.1290 - val_loss: 0.1267\n",
      "Epoch 28/200\n",
      "1183744/1286325 [==========================>...] - ETA: 120s - loss: 0.1290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 02:42:51,494 : INFO : in new epoch for X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 02:45:43,005 : INFO : in new epoch for Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 1646s - loss: 0.1293 - val_loss: 0.1275\n",
      "Epoch 00027: early stopping\n",
      "CPU times: user 5h 9min 59s, sys: 7h 49min 19s, total: 12h 59min 19s\n",
      "Wall time: 13h 21min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 02:47:05,527 : INFO : Evaluating on Validation Data using saved best weights\n",
      "2017-04-20 02:48:37,664 : INFO : in new epoch for Xv_level_3.npy\n",
      "2017-04-20 02:49:21,172 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.371 | Top 3: 0.980 | Top 5: 0.997 | F1 Micro: 0.819 | F1 Macro: 0.774\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "for GLOBAL_PARAMS in GLOBAL_PARMS_TO_RUN:\n",
    "    \n",
    "    print '==================================== NEW PARAM SET ============================================'\n",
    "    print {k:v for k,v in GLOBAL_PARAMS.items() if k != 'classifications'}\n",
    "    \n",
    "    classifications = GLOBAL_PARAMS['classifications']\n",
    "    classifications_type = GLOBAL_PARAMS['classifications_type']\n",
    "    classifier_file = TYPE_CLASSIFIER.format(classifications_type)\n",
    "    \n",
    "    PARTS_LEVEL = GLOBAL_PARAMS['parts_level']\n",
    "    \n",
    "    \n",
    "    placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "    placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "    epoch = GLOBAL_PARAMS['doc2vec_epoch']\n",
    "\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    print GLOBAL_VARS.MODEL_NAME\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    \n",
    "    X_file, y_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'training')\n",
    "    Xv_file, yv_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'validation')\n",
    "    X, y = get_data(X_file, y_file, mmap=True)\n",
    "    \n",
    "    \n",
    "#     info(\"Loading Validation Documents\")\n",
    "#     Xv, yv = get_validation_data(classifications_type, PARTS_LEVEL)\n",
    "#     print Xv.shape\n",
    "#     print yv.shape\n",
    "    \n",
    "    NN_INPUT_NEURONS = DOC2VEC_SIZE\n",
    "    NN_OUTPUT_NEURONS = len(classifications)\n",
    "    EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "    EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "\n",
    "    NN_MAX_EPOCHS = 200\n",
    "    NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "    NN_BATCH_SIZE = GLOBAL_PARAMS['nn_batch_size']\n",
    "\n",
    "    MODEL_VERBOSITY = 2\n",
    "\n",
    "    NN_OPTIMIZER = 'rmsprop'\n",
    "    # NN_OPTIMIZER = 'adam'\n",
    "\n",
    "    to_skip = []\n",
    "\n",
    "    load_existing_results = True\n",
    "    save_results = True\n",
    "\n",
    "\n",
    "    np.random.seed(NN_SEED)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    ############### Actual Training\n",
    "\n",
    "\n",
    "    # load previous finshed results so we dont redo them\n",
    "    param_results_dict = {}\n",
    "    \n",
    "    param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                   NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "        \n",
    "    if load_existing_results:\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results from {}'.format(param_results_path))\n",
    "            param_results_dict = pickle.load(open(param_results_path))\n",
    "        else:\n",
    "            info('No Previous results exist in {}'.format(param_results_path))\n",
    "\n",
    "    ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "    start_time = time.time()\n",
    "    lstm_output_size = GLOBAL_PARAMS['lstm_output_size']\n",
    "    w_dropout_do = GLOBAL_PARAMS['lstm_w_dropout']\n",
    "    u_dropout_do = GLOBAL_PARAMS['lstm_u_dropout']\n",
    "    stack_layers = GLOBAL_PARAMS['lstm_stack_layers']\n",
    "    conv_size = GLOBAL_PARAMS['lstm_conv_size']\n",
    "    conv_filter_length = GLOBAL_PARAMS['lstm_conv_filter_length']\n",
    "    conv_max_pooling_length = GLOBAL_PARAMS['lstm_max_pooling_length']\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "        lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    "    )\n",
    "    if conv_size:\n",
    "        GLOBAL_VARS.NN_MODEL_NAME += '_conv-filter-length_{}_max-pooling-size_{}'.format(conv_filter_length, \n",
    "                                                                                         conv_max_pooling_length)\n",
    "\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "\n",
    "    info('***************************************************************************************')\n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "    # creating the actual keras model\n",
    "    model = create_keras_rnn_model(NN_INPUT_NEURONS, NN_OUTPUT_NEURONS, \n",
    "                                  lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size, \n",
    "                                   conv_filter_length, conv_max_pooling_length)\n",
    "    model.summary()\n",
    "\n",
    "    # callbacks for early stopping and for generating validation metrics\n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit_generator(generator=batch_generator(X_file, y_file, NN_BATCH_SIZE, is_mlp=False, validate=False),\\\n",
    "                                        validation_data=batch_generator(Xv_file, yv_file, NN_BATCH_SIZE, is_mlp=False, validate=True),\\\n",
    "                                        samples_per_epoch=len(training_docs_list), \\\n",
    "                                        nb_val_samples=len(validation_docs_list),\\\n",
    "                                        nb_epoch=NN_MAX_EPOCHS,\\\n",
    "                                        callbacks=[early_stopper, metrics_callback],\\\n",
    "                                        max_q_size=QUEUE_SIZE)\n",
    "                                        #validation_data=(Xv,yv), \n",
    "                                        \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Validation Data using saved best weights')\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    yvp = model.predict_generator(generator=batch_generator(Xv_file, yv_file, NN_BATCH_SIZE, is_mlp=False, validate=True),\\\n",
    "                                       max_q_size=QUEUE_SIZE,\\\n",
    "                                       val_samples=len(validation_docs_list))\n",
    "    yvp_binary = get_binary_0_5(yvp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    Xv, yv = get_data(Xv_file, yv_file, mmap=True)\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    best_validation_metrics = validation_metrics\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "#     del history, metrics_callback, model\n",
    "\n",
    "    for p in multiprocessing.active_children():\n",
    "        # closing the array readers\n",
    "        p.terminate()\n",
    "\n",
    "    if save_results:\n",
    "        if load_existing_results:\n",
    "            if os.path.exists(param_results_path):\n",
    "                info('Loading Previous results from {}'.format(param_results_path))\n",
    "                loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "                param_results_dict.update(loaded_param_results_dict)\n",
    "\n",
    "        pickle.dump(param_results_dict, open(param_results_path, 'w'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 2.389 | Top 3: 0.890 | Top 5: 0.940 | F1 Micro: 0.720 | F1 Macro: 0.252\n"
     ]
    }
   ],
   "source": [
    "print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0075913524570534914"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict['lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None']['best_val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01050170663879005,\n",
       " 0.0090657171222329001,\n",
       " 0.0085820102446928677,\n",
       " 0.0082740513082422088,\n",
       " 0.0080953338588571275,\n",
       " 0.0079837451293953143,\n",
       " 0.0078970913544663124,\n",
       " 0.0078293905090200018,\n",
       " 0.0077628953955866603,\n",
       " 0.0077554889650937753,\n",
       " 0.0077339486957828732,\n",
       " 0.0077151205925956061,\n",
       " 0.0076659656284575372,\n",
       " 0.0076745006155642973,\n",
       " 0.0076361523829040611,\n",
       " 0.0076549050046683751,\n",
       " 0.007637245562640115,\n",
       " 0.0076154745703354695,\n",
       " 0.0076402593944194675,\n",
       " 0.0076242940957613834,\n",
       " 0.007618327702497713,\n",
       " 0.0076008553594760315,\n",
       " 0.0075944709904860038,\n",
       " 0.007598528838515986,\n",
       " 0.0076041536409553016,\n",
       " 0.0076030635436532415,\n",
       " 0.0075974386982811289,\n",
       " 0.0075913524570534914,\n",
       " 0.0076024745074609271,\n",
       " 0.0076338187615686689,\n",
       " 0.0076066432222525104,\n",
       " 0.0076335796718102764,\n",
       " 0.0076218562947903854,\n",
       " 0.0076157897005890559,\n",
       " 0.0076104816512236337,\n",
       " 0.0076137729182959961,\n",
       " 0.007612090691736911,\n",
       " 0.0075982357561560476]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict['lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None']['validation_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(param_results_dict, open(param_results_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_full_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_classes_level_3_batch_2048_nn_parameter_searches.pkl'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None': {'best_validation_metrics': {'average_num_of_labels': 1.24,\n",
       "   'coverage_error': 2.3885676246527701,\n",
       "   'f1_macro': 0.25157364167930385,\n",
       "   'f1_micro': 0.72034728352217081,\n",
       "   'precision_macro': 0.30967626980474916,\n",
       "   'precision_micro': 0.77468854846680013,\n",
       "   'recall_macro': 0.22351976593346423,\n",
       "   'recall_micro': 0.67312994350282485,\n",
       "   'top_1': 0.7531098556183302,\n",
       "   'top_3': 0.889639673571877,\n",
       "   'top_5': 0.9399949780288763,\n",
       "   'total_positive': 346041}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = sections\n",
    "classifications_type = 'sections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_METRICS_FILENAME = '{}_level_{}_lstm_test_metrics_dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = DOC2VEC_EPOCH\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "print GLOBAL_VARS.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARTS_LEVEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "param_results_dict = pickle.load(open(param_results_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_full_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_3_batch_1024_nn_parameter_searches.pkl'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt_file, yt_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'test')\n",
    "Xt, yt = get_data(Xt_file, yt_file, mmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "NN_INPUT_NEURONS = Xt.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_2_conv_None']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 18:44:40,017 : INFO : ***************************************************************************************\n",
      "2017-04-21 18:44:40,018 : INFO : lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_2_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, None, 1000)    4804000     lstm_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, 1000)          8004000     lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 8)             8008        lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 18:44:42,151 : INFO : Evaluating on Test Data using best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 12,816,008\n",
      "Trainable params: 12,816,008\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 18:46:35,684 : INFO : in new epoch for Xt_level_3.npy\n",
      "2017-04-21 18:47:09,141 : INFO : Generating Test Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test Metrics: Cov Err: 1.370, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.858, Top 3: 0.980, Top 5: 0.997, \n",
      "\t\t F1 Micro: 0.820, F1 Macro: 0.777, Total Pos: 442,382\n"
     ]
    }
   ],
   "source": [
    "lstm_output_size = 1000\n",
    "w_dropout_do = 0.5\n",
    "u_dropout_do = 0.5\n",
    "stack_layers = 2\n",
    "conv_size = None\n",
    "conv_filter_length = None\n",
    "conv_max_pooling_length = None\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "    lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    ")\n",
    "if conv_size:\n",
    "    GLOBAL_VARS.NN_MODEL_NAME += '_conv-filter-length_{}_max-pooling-size_{}'.format(conv_filter_length, \n",
    "                                                                                     conv_max_pooling_length)\n",
    "                                                                                     \n",
    "if GLOBAL_VARS.NN_MODEL_NAME not in param_results_dict.keys():\n",
    "    print \"Can't find model: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    raise Exception()\n",
    "\n",
    "\n",
    "test_metrics_dict = {}\n",
    "test_metrics_path = os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                            TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL))\n",
    "if os.path.exists(test_metrics_path):\n",
    "    test_metrics_dict =  pickle.load(open(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                            TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL))))\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in test_metrics_dict.keys():\n",
    "        print \"Test metrics already exist for: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        test_metrics = test_metrics_dict[GLOBAL_VARS.NN_MODEL_NAME]\n",
    "        print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "            test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "            test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "            test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "        raise Exception()\n",
    "        \n",
    "info('***************************************************************************************')\n",
    "info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "# creating the actual keras model\n",
    "model = create_keras_rnn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                              lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size, \n",
    "                               conv_filter_length, conv_max_pooling_length)\n",
    "model.summary()\n",
    "\n",
    "# get model best weights\n",
    "# weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'].best_weights\n",
    "weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights']\n",
    "model.set_weights(weights)\n",
    "\n",
    "info('Evaluating on Test Data using best weights')\n",
    "ytp = model.predict_generator(generator=batch_generator(Xt_file, yt_file, NN_BATCH_SIZE, is_mlp=False, validate=True),\\\n",
    "                                       max_q_size=QUEUE_SIZE,\\\n",
    "                                       val_samples=len(test_docs_list))\n",
    "ytp_binary = get_binary_0_5(ytp)\n",
    "#print yvp\n",
    "info('Generating Test Metrics')\n",
    "test_metrics = get_metrics(yt, ytp, ytp_binary)\n",
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "\n",
    "ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "\n",
    "test_metrics_dict[GLOBAL_VARS.NN_MODEL_NAME] = test_metrics\n",
    "pickle.dump(test_metrics_dict, open(test_metrics_path, 'w'))\n",
    "\n",
    "# pickle.dump(test_metrics, open(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                             TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL)), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = 8\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications_type = 'sections'\n",
    "level = 3\n",
    "batch_size = 2048\n",
    "is_mlp, validate = False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = Queue(maxsize=10)\n",
    "p = ArrayReader(classifications_type, level, q, batch_size, is_mlp, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-14 23:56:48,393 : INFO : Loading Training Data from file using mmap\n",
      "2017-04-14 23:56:48,398 : INFO : Finished Loading Training Data from file using mmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 159 Âµs\n",
      "CPU times: user 12 ms, sys: 24 ms, total: 36 ms\n",
      "Wall time: 38.1 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 205 Âµs\n",
      "CPU times: user 28 ms, sys: 8 ms, total: 36 ms\n",
      "Wall time: 37.2 ms\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 115 Âµs\n",
      "CPU times: user 12 ms, sys: 24 ms, total: 36 ms\n",
      "Wall time: 36.9 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 345 Âµs\n",
      "CPU times: user 16 ms, sys: 16 ms, total: 32 ms\n",
      "Wall time: 33.4 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 422 Âµs\n",
      "CPU times: user 12 ms, sys: 20 ms, total: 32 ms\n",
      "Wall time: 29.4 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 121 Âµs\n",
      "CPU times: user 4 ms, sys: 24 ms, total: 28 ms\n",
      "Wall time: 26.6 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 159 Âµs\n",
      "CPU times: user 16 ms, sys: 8 ms, total: 24 ms\n",
      "Wall time: 25.4 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 67 Âµs\n",
      "CPU times: user 12 ms, sys: 12 ms, total: 24 ms\n",
      "Wall time: 24.3 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 62.9 Âµs\n",
      "CPU times: user 4 ms, sys: 20 ms, total: 24 ms\n",
      "Wall time: 22.7 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 136 Âµs\n",
      "CPU times: user 0 ns, sys: 24 ms, total: 24 ms\n",
      "Wall time: 23.1 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 152 Âµs\n",
      "CPU times: user 4 ms, sys: 20 ms, total: 24 ms\n",
      "Wall time: 23.6 ms\n"
     ]
    }
   ],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate Child Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in multiprocessing.active_children():\n",
    "    # closing the array readers\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
