{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SVM on Extended PV Doc2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "from thesis.utils.metrics import *\n",
    "from thesis.utils.file import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "TYPE_CLASSIFIER= \"{}_classifier.pkl\"\n",
    "\n",
    "TRAINING_DATA_MATRIX = \"X_level_{}.npy\"\n",
    "TRAINING_LABELS_MATRIX = \"y_{}.npy\"\n",
    "VALIDATION_DATA_MATRIX = \"Xv_level_{}.npy\"\n",
    "VALIDATION_LABELS_MATRIX = \"yv_{}.npy\"\n",
    "TEST_DATA_MATRIX = \"Xt_level_{}.npy\"\n",
    "TEST_LABELS_MATRIX = \"yt_{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "root_location = \"/home/local/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "matrices_save_location = root_location + \"extended_pv_matrices/\"\n",
    "doc2vec_results_location = root_location + \"extended_pv_doc2vec_svm/\"\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.8 s, sys: 1.89 s, total: 29.7 s\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Utility functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(classifications_type, level):\n",
    "    info(\"Loading Training Data from file\")\n",
    "    training_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                              TRAINING_DATA_MATRIX.format(level))))\n",
    "    training_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                TRAINING_LABELS_MATRIX.format(classifications_type))))\n",
    "    return training_data, training_labels\n",
    "\n",
    "def get_validation_data(classifications_type, level):\n",
    "    info(\"Loading Validation Data from file\")\n",
    "    validation_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                VALIDATION_DATA_MATRIX.format(level))))\n",
    "    validation_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  VALIDATION_LABELS_MATRIX.format(classifications_type))))\n",
    "    return validation_data, validation_labels\n",
    "\n",
    "def get_test_data(classifications_type, level):\n",
    "    info(\"Loading Test Data from file\")\n",
    "    test_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                TEST_DATA_MATRIX.format(level))))\n",
    "    test_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  TEST_LABELS_MATRIX.format(classifications_type))))\n",
    "    return test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Global Param Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LEVEL_DOC = 1\n",
    "LEVEL_DIVISIONS = 2\n",
    "LEVEL_CHUNKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_EPOCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_PARMS_TO_RUN = [\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_DOC,\n",
    "        'svm_iterations': 10,\n",
    "        'svm_reg': 0.01,\n",
    "        'svm_class_weights': None\n",
    "    },\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': valid_classes,\n",
    "        'classifications_type': 'classes',\n",
    "        'parts_level': LEVEL_DOC,\n",
    "        'svm_iterations': 10,\n",
    "        'svm_reg': 0.01,\n",
    "        'svm_class_weights': None\n",
    "    },\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': valid_subclasses,\n",
    "        'classifications_type': 'subclasses',\n",
    "        'parts_level': LEVEL_DOC,\n",
    "        'svm_iterations': 10,\n",
    "        'svm_reg': 0.01,\n",
    "        'svm_class_weights': None\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Actual Training, validation and Metrics Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== NEW PARAM SET ============================================\n",
      "{'classifications_type': 'sections', 'parts_level': 1, 'svm_reg': 0.01, 'svm_iterations': 10, 'svm_class_weights': None, 'doc2vec_epoch': 8}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n",
      "svm_iter_10_reg_0.01_classweights_None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-12 19:53:30,158 : INFO : Loading Training Documents\n",
      "2017-04-12 19:53:30,161 : INFO : Loading Validation Data from file\n",
      "2017-04-12 19:53:30,615 : INFO : Loading Validation Documents\n",
      "2017-04-12 19:53:30,616 : INFO : Loading Validation Data from file\n",
      "2017-04-12 19:53:30,727 : INFO : Reshaping\n",
      "2017-04-12 19:53:30,729 : INFO : Training Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1286325, 1, 200)\n",
      "(1286325, 8)\n",
      "(321473, 1, 200)\n",
      "(321473, 8)\n",
      "(1286325, 200)\n",
      "(321473, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-12 19:54:57,215 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 4.06 s, total: 1min 26s\n",
      "Wall time: 1min 26s\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 1.747, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.712, Top 3: 0.924, Top 5: 0.976, \n",
      "\t\t F1 Micro: 0.655, F1 Macro: 0.519, Total Pos: 291,204\n",
      "==================================== NEW PARAM SET ============================================\n",
      "{'classifications_type': 'classes', 'parts_level': 1, 'svm_reg': 0.01, 'svm_iterations': 10, 'svm_class_weights': None, 'doc2vec_epoch': 8}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n",
      "svm_iter_10_reg_0.01_classweights_None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-12 19:55:24,381 : INFO : Loading Training Documents\n",
      "2017-04-12 19:55:24,382 : INFO : Loading Validation Data from file\n",
      "2017-04-12 19:55:24,962 : INFO : Loading Validation Documents\n",
      "2017-04-12 19:55:24,963 : INFO : Loading Validation Data from file\n",
      "2017-04-12 19:55:25,105 : INFO : Reshaping\n",
      "2017-04-12 19:55:25,106 : INFO : Training Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1286325, 1, 200)\n",
      "(1286325, 244)\n",
      "(321473, 1, 200)\n",
      "(321473, 244)\n",
      "(1286325, 200)\n",
      "(321473, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-12 20:33:47,522 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 24s, sys: 1min 59s, total: 38min 24s\n",
      "Wall time: 38min 22s\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 5.941, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.435, Top 3: 0.700, Top 5: 0.820, \n",
      "\t\t F1 Micro: 0.513, F1 Macro: 0.059, Total Pos: 203,040\n",
      "==================================== NEW PARAM SET ============================================\n",
      "{'classifications_type': 'subclasses', 'parts_level': 1, 'svm_reg': 0.01, 'svm_iterations': 10, 'svm_class_weights': None, 'doc2vec_epoch': 8}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n",
      "svm_iter_10_reg_0.01_classweights_None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-12 20:37:39,126 : INFO : Loading Training Documents\n",
      "2017-04-12 20:37:39,128 : INFO : Loading Validation Data from file\n",
      "2017-04-12 20:37:40,052 : INFO : Loading Validation Documents\n",
      "2017-04-12 20:37:40,053 : INFO : Loading Validation Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1286325, 1, 200)\n",
      "(1286325, 940)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-12 20:37:40,280 : INFO : Reshaping\n",
      "2017-04-12 20:37:40,282 : INFO : Training Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(321473, 1, 200)\n",
      "(321473, 940)\n",
      "(1286325, 200)\n",
      "(321473, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for GLOBAL_PARAMS in GLOBAL_PARMS_TO_RUN:\n",
    "    \n",
    "    print '==================================== NEW PARAM SET ============================================'\n",
    "    print {k:v for k,v in GLOBAL_PARAMS.items() if k != 'classifications'}\n",
    "    \n",
    "    classifications = GLOBAL_PARAMS['classifications']\n",
    "    classifications_type = GLOBAL_PARAMS['classifications_type']\n",
    "    PARTS_LEVEL = GLOBAL_PARAMS['parts_level']\n",
    "    \n",
    "    classifier_file = TYPE_CLASSIFIER.format(classifications_type)\n",
    "    \n",
    "    SVM_ITERATIONS = GLOBAL_PARAMS['svm_iterations']\n",
    "    SVM_REG = GLOBAL_PARAMS['svm_reg']\n",
    "    SVM_CLASS_WEIGHTS = GLOBAL_PARAMS['svm_class_weights']\n",
    "    GLOBAL_VARS.SVM_MODEL_NAME = 'svm_iter_{}_reg_{}_classweights_{}'.format(SVM_ITERATIONS, SVM_REG, str(SVM_CLASS_WEIGHTS))\n",
    "    \n",
    "    placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "    placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "    epoch = GLOBAL_PARAMS['doc2vec_epoch']\n",
    "\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    print GLOBAL_VARS.MODEL_NAME\n",
    "    print GLOBAL_VARS.SVM_MODEL_NAME\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    info(\"Loading Training Documents\")\n",
    "    X, y = get_training_data(classifications_type, PARTS_LEVEL)\n",
    "    print X.shape\n",
    "    print y.shape\n",
    "    \n",
    "    info(\"Loading Validation Documents\")\n",
    "    Xv, yv = get_validation_data(classifications_type, PARTS_LEVEL)\n",
    "    print Xv.shape\n",
    "    print yv.shape\n",
    "    \n",
    "    info(\"Reshaping\")\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1]* X.shape[2]))\n",
    "    Xv = np.reshape(Xv, (Xv.shape[0], Xv.shape[1]* Xv.shape[2]))\n",
    "    print X.shape\n",
    "    print Xv.shape\n",
    "    \n",
    "    \n",
    "    VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'.format(classifications_type)\n",
    "    TRAINING_METRICS_FILENAME = '{}_training_metrics.pkl'.format(classifications_type)\n",
    "\n",
    "    \n",
    "    ensure_disk_location_exists(os.path.join(doc2vec_results_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "\n",
    "    if not os.path.exists(os.path.join(doc2vec_results_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, classifier_file)):\n",
    "\n",
    "        info('Training Classifier')\n",
    "        clf = OneVsRestClassifier(linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                             #alpha is the 1/C parameter\n",
    "                                                             alpha=SVM_REG, fit_intercept=True, n_iter=SVM_ITERATIONS,\n",
    "                                                             #n_jobs=-1 means use all cpus\n",
    "                                                             shuffle=True, verbose=0, n_jobs=1,\n",
    "                                                             #eta0 is the learning rate when we use constant configuration\n",
    "                                                             random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                             class_weight=SVM_CLASS_WEIGHTS, warm_start=False), n_jobs=1)\n",
    "\n",
    "        # Training of a classifier\n",
    "        %time clf.fit(X,y)\n",
    "        pickle.dump(clf, open(os.path.join(doc2vec_results_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                              GLOBAL_VARS.SVM_MODEL_NAME, classifier_file), 'w'))\n",
    "\n",
    "        del X, y\n",
    "\n",
    "    else:\n",
    "        info('Loading Classifier')\n",
    "        clf = pickle.load(open(os.path.join(doc2vec_results_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, classifier_file), 'r'))\n",
    "\n",
    "    info('Evaluating on Validation Data')\n",
    "    yvp = clf.predict(Xv)\n",
    "    yvp_score = clf.decision_function(Xv)\n",
    "    print yvp\n",
    "    validation_metrics = get_metrics(yv, yvp_score, yvp)\n",
    "    print \"** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "        validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "\n",
    "    # Saving the metrics\n",
    "    #     pickle.dump(training_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "    #                                                           GLOBAL_VARS.SVM_MODEL_NAME, TRAINING_METRICS_FILENAME), 'w'))\n",
    "    pickle.dump(validation_metrics, open(os.path.join(doc2vec_results_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, VALIDATION_METRICS_FILENAME), 'w'))\n",
    "\n",
    "    del Xv, yv, yvp, yvp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = valid_subclasses\n",
    "classifications_type = \"subclasses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_METRICS_FILENAME = '{}_level_{}_test_metrics.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARTS_LEVEL = LEVEL_DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_file = TYPE_CLASSIFIER.format(classifications_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = DOC2VEC_EPOCH\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_ITERATIONS = 10\n",
    "SVM_REG = 0.001\n",
    "SVM_CLASS_WEIGHTS = None\n",
    "GLOBAL_VARS.SVM_MODEL_NAME = 'svm_iter_{}_reg_{}_classweights_{}'.format(SVM_ITERATIONS, SVM_REG, str(SVM_CLASS_WEIGHTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = pickle.load(open(os.path.join(doc2vec_results_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, classifier_file), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt, yt = get_test_data(classifications_type, PARTS_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info(\"Reshaping\")\n",
    "Xt = np.reshape(Xt, (Xt.shape[0], Xt.shape[1]* Xt.shape[2]))\n",
    "print Xt.shape\n",
    "print yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test Metrics\n",
    "info('Evaluating on Test Data')\n",
    "%time ytp = clf.predict(Xt)\n",
    "%time ytp_score = clf.decision_function(Xt)\n",
    "print ytp\n",
    "%time test_metrics = get_metrics(yt, ytp_score, ytp)\n",
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "\n",
    "pickle.dump(test_metrics, open(os.path.join(doc2vec_results_location, GLOBAL_VARS.MODEL_NAME, TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL)), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
