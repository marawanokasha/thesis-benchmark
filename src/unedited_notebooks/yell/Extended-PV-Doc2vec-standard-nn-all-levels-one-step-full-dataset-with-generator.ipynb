{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of fixed size paragraph vectors using MLP\n",
    "should be able to deal with all levels using the PARTS_LEVEL param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: Tesla K40m (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple, defaultdict\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import multiprocessing\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "import seaborn\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Masking\n",
    "from keras.layers.convolutional import MaxPooling1D, Convolution1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from thesis.utils.metrics import *\n",
    "from thesis.utils.file import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables used throughout the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234\n",
    "NN_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUEUE_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "VALIDATION_DICT = \"validation_dict.pkl\"\n",
    "TEST_MATRIX = \"test_matrix.pkl\"\n",
    "TEST_DICT = \"test_dict.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\"\n",
    "TYPE_CLASSIFIER= \"{}_classifier.pkl\"\n",
    "\n",
    "TRAINING_DATA_MATRIX = \"X_level_{}.npy\"\n",
    "TRAINING_LABELS_MATRIX = \"y_{}.npy\"\n",
    "VALIDATION_DATA_MATRIX = \"Xv_level_{}.npy\"\n",
    "VALIDATION_LABELS_MATRIX = \"yv_{}.npy\"\n",
    "TEST_DATA_MATRIX = \"Xt_level_{}.npy\"\n",
    "TEST_LABELS_MATRIX = \"yt_{}.npy\"\n",
    "\n",
    "TRAINING_DATA_MATRIX_PART = \"X_level_{}-{}.npy\"\n",
    "TRAINING_LABELS_MATRIX_PART = \"y_{}-{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"standard_nn_{}_level_{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "big_data_location = \"/mnt/data/shalaby/\"\n",
    "\n",
    "matrices_save_location = big_data_location + \"extended_pv_matrices/\"\n",
    "# matrices_save_location = big_data_location + \"extended_pv_matrices/one_model/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_parameter_search_extended_abs_desc_claims_full_chunks\")\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load general data required for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.11 s, sys: 112 ms, total: 2.22 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sections = pickle.load(open(sections_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401877"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type_file_dict ={\n",
    "    \"training\": TRAINING_DATA_MATRIX,\n",
    "    \"validation\": VALIDATION_DATA_MATRIX,\n",
    "    \"test\": TEST_DATA_MATRIX,\n",
    "}\n",
    "labels_type_file_dict ={\n",
    "    \"training\": TRAINING_LABELS_MATRIX,\n",
    "    \"validation\": VALIDATION_LABELS_MATRIX,\n",
    "    \"test\": TEST_LABELS_MATRIX,\n",
    "}\n",
    "\n",
    "def get_data_dirs(classifications_type, level, data_type):\n",
    "    data_dir = os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                data_type_file_dict[data_type].format(level))\n",
    "    labels_dir = os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                labels_type_file_dict[data_type].format(classifications_type))\n",
    "    return data_dir, labels_dir\n",
    "\n",
    "def get_data(data_file, labels_file, mmap=False):\n",
    "    mmap_mode = None\n",
    "    if mmap == True:\n",
    "        mmap_mode = \"r\"\n",
    "    X_data = np.load(data_file, mmap_mode=mmap_mode)\n",
    "    y_data = np.load(labels_file, mmap_mode=mmap_mode)\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the \n",
    "    validation metrics\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        MetricsCallback.EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "        MetricsCallback.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
    "        MetricsCallback.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
    "        self.ax = plt.subplot(111)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
    "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
    "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
    "        self.ax.set_ylim((MetricsCallback.GRAPH_MIN, MetricsCallback.GRAPH_MAX))\n",
    "        self.fig.canvas.draw()\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            #time.sleep(0.1)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                Xv_file, yv_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'validation')\n",
    "                Xv, yv = get_data(Xv_file, yv_file, mmap=True)\n",
    "                yvp = self.model.predict_generator(generator=batch_generator(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE, is_mlp=True, validate=True),\\\n",
    "                                                   max_q_size=QUEUE_SIZE,\\\n",
    "                                                   val_samples=len(validation_docs_list))\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_keras_nn_model(input_size, output_size, \n",
    "                          first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                          second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                          input_dropout_do, hidden_dropout_do, second_hidden_dropout_do=False):\n",
    "    \n",
    "    doc_input = Input(shape=(input_size,), name='doc_input')\n",
    "    if input_dropout_do:\n",
    "        hidden = Dropout(0.7)(doc_input)\n",
    "    hidden = Dense(first_hidden_layer_size, activation=first_hidden_layer_activation, \n",
    "                   name='hidden_layer_{}'.format(first_hidden_layer_activation))(doc_input if not input_dropout_do else hidden)\n",
    "    if hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    if second_hidden_layer_size is not None:\n",
    "        hidden = Dense(second_hidden_layer_size, activation=second_hidden_layer_activation, \n",
    "                       name='hidden_layer2_{}'.format(second_hidden_layer_activation))(hidden)\n",
    "    if second_hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    softmax_output = Dense(output_size, activation='sigmoid', name='softmax_output')(hidden)\n",
    "\n",
    "    model = Model(input=doc_input, output=softmax_output)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ArrayReader(Process):\n",
    "    def __init__(self, input_file, label_file, out_queue, batch_size, is_mlp=False, validate=False):\n",
    "        super(ArrayReader, self).__init__()\n",
    "        self.is_mlp = is_mlp\n",
    "        self.validate = validate\n",
    "        self.q = out_queue\n",
    "        self.batch_size = batch_size\n",
    "        self.input_file = input_file\n",
    "        self.label_file = label_file\n",
    "\n",
    "    def run(self):\n",
    "        x_file = np.load(self.input_file, mmap_mode='r')\n",
    "        y_file = np.load(self.label_file, mmap_mode='r')\n",
    "        start_item = 0\n",
    "        num_iter = 0\n",
    "#         shuffled_indices = np.arange(y_file.shape[0])\n",
    "#         np.random.shuffle(shuffled_indices)\n",
    "        while True:\n",
    "            if start_item > y_file.shape[0]:\n",
    "                info('in new epoch for {}'.format(os.path.basename(self.input_file)))\n",
    "#                 np.random.seed(42 + num_iter)\n",
    "#                 np.random.shuffle(shuffled_indices)\n",
    "                start_item = 0\n",
    "#             start_time = time.time()\n",
    "            x_file[0:200000]\n",
    "#             y_batch = np.copy(y_file[start_item: start_item + self.batch_size])\n",
    "#             x_batch = np.copy(x_file[start_item: start_item + self.batch_size])\n",
    "            y_batch = y_file[start_item: start_item + self.batch_size]\n",
    "            x_batch = x_file[start_item: start_item + self.batch_size]\n",
    "#             batch_indices = shuffled_indices[start_item: start_item + self.batch_size]\n",
    "#             x_batch = x_file[batch_indices]\n",
    "#             y_batch = y_file[batch_indices]\n",
    "#             print 'Duration: {}'.format(str(time.time() - start_time))\n",
    "            # because we use MLP\n",
    "            if self.is_mlp:\n",
    "                x_batch = np.reshape(x_batch, (x_batch.shape[0], x_batch.shape[1] * x_batch.shape[2]))\n",
    "            start_item += self.batch_size\n",
    "            num_iter += 1\n",
    "            try:\n",
    "                #print 'adding new batch'\n",
    "                self.q.put((x_batch, y_batch), block=True)\n",
    "            except:\n",
    "                return\n",
    "\n",
    "            \n",
    "def batch_generator(input_file, label_file, batch_size, is_mlp=False, validate=False):\n",
    "    q = Queue(maxsize=QUEUE_SIZE)\n",
    "    p = ArrayReader(input_file, label_file, q, batch_size, is_mlp, validate)\n",
    "    p.start()\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if not item:\n",
    "            p.terminate()\n",
    "            info('Finished batch iteration')\n",
    "            raise StopIteration()\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Param Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum change in val_loss from previous epoch to register as a decrease\n",
    "early_stopper_deltas = {\n",
    "    'sections': 0.00001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "# how many epochs to wait when there is no decrease in val_loss before early stopping\n",
    "early_stopper_patience = {\n",
    "    'sections': 15,\n",
    "    'classes': 15,\n",
    "    'subclasses': 15\n",
    "}\n",
    "# number of epochs after which we do periodic evaluation of validation metrics\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 20,\n",
    "    'subclasses': 20\n",
    "}\n",
    "\n",
    "# ranges for learning graph shown\n",
    "metrics_graph_ranges = {\n",
    "    'sections': {'min':0, 'max': 0.3},\n",
    "    'classes': {'min':0, 'max': 0.05},\n",
    "    'subclasses': {'min':0, 'max': 0.05}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEVEL_DOC = 1\n",
    "LEVEL_DIVISIONS = 2\n",
    "LEVEL_CHUNKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_EPOCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_PARMS_TO_RUN = [\n",
    "#     {\n",
    "#         'doc2vec_epoch': DOC2VEC_EPOCH,\n",
    "#         'classifications': valid_classes,\n",
    "#         'classifications_type': 'classes',\n",
    "#         'parts_level': LEVEL_CHUNKS,\n",
    "#         'nn_batch_size': 4096,\n",
    "#     },\n",
    "    {\n",
    "        'doc2vec_epoch': DOC2VEC_EPOCH,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_CHUNKS,\n",
    "        'nn_batch_size': 4096,\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== NEW PARAM SET ============================================\n",
      "{'classifications_type': 'sections', 'parts_level': 3, 'doc2vec_epoch': 8, 'nn_batch_size': 4096}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 18:55:20,608 : INFO : No Previous results exist in /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_full_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/standard_nn_sections_level_3_batch_4096_nn_parameter_searches.pkl\n",
      "2017-04-15 18:55:20,610 : INFO : ***************************************************************************************\n",
      "2017-04-15 18:55:20,611 : INFO : nn_1st-size_1000_1st-act_sigmoid_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 6800)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1000)          6801000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_relu (Dense)       (None, 500)           500500      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_relu[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 7,305,508\n",
      "Trainable params: 7,305,508\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 876544/1286325 [===================>..........] - ETA: 23s - loss: 0.2019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 18:56:12,674 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 18:56:36,293 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 18:57:11,648 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 18:57:34,004 : INFO : Found lower val loss for epoch 1 => 0.14898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 131s - loss: 0.1881 - val_loss: 0.1490\n",
      "Epoch 2/200\n",
      " 753664/1286325 [================>.............] - ETA: 28s - loss: 0.1451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 18:58:14,375 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 18:59:15,939 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 18:59:45,257 : INFO : Found lower val loss for epoch 2 => 0.13484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 131s - loss: 0.1428 - val_loss: 0.1348\n",
      "Epoch 3/200\n",
      " 876544/1286325 [===================>..........] - ETA: 17s - loss: 0.1310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:00:22,651 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:01:17,442 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 19:01:44,847 : INFO : Found lower val loss for epoch 3 => 0.13064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 119s - loss: 0.1317 - val_loss: 0.1306\n",
      "Epoch 4/200\n",
      " 823296/1286325 [==================>...........] - ETA: 21s - loss: 0.1228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:02:22,339 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:03:16,389 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 19:03:44,131 : INFO : Found lower val loss for epoch 4 => 0.12645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 119s - loss: 0.1242 - val_loss: 0.1265\n",
      "Epoch 5/200\n",
      " 823296/1286325 [==================>...........] - ETA: 21s - loss: 0.1159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:04:22,276 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:05:23,421 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 19:05:50,624 : INFO : Found lower val loss for epoch 5 => 0.12588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 126s - loss: 0.1181 - val_loss: 0.1259\n",
      "Epoch 6/200\n",
      " 876544/1286325 [===================>..........] - ETA: 30s - loss: 0.1092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:06:55,152 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:08:03,685 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 163s - loss: 0.1126 - val_loss: 0.1268\n",
      "Epoch 7/200\n",
      " 880640/1286325 [===================>..........] - ETA: 20s - loss: 0.1036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:09:18,799 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:11:09,900 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 200s - loss: 0.1078 - val_loss: 0.1281\n",
      "Epoch 8/200\n",
      " 876544/1286325 [===================>..........] - ETA: 20s - loss: 0.0985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:12:38,892 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.1034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:14:08,743 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 168s - loss: 0.1034 - val_loss: 0.1289\n",
      "Epoch 9/200\n",
      " 876544/1286325 [===================>..........] - ETA: 22s - loss: 0.0936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:15:31,261 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:17:07,155 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 178s - loss: 0.0992 - val_loss: 0.1313\n",
      "Epoch 10/200\n",
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:18:27,865 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:19:19,960 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 132s - loss: 0.0954 - val_loss: 0.1324\n",
      "Epoch 11/200\n",
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:20:40,859 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:21:43,273 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 144s - loss: 0.0917 - val_loss: 0.1347\n",
      "Epoch 12/200\n",
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:23:04,302 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:24:06,627 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 144s - loss: 0.0886 - val_loss: 0.1356\n",
      "Epoch 13/200\n",
      " 876544/1286325 [===================>..........] - ETA: 22s - loss: 0.0779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:25:31,176 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:26:31,407 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 146s - loss: 0.0854 - val_loss: 0.1388\n",
      "Epoch 14/200\n",
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:27:55,143 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:28:51,664 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 142s - loss: 0.0827 - val_loss: 0.1418\n",
      "Epoch 15/200\n",
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:30:18,194 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:31:20,356 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 149s - loss: 0.0802 - val_loss: 0.1438\n",
      "Epoch 16/200\n",
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0692"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:32:46,356 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:33:44,317 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 145s - loss: 0.0776 - val_loss: 0.1450\n",
      "Epoch 17/200\n",
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:35:12,604 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:36:10,536 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 145s - loss: 0.0753 - val_loss: 0.1471\n",
      "Epoch 18/200\n",
      " 876544/1286325 [===================>..........] - ETA: 22s - loss: 0.0644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:37:38,443 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:38:35,588 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 147s - loss: 0.0733 - val_loss: 0.1496\n",
      "Epoch 19/200\n",
      " 876544/1286325 [===================>..........] - ETA: 22s - loss: 0.0623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:40:07,810 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:41:03,019 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 149s - loss: 0.0714 - val_loss: 0.1530\n",
      "Epoch 20/200\n",
      "  20480/1286325 [..............................] - ETA: 88s - loss: 0.0643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/keras/callbacks.py:119: UserWarning: Method on_batch_end() is slow compared to the batch update (0.120293). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 876544/1286325 [===================>..........] - ETA: 21s - loss: 0.0603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:42:35,314 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:43:30,775 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 148s - loss: 0.0695 - val_loss: 0.1544\n",
      "Epoch 21/200\n",
      " 876544/1286325 [===================>..........] - ETA: 22s - loss: 0.0587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:45:04,926 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/X_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:45:58,268 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286325/1286325 [==============================] - 148s - loss: 0.0679 - val_loss: 0.1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:46:45,642 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: early stopping\n",
      "CPU times: user 12min 4s, sys: 46min 17s, total: 58min 21s\n",
      "Wall time: 51min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 19:46:46,112 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 19:46:59,558 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xv_level_3.npy\n",
      "2017-04-15 19:47:05,253 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.376 | Top 3: 0.979 | Top 5: 0.997 | F1 Micro: 0.818 | F1 Macro: 0.770\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "for GLOBAL_PARAMS in GLOBAL_PARMS_TO_RUN:\n",
    "    \n",
    "    print '==================================== NEW PARAM SET ============================================'\n",
    "    print {k:v for k,v in GLOBAL_PARAMS.items() if k != 'classifications'}\n",
    "    \n",
    "    classifications = GLOBAL_PARAMS['classifications']\n",
    "    classifications_type = GLOBAL_PARAMS['classifications_type']\n",
    "    \n",
    "    PARTS_LEVEL = GLOBAL_PARAMS['parts_level']\n",
    "    \n",
    "    placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "    placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "    epoch = GLOBAL_PARAMS['doc2vec_epoch']\n",
    "\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    print GLOBAL_VARS.MODEL_NAME\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    X_file, y_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'training')\n",
    "    Xv_file, yv_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'validation')\n",
    "    X, y = get_data(X_file, y_file, mmap=True)\n",
    "    \n",
    "#     X,y = get_training_data_mmap(classifications_type, PARTS_LEVEL)\n",
    "    \n",
    "    NN_INPUT_NEURONS = X.shape[1] * X.shape[2]\n",
    "    NN_OUTPUT_NEURONS = len(classifications)\n",
    "    \n",
    "    EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "    EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "\n",
    "    NN_MAX_EPOCHS = 200\n",
    "    NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "    NN_BATCH_SIZE = GLOBAL_PARAMS['nn_batch_size']\n",
    "\n",
    "    MODEL_VERBOSITY = 1\n",
    "\n",
    "    NN_OPTIMIZER = 'rmsprop'\n",
    "    # NN_OPTIMIZER = 'adam'\n",
    "\n",
    "    to_skip = []\n",
    "\n",
    "    load_existing_results = True\n",
    "    save_results = True\n",
    "\n",
    "\n",
    "    first_hidden_layer_sizes = [100,200,500,1000]\n",
    "    second_hidden_layer_sizes = [None,500,1000,2000]\n",
    "    first_hidden_layer_activations = ['relu','sigmoid', 'tanh']\n",
    "    second_hidden_layer_activations = ['relu','sigmoid', 'tanh']\n",
    "    # first_hidden_layer_activations = ['relu']\n",
    "    # second_hidden_layer_activations = ['relu']\n",
    "    # input_dropout_options = [False, True]\n",
    "    # hidden_dropout_options = [False, True]\n",
    "    input_dropout_options = [False]\n",
    "    hidden_dropout_options = [True]\n",
    "    second_hidden_dropout_options = [False]\n",
    "\n",
    "    \n",
    "    first_hidden_layer_sizes = [1000]\n",
    "    second_hidden_layer_sizes = [500,]\n",
    "    first_hidden_layer_activations = ['sigmoid']\n",
    "    second_hidden_layer_activations = ['relu']\n",
    "    # first_hidden_layer_activations = ['relu']\n",
    "    # second_hidden_layer_activations = ['relu']\n",
    "    # input_dropout_options = [False, True]\n",
    "    # hidden_dropout_options = [False, True]\n",
    "    input_dropout_options = [False]\n",
    "    hidden_dropout_options = [True]\n",
    "    second_hidden_dropout_options = [False]\n",
    "    NN_RANDOM_SEARCH_BUDGET = 1\n",
    "\n",
    "\n",
    "    np.random.seed(NN_SEED)\n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    ############### Actual Training\n",
    "\n",
    "\n",
    "    # load previous finshed results so we dont redo them\n",
    "    param_results_dict = {}\n",
    "\n",
    "    param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "\n",
    "    if load_existing_results:\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results in {}'.format(param_results_path))\n",
    "            param_results_dict = pickle.load(open(param_results_path))\n",
    "        else:\n",
    "            info('No Previous results exist in {}'.format(param_results_path))\n",
    "\n",
    "    ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "    param_sampler = ParameterSampler({\n",
    "        'first_hidden_layer_size':first_hidden_layer_sizes,\n",
    "        'first_hidden_layer_activation':first_hidden_layer_activations,\n",
    "        'second_hidden_layer_size':second_hidden_layer_sizes,\n",
    "        'second_hidden_layer_activation':second_hidden_layer_activations,\n",
    "        'input_dropout':input_dropout_options,\n",
    "        'hidden_dropout':hidden_dropout_options,\n",
    "        'second_hidden_dropout':second_hidden_dropout_options\n",
    "    }, n_iter=NN_RANDOM_SEARCH_BUDGET, random_state=NN_PARAM_SAMPLE_SEED)\n",
    "\n",
    "\n",
    "    for parameters in param_sampler:\n",
    "        start_time = time.time()\n",
    "        first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "        first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "        second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "        second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "        input_dropout_do = parameters['input_dropout']\n",
    "        hidden_dropout_do = parameters['hidden_dropout']\n",
    "        second_hidden_dropout_do = parameters['second_hidden_dropout']\n",
    "\n",
    "        GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "            first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "            second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "        )\n",
    "        if second_hidden_dropout_do:\n",
    "            GLOBAL_VARS.NN_MODEL_NAME = GLOBAL_VARS.NN_MODEL_NAME + '_2nd-hid-drop_{}'.format(str(second_hidden_dropout_do))\n",
    "\n",
    "        if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "            print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "            continue\n",
    "            \n",
    "\n",
    "        info('***************************************************************************************')\n",
    "        info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "        \n",
    "        model = create_keras_nn_model(NN_INPUT_NEURONS, NN_OUTPUT_NEURONS, \n",
    "                                      first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                      second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                      input_dropout_do, hidden_dropout_do, second_hidden_dropout_do)\n",
    "        model.summary()\n",
    "\n",
    "        early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA,\n",
    "                                                      patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "        metrics_callback = MetricsCallback()\n",
    "\n",
    "\n",
    "        # Model Fitting\n",
    "        %time history = model.fit_generator(generator=batch_generator(X_file, y_file, NN_BATCH_SIZE, is_mlp=True, validate=False),\\\n",
    "                                            validation_data=batch_generator(Xv_file, yv_file, NN_BATCH_SIZE, is_mlp=True, validate=True),\\\n",
    "                                            samples_per_epoch=len(training_docs_list), \\\n",
    "                                            nb_val_samples=len(validation_docs_list),\\\n",
    "                                            nb_epoch=NN_MAX_EPOCHS,\\\n",
    "                                            callbacks=[early_stopper, metrics_callback],\\\n",
    "                                            max_q_size=QUEUE_SIZE)\n",
    "                                            #validation_data=(Xv,yv), \n",
    "\n",
    "    \n",
    "\n",
    "        # using the recorded weights of the best recorded validation loss\n",
    "        last_model_weights = model.get_weights()\n",
    "        info('Evaluating on Validation Data using saved best weights')\n",
    "        model.set_weights(metrics_callback.best_weights)\n",
    "        yvp = model.predict_generator(generator=batch_generator(Xv_file, yv_file, NN_BATCH_SIZE, is_mlp=True, validate=True),\\\n",
    "                                       max_q_size=QUEUE_SIZE,\\\n",
    "                                       val_samples=len(validation_docs_list))\n",
    "        yvp_binary = get_binary_0_5(yvp)\n",
    "        Xv, yv = get_data(Xv_file, yv_file, mmap=True)\n",
    "        #print yvp\n",
    "        info('Generating Validation Metrics')\n",
    "        validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "        print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "            validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "            validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "        best_validation_metrics = validation_metrics\n",
    "        \n",
    "        time.sleep(0.2)\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "        del history, last_model_weights, metrics_callback\n",
    "        \n",
    "        for p in multiprocessing.active_children():\n",
    "            # closing the array readers\n",
    "            p.terminate()\n",
    "\n",
    "    if save_results:\n",
    "        if load_existing_results:\n",
    "            if os.path.exists(param_results_path):\n",
    "                info('Loading Previous results from {}'.format(param_results_path))\n",
    "                loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "                param_results_dict.update(loaded_param_results_dict)\n",
    "\n",
    "        pickle.dump(param_results_dict, open(param_results_path, 'w'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 03:55:37,925 : INFO : Loading Validation Data from file using mmap\n",
      "2017-04-15 03:55:37,995 : INFO : Finished Loading Validation Data from file using mmap\n",
      "2017-04-15 03:55:37,996 : INFO : Generating Validation Metrics\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 5.945 | Top 3: 0.764 | Top 5: 0.843 | F1 Micro: 0.574 | F1 Macro: 0.181\n"
     ]
    }
   ],
   "source": [
    "Xv, yv = get_validation_data_mmap(classifications_type, PARTS_LEVEL)\n",
    "#print yvp\n",
    "info('Generating Validation Metrics')\n",
    "validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "best_validation_metrics = validation_metrics\n",
    "\n",
    "time.sleep(0.2)\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "duration = time.time() - start_time\n",
    "param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "del history, last_model_weights, metrics_callback\n",
    "\n",
    "if save_results:\n",
    "    if load_existing_results:\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results from {}'.format(param_results_path))\n",
    "            loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "            param_results_dict.update(loaded_param_results_dict)\n",
    "\n",
    "    pickle.dump(param_results_dict, open(param_results_path, 'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = valid_subclasses\n",
    "classifications_type = 'subclasses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_METRICS_FILENAME = '{}_level_{}_standard_nn_test_metrics.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = DOC2VEC_EPOCH\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "print GLOBAL_VARS.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARTS_LEVEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "param_results_dict = pickle.load(open(param_results_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt_file, yt_file = get_data_dirs(classifications_type, PARTS_LEVEL, 'test')\n",
    "Xt, yt = get_data(Xt_file, yt_file, mmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 20:56:07,114 : INFO : Reshaping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401877, 6800)\n"
     ]
    }
   ],
   "source": [
    "info(\"Reshaping\")\n",
    "Xt = np.reshape(Xt, (Xt.shape[0], Xt.shape[1]* Xt.shape[2]))\n",
    "print Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "NN_INPUT_NEURONS = Xt.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_1st-size_1000_1st-act_sigmoid_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 20:56:07,187 : INFO : ***************************************************************************************\n",
      "2017-04-15 20:56:07,188 : INFO : nn_1st-size_1000_1st-act_sigmoid_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "2017-04-15 20:56:07,608 : INFO : Evaluating on Test Data using best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 6800)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1000)          6801000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 1000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_relu (Dense)       (None, 500)           500500      dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           470940      hidden_layer2_relu[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 7,772,440\n",
      "Trainable params: 7,772,440\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 20:56:08,473 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xt_level_3.npy\n",
      "2017-04-15 20:57:24,534 : INFO : in new epoch for /mnt/data/shalaby/extended_pv_matrices/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/Xt_level_3.npy\n",
      "2017-04-15 20:58:42,256 : INFO : Generating Test Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test Metrics: Cov Err: 5.728, Avg Labels: 1.340, \n",
      "\t\t Top 1: 0.635, Top 3: 0.775, Top 5: 0.852, \n",
      "\t\t F1 Micro: 0.590, F1 Macro: 0.206, Total Pos: 378,343\n"
     ]
    }
   ],
   "source": [
    "first_hidden_layer_size = 1000\n",
    "first_hidden_layer_activation = 'sigmoid'\n",
    "second_hidden_layer_size = 500\n",
    "second_hidden_layer_activation = 'relu'\n",
    "input_dropout_do = False\n",
    "hidden_dropout_do = True\n",
    "second_hidden_dropout_do = False\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "    first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "    second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    ")\n",
    "if second_hidden_dropout_do:\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = GLOBAL_VARS.NN_MODEL_NAME + '_2nd-hid-drop_{}'.format(str(second_hidden_dropout_do))\n",
    "\n",
    "if GLOBAL_VARS.NN_MODEL_NAME not in param_results_dict.keys():\n",
    "    print \"Can't find model: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    raise Exception()\n",
    "\n",
    "    \n",
    "info('***************************************************************************************')\n",
    "info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "model = create_keras_nn_model(NN_INPUT_NEURONS, NN_OUTPUT_NEURONS, \n",
    "                              first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                              second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                              input_dropout_do, hidden_dropout_do)\n",
    "model.summary()\n",
    "\n",
    "# get model best weights\n",
    "# weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'].best_weights\n",
    "weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights']\n",
    "model.set_weights(weights)\n",
    "\n",
    "info('Evaluating on Test Data using best weights')\n",
    "ytp = model.predict_generator(generator=batch_generator(Xt_file, yt_file, NN_BATCH_SIZE, is_mlp=True, validate=True),\\\n",
    "                                       max_q_size=QUEUE_SIZE,\\\n",
    "                                       val_samples=len(test_docs_list))\n",
    "ytp_binary = get_binary_0_5(ytp)\n",
    "#print yvp\n",
    "info('Generating Test Metrics')\n",
    "test_metrics = get_metrics(yt, ytp, ytp_binary)\n",
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "\n",
    "ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "pickle.dump(test_metrics, open(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                            TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL)), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = 8\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications_type = 'sections'\n",
    "level = 3\n",
    "batch_size = 2048\n",
    "is_mlp, validate = False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = Queue(maxsize=10)\n",
    "p = ArrayReader(classifications_type, level, q, batch_size, is_mlp, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-14 23:56:48,393 : INFO : Loading Training Data from file using mmap\n",
      "2017-04-14 23:56:48,398 : INFO : Finished Loading Training Data from file using mmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 159 µs\n",
      "CPU times: user 12 ms, sys: 24 ms, total: 36 ms\n",
      "Wall time: 38.1 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 205 µs\n",
      "CPU times: user 28 ms, sys: 8 ms, total: 36 ms\n",
      "Wall time: 37.2 ms\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 115 µs\n",
      "CPU times: user 12 ms, sys: 24 ms, total: 36 ms\n",
      "Wall time: 36.9 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 345 µs\n",
      "CPU times: user 16 ms, sys: 16 ms, total: 32 ms\n",
      "Wall time: 33.4 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 422 µs\n",
      "CPU times: user 12 ms, sys: 20 ms, total: 32 ms\n",
      "Wall time: 29.4 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 121 µs\n",
      "CPU times: user 4 ms, sys: 24 ms, total: 28 ms\n",
      "Wall time: 26.6 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 159 µs\n",
      "CPU times: user 16 ms, sys: 8 ms, total: 24 ms\n",
      "Wall time: 25.4 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 67 µs\n",
      "CPU times: user 12 ms, sys: 12 ms, total: 24 ms\n",
      "Wall time: 24.3 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 62.9 µs\n",
      "CPU times: user 4 ms, sys: 20 ms, total: 24 ms\n",
      "Wall time: 22.7 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 136 µs\n",
      "CPU times: user 0 ns, sys: 24 ms, total: 24 ms\n",
      "Wall time: 23.1 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 152 µs\n",
      "CPU times: user 4 ms, sys: 20 ms, total: 24 ms\n",
      "Wall time: 23.6 ms\n"
     ]
    }
   ],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_EPOCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = 8\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications_type = 'sections'\n",
    "level = 3\n",
    "batch_size = 2048\n",
    "is_mlp, validate = True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# class ArrayReader(Process):\n",
    "class ArrayReader():\n",
    "    def __init__(self, classifications_type, level, out_queue, batch_size, is_mlp=False, validate=False):\n",
    "#         super(ArrayReader, self).__init__()\n",
    "        self.is_mlp = is_mlp\n",
    "        self.validate = validate\n",
    "        self.q = out_queue\n",
    "        self.batch_size = batch_size\n",
    "        self.classifications_type = classifications_type\n",
    "        self.level = level\n",
    "\n",
    "    def run(self):\n",
    "        x_file, y_file = get_training_data_mmap(self.classifications_type, self.level) \n",
    "        start_item = 0\n",
    "        num_iter = 0\n",
    "        shuffled_indices = np.arange(y_file.shape[0])\n",
    "        while True:\n",
    "            if start_item > y_file.shape[0]:\n",
    "                print 'new epoch'\n",
    "                start_item = 0\n",
    "#             y_batch = np.copy(y_file[start_item: start_item + self.batch_size])\n",
    "#             x_batch = np.copy(x_file[start_item: start_item + self.batch_size])\n",
    "            batch_indices = shuffled_indices[start_item: start_item + self.batch_size]\n",
    "            print x_file.shape\n",
    "            y_batch = y_file[batch_indices]\n",
    "            x_batch = x_file[batch_indices]\n",
    "            print y_batch.shape\n",
    "            print x_batch.shape\n",
    "            # because we use MLP\n",
    "            if self.is_mlp:\n",
    "                x_batch = np.reshape(x_batch, (x_batch.shape[0], x_batch.shape[1] * x_batch.shape[2]))\n",
    "            start_item += self.batch_size\n",
    "            num_iter += 1\n",
    "            self.q.put((x_batch, y_batch), block=True)\n",
    "            \n",
    "def batch_generator(classifications_type, level, batch_size, is_mlp=False, validate=False):\n",
    "    q = Queue(maxsize=10)\n",
    "    p = ArrayReader(classifications_type, level, q, batch_size, is_mlp, validate)\n",
    "    p.start()\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if not item:\n",
    "            p.terminate()\n",
    "            raise StopIteration()\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ArrayReader(Process):\n",
    "    def __init__(self, classifications_type, level, out_queue, batch_size, is_mlp=False, validate=False):\n",
    "        super(ArrayReader, self).__init__()\n",
    "        self.is_mlp = is_mlp\n",
    "        self.validate = validate\n",
    "        self.q = out_queue\n",
    "        self.batch_size = batch_size\n",
    "        self.classifications_type = classifications_type\n",
    "        self.level = level\n",
    "\n",
    "    def run(self):\n",
    "        if not self.validate:\n",
    "            x_file, y_file = get_training_data_mmap(self.classifications_type, self.level)\n",
    "        else:\n",
    "            x_file, y_file = get_validation_data_mmap(self.classifications_type, self.level)\n",
    "        start_item = 0\n",
    "        num_iter = 0\n",
    "        shuffled_indices = np.arange(y_file.shape[0])\n",
    "#         np.random.shuffle(shuffled_indices)\n",
    "        while True:\n",
    "            if start_item > y_file.shape[0]:\n",
    "                print 'in new epoch'\n",
    "#                 np.random.seed(42 + num_iter)\n",
    "#                 np.random.shuffle(shuffled_indices)\n",
    "                start_item = 0\n",
    "#             y_batch = np.copy(y_file[start_item: start_item + self.batch_size])\n",
    "#             x_batch = np.copy(x_file[start_item: start_item + self.batch_size])\n",
    "            batch_indices = shuffled_indices[start_item: start_item + self.batch_size]\n",
    "            x_batch, y_array = np.zeros((1,1)), np.zeros((1,1))\n",
    "            start_time = time.time()\n",
    "            x_batch = np.copy(x_file[batch_indices])\n",
    "            y_batch = np.copy(y_file[batch_indices])\n",
    "            print 'Duration: {}'.format(str(time.time() - start_time))\n",
    "            # because we use MLP\n",
    "            if self.is_mlp:\n",
    "                x_batch = np.reshape(x_batch, (x_batch.shape[0], x_batch.shape[1] * x_batch.shape[2]))\n",
    "            start_item += self.batch_size\n",
    "            num_iter += 1\n",
    "            try:\n",
    "                print 'adding new batch'\n",
    "                self.q.put((x_batch, y_batch), block=True)\n",
    "            except:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = Queue(maxsize=100)\n",
    "p = ArrayReader(classifications_type, level, q, batch_size, is_mlp, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 03:26:42,036 : INFO : Loading Training Data from file using mmap\n",
      "2017-04-15 03:26:42,040 : INFO : Finished Loading Training Data from file using mmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0.0615739822388\n",
      "adding new batch\n",
      "Duration: 0.188284873962\n",
      "adding new batch\n",
      "Duration: 0.0573651790619\n",
      "adding new batch\n",
      "Duration: 0.0536658763885\n",
      "adding new batch\n",
      "Duration: 0.163289070129\n",
      "adding new batch\n",
      "Duration: 0.162258863449\n",
      "adding new batch\n",
      "Duration: 0.159317970276\n",
      "adding new batch\n",
      "Duration: 0.157483100891\n",
      "adding new batch\n",
      "Duration: 0.153153896332\n",
      "adding new batch\n",
      "Duration: 0.153907060623\n",
      "adding new batch\n",
      "Duration: 0.132169961929\n",
      "adding new batch\n",
      "Duration: 0.134433031082\n",
      "adding new batch\n",
      "Duration: 0.182116985321\n",
      "adding new batch\n",
      "Duration: 0.154788970947\n",
      "adding new batch\n",
      "Duration: 0.149490833282\n",
      "adding new batch\n",
      "Duration: 0.156996011734\n",
      "adding new batch\n",
      "Duration: 0.144598007202\n",
      "adding new batch\n",
      "Duration: 0.212677001953\n",
      "adding new batch\n",
      "Duration: 0.115936040878\n",
      "adding new batch\n",
      "Duration: 0.202229976654\n",
      "adding new batch\n",
      "Duration: 0.174211978912\n",
      "adding new batch\n",
      "Duration: 0.15162396431\n",
      "adding new batch\n",
      "Duration: 0.146477937698\n",
      "adding new batch\n",
      "Duration: 0.0841519832611\n",
      "adding new batch\n",
      "Duration: 0.148650884628\n",
      "adding new batch\n",
      "Duration: 0.144529104233\n",
      "adding new batch\n",
      "Duration: 0.146453857422\n",
      "adding new batch\n",
      "Duration: 0.143181085587\n",
      "adding new batch\n",
      "Duration: 0.146729946136\n",
      "adding new batch\n",
      "Duration: 0.141415119171\n",
      "adding new batch\n",
      "Duration: 0.145812034607\n",
      "adding new batch\n",
      "Duration: 0.103158950806\n",
      "adding new batch\n",
      "Duration: 0.125601053238\n",
      "adding new batch\n",
      "Duration: 0.121280193329\n",
      "adding new batch\n",
      "Duration: 0.124383926392\n",
      "adding new batch\n",
      "Duration: 0.133429050446\n",
      "adding new batch\n",
      "Duration: 0.127221822739\n",
      "adding new batch\n",
      "Duration: 0.130682945251\n",
      "adding new batch\n",
      "Duration: 0.127993106842\n",
      "adding new batch\n",
      "Duration: 0.125495910645\n",
      "adding new batch\n",
      "Duration: 0.129567861557\n",
      "adding new batch\n",
      "Duration: 1.01302790642\n",
      "adding new batch\n",
      "Duration: 0.567863941193\n",
      "adding new batch\n",
      "Duration: 0.580572843552\n",
      "adding new batch\n",
      "Duration: 0.524386167526\n",
      "adding new batch\n",
      "Duration: 1.68219399452\n",
      "adding new batch\n",
      "Duration: 0.621116161346\n",
      "adding new batch\n",
      "Duration: 0.578160047531\n",
      "adding new batch\n",
      "Duration: 0.353053092957\n",
      "adding new batch\n",
      "Duration: 1.81583213806\n",
      "adding new batch\n",
      "Duration: 0.444869995117\n",
      "adding new batch\n",
      "Duration: 0.738863945007\n",
      "adding new batch\n",
      "Duration: 1.67818593979\n",
      "adding new batch\n",
      "Duration: 6.17045903206\n",
      "adding new batch\n",
      "Duration: 6.96332001686\n",
      "adding new batch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-76aedfc5f0a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-47ebc6d1d9f3>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m'Duration: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/numpy/core/memmap.pyc\u001b[0m in \u001b[0;36m__array_finalize__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_mmap'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'terminate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e93f87b8387e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mTerminate\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0msends\u001b[0m \u001b[0mSIGTERM\u001b[0m \u001b[0msignal\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0muses\u001b[0m \u001b[0mTerminateProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         '''\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'terminate'"
     ]
    }
   ],
   "source": [
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 03:14:23,156 : INFO : Loading Training Data from file using mmap\n",
      "2017-04-15 03:14:23,162 : INFO : Finished Loading Training Data from file using mmap\n"
     ]
    }
   ],
   "source": [
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in multiprocessing.active_children():\n",
    "    # closing the array readers\n",
    "    p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
