{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_WORD_COUNT = 100\n",
    "MIN_SIZE = 0\n",
    "NUM_CORES = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "TEST_MATRIX = \"test_matrix.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training_file = \"/home/local/shalaby/docs_output_sample_100.json\"\n",
    "\n",
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "doc2vec_model_save_location = os.path.join(root_location, \"parameter_search_doc2vec_models_new\", \"full\")\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_parameter_search\")\n",
    "if not os.path.exists(doc2vec_model_save_location):\n",
    "    os.makedirs(doc2vec_model_save_location)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL)):\n",
    "    os.makedirs(os.path.join(doc2vec_model_save_location, VOCAB_MODEL))\n",
    "\n",
    "training_file = root_location + \"docs_output.json\"\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "classification_index_file = exports_location + \"classification_index.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\"\n",
    "\n",
    "preprocessed_location = root_location + \"preprocessed_data/\"\n",
    "\n",
    "training_preprocessed_files_prefix = preprocessed_location + \"training_docs_merged_data_preprocessed-\"\n",
    "training_preprocessed_docids_files_prefix = preprocessed_location + \"training_docs_merged_docids_preprocessed-\"\n",
    "validation_preprocessed_files_prefix = preprocessed_location + \"validation_docs_merged_data_preprocessed-\"\n",
    "validation_preprocessed_docids_files_prefix = preprocessed_location + \"validation_docs_merged_docids_preprocessed-\"\n",
    "test_preprocessed_files_prefix = preprocessed_location + \"test_docs_merged_data_preprocessed-\"\n",
    "test_preprocessed_docids_files_prefix = preprocessed_location + \"test_docs_merged_docids_preprocessed-\"\n",
    "\n",
    "word2vec_questions_file = result = root_location + 'tensorflow/word2vec/questions-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 764 ms, total: 17.4 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "# classifications_index = pickle.load(open(classification_index_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401877"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ensure_disk_location_exists(location):\n",
    "    if not os.path.exists(location):\n",
    "        os.makedirs(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_docs_with_inference(doc2vec_model, doc_classification_map, classifications,\n",
    "                                           docs_list, file_to_write, preprocessed_files_prefix,\n",
    "                                           preprocessed_docids_files_prefix):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation or test documents\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_one_doc(doc_tuple):\n",
    "        # doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "        doc_id, doc_tokens = doc_tuple\n",
    "        rep = doc2vec_model.infer_vector(doc_tokens)\n",
    "        return (doc_id, rep)\n",
    "\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    classifications_set = set(classifications)\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, file_to_write)):\n",
    "        info(\"===== Loading inference vectors\")\n",
    "        inference_labels = []\n",
    "        inference_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, file_to_write)))\n",
    "        info(\"Loaded inference vectors matrix\")\n",
    "        for doc_id in docs_list:\n",
    "            curr_doc_labels = set(doc_classification_map[doc_id]) & classifications_set\n",
    "            inference_labels.append(one_hot_encoder.get_label_vector(curr_doc_labels))\n",
    "        inference_labels = np.array(inference_labels, dtype=np.int8)\n",
    "    else:\n",
    "        inference_documents_reps = {}\n",
    "        inference_vectors = []\n",
    "        inference_labels = []\n",
    "        info(\"===== Getting vectors with inference\")\n",
    "\n",
    "\n",
    "        # Multi-threaded inference\n",
    "        inference_docs_iterator = DocumentBatchGenerator(preprocessed_files_prefix,\n",
    "                                                          preprocessed_docids_files_prefix, batch_size=None)\n",
    "        generator_func = inference_docs_iterator.__iter__()\n",
    "        pool = ThreadPool(NUM_CORES)\n",
    "        # map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "        mini_batch_size = 1000\n",
    "        while True:\n",
    "            threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "            info(\"Finished: {}\".format(str(inference_docs_iterator.curr_index)))\n",
    "            if threaded_reps_partial:\n",
    "                # threaded_reps.extend(threaded_reps_partial)\n",
    "                inference_documents_reps.update(threaded_reps_partial)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # create matrix for the inferred vectors\n",
    "        for doc_id in docs_list:\n",
    "            inference_vectors.append(inference_documents_reps[doc_id])\n",
    "            curr_doc_labels = set(doc_classification_map[doc_id]) & classifications_set\n",
    "            inference_labels.append(one_hot_encoder.get_label_vector(curr_doc_labels))\n",
    "        inference_vectors_matrix = np.array(inference_vectors)\n",
    "        inference_labels = np.array(inference_labels, dtype=np.int8)\n",
    "        pickle.dump(inference_vectors_matrix,\n",
    "                    open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, file_to_write), 'w'))\n",
    "\n",
    "    return inference_vectors_matrix, inference_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference(doc2vec_model, doc_classification_map):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # do inference and store results in dict\n",
    "        i = 0\n",
    "        for (doc_id, doc_contents_array) in ValidationDocumentGenerator(training_file, validation_docs_list):\n",
    "            i += 1\n",
    "            if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "            validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "\n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in validation_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            validation_labels.append([classf for classf in doc_classification_map[validation_doc_id] if classf in sections])\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                           val_docs_list, val_preprocessed_files_prefix, val_preprocessed_docids_files_prefix):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_one_doc(doc_tuple):\n",
    "        #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "        doc_id, doc_tokens = doc_tuple\n",
    "        rep = doc2vec_model.infer_vector(doc_tokens)\n",
    "        return (doc_id, rep)\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    classifications_set = set(classifications)\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_labels = []\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "        info(\"Loaded validation vectors matrix\")\n",
    "        for i, validation_doc_id in enumerate(val_docs_list):\n",
    "#             val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            val_labels = list(set(doc_classification_map[validation_doc_id]) & classifications_set)\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "            if i % 100000 == 0:\n",
    "                info(\"Finished {} in validation loading\".format(i))\n",
    "        validation_labels = np.array(validation_labels, dtype=np.int8)\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # Single-threaded inference\n",
    "        # do inference and store results in dict\n",
    "#         i = 0\n",
    "        \n",
    "#         validation_docs_iterator = DocumentBatchGenerator(val_preprocessed_files_prefix, \n",
    "#                                                         val_preprocessed_docids_files_prefix, batch_size=None)\n",
    "#         for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "#             i += 1\n",
    "#             if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "#             validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "        \n",
    "        # Multi-threaded inference\n",
    "        validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                          validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "        generator_func = validation_docs_iterator.__iter__()\n",
    "        pool = ThreadPool(NUM_CORES)\n",
    "        # map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "        validation_documents_reps = {}\n",
    "        mini_batch_size = 1000\n",
    "        while True:\n",
    "            threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "            info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "            if threaded_reps_partial:\n",
    "                #threaded_reps.extend(threaded_reps_partial)\n",
    "                validation_documents_reps.update(threaded_reps_partial)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "                \n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "#             val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            val_labels = set(doc_classification_map[validation_doc_id]) & classifications_set\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        validation_labels = np.array(validation_labels, dtype=np.int8)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "\n",
    "def get_training_data(doc2vec_model, classifications):\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    classifications_set = set(classifications)\n",
    "    training_data = []\n",
    "    training_labels_mat = np.zeros((len(training_docs_list), len(classifications)), dtype=np.int8)\n",
    "#     training_data_mat = np.zeros((len(training_docs_list), DOC2VEC_SIZE), dtype=np.float32)\n",
    "    for i,doc_id in enumerate(training_docs_list):\n",
    "        # converting from memmap to a normal array\n",
    "#         normal_array = []\n",
    "#         normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "        normal_array = doc2vec_model.docvecs[doc_id]\n",
    "        training_data.append(normal_array)\n",
    "#         eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "        eligible_classifications = set(doc_classification_map[doc_id]) & classifications_set\n",
    "        training_labels_mat[i][:] = one_hot_encoder.get_label_vector(eligible_classifications)\n",
    "        if i % 100000 == 0:\n",
    "            info(\"Finished {} in training\".format(i))\n",
    "    info(\"doing matrix creation\")\n",
    "    training_data_mat = np.array(training_data)\n",
    "#     training_labels_mat = np.array(training_labels, dtype=np.int8)\n",
    "    del training_data\n",
    "    return training_data_mat, training_labels_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "                    \n",
    "class DocumentBatchGenerator(object):\n",
    "    def __init__(self, filename_prefix, filename_docids_prefix, batch_size=10000 ):\n",
    "        \"\"\"\n",
    "        batch_size cant be > 10,000 due to a limitation in doc2vec training, \n",
    "        None means no batching (only use for inference)\n",
    "        \"\"\"\n",
    "        assert batch_size <= 10000 or batch_size is None\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.filename_docids_prefix = filename_docids_prefix\n",
    "        self.curr_lines = []\n",
    "        self.curr_docids = []\n",
    "        self.batch_size = batch_size\n",
    "        self.curr_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        del self.curr_lines, self.curr_docids\n",
    "        self.curr_lines, self.docids = [], []\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_index) )\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    self.curr_lines.append(line.split(\" \"))\n",
    "#                     if i % 1000 == 0:\n",
    "#                         print i\n",
    "            self.curr_docids = pickle.load(open(self.filename_docids_prefix + str(self.curr_index), \"r\"))\n",
    "            self.batch_end = self.curr_index + len(self.curr_lines) -1 \n",
    "            info(\"Finished loading new batch\")\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_index))\n",
    "            raise StopIteration()\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            if self.curr_index > self.batch_end:\n",
    "                self.load_new_batch_in_memory()\n",
    "            for (doc_id, tokens) in zip(self.curr_docids, self.curr_lines):\n",
    "                if self.batch_size is not None:\n",
    "                    curr_batch_iter = 0\n",
    "                    # divide the document to batches according to the batch size\n",
    "                    while curr_batch_iter < len(tokens):\n",
    "                        yield LabeledSentence(words=tokens[curr_batch_iter: curr_batch_iter + self.batch_size], tags=[doc_id])\n",
    "                        curr_batch_iter += self.batch_size\n",
    "                else:\n",
    "                    yield doc_id, tokens\n",
    "                self.curr_index += 1\n",
    "\n",
    "class Word2VecTrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield stemtokenizer(text)\n",
    "                \n",
    "class ValidationDocumentGenerator(object):\n",
    "    def __init__(self, filename, validation_docs_list):\n",
    "        self.filename = filename\n",
    "        self.validation_docs_list = validation_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.validation_docs_list:\n",
    "                    yield doc_id, stemtokenizer(text)\n",
    "                    \n",
    "class StochasticDocumentGenerator(object):\n",
    "    \"\"\"\n",
    "    Randomly shuffle rows while reading them\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, training_docs_list, line_positions):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "        self.line_positions = line_positions\n",
    "        self.lines = set(line_positions.keys())\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            while len(self.lines) > 0:\n",
    "                random_line = random.sample(self.lines,1)[0]\n",
    "                self.lines.remove(random_line)\n",
    "                file_obj.seek(self.line_positions[random_line])\n",
    "                line = file_obj.readline()\n",
    "                if not line.strip(): continue\n",
    "#                 print random_line, self.line_positions[random_line], line[:30]\n",
    "                (doc_id, text) = eval(line)\n",
    "                # print random_line , doc_id\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "#                     yield doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Specific Doc2vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 20\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 10000 # report vocab progress every x documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_{}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "placeholder_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_methods_dict = {\n",
    "#     'doc2vec_size_50_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None' : 7,\n",
    "#     'doc2vec_size_50_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None' : 8,\n",
    "#     'doc2vec_size_50_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 8,\n",
    "#     'doc2vec_size_100_w_2_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 9,\n",
    "#     'doc2vec_size_100_w_5_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 18,\n",
    "#     'doc2vec_size_100_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 10,\n",
    "#     'doc2vec_size_100_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 4,\n",
    "#     'doc2vec_size_100_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 7,\n",
    "#     'doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 8,\n",
    "#     'doc2vec_size_200_w_2_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 7,\n",
    "#     'doc2vec_size_200_w_4_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 6,\n",
    "#     'doc2vec_size_200_w_4_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 8,\n",
    "#     'doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 14,\n",
    "#     'doc2vec_size_200_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 1,\n",
    "#     'doc2vec_size_200_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 8,\n",
    "#     'doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 8,\n",
    "#     'doc2vec_size_500_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 8,\n",
    "#     'doc2vec_size_1000_w_8_type_pv-dbow_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None': 6,\n",
    "#     'doc2vec_size_1000_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifications = sections\n",
    "classifications_type = 'sections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-27 11:29:21,274 : INFO : ****************** Epoch 8 --- Loading doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8 *******************\n",
      "2017-02-27 11:29:21,276 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model\n",
      "2017-02-27 11:29:27,608 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.* with mmap=None\n",
      "2017-02-27 11:29:27,609 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-02-27 11:29:29,781 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn1neg.npy with mmap=None\n",
      "2017-02-27 11:29:30,456 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn0.npy with mmap=None\n",
      "2017-02-27 11:29:31,129 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-02-27 11:29:31,131 : INFO : setting ignored attribute cum_table to None\n",
      "2017-02-27 11:29:32,057 : INFO : Getting training Data\n",
      "2017-02-27 11:29:32,059 : INFO : Finished 0 in training\n",
      "2017-02-27 11:29:32,640 : INFO : Finished 100000 in training\n",
      "2017-02-27 11:29:33,163 : INFO : Finished 200000 in training\n",
      "2017-02-27 11:29:33,672 : INFO : Finished 300000 in training\n",
      "2017-02-27 11:29:34,199 : INFO : Finished 400000 in training\n",
      "2017-02-27 11:29:34,728 : INFO : Finished 500000 in training\n",
      "2017-02-27 11:29:35,237 : INFO : Finished 600000 in training\n",
      "2017-02-27 11:29:35,746 : INFO : Finished 700000 in training\n",
      "2017-02-27 11:29:36,283 : INFO : Finished 800000 in training\n",
      "2017-02-27 11:29:36,819 : INFO : Finished 900000 in training\n",
      "2017-02-27 11:29:37,302 : INFO : Finished 1000000 in training\n",
      "2017-02-27 11:29:37,804 : INFO : Finished 1100000 in training\n",
      "2017-02-27 11:29:38,345 : INFO : Finished 1200000 in training\n",
      "2017-02-27 11:29:38,790 : INFO : doing matrix creation\n",
      "2017-02-27 11:29:39,578 : INFO : Getting Validation Embeddings\n",
      "2017-02-27 11:29:39,579 : INFO : ===== Loading validation vectors\n",
      "2017-02-27 11:30:06,054 : INFO : Loaded validation vectors matrix\n",
      "2017-02-27 11:30:06,056 : INFO : Finished 0 in validation loading\n",
      "2017-02-27 11:30:06,359 : INFO : Finished 100000 in validation loading\n",
      "2017-02-27 11:30:06,641 : INFO : Finished 200000 in validation loading\n",
      "2017-02-27 11:30:06,906 : INFO : Finished 300000 in validation loading\n"
     ]
    }
   ],
   "source": [
    "epoch = 8\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "info(\"****************** Epoch {} --- Loading {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "# if we have the model, just load it, otherwise train the previous model\n",
    "if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "    doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "\n",
    "info('Getting training Data')\n",
    "X, y = get_training_data(doc2vec_model, classifications)\n",
    "\n",
    "info('Getting Validation Embeddings')\n",
    "Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                validation_preprocessed_docids_files_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create nn parameter search directory\n",
    "if not os.path.exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME)):\n",
    "    os.makedirs(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_keras_nn_model(input_size, output_size, \n",
    "                          first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                          second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                          input_dropout_do, hidden_dropout_do):\n",
    "    \n",
    "    doc_input = Input(shape=(DOC2VEC_SIZE,), name='doc_input')\n",
    "    if input_dropout_do:\n",
    "        hidden = Dropout(0.7)(doc_input)\n",
    "    hidden = Dense(first_hidden_layer_size, activation=first_hidden_layer_activation, \n",
    "                   name='hidden_layer_{}'.format(first_hidden_layer_activation))(doc_input if not input_dropout_do else hidden)\n",
    "    if hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    if second_hidden_layer_size is not None:\n",
    "        hidden = Dense(second_hidden_layer_size, activation=second_hidden_layer_activation, \n",
    "                       name='hidden_layer2_{}'.format(second_hidden_layer_activation))(hidden)\n",
    "    softmax_output = Dense(output_size, activation='sigmoid', name='softmax_output')(hidden)\n",
    "\n",
    "    model = Model(input=doc_input, output=softmax_output)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'.format(classifications_type)\n",
    "TRAINING_METRICS_FILENAME = '{}_training_metrics.pkl'.format(classifications_type)\n",
    "TEST_METRICS_FILENAME = '{}_test_metrics.pkl'.format(classifications_type)\n",
    "METRICS_FIG_PNG_FILENAME = '{}_validation_metrics.png'.format(classifications_type)\n",
    "METRICS_FIG_PDF_FILENAME = '{}_validation_metrics.pdf'.format(classifications_type)\n",
    "WORD2VEC_METRICS_FILENAME = 'word2vec_metrics.pkl'\n",
    "\n",
    "# for epoch in range(DOC2VEC_MAX_EPOCHS):\n",
    "#     GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "# fig_save_location = placeholder_model_name.format('run')\n",
    "# plt.savefig(os.path.join(fig_save_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_binary_0_5 = lambda x: 1 if x > 0.5 else 0\n",
    "get_binary_0_5 = np.vectorize(get_binary_0_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "NN_MAX_EPOCHS = 100\n",
    "NN_BATCH_SIZE = 1024\n",
    "NN_RANDOM_SEARCH_BUDGET = 30\n",
    "NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "first_hidden_layer_sizes = [200,500]\n",
    "second_hidden_layer_sizes = [None,50,200,500,1000,2000]\n",
    "first_hidden_layer_activations = ['relu','sigmoid', 'tanh', 'softmax']\n",
    "second_hidden_layer_activations = ['relu','sigmoid', 'tanh', 'softmax']\n",
    "# first_hidden_layer_activations = ['relu']\n",
    "# second_hidden_layer_activations = ['relu']\n",
    "input_dropout_options = [False, True]\n",
    "hidden_dropout_options = [False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Batch Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:18:08,422 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 749s - loss: 0.2799 - val_loss: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:30:46,709 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 22s, sys: 52.7 s, total: 2min 15s\n",
      "Wall time: 12min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:30:56,551 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:31:14,674 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.709, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.705, Top 3: 0.932, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.633, F1 Macro: 0.416, Total Pos: 266,589\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 109s - loss: 0.2730 - val_loss: 0.2065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:33:03,732 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 5s, sys: 38.6 s, total: 1min 44s\n",
      "Wall time: 1min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:33:10,364 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:33:26,903 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.664, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.943, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.627, F1 Macro: 0.455, Total Pos: 245,299\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 109s - loss: 0.2724 - val_loss: 0.2082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:35:16,033 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 4s, sys: 38.4 s, total: 1min 42s\n",
      "Wall time: 1min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:35:23,493 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:35:39,934 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.684, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.707, Top 3: 0.938, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.634, F1 Macro: 0.436, Total Pos: 269,296\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 93s - loss: 0.2721 - val_loss: 0.2077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:37:13,820 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 58.6 s, sys: 34.1 s, total: 1min 32s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:37:19,295 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:37:28,746 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.688, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.710, Top 3: 0.936, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.631, F1 Macro: 0.433, Total Pos: 261,761\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2719 - val_loss: 0.2030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:38:29,795 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.5 s, sys: 28 s, total: 1min 12s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:38:34,949 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:38:45,755 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.675, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.722, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.647, F1 Macro: 0.446, Total Pos: 260,299\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 64s - loss: 0.2720 - val_loss: 0.2034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:39:50,345 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 47 s, sys: 29.7 s, total: 1min 16s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:39:55,424 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:40:06,470 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.726, Top 3: 0.935, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.648, F1 Macro: 0.434, Total Pos: 255,847\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2721 - val_loss: 0.2062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:41:07,572 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.4 s, sys: 28.2 s, total: 1min 12s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:41:12,301 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:41:20,732 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.708, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.712, Top 3: 0.930, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.641, F1 Macro: 0.439, Total Pos: 259,504\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 63s - loss: 0.2721 - val_loss: 0.2062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:42:24,126 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.9 s, sys: 31.9 s, total: 1min 16s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:42:29,017 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:42:37,494 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.728, Top 3: 0.935, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.460, Total Pos: 259,484\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 63s - loss: 0.2720 - val_loss: 0.2038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:43:40,568 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 45.9 s, sys: 30.4 s, total: 1min 16s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:43:45,346 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:43:56,554 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.724, Top 3: 0.941, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.642, F1 Macro: 0.459, Total Pos: 261,635\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 62s - loss: 0.2722 - val_loss: 0.2044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:44:58,610 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.8 s, sys: 30.2 s, total: 1min 14s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:45:03,627 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:45:13,198 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.665, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.940, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.658, F1 Macro: 0.435, Total Pos: 277,230\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 124s - loss: 0.2722 - val_loss: 0.2054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:47:17,397 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 26s, sys: 47.6 s, total: 2min 13s\n",
      "Wall time: 2min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:47:28,524 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:47:43,417 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.669, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.939, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.482, Total Pos: 266,918\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 212s - loss: 0.2721 - val_loss: 0.2075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:51:16,274 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 32s, sys: 1min 18s, total: 3min 51s\n",
      "Wall time: 3min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:51:32,942 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:51:55,045 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.691, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.934, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.632, F1 Macro: 0.423, Total Pos: 255,122\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 263s - loss: 0.2722 - val_loss: 0.2097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:56:18,726 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 5s, sys: 1min 53s, total: 4min 59s\n",
      "Wall time: 4min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-22 23:56:36,108 : INFO : Generating Validation Metrics\n",
      "2017-01-22 23:56:59,743 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.711, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.720, Top 3: 0.927, Top 5: 0.981, \n",
      "\t\t F1 Micro: 0.605, F1 Macro: 0.421, Total Pos: 219,893\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 226s - loss: 0.2724 - val_loss: 0.2049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:00:46,496 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 39s, sys: 1min 35s, total: 4min 14s\n",
      "Wall time: 3min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:01:03,139 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:01:26,373 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.938, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.637, F1 Macro: 0.451, Total Pos: 253,115\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 267s - loss: 0.2724 - val_loss: 0.2065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:05:54,353 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 6s, sys: 1min 51s, total: 4min 57s\n",
      "Wall time: 4min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:06:03,468 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.700, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.932, Top 5: 0.982, \n",
      "\t\t F1 Micro: 0.663, F1 Macro: 0.458, Total Pos: 286,271\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:06:28,943 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 165s - loss: 0.2801 - val_loss: 0.2087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:09:21,241 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 56s, sys: 1min 14s, total: 3min 10s\n",
      "Wall time: 2min 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:09:40,226 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:10:05,799 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.686, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.935, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.630, F1 Macro: 0.424, Total Pos: 249,069\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 160s - loss: 0.2710 - val_loss: 0.2030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:12:45,850 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 41s, sys: 1min, total: 2min 42s\n",
      "Wall time: 2min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:13:03,894 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:13:23,840 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.647, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.729, Top 3: 0.943, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.645, F1 Macro: 0.444, Total Pos: 259,649\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 135s - loss: 0.2697 - val_loss: 0.2030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:15:39,372 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 29s, sys: 53.3 s, total: 2min 22s\n",
      "Wall time: 2min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:15:54,793 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:16:10,639 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.665, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.939, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.643, F1 Macro: 0.448, Total Pos: 257,832\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 165s - loss: 0.2692 - val_loss: 0.2024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:18:55,909 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 48s, sys: 1min 3s, total: 2min 51s\n",
      "Wall time: 2min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:19:03,646 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:19:29,019 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.668, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.720, Top 3: 0.938, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.641, F1 Macro: 0.450, Total Pos: 264,452\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 155s - loss: 0.2691 - val_loss: 0.2019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:22:04,072 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 42s, sys: 1min, total: 2min 42s\n",
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:22:21,785 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:22:45,764 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.668, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.726, Top 3: 0.938, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.660, F1 Macro: 0.445, Total Pos: 275,878\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 157s - loss: 0.2686 - val_loss: 0.2033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:25:23,683 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 44s, sys: 1min 1s, total: 2min 45s\n",
      "Wall time: 2min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:25:41,829 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:25:59,425 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.649, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.940, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.648, F1 Macro: 0.505, Total Pos: 258,654\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 154s - loss: 0.2684 - val_loss: 0.2029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:28:33,752 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 40s, sys: 1min 2s, total: 2min 42s\n",
      "Wall time: 2min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:28:38,341 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:28:50,079 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.691, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.709, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.645, F1 Macro: 0.416, Total Pos: 274,392\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 160s - loss: 0.2684 - val_loss: 0.2083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:31:30,955 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 41s, sys: 1min, total: 2min 41s\n",
      "Wall time: 2min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:31:40,319 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:32:02,290 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.745, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.695, Top 3: 0.924, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.645, F1 Macro: 0.410, Total Pos: 288,486\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 158s - loss: 0.2684 - val_loss: 0.2008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:34:41,296 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 44s, sys: 1min 3s, total: 2min 48s\n",
      "Wall time: 2min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:34:59,535 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:35:24,281 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.722, Top 3: 0.942, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.635, F1 Macro: 0.441, Total Pos: 246,453\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 163s - loss: 0.2682 - val_loss: 0.2007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:38:08,185 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 47s, sys: 1min 2s, total: 2min 49s\n",
      "Wall time: 2min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:38:25,722 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:38:47,390 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.628, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.742, Top 3: 0.944, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.507, Total Pos: 252,998\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 162s - loss: 0.2681 - val_loss: 0.1976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:41:30,379 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 46s, sys: 1min 2s, total: 2min 49s\n",
      "Wall time: 2min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:41:40,981 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:42:02,913 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.646, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.666, F1 Macro: 0.499, Total Pos: 277,265\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 139s - loss: 0.2681 - val_loss: 0.1998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:44:22,267 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 31s, sys: 55 s, total: 2min 26s\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:44:36,492 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:44:56,939 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.634, F1 Macro: 0.442, Total Pos: 240,993\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 153s - loss: 0.2680 - val_loss: 0.1981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:47:30,293 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 41s, sys: 1min, total: 2min 42s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:47:48,031 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:48:12,449 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.643, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.667, F1 Macro: 0.494, Total Pos: 274,374\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 152s - loss: 0.2684 - val_loss: 0.1994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:50:45,372 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 36s, sys: 58.5 s, total: 2min 35s\n",
      "Wall time: 2min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:51:03,675 : INFO : Generating Validation Metrics\n",
      "2017-01-23 00:51:28,183 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.650, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.734, Top 3: 0.942, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.672, F1 Macro: 0.465, Total Pos: 286,275\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 150s - loss: 0.2679 - val_loss: 0.2027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:53:59,101 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 40s, sys: 59.4 s, total: 2min 39s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:54:16,237 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.728, Top 3: 0.939, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.677, F1 Macro: 0.506, Total Pos: 304,618\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 00:54:39,255 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 94s - loss: 0.2822 - val_loss: 0.2092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:07:49,442 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 17s, sys: 54.8 s, total: 2min 12s\n",
      "Wall time: 13min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:08:10,668 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:08:35,401 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.677, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.718, Top 3: 0.938, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.630, F1 Macro: 0.413, Total Pos: 251,200\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 90s - loss: 0.2702 - val_loss: 0.2063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:10:05,911 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 55.7 s, sys: 38.1 s, total: 1min 33s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:10:25,051 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:10:49,649 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.685, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.723, Top 3: 0.936, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.640, F1 Macro: 0.404, Total Pos: 258,544\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 60s - loss: 0.2681 - val_loss: 0.2027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:11:50,271 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 38.6 s, sys: 27.4 s, total: 1min 6s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:12:07,764 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:12:31,861 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.658, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.940, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.662, F1 Macro: 0.461, Total Pos: 279,292\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 91s - loss: 0.2674 - val_loss: 0.1999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:14:03,790 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 57.3 s, sys: 39.8 s, total: 1min 37s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:14:10,741 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:14:34,977 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.629, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.947, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.479, Total Pos: 262,190\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 90s - loss: 0.2668 - val_loss: 0.2006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:16:05,388 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 55 s, sys: 38.1 s, total: 1min 33s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:16:22,853 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:16:40,009 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.739, Top 3: 0.947, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.468, Total Pos: 257,948\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 93s - loss: 0.2665 - val_loss: 0.2032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:18:13,399 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 58.3 s, sys: 38.5 s, total: 1min 36s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:18:30,724 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:18:54,928 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.685, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.714, Top 3: 0.935, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.405, Total Pos: 277,088\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 90s - loss: 0.2662 - val_loss: 0.1993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:20:25,444 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 56.7 s, sys: 37.4 s, total: 1min 34s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:20:40,609 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:20:56,343 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.637, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.943, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.656, F1 Macro: 0.489, Total Pos: 266,847\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 95s - loss: 0.2662 - val_loss: 0.2008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:22:32,201 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min, sys: 39 s, total: 1min 39s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:22:50,243 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:23:14,582 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.639, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.654, F1 Macro: 0.465, Total Pos: 269,813\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 95s - loss: 0.2661 - val_loss: 0.1995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:24:50,411 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 59.6 s, sys: 39.2 s, total: 1min 38s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:24:56,108 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:25:04,870 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.640, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.943, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.447, Total Pos: 256,639\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 91s - loss: 0.2658 - val_loss: 0.1980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:26:36,664 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 57.2 s, sys: 37.9 s, total: 1min 35s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:26:54,972 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:27:19,805 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.625, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.740, Top 3: 0.946, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.484, Total Pos: 282,533\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 98s - loss: 0.2658 - val_loss: 0.1975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:28:58,246 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 2s, sys: 39.8 s, total: 1min 42s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:29:05,446 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:29:30,099 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.631, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.733, Top 3: 0.946, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.661, F1 Macro: 0.471, Total Pos: 276,097\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 96s - loss: 0.2657 - val_loss: 0.1985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:31:06,169 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 57.7 s, sys: 39.9 s, total: 1min 37s\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:31:25,112 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:31:48,517 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.732, Top 3: 0.938, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.672, F1 Macro: 0.449, Total Pos: 295,226\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 97s - loss: 0.2655 - val_loss: 0.1960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:33:26,108 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 1s, sys: 46.9 s, total: 1min 48s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:33:45,391 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:34:09,936 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.612, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.749, Top 3: 0.947, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.673, F1 Macro: 0.510, Total Pos: 269,819\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 99s - loss: 0.2651 - val_loss: 0.1957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:35:49,897 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 2s, sys: 46 s, total: 1min 48s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:36:08,525 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:36:27,175 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.620, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.744, Top 3: 0.945, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.676, F1 Macro: 0.518, Total Pos: 281,954\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 97s - loss: 0.2653 - val_loss: 0.1963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:38:04,205 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 2s, sys: 45.6 s, total: 1min 47s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:38:22,405 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.641, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.945, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.487, Total Pos: 286,206\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:38:48,043 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 45s - loss: 0.2864 - val_loss: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:39:39,214 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 31.6 s, sys: 23.6 s, total: 55.2 s\n",
      "Wall time: 51.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:39:58,108 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:40:23,756 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.782, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.686, Top 3: 0.917, Top 5: 0.980, \n",
      "\t\t F1 Micro: 0.638, F1 Macro: 0.367, Total Pos: 286,361\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 59s - loss: 0.2709 - val_loss: 0.2045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:41:23,096 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35.2 s, sys: 28.9 s, total: 1min 4s\n",
      "Wall time: 59.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:41:41,620 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:42:06,420 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.637, F1 Macro: 0.432, Total Pos: 249,573\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2681 - val_loss: 0.2051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:43:07,921 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 36.5 s, sys: 29.7 s, total: 1min 6s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:43:25,772 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:43:45,194 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.657, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.724, Top 3: 0.942, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.647, F1 Macro: 0.475, Total Pos: 268,660\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 60s - loss: 0.2666 - val_loss: 0.2021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:44:45,645 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35.2 s, sys: 28.7 s, total: 1min 3s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:44:59,910 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:45:23,521 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.667, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.941, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.647, F1 Macro: 0.415, Total Pos: 274,404\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 54s - loss: 0.2658 - val_loss: 0.2002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:46:18,473 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 32 s, sys: 26.5 s, total: 58.5 s\n",
      "Wall time: 54.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:46:36,167 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:47:00,643 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.625, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.740, Top 3: 0.946, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.664, F1 Macro: 0.498, Total Pos: 276,415\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 61s - loss: 0.2652 - val_loss: 0.2020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:48:02,497 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 36.2 s, sys: 29.3 s, total: 1min 5s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:48:20,189 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:48:43,755 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.677, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.721, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.663, F1 Macro: 0.436, Total Pos: 286,090\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 60s - loss: 0.2649 - val_loss: 0.1969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:49:44,177 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35 s, sys: 28.7 s, total: 1min 3s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:50:02,758 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:50:23,157 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.741, Top 3: 0.945, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.685, F1 Macro: 0.507, Total Pos: 299,021\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 66s - loss: 0.2646 - val_loss: 0.1982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:51:30,141 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 37.1 s, sys: 28.6 s, total: 1min 5s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:51:41,871 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:52:06,573 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.741, Top 3: 0.946, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.653, F1 Macro: 0.473, Total Pos: 261,249\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 58s - loss: 0.2643 - val_loss: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:53:05,190 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 33.5 s, sys: 26.5 s, total: 1min\n",
      "Wall time: 58.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:53:09,850 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:53:25,166 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.638, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.732, Top 3: 0.945, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.664, F1 Macro: 0.449, Total Pos: 283,275\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 64s - loss: 0.2643 - val_loss: 0.1968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:54:30,013 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 36.7 s, sys: 28.8 s, total: 1min 5s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:54:38,033 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:55:02,352 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.629, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.740, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.665, F1 Macro: 0.481, Total Pos: 268,183\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 58s - loss: 0.2641 - val_loss: 0.2022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:56:01,005 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 33.5 s, sys: 26.8 s, total: 1min\n",
      "Wall time: 58.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:56:18,842 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:56:43,028 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.674, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.937, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.454, Total Pos: 301,568\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 53s - loss: 0.2639 - val_loss: 0.1963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:57:36,894 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 31.8 s, sys: 24.9 s, total: 56.7 s\n",
      "Wall time: 53.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:57:55,832 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:58:20,534 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.622, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.737, Top 3: 0.948, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.646, F1 Macro: 0.457, Total Pos: 252,998\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 55s - loss: 0.2639 - val_loss: 0.2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:59:15,712 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 32.1 s, sys: 25.2 s, total: 57.3 s\n",
      "Wall time: 55.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 01:59:34,166 : INFO : Generating Validation Metrics\n",
      "2017-01-23 01:59:58,807 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.659, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.940, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.659, F1 Macro: 0.441, Total Pos: 276,067\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 59s - loss: 0.2640 - val_loss: 0.1978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:00:58,178 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 35.2 s, sys: 26.1 s, total: 1min 1s\n",
      "Wall time: 59.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:01:16,349 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:01:32,056 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.643, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.725, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.654, F1 Macro: 0.457, Total Pos: 276,519\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 65s - loss: 0.2638 - val_loss: 0.1969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:02:37,802 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 38 s, sys: 28.6 s, total: 1min 6s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:02:49,256 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.643, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.736, Top 3: 0.942, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.671, F1 Macro: 0.455, Total Pos: 290,945\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:03:14,123 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 43s - loss: 0.2922 - val_loss: 0.2192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:04:03,649 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 29.6 s, sys: 20.5 s, total: 50.1 s\n",
      "Wall time: 49.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:04:15,782 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:04:37,479 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.748, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.684, Top 3: 0.928, Top 5: 0.984, \n",
      "\t\t F1 Micro: 0.600, F1 Macro: 0.359, Total Pos: 244,661\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 41s - loss: 0.2726 - val_loss: 0.2115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:05:19,100 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 23 s, sys: 19.5 s, total: 42.5 s\n",
      "Wall time: 41.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:05:32,660 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:05:51,639 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.689, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.718, Top 3: 0.935, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.623, F1 Macro: 0.412, Total Pos: 245,614\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 41s - loss: 0.2689 - val_loss: 0.2092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:06:33,550 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 23.3 s, sys: 19.1 s, total: 42.4 s\n",
      "Wall time: 41.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:06:50,593 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:07:00,402 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.711, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.700, Top 3: 0.933, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.629, F1 Macro: 0.400, Total Pos: 274,559\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.2670 - val_loss: 0.2063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:07:32,519 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 17.3 s, sys: 16.5 s, total: 33.8 s\n",
      "Wall time: 32.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:07:49,688 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:08:13,042 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.690, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.717, Top 3: 0.932, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.636, F1 Macro: 0.413, Total Pos: 253,934\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 33s - loss: 0.2660 - val_loss: 0.2010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:08:46,644 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 18.8 s, sys: 17 s, total: 35.8 s\n",
      "Wall time: 33.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:09:03,835 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:09:27,080 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.654, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.729, Top 3: 0.941, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.646, F1 Macro: 0.438, Total Pos: 260,230\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.2652 - val_loss: 0.1971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:09:56,737 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 16.3 s, sys: 15.8 s, total: 32 s\n",
      "Wall time: 29.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:10:06,870 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:10:20,406 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.619, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.746, Top 3: 0.946, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.469, Total Pos: 273,493\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.2645 - val_loss: 0.1986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:10:45,235 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 14.1 s, sys: 13.9 s, total: 28 s\n",
      "Wall time: 24.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:10:54,238 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:11:11,006 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.660, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.722, Top 3: 0.940, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.652, F1 Macro: 0.445, Total Pos: 269,235\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 38s - loss: 0.2643 - val_loss: 0.1965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:11:49,853 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 21 s, sys: 18.1 s, total: 39.1 s\n",
      "Wall time: 38.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:12:01,856 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:12:19,188 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.641, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.735, Top 3: 0.942, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.667, F1 Macro: 0.462, Total Pos: 278,876\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 38s - loss: 0.2640 - val_loss: 0.1968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:12:57,716 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 21.1 s, sys: 17.9 s, total: 39 s\n",
      "Wall time: 38.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:13:13,181 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:13:28,550 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.638, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.668, F1 Macro: 0.475, Total Pos: 288,099\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 37s - loss: 0.2638 - val_loss: 0.1963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:14:06,369 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 21 s, sys: 17.5 s, total: 38.6 s\n",
      "Wall time: 37.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:14:22,775 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:14:36,397 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.619, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.738, Top 3: 0.948, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.654, F1 Macro: 0.464, Total Pos: 260,415\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 37s - loss: 0.2634 - val_loss: 0.2001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:15:13,795 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 20.9 s, sys: 18 s, total: 38.9 s\n",
      "Wall time: 37.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:15:29,749 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:15:44,320 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.641, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.731, Top 3: 0.944, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.659, F1 Macro: 0.462, Total Pos: 282,548\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 35s - loss: 0.2635 - val_loss: 0.1935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:16:19,948 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 18.9 s, sys: 17.5 s, total: 36.4 s\n",
      "Wall time: 35.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:16:35,021 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:16:52,729 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.602, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.747, Top 3: 0.950, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.678, F1 Macro: 0.502, Total Pos: 290,620\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.2632 - val_loss: 0.1947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:17:23,331 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 16.2 s, sys: 16 s, total: 32.3 s\n",
      "Wall time: 30.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:17:38,766 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:18:01,393 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.621, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.738, Top 3: 0.947, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.658, F1 Macro: 0.469, Total Pos: 266,806\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.2630 - val_loss: 0.1956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:18:31,849 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 15.7 s, sys: 16.5 s, total: 32.3 s\n",
      "Wall time: 30.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:18:47,231 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:19:09,777 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.610, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.742, Top 3: 0.950, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.650, F1 Macro: 0.502, Total Pos: 255,701\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2629 - val_loss: 0.1984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:19:30,602 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.1 s, sys: 13.1 s, total: 24.1 s\n",
      "Wall time: 20.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:19:45,517 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.612, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.744, Top 3: 0.948, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.661, F1 Macro: 0.518, Total Pos: 264,403\n",
      "===================================================================================\n",
      "========== 1st Layer Size: 200, 1st Layer Activation: tanh, \n",
      " 2nd Layer Size: 500, 2nd Layer Activation: tanh, \n",
      "Input Dropout: True, Hidden Dropout: True \n",
      "==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)             (None, 100)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           20200       dropout_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 500)           100500      dropout_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:20:09,190 : INFO : ======= NN Epoch: 1 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124708\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.3015 - val_loss: 0.2350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:20:31,995 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 13.9 s, sys: 10.2 s, total: 24.1 s\n",
      "Wall time: 22.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:20:41,434 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:21:04,015 : INFO : ======= NN Epoch: 2 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.797, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.676, Top 3: 0.917, Top 5: 0.980, \n",
      "\t\t F1 Micro: 0.527, F1 Macro: 0.246, Total Pos: 209,201\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2775 - val_loss: 0.2228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:21:25,732 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 12 s, sys: 10.8 s, total: 22.8 s\n",
      "Wall time: 21.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:21:37,779 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:21:55,280 : INFO : ======= NN Epoch: 3 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.774, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.658, Top 3: 0.929, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.590, F1 Macro: 0.364, Total Pos: 262,715\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2717 - val_loss: 0.2108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:22:16,570 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.4 s, sys: 11.1 s, total: 22.4 s\n",
      "Wall time: 21.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:22:30,670 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:22:49,712 : INFO : ======= NN Epoch: 4 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.708, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.712, Top 3: 0.931, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.643, F1 Macro: 0.376, Total Pos: 280,861\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.2692 - val_loss: 0.2108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:23:06,700 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 8.64 s, sys: 9.77 s, total: 18.4 s\n",
      "Wall time: 17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:23:20,964 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:23:43,813 : INFO : ======= NN Epoch: 5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.706, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.697, Top 3: 0.936, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.627, F1 Macro: 0.393, Total Pos: 273,790\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.2673 - val_loss: 0.2031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:24:00,878 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 9.3 s, sys: 9.83 s, total: 19.1 s\n",
      "Wall time: 17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:24:15,105 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:24:37,815 : INFO : ======= NN Epoch: 6 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.656, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.726, Top 3: 0.943, Top 5: 0.986, \n",
      "\t\t F1 Micro: 0.652, F1 Macro: 0.459, Total Pos: 275,756\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2661 - val_loss: 0.2020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:24:58,839 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.2 s, sys: 11.2 s, total: 22.4 s\n",
      "Wall time: 21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:25:06,465 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:25:26,638 : INFO : ======= NN Epoch: 7 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.652, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.732, Top 3: 0.941, Top 5: 0.987, \n",
      "\t\t F1 Micro: 0.644, F1 Macro: 0.429, Total Pos: 260,530\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 21s - loss: 0.2653 - val_loss: 0.2043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:25:48,177 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.2 s, sys: 11 s, total: 22.2 s\n",
      "Wall time: 21.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:26:02,180 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:26:16,608 : INFO : ======= NN Epoch: 8 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.673, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.714, Top 3: 0.941, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.640, F1 Macro: 0.422, Total Pos: 270,169\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.2649 - val_loss: 0.1973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:26:35,772 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 10.2 s, sys: 10.3 s, total: 20.5 s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:26:49,889 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:27:12,696 : INFO : ======= NN Epoch: 9 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.626, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.737, Top 3: 0.948, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.658, F1 Macro: 0.473, Total Pos: 268,516\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.2642 - val_loss: 0.2025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:27:30,309 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 9.38 s, sys: 10.3 s, total: 19.7 s\n",
      "Wall time: 17.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:27:43,264 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:28:05,710 : INFO : ======= NN Epoch: 10 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.665, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.727, Top 3: 0.939, Top 5: 0.985, \n",
      "\t\t F1 Micro: 0.666, F1 Macro: 0.479, Total Pos: 296,239\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2638 - val_loss: 0.1985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:28:26,167 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.1 s, sys: 11.3 s, total: 22.3 s\n",
      "Wall time: 20.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:28:35,890 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:28:55,270 : INFO : ======= NN Epoch: 11 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.661, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.719, Top 3: 0.940, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.656, F1 Macro: 0.445, Total Pos: 285,264\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2638 - val_loss: 0.1965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:29:15,812 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.2 s, sys: 11.3 s, total: 22.5 s\n",
      "Wall time: 20.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:29:29,942 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:29:45,537 : INFO : ======= NN Epoch: 12 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.640, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.731, Top 3: 0.944, Top 5: 0.989, \n",
      "\t\t F1 Micro: 0.664, F1 Macro: 0.443, Total Pos: 285,562\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.2635 - val_loss: 0.1988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:03,898 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 9.66 s, sys: 10.1 s, total: 19.8 s\n",
      "Wall time: 18.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:11,597 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:30:24,512 : INFO : ======= NN Epoch: 13 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.642, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.730, Top 3: 0.943, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.671, F1 Macro: 0.466, Total Pos: 303,967\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 13s - loss: 0.2631 - val_loss: 0.1949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:38,081 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 7.46 s, sys: 7.78 s, total: 15.2 s\n",
      "Wall time: 13.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:30:49,630 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:30:59,570 : INFO : ======= NN Epoch: 14 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.607, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.746, Top 3: 0.949, Top 5: 0.990, \n",
      "\t\t F1 Micro: 0.661, F1 Macro: 0.488, Total Pos: 265,989\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.2632 - val_loss: 0.1991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:31:13,962 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 7.29 s, sys: 8.3 s, total: 15.6 s\n",
      "Wall time: 14.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:31:28,660 : INFO : Generating Validation Metrics\n",
      "2017-01-23 02:31:51,300 : INFO : ======= NN Epoch: 15 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.625, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.738, Top 3: 0.948, Top 5: 0.988, \n",
      "\t\t F1 Micro: 0.651, F1 Macro: 0.464, Total Pos: 267,543\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/1\n",
      "1286325/1286325 [==============================] - 20s - loss: 0.2630 - val_loss: 0.1998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:32:11,581 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.4 s, sys: 9.79 s, total: 21.2 s\n",
      "Wall time: 20.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 02:32:18,510 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.676, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.731, Top 3: 0.935, Top 5: 0.983, \n",
      "\t\t F1 Micro: 0.677, F1 Macro: 0.433, Total Pos: 308,801\n"
     ]
    }
   ],
   "source": [
    "batch_dict = {}\n",
    "for batch_sz in [64,128,256,512,1024,2048]:\n",
    "# for batch_sz in [2048]:\n",
    "    NN_BATCH_SIZE = batch_sz\n",
    "    batch_dict[batch_sz] = {}\n",
    "    start_time = time.time()\n",
    "    param_sampler = ParameterSampler({\n",
    "            'first_hidden_layer_size':first_hidden_layer_sizes,\n",
    "            'first_hidden_layer_activation':first_hidden_layer_activations,\n",
    "            'second_hidden_layer_size':second_hidden_layer_sizes,\n",
    "            'second_hidden_layer_activation':second_hidden_layer_activations,\n",
    "            'input_dropout':input_dropout_options,\n",
    "            'hidden_dropout':hidden_dropout_options\n",
    "        }, n_iter=NN_RANDOM_SEARCH_BUDGET, random_state=NN_PARAM_SAMPLE_SEED)\n",
    "    for parameters in param_sampler:\n",
    "        first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "        first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "        second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "        second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "        input_dropout_do = parameters['input_dropout']\n",
    "        hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "        print (\"===================================================================================\\n\" + \\\n",
    "              \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "              \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "              \"==========================\").format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                                    second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                                    input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "        GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "            first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "            second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "        )\n",
    "\n",
    "        model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                      first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                      second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                      input_dropout_do, hidden_dropout_do)\n",
    "        model.summary()\n",
    "        \n",
    "        batch_dict[batch_sz]['metrics'] = []\n",
    "        batch_dict[batch_sz]['history'] = []\n",
    "\n",
    "        for nn_epoch in range(1, NN_MAX_EPOCHS+1):\n",
    "            info('======= NN Epoch: {} =========='.format(nn_epoch)) \n",
    "            %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, nb_epoch=1, verbose=1, callbacks=[early_stopper])\n",
    "    #         info('Evaluating on Training Data')\n",
    "    #         yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "    #         yp_binary = get_binary_0_5(yp)\n",
    "    #         #print yp\n",
    "    #         info('Generating Training Metrics')\n",
    "    #         training_metrics = get_metrics(y, yp, yp_binary)\n",
    "    #         print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    #             training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "    #             training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "    #             training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "            info('Evaluating on Validation Data')\n",
    "            yvp = model.predict(Xv)\n",
    "            yvp_binary = get_binary_0_5(yvp)\n",
    "            #print yvp\n",
    "            info('Generating Validation Metrics')\n",
    "            validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "            print \"****** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "                validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "                validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "            \n",
    "            batch_dict[batch_sz]['metrics'].append(validation_metrics)\n",
    "            batch_dict[batch_sz]['history'].append(history)\n",
    "            \n",
    "        break\n",
    "    duration = time.time() - start_time\n",
    "    batch_dict[batch_sz]['duration'] =  duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Batch Size: 64\n",
      "Duration => 2902.9390409\n",
      "Loss History => [0.28, 0.273, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272, 0.272]\n",
      "Val Loss Hist => [0.211, 0.207, 0.208, 0.208, 0.203, 0.203, 0.206, 0.206, 0.204, 0.204, 0.205, 0.207, 0.21, 0.205, 0.206]\n",
      "Cov Erro Hist=> [1.709, 1.664, 1.684, 1.688, 1.675, 1.676, 1.708, 1.676, 1.66, 1.665, 1.669, 1.691, 1.711, 1.676, 1.7]\n",
      "F1 Micro Hist=> [0.633, 0.627, 0.634, 0.631, 0.647, 0.648, 0.641, 0.65, 0.642, 0.658, 0.65, 0.632, 0.605, 0.637, 0.663]\n",
      "F1 Macro Hist=> [0.416, 0.455, 0.436, 0.433, 0.446, 0.434, 0.439, 0.46, 0.459, 0.435, 0.482, 0.423, 0.421, 0.451, 0.458]\n",
      "Coverage Error Max: 8 => 1.66 | F1 Micro Max: 14 => 0.663 | F1 Macro Max: 10 => 0.482\n",
      "========== Batch Size: 128\n",
      "Duration => 2890.55074692\n",
      "Loss History => [0.28, 0.271, 0.27, 0.269, 0.269, 0.269, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268, 0.268]\n",
      "Val Loss Hist => [0.209, 0.203, 0.203, 0.202, 0.202, 0.203, 0.203, 0.208, 0.201, 0.201, 0.198, 0.2, 0.198, 0.199, 0.203]\n",
      "Cov Erro Hist=> [1.686, 1.647, 1.665, 1.668, 1.668, 1.649, 1.691, 1.745, 1.656, 1.628, 1.646, 1.656, 1.643, 1.65, 1.66]\n",
      "F1 Micro Hist=> [0.63, 0.645, 0.643, 0.641, 0.66, 0.648, 0.645, 0.645, 0.635, 0.651, 0.666, 0.634, 0.667, 0.672, 0.677]\n",
      "F1 Macro Hist=> [0.424, 0.444, 0.448, 0.45, 0.445, 0.505, 0.416, 0.41, 0.441, 0.507, 0.499, 0.442, 0.494, 0.465, 0.506]\n",
      "Coverage Error Max: 9 => 1.628 | F1 Micro Max: 14 => 0.677 | F1 Macro Max: 9 => 0.507\n",
      "========== Batch Size: 256\n",
      "Duration => 2648.8733201\n",
      "Loss History => [0.282, 0.27, 0.268, 0.267, 0.267, 0.267, 0.266, 0.266, 0.266, 0.266, 0.266, 0.266, 0.265, 0.265, 0.265]\n",
      "Val Loss Hist => [0.209, 0.206, 0.203, 0.2, 0.201, 0.203, 0.199, 0.201, 0.2, 0.198, 0.198, 0.199, 0.196, 0.196, 0.196]\n",
      "Cov Erro Hist=> [1.677, 1.685, 1.658, 1.629, 1.626, 1.685, 1.637, 1.639, 1.64, 1.625, 1.631, 1.66, 1.612, 1.62, 1.641]\n",
      "F1 Micro Hist=> [0.63, 0.64, 0.662, 0.651, 0.651, 0.651, 0.656, 0.654, 0.65, 0.668, 0.661, 0.672, 0.673, 0.676, 0.668]\n",
      "F1 Macro Hist=> [0.413, 0.404, 0.461, 0.479, 0.468, 0.405, 0.489, 0.465, 0.447, 0.484, 0.471, 0.449, 0.51, 0.518, 0.487]\n",
      "Coverage Error Max: 12 => 1.612 | F1 Micro Max: 13 => 0.676 | F1 Macro Max: 13 => 0.518\n",
      "========== Batch Size: 512\n",
      "Duration => 1466.01992393\n",
      "Loss History => [0.286, 0.271, 0.268, 0.267, 0.266, 0.265, 0.265, 0.265, 0.264, 0.264, 0.264, 0.264, 0.264, 0.264, 0.264]\n",
      "Val Loss Hist => [0.219, 0.205, 0.205, 0.202, 0.2, 0.202, 0.197, 0.198, 0.197, 0.197, 0.202, 0.196, 0.2, 0.198, 0.197]\n",
      "Cov Erro Hist=> [1.782, 1.656, 1.657, 1.667, 1.625, 1.677, 1.626, 1.626, 1.638, 1.629, 1.674, 1.622, 1.659, 1.643, 1.643]\n",
      "F1 Micro Hist=> [0.638, 0.637, 0.647, 0.647, 0.664, 0.663, 0.685, 0.653, 0.664, 0.665, 0.668, 0.646, 0.659, 0.654, 0.671]\n",
      "F1 Macro Hist=> [0.367, 0.432, 0.475, 0.415, 0.498, 0.436, 0.507, 0.473, 0.449, 0.481, 0.454, 0.457, 0.441, 0.457, 0.455]\n",
      "Coverage Error Max: 11 => 1.622 | F1 Micro Max: 6 => 0.685 | F1 Macro Max: 6 => 0.507\n",
      "========== Batch Size: 1024\n",
      "Duration => 1015.32090187\n",
      "Loss History => [0.292, 0.273, 0.269, 0.267, 0.266, 0.265, 0.265, 0.264, 0.264, 0.264, 0.263, 0.264, 0.263, 0.263, 0.263]\n",
      "Val Loss Hist => [0.219, 0.211, 0.209, 0.206, 0.201, 0.197, 0.199, 0.197, 0.197, 0.196, 0.2, 0.194, 0.195, 0.196, 0.198]\n",
      "Cov Erro Hist=> [1.748, 1.689, 1.711, 1.69, 1.654, 1.619, 1.66, 1.641, 1.638, 1.619, 1.641, 1.602, 1.621, 1.61, 1.612]\n",
      "F1 Micro Hist=> [0.6, 0.623, 0.629, 0.636, 0.646, 0.668, 0.652, 0.667, 0.668, 0.654, 0.659, 0.678, 0.658, 0.65, 0.661]\n",
      "F1 Macro Hist=> [0.359, 0.412, 0.4, 0.413, 0.438, 0.469, 0.445, 0.462, 0.475, 0.464, 0.462, 0.502, 0.469, 0.502, 0.518]\n",
      "Coverage Error Max: 11 => 1.602 | F1 Micro Max: 11 => 0.678 | F1 Macro Max: 14 => 0.518\n",
      "========== Batch Size: 2048\n",
      "Duration => 753.347830057\n",
      "Loss History => [0.301, 0.277, 0.272, 0.269, 0.267, 0.266, 0.265, 0.265, 0.264, 0.264, 0.264, 0.263, 0.263, 0.263, 0.263]\n",
      "Val Loss Hist => [0.235, 0.223, 0.211, 0.211, 0.203, 0.202, 0.204, 0.197, 0.202, 0.198, 0.196, 0.199, 0.195, 0.199, 0.2]\n",
      "Cov Erro Hist=> [1.797, 1.774, 1.708, 1.706, 1.656, 1.652, 1.673, 1.626, 1.665, 1.661, 1.64, 1.642, 1.607, 1.625, 1.676]\n",
      "F1 Micro Hist=> [0.527, 0.59, 0.643, 0.627, 0.652, 0.644, 0.64, 0.658, 0.666, 0.656, 0.664, 0.671, 0.661, 0.651, 0.677]\n",
      "F1 Macro Hist=> [0.246, 0.364, 0.376, 0.393, 0.459, 0.429, 0.422, 0.473, 0.479, 0.445, 0.443, 0.466, 0.488, 0.464, 0.433]\n",
      "Coverage Error Max: 12 => 1.607 | F1 Micro Max: 14 => 0.677 | F1 Macro Max: 12 => 0.488\n"
     ]
    }
   ],
   "source": [
    "for sz in sorted(batch_dict.keys()):\n",
    "    print '========== Batch Size: {}'.format(sz)\n",
    "    print 'Duration => {}'.format(batch_dict[sz]['duration'])\n",
    "    print 'Loss History => {}'.format([round(hist.history['loss'][0],3) for hist in batch_dict[sz]['history']])\n",
    "    print 'Val Loss Hist => {}'.format([round(hist.history['val_loss'][0],3) for hist in batch_dict[sz]['history']])\n",
    "    cov_error_history = [round(metrics['coverage_error'],3) for metrics in batch_dict[sz]['metrics']]\n",
    "    f1_micro_history = [round(metrics['f1_micro'],3) for metrics in batch_dict[sz]['metrics']]\n",
    "    f1_macro_history = [round(metrics['f1_macro'],3) for metrics in batch_dict[sz]['metrics']]\n",
    "    print 'Cov Erro Hist=> {}'.format(cov_error_history)\n",
    "    print 'F1 Micro Hist=> {}'.format(f1_micro_history)\n",
    "    print 'F1 Macro Hist=> {}'.format(f1_macro_history)\n",
    "    print 'Coverage Error Max: {} => {} | F1 Micro Max: {} => {} | F1 Macro Max: {} => {}'.format(np.argmin(cov_error_history),\n",
    "                                                                                                np.min(cov_error_history),\n",
    "                                                                                                np.argmax(f1_micro_history),\n",
    "                                                                                                np.max(f1_micro_history), \n",
    "                                                                                                np.argmax(f1_macro_history),\n",
    "                                                                                                np.max(f1_macro_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(batch_dict, open('/mnt/data2/shalaby/exported_data/nn_batch_sizes.pkl','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Parameter searches for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopper_deltas = {\n",
    "    'sections': 0.0001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "early_stopper_patience = {\n",
    "    'sections': 5,\n",
    "    'classes': 10,\n",
    "    'subclasses': 10\n",
    "}\n",
    "epochs_before_validation = {\n",
    "    'sections': 50,\n",
    "    'classes': 50,\n",
    "    'subclasses': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            time.sleep(0.2)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                yvp = self.model.predict(Xv)\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_sampler = ParameterSampler({\n",
    "        'first_hidden_layer_size':first_hidden_layer_sizes,\n",
    "        'first_hidden_layer_activation':first_hidden_layer_activations,\n",
    "        'second_hidden_layer_size':second_hidden_layer_sizes,\n",
    "        'second_hidden_layer_activation':second_hidden_layer_activations,\n",
    "        'input_dropout':input_dropout_options,\n",
    "        'hidden_dropout':hidden_dropout_options\n",
    "    }, n_iter=NN_RANDOM_SEARCH_BUDGET, random_state=NN_PARAM_SAMPLE_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_200_2nd-act_softmax_in-drop_True_hid-drop_True\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_1000_2nd-act_tanh_in-drop_False_hid-drop_False\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_1000_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "nn_1st-size_500_1st-act_relu_2nd-size_200_2nd-act_tanh_in-drop_True_hid-drop_False\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_200_2nd-act_tanh_in-drop_False_hid-drop_False\n",
      "nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_softmax_2nd-size_500_2nd-act_softmax_in-drop_True_hid-drop_True\n",
      "nn_1st-size_200_1st-act_relu_2nd-size_1000_2nd-act_sigmoid_in-drop_True_hid-drop_True\n"
     ]
    }
   ],
   "source": [
    "for parameters in param_sampler:\n",
    "    start_time = time.time()\n",
    "    first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "    first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "    second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "    second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "    input_dropout_do = parameters['input_dropout']\n",
    "    hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "    dd = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "        first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "        second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "    )\n",
    "    print dd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_results_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load param results if needed to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_results_dict = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_skip = []\n",
    "# to_skip = ['nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False', \n",
    "#            'nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True']\n",
    "to_skip = [\n",
    "    'nn_1st-size_500_1st-act_tanh_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_True'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 05:59:48,688 : INFO : ***************************************************************************************\n",
      "2017-02-02 05:59:48,690 : INFO : nn_1st-size_500_1st-act_relu_2nd-size_2000_2nd-act_sigmoid_in-drop_True_hid-drop_False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_200_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "skipping: nn_1st-size_200_1st-act_relu_2nd-size_1000_2nd-act_tanh_in-drop_True_hid-drop_False\n",
      "skipping: nn_1st-size_200_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_sigmoid_2nd-size_200_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_sigmoid_2nd-size_2000_2nd-act_tanh_in-drop_False_hid-drop_False\n",
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_500_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_tanh_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_200_1st-act_softmax_2nd-size_200_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_tanh_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_200_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "skipping: nn_1st-size_200_1st-act_tanh_2nd-size_2000_2nd-act_tanh_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_200_1st-act_tanh_2nd-size_2000_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "skipping: nn_1st-size_200_1st-act_tanh_2nd-size_2000_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_softmax_2nd-size_1000_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_200_2nd-act_tanh_in-drop_True_hid-drop_False\n",
      "skipping: nn_1st-size_200_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_True\n",
      "skipping: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "skipping: nn_1st-size_500_1st-act_tanh_2nd-size_2000_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "skipping: nn_1st-size_500_1st-act_relu_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "skipping: nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "skipping: nn_1st-size_500_1st-act_tanh_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 200)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           100500      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_sigmoid (Dense)    (None, 2000)          1002000     hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           1880940     hidden_layer2_sigmoid[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 2983440\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:00:28,257 : INFO : Found lower val loss for epoch 1 => 0.00583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 34s - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 2/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:01:00,260 : INFO : Found lower val loss for epoch 2 => 0.00522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:01:32,265 : INFO : Found lower val loss for epoch 3 => 0.00472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:02:03,880 : INFO : Found lower val loss for epoch 4 => 0.00434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 5/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:02:35,953 : INFO : Found lower val loss for epoch 5 => 0.00422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 6/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:03:07,734 : INFO : Found lower val loss for epoch 6 => 0.00412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 7/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:03:39,315 : INFO : Found lower val loss for epoch 7 => 0.00403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 8/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:04:11,131 : INFO : Found lower val loss for epoch 8 => 0.00397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 9/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:04:43,006 : INFO : Found lower val loss for epoch 9 => 0.00393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 10/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:05:14,950 : INFO : Found lower val loss for epoch 10 => 0.00391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 11/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:05:47,157 : INFO : Found lower val loss for epoch 11 => 0.00389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 12/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:06:19,180 : INFO : Found lower val loss for epoch 12 => 0.00384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 13/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:06:50,842 : INFO : Found lower val loss for epoch 13 => 0.00382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 14/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 15/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:07:54,378 : INFO : Found lower val loss for epoch 15 => 0.00379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 16/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:08:26,072 : INFO : Found lower val loss for epoch 16 => 0.00374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 17/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:08:57,995 : INFO : Found lower val loss for epoch 17 => 0.00371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 18/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:09:30,196 : INFO : Found lower val loss for epoch 18 => 0.00371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 21/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:11:06,548 : INFO : Found lower val loss for epoch 21 => 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 22/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 23/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 24/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 25/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:13:12,736 : INFO : Found lower val loss for epoch 25 => 0.00369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 26/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 27/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 28/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 30/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 31/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 32/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 34/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 35/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:18:28,095 : INFO : Found lower val loss for epoch 35 => 0.00366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 36/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 37/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 38/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 39/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 40/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:21:05,653 : INFO : Found lower val loss for epoch 40 => 0.00364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 41/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 42/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 43/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:22:40,558 : INFO : Found lower val loss for epoch 43 => 0.00362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 44/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 45/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 46/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 47/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 48/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:25:19,203 : INFO : Found lower val loss for epoch 48 => 0.00362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 49/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 50/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 51/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 52/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 53/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 54/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0049 - val_loss: 0.0036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:28:28,903 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: early stopping\n",
      "CPU times: user 13min 38s, sys: 15min 57s, total: 29min 36s\n",
      "Wall time: 28min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:29:46,887 : INFO : Generating Validation Metrics\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.485 | Top 3: 0.711 | Top 5: 0.794 | F1 Micro: 0.473 | F1 Macro: 0.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:38:42,862 : INFO : Evaluating on Validation Data using saved best weights\n",
      "2017-02-02 06:39:49,354 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.314 | Top 3: 0.711 | Top 5: 0.795 | F1 Micro: 0.468 | F1 Macro: 0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:47:51,015 : INFO : ***************************************************************************************\n",
      "2017-02-02 06:47:51,079 : INFO : nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_tanh_in-drop_True_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 200)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           100500      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 500)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_tanh (Dense)       (None, 50)            25050       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           47940       hidden_layer2_tanh[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 173490\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:48:20,336 : INFO : Found lower val loss for epoch 1 => 0.00812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0506 - val_loss: 0.0081\n",
      "Epoch 2/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:48:38,462 : INFO : Found lower val loss for epoch 2 => 0.00812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 3/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:48:56,337 : INFO : Found lower val loss for epoch 3 => 0.00811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 4/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:49:14,307 : INFO : Found lower val loss for epoch 4 => 0.00755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 5/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:49:32,408 : INFO : Found lower val loss for epoch 5 => 0.00673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 6/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:49:49,969 : INFO : Found lower val loss for epoch 6 => 0.00625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 7/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0067"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:50:08,000 : INFO : Found lower val loss for epoch 7 => 0.00602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 8/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:50:25,992 : INFO : Found lower val loss for epoch 8 => 0.00586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 9/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:50:44,064 : INFO : Found lower val loss for epoch 9 => 0.00578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 10/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:51:01,945 : INFO : Found lower val loss for epoch 10 => 0.00567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:51:19,759 : INFO : Found lower val loss for epoch 11 => 0.00561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 12/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:51:37,416 : INFO : Found lower val loss for epoch 12 => 0.00559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 13/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:51:55,188 : INFO : Found lower val loss for epoch 13 => 0.00553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 14/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 15/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:52:30,904 : INFO : Found lower val loss for epoch 15 => 0.00545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 16/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 18/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:53:25,003 : INFO : Found lower val loss for epoch 18 => 0.00539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 21/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 22/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:54:36,236 : INFO : Found lower val loss for epoch 22 => 0.00538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 23/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 24/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 25/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:55:29,531 : INFO : Found lower val loss for epoch 25 => 0.00534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 26/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:55:47,286 : INFO : Found lower val loss for epoch 26 => 0.00533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 27/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:56:05,373 : INFO : Found lower val loss for epoch 27 => 0.00532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 28/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 30/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 31/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 32/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 33/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 34/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 35/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:58:27,219 : INFO : Found lower val loss for epoch 35 => 0.00527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 36/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 37/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 38/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 39/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 40/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 41/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 42/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 43/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 44/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:01:08,507 : INFO : Found lower val loss for epoch 44 => 0.00524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 45/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 46/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 47/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 48/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:02:20,172 : INFO : Found lower val loss for epoch 48 => 0.00523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 49/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 50/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 51/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 52/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 53/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 54/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 55/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 56/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 57/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 58/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 59/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0062 - val_loss: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:05:36,193 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00058: early stopping\n",
      "CPU times: user 9min 59s, sys: 8min 41s, total: 18min 40s\n",
      "Wall time: 17min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:06:34,022 : INFO : Generating Validation Metrics\n",
      "2017-02-02 07:14:15,501 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 20.590 | Top 3: 0.512 | Top 5: 0.603 | F1 Micro: 0.250 | F1 Macro: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:15:10,358 : INFO : Generating Validation Metrics\n",
      "2017-02-02 07:22:52,189 : INFO : ***************************************************************************************\n",
      "2017-02-02 07:22:52,191 : INFO : nn_1st-size_200_1st-act_tanh_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 20.426 | Top 3: 0.512 | Top 5: 0.603 | F1 Micro: 0.241 | F1 Macro: 0.005\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           40200       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           188940      dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 229140\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:23:13,379 : INFO : Found lower val loss for epoch 1 => 0.00559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0304 - val_loss: 0.0056\n",
      "Epoch 2/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:23:29,717 : INFO : Found lower val loss for epoch 2 => 0.00453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 3/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:23:46,829 : INFO : Found lower val loss for epoch 3 => 0.00424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 4/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:24:03,897 : INFO : Found lower val loss for epoch 4 => 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 5/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:24:20,966 : INFO : Found lower val loss for epoch 5 => 0.00408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 6/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:24:37,818 : INFO : Found lower val loss for epoch 6 => 0.00404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:24:54,809 : INFO : Found lower val loss for epoch 7 => 0.00403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 8/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 9/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 10/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:25:43,744 : INFO : Found lower val loss for epoch 10 => 0.00397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 11/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 12/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:26:18,233 : INFO : Found lower val loss for epoch 12 => 0.00396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 13/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 14/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 16/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:27:25,339 : INFO : Found lower val loss for epoch 16 => 0.00395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 18/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 21/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 22/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:29:04,549 : INFO : Found lower val loss for epoch 22 => 0.00395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 23/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:29:21,604 : INFO : Found lower val loss for epoch 23 => 0.00393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 24/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 25/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 26/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 27/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 30/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:31:15,342 : INFO : Found lower val loss for epoch 30 => 0.00392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 31/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 32/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 33/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 34/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0043 - val_loss: 0.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:32:20,024 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: early stopping\n",
      "CPU times: user 5min 28s, sys: 4min 34s, total: 10min 3s\n",
      "Wall time: 9min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:33:15,373 : INFO : Generating Validation Metrics\n",
      "2017-02-02 07:41:01,271 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.867 | Top 3: 0.695 | Top 5: 0.781 | F1 Micro: 0.423 | F1 Macro: 0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:41:55,751 : INFO : Generating Validation Metrics\n",
      "2017-02-02 07:49:39,451 : INFO : ***************************************************************************************\n",
      "2017-02-02 07:49:39,453 : INFO : nn_1st-size_200_1st-act_relu_2nd-size_None_2nd-act_tanh_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.822 | Top 3: 0.696 | Top 5: 0.782 | F1 Micro: 0.428 | F1 Macro: 0.062\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 200)           40200       doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 200)           0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           188940      dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 229140\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:49:58,185 : INFO : Found lower val loss for epoch 1 => 0.00507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0295 - val_loss: 0.0051\n",
      "Epoch 2/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:50:12,663 : INFO : Found lower val loss for epoch 2 => 0.00431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 3/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:50:27,261 : INFO : Found lower val loss for epoch 3 => 0.00412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 4/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:50:42,695 : INFO : Found lower val loss for epoch 4 => 0.00407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 5/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:50:58,316 : INFO : Found lower val loss for epoch 5 => 0.00401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 6/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:51:14,071 : INFO : Found lower val loss for epoch 6 => 0.00399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:51:30,644 : INFO : Found lower val loss for epoch 7 => 0.00397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 8/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:51:47,628 : INFO : Found lower val loss for epoch 8 => 0.00396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 9/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 11/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 12/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 13/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 14/100\n",
      "1286325/1286325 [==============================] - 14s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 17s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 16/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 15s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 18/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:54:45,779 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: early stopping\n",
      "CPU times: user 3min 1s, sys: 2min 26s, total: 5min 27s\n",
      "Wall time: 5min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:55:41,341 : INFO : Generating Validation Metrics\n",
      "2017-02-02 08:03:20,165 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.373 | Top 3: 0.696 | Top 5: 0.784 | F1 Micro: 0.367 | F1 Macro: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:04:13,893 : INFO : Generating Validation Metrics\n",
      "2017-02-02 08:11:52,609 : INFO : ***************************************************************************************\n",
      "2017-02-02 08:11:52,610 : INFO : nn_1st-size_500_1st-act_sigmoid_2nd-size_1000_2nd-act_sigmoid_in-drop_True_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.573 | Top 3: 0.690 | Top 5: 0.778 | F1 Micro: 0.363 | F1 Macro: 0.032\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 200)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           100500      dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 500)           0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_sigmoid (Dense)    (None, 1000)          501000      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           940940      hidden_layer2_sigmoid[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 1542440\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:12:19,670 : INFO : Found lower val loss for epoch 1 => 0.00703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0115 - val_loss: 0.0070\n",
      "Epoch 2/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0067"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:12:44,257 : INFO : Found lower val loss for epoch 2 => 0.00591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 3/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:13:07,586 : INFO : Found lower val loss for epoch 3 => 0.00546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 4/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:13:30,377 : INFO : Found lower val loss for epoch 4 => 0.00521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 5/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:13:53,829 : INFO : Found lower val loss for epoch 5 => 0.00499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 6/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:14:18,716 : INFO : Found lower val loss for epoch 6 => 0.00482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 7/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:14:42,753 : INFO : Found lower val loss for epoch 7 => 0.00474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 8/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:15:06,793 : INFO : Found lower val loss for epoch 8 => 0.00463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 9/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:15:30,291 : INFO : Found lower val loss for epoch 9 => 0.00455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 10/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:15:54,443 : INFO : Found lower val loss for epoch 10 => 0.00451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 11/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:16:19,126 : INFO : Found lower val loss for epoch 11 => 0.00446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 12/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:16:43,027 : INFO : Found lower val loss for epoch 12 => 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 13/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:17:06,898 : INFO : Found lower val loss for epoch 13 => 0.00434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:17:31,427 : INFO : Found lower val loss for epoch 14 => 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:17:55,934 : INFO : Found lower val loss for epoch 15 => 0.00429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:18:20,365 : INFO : Found lower val loss for epoch 16 => 0.00427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:18:43,368 : INFO : Found lower val loss for epoch 17 => 0.00424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:19:07,931 : INFO : Found lower val loss for epoch 18 => 0.00422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:19:31,840 : INFO : Found lower val loss for epoch 19 => 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:19:56,048 : INFO : Found lower val loss for epoch 20 => 0.00417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:20:43,861 : INFO : Found lower val loss for epoch 22 => 0.00414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 23/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:21:29,189 : INFO : Found lower val loss for epoch 24 => 0.00412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 25/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:21:51,722 : INFO : Found lower val loss for epoch 25 => 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 26/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:22:40,862 : INFO : Found lower val loss for epoch 27 => 0.00409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 28/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 29/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:23:29,582 : INFO : Found lower val loss for epoch 29 => 0.00406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 30/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 31/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:24:16,940 : INFO : Found lower val loss for epoch 31 => 0.00404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 32/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 33/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:25:05,988 : INFO : Found lower val loss for epoch 33 => 0.00404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 34/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 35/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:25:54,157 : INFO : Found lower val loss for epoch 35 => 0.00403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 36/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:26:18,619 : INFO : Found lower val loss for epoch 36 => 0.00402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 37/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 38/100\n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 39/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:27:27,626 : INFO : Found lower val loss for epoch 39 => 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 40/100\n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 41/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:28:12,666 : INFO : Found lower val loss for epoch 41 => 0.00398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 42/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 43/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 44/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 45/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:29:49,065 : INFO : Found lower val loss for epoch 45 => 0.00397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 46/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 47/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 48/100\n",
      "1286325/1286325 [==============================] - 22s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 49/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:31:21,656 : INFO : Found lower val loss for epoch 49 => 0.00397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 50/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 51/100\n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 52/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:32:33,504 : INFO : Found lower val loss for epoch 52 => 0.00396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 53/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 54/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 55/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 56/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 57/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 58/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:34:59,129 : INFO : Found lower val loss for epoch 58 => 0.00395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 59/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 60/100\n",
      "1286325/1286325 [==============================] - 24s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 61/100\n",
      "1286325/1286325 [==============================] - 25s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 62/100\n",
      "1286325/1286325 [==============================] - 25s - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 63/100\n",
      "1286325/1286325 [==============================] - 25s - loss: 0.0054 - val_loss: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:37:05,133 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00062: early stopping\n",
      "CPU times: user 12min 47s, sys: 13min 30s, total: 26min 18s\n",
      "Wall time: 25min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:38:03,390 : INFO : Generating Validation Metrics\n",
      "2017-02-02 08:45:43,808 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 9.932 | Top 3: 0.669 | Top 5: 0.759 | F1 Micro: 0.421 | F1 Macro: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:46:41,810 : INFO : Generating Validation Metrics\n",
      "2017-02-02 08:54:28,796 : INFO : ***************************************************************************************\n",
      "2017-02-02 08:54:28,797 : INFO : nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_tanh_in-drop_True_hid-drop_False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 9.788 | Top 3: 0.672 | Top 5: 0.761 | F1 Micro: 0.409 | F1 Macro: 0.033\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 200)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           100500      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           470940      hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 571440\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:54:49,439 : INFO : Found lower val loss for epoch 1 => 0.0061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0157 - val_loss: 0.0061\n",
      "Epoch 2/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:55:08,252 : INFO : Found lower val loss for epoch 2 => 0.00515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:55:27,056 : INFO : Found lower val loss for epoch 3 => 0.00478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:55:45,758 : INFO : Found lower val loss for epoch 4 => 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:56:04,764 : INFO : Found lower val loss for epoch 5 => 0.00448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:56:23,396 : INFO : Found lower val loss for epoch 6 => 0.00441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:56:41,707 : INFO : Found lower val loss for epoch 7 => 0.00434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:57:00,301 : INFO : Found lower val loss for epoch 8 => 0.00434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:57:18,784 : INFO : Found lower val loss for epoch 9 => 0.00428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:57:37,086 : INFO : Found lower val loss for epoch 10 => 0.00427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:57:55,647 : INFO : Found lower val loss for epoch 11 => 0.00424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:58:33,045 : INFO : Found lower val loss for epoch 13 => 0.00424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:58:52,259 : INFO : Found lower val loss for epoch 14 => 0.00422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:00:08,501 : INFO : Found lower val loss for epoch 18 => 0.00421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 26/100\n",
      "1286325/1286325 [==============================] - 19s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 27/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 28/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:03:33,893 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: early stopping\n",
      "CPU times: user 5min 4s, sys: 4min 30s, total: 9min 35s\n",
      "Wall time: 9min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:04:30,178 : INFO : Generating Validation Metrics\n",
      "2017-02-02 09:12:13,369 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 8.982 | Top 3: 0.685 | Top 5: 0.772 | F1 Micro: 0.409 | F1 Macro: 0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:13:08,202 : INFO : Generating Validation Metrics\n",
      "2017-02-02 09:20:54,399 : INFO : ***************************************************************************************\n",
      "2017-02-02 09:20:54,400 : INFO : nn_1st-size_200_1st-act_tanh_2nd-size_2000_2nd-act_sigmoid_in-drop_True_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 9.334 | Top 3: 0.677 | Top 5: 0.764 | F1 Micro: 0.373 | F1 Macro: 0.040\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 200)           0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 200)           40200       dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 200)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_sigmoid (Dense)    (None, 2000)          402000      dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           1880940     hidden_layer2_sigmoid[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 2323140\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:21:29,436 : INFO : Found lower val loss for epoch 1 => 0.00659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0101 - val_loss: 0.0066\n",
      "Epoch 2/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:22:00,043 : INFO : Found lower val loss for epoch 2 => 0.00553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 3/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:22:30,689 : INFO : Found lower val loss for epoch 3 => 0.00526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:23:01,228 : INFO : Found lower val loss for epoch 4 => 0.00512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 5/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:23:31,445 : INFO : Found lower val loss for epoch 5 => 0.00484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 6/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:24:01,900 : INFO : Found lower val loss for epoch 6 => 0.00475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 7/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:24:32,129 : INFO : Found lower val loss for epoch 7 => 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 8/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:25:02,731 : INFO : Found lower val loss for epoch 8 => 0.00463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 9/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 10/100\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 11/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:26:32,580 : INFO : Found lower val loss for epoch 11 => 0.00458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 12/100\n",
      "1286325/1286325 [==============================] - 33s - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 13/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:27:39,504 : INFO : Found lower val loss for epoch 13 => 0.00451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 33s - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "1286325/1286325 [==============================] - 31s - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 15/100\n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 16/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:29:15,848 : INFO : Found lower val loss for epoch 16 => 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 17/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:29:45,686 : INFO : Found lower val loss for epoch 17 => 0.00449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 18/100\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 20/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 21/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:31:45,576 : INFO : Found lower val loss for epoch 21 => 0.00446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 22/100\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 23/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 24/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 25/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:33:45,038 : INFO : Found lower val loss for epoch 25 => 0.00443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 26/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 27/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:34:44,532 : INFO : Found lower val loss for epoch 27 => 0.00443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 28/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:35:14,155 : INFO : Found lower val loss for epoch 28 => 0.00443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 31/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 32/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 33/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 34/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 35/100\n",
      "1286325/1286325 [==============================] - 30s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 36/100\n",
      "1286325/1286325 [==============================] - 29s - loss: 0.0056 - val_loss: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:39:11,253 : INFO : Evaluating on Validation Data using last weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: early stopping\n",
      "CPU times: user 8min 44s, sys: 10min, total: 18min 45s\n",
      "Wall time: 18min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:48:49,597 : INFO : Generating Validation Metrics\n",
      "2017-02-02 09:57:06,135 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 10.776 | Top 3: 0.631 | Top 5: 0.723 | F1 Micro: 0.331 | F1 Macro: 0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 09:58:04,488 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 10.809 | Top 3: 0.629 | Top 5: 0.722 | F1 Micro: 0.330 | F1 Macro: 0.017\n"
     ]
    }
   ],
   "source": [
    "for parameters in param_sampler:\n",
    "    start_time = time.time()\n",
    "    first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "    first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "    second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "    second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "    input_dropout_do = parameters['input_dropout']\n",
    "    hidden_dropout_do = parameters['hidden_dropout']\n",
    "\n",
    "#     print \"===================================================================================\\n\" + \\\n",
    "#           \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "#           \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "#           \"==========================\".format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "#                                                 second_hidden_layer_size, second_hidden_layer_activation, \n",
    "#                                                 input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "        first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "        second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "    )\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "#     if input_dropout_do:\n",
    "#         print \"skipping: {} due to input dropout\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "#         continue\n",
    "    \n",
    "    info('***************************************************************************************')\n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    \n",
    "    model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                  second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                  input_dropout_do, hidden_dropout_do)\n",
    "    model.summary()\n",
    "    \n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=4096, \\\n",
    "                              nb_epoch=NN_MAX_EPOCHS, verbose=1, callbacks=[early_stopper, metrics_callback])\n",
    "    \n",
    "#     info('Evaluating on Training Data')\n",
    "#     yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "#     yp_binary = get_binary_0_5(yp)\n",
    "#     #print yp\n",
    "#     info('Generating Training Metrics')\n",
    "#     training_metrics = get_metrics(y, yp, yp_binary)\n",
    "#     print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "#         training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "#         training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#         training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "    info('Evaluating on Validation Data using last weights')\n",
    "    yvp = model.predict(Xv)\n",
    "    yvp_binary = get_binary_0_5(yvp)\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    last_validation_metrics = validation_metrics\n",
    "\n",
    "    # using the recorded weights of the best recorded validation loss\n",
    "    last_model_weights = model.get_weights()\n",
    "    info('Evaluating on Validation Data using saved best weights')\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    yvp = model.predict(Xv)\n",
    "    yvp_binary = get_binary_0_5(yvp)\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    best_validation_metrics = validation_metrics\n",
    "\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "#     param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_metrics'] = training_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_validation_metrics'] = last_validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "#     param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['history'] = history\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_weights'] = last_model_weights\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "    \n",
    "    # setting the model weights to the best weights\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    \n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.NN_MODEL_NAME))\n",
    "    \n",
    "#     pickle.dump(model, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                             GLOBAL_VARS.NN_MODEL_NAME, CLASSIFIER), 'w'))\n",
    "    \n",
    "#     pickle.dump(best_validation_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                                           GLOBAL_VARS.NN_MODEL_NAME, VALIDATION_METRICS_FILENAME), 'w'))\n",
    "\n",
    "    del history, last_model_weights\n",
    "    \n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 s, sys: 588 ms, total: 12.2 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print len(param_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 64 ms, total: 1.12 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key in param_results_dict:\n",
    "    if param_results_dict[key]['history'] is not None:\n",
    "        val = param_results_dict[key]\n",
    "        #param_results_dict[key]['last_weights'] = None\n",
    "        #param_results_dict[key]['epochs'] = len(val['history'].history['val_loss'])\n",
    "        param_results_dict[key]['history'] = None\n",
    "#         param_results_dict[key]['best_weights'] = param_results_dict[key]['metrics_callback'].best_weights\n",
    "#         param_results_dict[key]['metrics_callback'] = None\n",
    "        #pickle.dump(param_results_dict[key], open('/mnt/data2/shalaby/nn_parameter_search/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/{}_metrics_callback.pkl'.format(key), 'w'))\n",
    "\n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 25s, sys: 19.3 s, total: 3min 44s\n",
      "Wall time: 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 29\n",
      "Last Val: Coverage Error => 75.0916 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1867\n",
      "Best Val: Coverage Error => 75.1124 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1862\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 29\n",
      "Last Val: Coverage Error => 75.0962 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1862\n",
      "Best Val: Coverage Error => 75.0842 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1867\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "Epochs => 86\n",
      "Last Val: Coverage Error => 8.7398 | F1 Micro => 0.4502 | F1 Macro => 0.0710 | Top 3 => 0.6884\n",
      "Best Val: Coverage Error => 8.6882 | F1 Micro => 0.4501 | F1 Macro => 0.0732 | Top 3 => 0.6894\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 39\n",
      "Last Val: Coverage Error => 7.4138 | F1 Micro => 0.4928 | F1 Macro => 0.1153 | Top 3 => 0.7244\n",
      "Best Val: Coverage Error => 7.3956 | F1 Micro => 0.5006 | F1 Macro => 0.1307 | Top 3 => 0.7251\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 50\n",
      "Last Val: Coverage Error => 8.1527 | F1 Micro => 0.4694 | F1 Macro => 0.0935 | Top 3 => 0.7074\n",
      "Best Val: Coverage Error => 8.1527 | F1 Micro => 0.4694 | F1 Macro => 0.0935 | Top 3 => 0.7074\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "Epochs => 29\n",
      "Last Val: Coverage Error => 75.0862 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1867\n",
      "Best Val: Coverage Error => 75.0817 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1867\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 70\n",
      "Last Val: Coverage Error => 6.7475 | F1 Micro => 0.5155 | F1 Macro => 0.1422 | Top 3 => 0.7376\n",
      "Best Val: Coverage Error => 6.7112 | F1 Micro => 0.5173 | F1 Macro => 0.1401 | Top 3 => 0.7378\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 43\n",
      "Last Val: Coverage Error => 7.6632 | F1 Micro => 0.4863 | F1 Macro => 0.1149 | Top 3 => 0.7198\n",
      "Best Val: Coverage Error => 7.6742 | F1 Micro => 0.4839 | F1 Macro => 0.1128 | Top 3 => 0.7200\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 72\n",
      "Last Val: Coverage Error => 6.5022 | F1 Micro => 0.5302 | F1 Macro => 0.1523 | Top 3 => 0.7461\n",
      "Best Val: Coverage Error => 6.4725 | F1 Micro => 0.5250 | F1 Macro => 0.1505 | Top 3 => 0.7467\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "Epochs => 29\n",
      "Last Val: Coverage Error => 75.1022 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1862\n",
      "Best Val: Coverage Error => 75.0841 | F1 Micro => 0.0000 | F1 Macro => 0.0000 | Top 3 => 0.1867\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict.keys():\n",
    "    print('========== NN: {}'.format(key))\n",
    "    val = param_results_dict[key]\n",
    "    val_metrics = val['last_validation_metrics']\n",
    "    val_metrics2 =  val['best_validation_metrics']\n",
    "        \n",
    "    print('Epochs => {}'.format(val['epochs']))\n",
    "#     print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "#     print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Last Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Best Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix old param_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications_type = 'subclasses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 8\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_results_dict = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if this is an old param_results_dict (it would have history and metrics_callback in that case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights', 'last_weights']\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict:\n",
    "    print param_results_dict[key].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['epochs', 'best_validation_metrics', 'duration', 'best_weights']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "['last_validation_metrics', 'last_weights', 'best_validation_metrics', 'duration', 'metrics_callback', 'history']\n",
      "CPU times: user 1.23 s, sys: 164 ms, total: 1.4 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key in param_results_dict:\n",
    "    print param_results_dict[key].keys()\n",
    "    if param_results_dict[key].get('history') is not None:\n",
    "        val = param_results_dict[key]\n",
    "        param_results_dict[key]['epochs'] = len(val['history'].history['val_loss'])\n",
    "        param_results_dict[key]['best_weights'] = val['metrics_callback'].best_weights\n",
    "        del param_results_dict[key]['metrics_callback']\n",
    "        del param_results_dict[key]['history']\n",
    "\n",
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run network for specific configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import coverage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics_detailed(y_true, y_score, y_binary_score):\n",
    "    \"\"\"\n",
    "    create the metrics object containing all relevant metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    %time metrics['total_positive'] = np.sum(np.sum(y_binary_score))\n",
    "    #TODO remove those two when running on the whole set to avoid excessive storage costs\n",
    "    #metrics['y_true'] = y_true\n",
    "    #metrics['y_score'] = y_score\n",
    "    #metrics['y_binary_score'] = y_binary_score\n",
    "    %time metrics['coverage_error'] = coverage_error(y_true, y_score)\n",
    "    %time metrics['average_num_of_labels'] = round(float(np.sum(np.sum(y_true, axis=1)))/y_true.shape[0], 2)\n",
    "    # metrics['average_precision_micro'] = sklearn.metrics.average_precision_score(y_true, y_binary_score, average='micro')\n",
    "    # metrics['average_precision_macro'] = sklearn.metrics.average_precision_score(y_true, y_binary_score, average='macro')\n",
    "    #%time metrics['precision_micro'] = sklearn.metrics.precision_score(y_true, y_binary_score, average='micro')\n",
    "    #%time metrics['precision_macro'] = sklearn.metrics.precision_score(y_true, y_binary_score, average='macro')\n",
    "    #%time metrics['recall_micro'] = sklearn.metrics.recall_score(y_true, y_binary_score, average='micro')\n",
    "    #%time metrics['recall_macro'] = sklearn.metrics.recall_score(y_true, y_binary_score, average='macro')\n",
    "    %time metrics['f1_micro'] = sklearn.metrics.f1_score(y_true, y_binary_score, average='micro')\n",
    "    %time metrics['f1_macro'] = sklearn.metrics.f1_score(y_true, y_binary_score, average='macro')\n",
    "\n",
    "    \n",
    "    if y_true.shape[1] < 100:\n",
    "        precision_scores = np.zeros(y_true.shape[1])\n",
    "        for i in range(0, y_true.shape[1]):\n",
    "            precision_scores[i] = sklearn.metrics.precision_score(y_true[:,i], y_binary_score[:,i])\n",
    "        metrics['precision_scores_array'] = precision_scores.tolist()\n",
    "        info('Finished Precision')\n",
    "\n",
    "        recall_scores = np.zeros(y_true.shape[1])\n",
    "        for i in range(0, y_true.shape[1]):\n",
    "            recall_scores[i] = sklearn.metrics.recall_score(y_true[:,i], y_binary_score[:,i])\n",
    "        metrics['recall_scores_array'] = recall_scores.tolist()\n",
    "        info('Finished Recall')\n",
    "\n",
    "        f1_scores = np.zeros(y_true.shape[1])\n",
    "        for i in range(0, y_true.shape[1]):\n",
    "            f1_scores[i] = sklearn.metrics.f1_score(y_true[:,i], y_binary_score[:,i])\n",
    "        metrics['f1_scores_array'] = f1_scores.tolist()\n",
    "        info('Finished F1')\n",
    "\n",
    "    %time metrics['top_1'] = get_top_N_percentage(y_score, y_true, max_N=1)\n",
    "    %time metrics['top_3'] = get_top_N_percentage(y_score, y_true, max_N=3)\n",
    "    %time metrics['top_5'] = get_top_N_percentage(y_score, y_true, max_N=5)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "EARLY_STOPPER_MIN_DELTA = 1e-4\n",
    "EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "NN_BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-15 16:42:45,553 : INFO : ***************************************************************************************\n",
      "2017-02-15 16:42:45,563 : INFO : nn_1st-size_500_1st-act_tanh_2nd-size_2000_2nd-act_sigmoid_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           100500      doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 500)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_sigmoid (Dense)    (None, 2000)          1002000     dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 940)           1880940     hidden_layer2_sigmoid[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 2983440\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n",
      "Epoch 1/100\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-15 16:43:32,610 : INFO : Found lower val loss for epoch 1 => 0.00528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 32s - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 2/100\n",
      " 106496/1286325 [=>............................] - ETA: 28s - loss: 0.0044"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-2b121e7fee22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Model Fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE,                           nb_epoch=NN_MAX_EPOCHS, verbose=1, callbacks=[early_stopper, metrics_callback])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m#     info('Evaluating on Training Data')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "first_hidden_layer_size = 500\n",
    "first_hidden_layer_activation = 'tanh'\n",
    "second_hidden_layer_size = 2000\n",
    "second_hidden_layer_activation = 'sigmoid'\n",
    "input_dropout_do = False\n",
    "hidden_dropout_do = True\n",
    "\n",
    "#     print \"===================================================================================\\n\" + \\\n",
    "#           \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "#           \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "#           \"==========================\".format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "#                                                 second_hidden_layer_size, second_hidden_layer_activation, \n",
    "#                                                 input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "    first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "    second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    ")\n",
    "if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys():\n",
    "    print \"Should be skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "info('***************************************************************************************')\n",
    "info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                              first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                              second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                              input_dropout_do, hidden_dropout_do)\n",
    "model.summary()\n",
    "\n",
    "early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                              patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "metrics_callback = MetricsCallback()\n",
    "\n",
    "# Model Fitting\n",
    "%time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                          nb_epoch=NN_MAX_EPOCHS, verbose=1, callbacks=[early_stopper, metrics_callback])\n",
    "\n",
    "#     info('Evaluating on Training Data')\n",
    "#     yp = model.predict(X, batch_size=NN_BATCH_SIZE)\n",
    "#     yp_binary = get_binary_0_5(yp)\n",
    "#     #print yp\n",
    "#     info('Generating Training Metrics')\n",
    "#     training_metrics = get_metrics(y, yp, yp_binary)\n",
    "#     print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "#         training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "#         training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "#         training_metrics['f1_micro'],training_metrics['f1_macro'],  training_metrics['total_positive'])\n",
    "\n",
    "# info('Evaluating on Validation Data using last weights')\n",
    "# yvp = model.predict(Xv)\n",
    "# yvp_binary = get_binary_0_5(yvp)\n",
    "# #print yvp\n",
    "# info('Generating Validation Metrics')\n",
    "# validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "# print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "#     validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "#     validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "# last_validation_metrics = validation_metrics\n",
    "\n",
    "# using the recorded weights of the best recorded validation loss\n",
    "last_model_weights = model.get_weights()\n",
    "info('Evaluating on Validation Data using saved best weights')\n",
    "model.set_weights(metrics_callback.best_weights)\n",
    "yvp = model.predict(Xv)\n",
    "yvp_binary = get_binary_0_5(yvp)\n",
    "#print yvp\n",
    "info('Generating Validation Metrics')\n",
    "validation_metrics = get_metrics_detailed(yv, yvp, yvp_binary)\n",
    "print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "best_validation_metrics = validation_metrics\n",
    "\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "# #     param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_metrics'] = training_metrics\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_validation_metrics'] = last_validation_metrics\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['history'] = history\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'] = metrics_callback\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['last_weights'] = last_model_weights\n",
    "\n",
    "# duration = time.time() - start_time\n",
    "# param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "# pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                        NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = valid_subclasses\n",
    "classifications_type = 'subclasses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_results_dict = pickle.load(open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-27 20:42:31,653 : INFO : Getting Test Vectors Embeddings\n",
      "2017-02-27 20:42:31,670 : INFO : ===== Loading inference vectors\n",
      "2017-02-27 20:43:04,074 : INFO : Loaded inference vectors matrix\n"
     ]
    }
   ],
   "source": [
    "# Test Metrics\n",
    "info('Getting Test Vectors Embeddings')\n",
    "Xt, yt = get_docs_with_inference(doc2vec_model, doc_classification_map, classifications, \n",
    "                                               test_docs_list, TEST_MATRIX, \n",
    "                                               test_preprocessed_files_prefix, \n",
    "                                               test_preprocessed_docids_files_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_1st-size_200_1st-act_tanh_2nd-size_2000_2nd-act_relu_in-drop_False_hid-drop_True',\n",
       " 'nn_1st-size_1000_1st-act_tanh_2nd-size_2000_2nd-act_sigmoid_in-drop_False_hid-drop_True',\n",
       " 'nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True',\n",
       " 'nn_1st-size_500_1st-act_tanh_2nd-size_2000_2nd-act_relu_in-drop_False_hid-drop_True',\n",
       " 'nn_1st-size_500_1st-act_tanh_2nd-size_2000_2nd-act_sigmoid_in-drop_False_hid-drop_True']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-27 20:43:35,934 : INFO : ***************************************************************************************\n",
      "2017-02-27 20:43:35,935 : INFO : nn_1st-size_500_1st-act_tanh_2nd-size_2000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "2017-02-27 20:43:36,260 : INFO : Evaluating on Test Data using best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           100500      doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 500)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_relu (Dense)       (None, 2000)          1002000     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 600)           1200600     hidden_layer2_relu[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 2303100\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-27 20:44:53,016 : INFO : Generating Test Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test Metrics: Cov Err: 6.128, Avg Labels: 1.340, \n",
      "\t\t Top 1: 0.618, Top 3: 0.760, Top 5: 0.840, \n",
      "\t\t F1 Micro: 0.554, F1 Macro: 0.186, Total Pos: 331,043\n"
     ]
    }
   ],
   "source": [
    "first_hidden_layer_size = 500\n",
    "first_hidden_layer_activation = 'tanh'\n",
    "second_hidden_layer_size = 2000\n",
    "second_hidden_layer_activation = 'relu'\n",
    "input_dropout_do = False\n",
    "hidden_dropout_do = True\n",
    "\n",
    "#     print \"===================================================================================\\n\" + \\\n",
    "#           \"========== 1st Layer Size: {}, 1st Layer Activation: {}, \\n 2nd Layer Size: {}, 2nd Layer Activation: {}, \\n\" + \\\n",
    "#           \"Input Dropout: {}, Hidden Dropout: {} \\n\" + \\\n",
    "#           \"==========================\".format(first_hidden_layer_size, first_hidden_layer_activation, \n",
    "#                                                 second_hidden_layer_size, second_hidden_layer_activation, \n",
    "#                                                 input_dropout_do, hidden_dropout_do)\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "    first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "    second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    ")\n",
    "if GLOBAL_VARS.NN_MODEL_NAME not in param_results_dict.keys():\n",
    "    print \"Can't find model: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    raise Exception()\n",
    "\n",
    "info('***************************************************************************************')\n",
    "info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "model = create_keras_nn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                              first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                              second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                              input_dropout_do, hidden_dropout_do)\n",
    "model.summary()\n",
    "\n",
    "# get model best weights\n",
    "# weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'].best_weights\n",
    "weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights']\n",
    "model.set_weights(weights)\n",
    "\n",
    "info('Evaluating on Test Data using best weights')\n",
    "ytp = model.predict(Xt)\n",
    "ytp_binary = get_binary_0_5(ytp)\n",
    "#print yvp\n",
    "info('Generating Test Metrics')\n",
    "test_metrics = get_metrics(yt, ytp, ytp_binary)\n",
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "\n",
    "    \n",
    "ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.NN_MODEL_NAME))\n",
    "\n",
    "pickle.dump(test_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                      GLOBAL_VARS.NN_MODEL_NAME, TEST_METRICS_FILENAME), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>46751.0</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>7508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1540.0</td>\n",
       "      <td>33737.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>2054.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>14521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>397.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>31233.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>6694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>69.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>188.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5118.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>323.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>18152.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>6196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>1407.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>118088.0</td>\n",
       "      <td>8379.0</td>\n",
       "      <td>13086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>328.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>8070.0</td>\n",
       "      <td>98478.0</td>\n",
       "      <td>11792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>3483.0</td>\n",
       "      <td>3303.0</td>\n",
       "      <td>4579.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>9905.0</td>\n",
       "      <td>8728.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A        B        C       D       E        F         G        H  \\\n",
       "A     46751.0   1541.0    706.0    58.0   187.0    340.0    1275.0    510.0   \n",
       "B      1540.0  33737.0    998.0   200.0   387.0   2054.0    2521.0   2261.0   \n",
       "C       397.0    975.0  31233.0    70.0    24.0    116.0     719.0   1085.0   \n",
       "D        69.0    168.0     56.0  1385.0     4.0     26.0      28.0     33.0   \n",
       "E       188.0    781.0     47.0     4.0  5118.0    243.0     143.0    151.0   \n",
       "F       323.0   1229.0     98.0    37.0   163.0  18152.0     620.0    824.0   \n",
       "G      1407.0   1422.0    373.0    29.0   118.0    814.0  118088.0   8379.0   \n",
       "H       328.0    604.0    111.0    14.0    59.0    463.0    8070.0  98478.0   \n",
       "None   3483.0   3303.0   4579.0   402.0   528.0   1871.0    9905.0   8728.0   \n",
       "\n",
       "         None  \n",
       "A      7508.0  \n",
       "B     14521.0  \n",
       "C      6694.0  \n",
       "D       744.0  \n",
       "E      2752.0  \n",
       "F      6196.0  \n",
       "G     13086.0  \n",
       "H     11792.0  \n",
       "None      0.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = get_formatted_multilabel_confusion_matrix(yt, ytp_binary, sections)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A        58876.0\n",
       "B        58219.0\n",
       "C        41313.0\n",
       "D         2513.0\n",
       "E         9427.0\n",
       "F        27642.0\n",
       "G       143716.0\n",
       "H       119919.0\n",
       "None     32799.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.794059</td>\n",
       "      <td>0.026174</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.127522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.026452</td>\n",
       "      <td>0.579484</td>\n",
       "      <td>0.017142</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.035281</td>\n",
       "      <td>0.043302</td>\n",
       "      <td>0.038836</td>\n",
       "      <td>0.249420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.009610</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.756009</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>0.026263</td>\n",
       "      <td>0.162031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.027457</td>\n",
       "      <td>0.066852</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>0.551134</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.013132</td>\n",
       "      <td>0.296060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.019943</td>\n",
       "      <td>0.082847</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.542909</td>\n",
       "      <td>0.025777</td>\n",
       "      <td>0.015169</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.291927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.011685</td>\n",
       "      <td>0.044461</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.656682</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.029810</td>\n",
       "      <td>0.224152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.009790</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.821676</td>\n",
       "      <td>0.058302</td>\n",
       "      <td>0.091055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.067295</td>\n",
       "      <td>0.821204</td>\n",
       "      <td>0.098333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.106192</td>\n",
       "      <td>0.100704</td>\n",
       "      <td>0.139608</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.057044</td>\n",
       "      <td>0.301991</td>\n",
       "      <td>0.266106</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             A         B         C         D         E         F         G  \\\n",
       "A     0.794059  0.026174  0.011991  0.000985  0.003176  0.005775  0.021656   \n",
       "B     0.026452  0.579484  0.017142  0.003435  0.006647  0.035281  0.043302   \n",
       "C     0.009610  0.023600  0.756009  0.001694  0.000581  0.002808  0.017404   \n",
       "D     0.027457  0.066852  0.022284  0.551134  0.001592  0.010346  0.011142   \n",
       "E     0.019943  0.082847  0.004986  0.000424  0.542909  0.025777  0.015169   \n",
       "F     0.011685  0.044461  0.003545  0.001339  0.005897  0.656682  0.022430   \n",
       "G     0.009790  0.009895  0.002595  0.000202  0.000821  0.005664  0.821676   \n",
       "H     0.002735  0.005037  0.000926  0.000117  0.000492  0.003861  0.067295   \n",
       "None  0.106192  0.100704  0.139608  0.012256  0.016098  0.057044  0.301991   \n",
       "\n",
       "             H      None  \n",
       "A     0.008662  0.127522  \n",
       "B     0.038836  0.249420  \n",
       "C     0.026263  0.162031  \n",
       "D     0.013132  0.296060  \n",
       "E     0.016018  0.291927  \n",
       "F     0.029810  0.224152  \n",
       "G     0.058302  0.091055  \n",
       "H     0.821204  0.098333  \n",
       "None  0.266106  0.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix.div(conf_matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.106</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A      B      C      D      E      F      G      H   None\n",
       "A     0.794  0.026  0.012  0.001  0.003  0.006  0.022  0.009  0.128\n",
       "B     0.026  0.579  0.017  0.003  0.007  0.035  0.043  0.039  0.249\n",
       "C     0.010  0.024  0.756  0.002  0.001  0.003  0.017  0.026  0.162\n",
       "D     0.027  0.067  0.022  0.551  0.002  0.010  0.011  0.013  0.296\n",
       "E     0.020  0.083  0.005  0.000  0.543  0.026  0.015  0.016  0.292\n",
       "F     0.012  0.044  0.004  0.001  0.006  0.657  0.022  0.030  0.224\n",
       "G     0.010  0.010  0.003  0.000  0.001  0.006  0.822  0.058  0.091\n",
       "H     0.003  0.005  0.001  0.000  0.000  0.004  0.067  0.821  0.098\n",
       "None  0.106  0.101  0.140  0.012  0.016  0.057  0.302  0.266  0.000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix.div(conf_matrix.sum(axis=1), axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>79.41%</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>1.20%</td>\n",
       "      <td>0.10%</td>\n",
       "      <td>0.32%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>2.17%</td>\n",
       "      <td>0.87%</td>\n",
       "      <td>12.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.65%</td>\n",
       "      <td>57.95%</td>\n",
       "      <td>1.71%</td>\n",
       "      <td>0.34%</td>\n",
       "      <td>0.66%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>4.33%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>24.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.96%</td>\n",
       "      <td>2.36%</td>\n",
       "      <td>75.60%</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>0.06%</td>\n",
       "      <td>0.28%</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>2.63%</td>\n",
       "      <td>16.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>2.75%</td>\n",
       "      <td>6.69%</td>\n",
       "      <td>2.23%</td>\n",
       "      <td>55.11%</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>1.03%</td>\n",
       "      <td>1.11%</td>\n",
       "      <td>1.31%</td>\n",
       "      <td>29.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>1.99%</td>\n",
       "      <td>8.28%</td>\n",
       "      <td>0.50%</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>54.29%</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>29.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1.17%</td>\n",
       "      <td>4.45%</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>65.67%</td>\n",
       "      <td>2.24%</td>\n",
       "      <td>2.98%</td>\n",
       "      <td>22.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.98%</td>\n",
       "      <td>0.99%</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>0.02%</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>0.57%</td>\n",
       "      <td>82.17%</td>\n",
       "      <td>5.83%</td>\n",
       "      <td>9.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.27%</td>\n",
       "      <td>0.50%</td>\n",
       "      <td>0.09%</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>6.73%</td>\n",
       "      <td>82.12%</td>\n",
       "      <td>9.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>10.62%</td>\n",
       "      <td>10.07%</td>\n",
       "      <td>13.96%</td>\n",
       "      <td>1.23%</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>5.70%</td>\n",
       "      <td>30.20%</td>\n",
       "      <td>26.61%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A       B       C       D       E       F       G       H    None\n",
       "A     79.41%   2.62%   1.20%   0.10%   0.32%   0.58%   2.17%   0.87%  12.75%\n",
       "B      2.65%  57.95%   1.71%   0.34%   0.66%   3.53%   4.33%   3.88%  24.94%\n",
       "C      0.96%   2.36%  75.60%   0.17%   0.06%   0.28%   1.74%   2.63%  16.20%\n",
       "D      2.75%   6.69%   2.23%  55.11%   0.16%   1.03%   1.11%   1.31%  29.61%\n",
       "E      1.99%   8.28%   0.50%   0.04%  54.29%   2.58%   1.52%   1.60%  29.19%\n",
       "F      1.17%   4.45%   0.35%   0.13%   0.59%  65.67%   2.24%   2.98%  22.42%\n",
       "G      0.98%   0.99%   0.26%   0.02%   0.08%   0.57%  82.17%   5.83%   9.11%\n",
       "H      0.27%   0.50%   0.09%   0.01%   0.05%   0.39%   6.73%  82.12%   9.83%\n",
       "None  10.62%  10.07%  13.96%   1.23%   1.61%   5.70%  30.20%  26.61%   0.00%"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_perc = lambda x: \"{:.2f}%\".format(x)\n",
    "(conf_matrix.div(conf_matrix.sum(axis=1), axis=0).round(4) * 100).applymap(format_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recall_macro',\n",
       " 'f1_scores_array',\n",
       " 'average_precision_macro',\n",
       " 'average_num_of_labels',\n",
       " 'recall_scores_array',\n",
       " 'average_precision_micro',\n",
       " 'top_1',\n",
       " 'precision_micro',\n",
       " 'top_3',\n",
       " 'f1_micro',\n",
       " 'precision_scores_array',\n",
       " 'f1_macro',\n",
       " 'recall_micro',\n",
       " 'coverage_error',\n",
       " 'top_5',\n",
       " 'precision_macro',\n",
       " 'total_positive']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.86, 0.77, 0.82, 0.63, 0.78, 0.75, 0.84, 0.82]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(x,2) for x in test_metrics['precision_scores_array']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Scores: 0.86 & 0.77 & 0.82 & 0.63 & 0.78 & 0.75 & 0.84 & 0.82\n",
      "Recall Scores: 0.79 & 0.58 & 0.76 & 0.55 & 0.54 & 0.66 & 0.82 & 0.82\n",
      "F1 Scores: 0.82 & 0.66 & 0.79 & 0.59 & 0.64 & 0.7 & 0.83 & 0.82\n"
     ]
    }
   ],
   "source": [
    "print 'Precision Scores: {}'.format(' & '.join([str(round(x,2)) for x in test_metrics['precision_scores_array']]))\n",
    "print 'Recall Scores: {}'.format(' & '.join([str(round(x,2)) for x in test_metrics['recall_scores_array']]))\n",
    "print 'F1 Scores: {}'.format(' & '.join([str(round(x,2)) for x in test_metrics['f1_scores_array']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.NN_MODEL_NAME))\n",
    "pickle.dump(test_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                      GLOBAL_VARS.NN_MODEL_NAME, TEST_METRICS_FILENAME), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test Metrics: Cov Err: 2.955, Avg Labels: 1.240, \n",
      "\t\t Top 1: 0.699, Top 3: 0.850, Top 5: 0.911, \n",
      "\t\t F1 Micro: 0.648, F1 Macro: 0.169, Total Pos: 350,752\n"
     ]
    }
   ],
   "source": [
    "test_metrics = get_metrics(yt, ytp, ytp_binary)\n",
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "Epochs => 100\n",
      "Best Val Loss => 0.166829405505\n",
      "Last Val: Coverage Error => 1.4960 | F1 Micro => 0.7434 | F1 Macro => 0.6293 | Top 3 => 0.9637\n",
      "Best Val: Coverage Error => 1.4960 | F1 Micro => 0.7434 | F1 Macro => 0.6293 | Top 3 => 0.9637\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 47\n",
      "Best Val Loss => 0.147426413828\n",
      "Last Val: Coverage Error => 1.4576 | F1 Micro => 0.7738 | F1 Macro => 0.7021 | Top 3 => 0.9697\n",
      "Best Val: Coverage Error => 1.4576 | F1 Micro => 0.7738 | F1 Macro => 0.7021 | Top 3 => 0.9697\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.192695072037\n",
      "Last Val: Coverage Error => 1.6299 | F1 Micro => 0.6631 | F1 Macro => 0.4731 | Top 3 => 0.9455\n",
      "Best Val: Coverage Error => 1.6299 | F1 Micro => 0.6631 | F1 Macro => 0.4731 | Top 3 => 0.9455\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict.keys():\n",
    "    print('========== NN: {}'.format(key))\n",
    "    val = param_results_dict[key]\n",
    "    val_metrics = val['last_validation_metrics']\n",
    "    val_metrics2 =  val['best_validation_metrics']\n",
    "    \n",
    "    print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "    print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Last Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Best Val: Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 52\n",
      "Best Val Loss => 0.209273911595\n",
      "Coverage Error => 1.6301 | F1 Micro => 0.6278 | F1 Macro => 0.4057 | Top 3 => 0.9440\n",
      "Coverage Error => 1.6337 | F1 Micro => 0.6286 | F1 Macro => 0.4065 | Top 3 => 0.9448\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 35\n",
      "Best Val Loss => 0.218694725994\n",
      "Coverage Error => 1.6793 | F1 Micro => 0.5939 | F1 Macro => 0.3668 | Top 3 => 0.9360\n",
      "Coverage Error => 1.6744 | F1 Micro => 0.5924 | F1 Macro => 0.3680 | Top 3 => 0.9370\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 79\n",
      "Best Val Loss => 0.161037461469\n",
      "Coverage Error => 1.5147 | F1 Micro => 0.7480 | F1 Macro => 0.6480 | Top 3 => 0.9605\n",
      "Coverage Error => 1.5151 | F1 Micro => 0.7483 | F1 Macro => 0.6455 | Top 3 => 0.9606\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_tanh_in-drop_True_hid-drop_True\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.19296394765\n",
      "Coverage Error => 1.6255 | F1 Micro => 0.6765 | F1 Macro => 0.4847 | Top 3 => 0.9473\n",
      "Coverage Error => 1.6164 | F1 Micro => 0.6772 | F1 Macro => 0.4822 | Top 3 => 0.9479\n",
      "========== NN: nn_1st-size_200_1st-act_relu_2nd-size_500_2nd-act_softmax_in-drop_False_hid-drop_True\n",
      "Epochs => 62\n",
      "Best Val Loss => 0.153030478399\n",
      "Coverage Error => 1.4792 | F1 Micro => 0.7659 | F1 Macro => 0.6745 | Top 3 => 0.9663\n",
      "Coverage Error => 1.4793 | F1 Micro => 0.7658 | F1 Macro => 0.6767 | Top 3 => 0.9661\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "Epochs => 74\n",
      "Best Val Loss => 0.152595937912\n",
      "Coverage Error => 1.4762 | F1 Micro => 0.7662 | F1 Macro => 0.6849 | Top 3 => 0.9669\n",
      "Coverage Error => 1.4755 | F1 Micro => 0.7665 | F1 Macro => 0.6822 | Top 3 => 0.9669\n",
      "========== NN: nn_1st-size_500_1st-act_tanh_2nd-size_200_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 23\n",
      "Best Val Loss => 0.146622256775\n",
      "Coverage Error => 1.4371 | F1 Micro => 0.7814 | F1 Macro => 0.7202 | Top 3 => 0.9718\n",
      "Coverage Error => 1.4397 | F1 Micro => 0.7802 | F1 Macro => 0.7099 | Top 3 => 0.9716\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_50_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 28\n",
      "Best Val Loss => 0.150167715843\n",
      "Coverage Error => 1.4643 | F1 Micro => 0.7701 | F1 Macro => 0.6994 | Top 3 => 0.9683\n",
      "Coverage Error => 1.4615 | F1 Micro => 0.7701 | F1 Macro => 0.6962 | Top 3 => 0.9685\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_sigmoid_in-drop_False_hid-drop_False\n",
      "Epochs => 45\n",
      "Best Val Loss => 0.144718239361\n",
      "Coverage Error => 1.4385 | F1 Micro => 0.7851 | F1 Macro => 0.7142 | Top 3 => 0.9709\n",
      "Coverage Error => 1.4387 | F1 Micro => 0.7850 | F1 Macro => 0.7155 | Top 3 => 0.9709\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_sigmoid_in-drop_False_hid-drop_True\n",
      "Epochs => 69\n",
      "Best Val Loss => 0.152811881308\n",
      "Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "Coverage Error => 1.4786 | F1 Micro => 0.7641 | F1 Macro => 0.6747 | Top 3 => 0.9664\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_softmax_in-drop_False_hid-drop_False\n",
      "Epochs => 31\n",
      "Best Val Loss => 0.188622105058\n",
      "Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "Coverage Error => 1.6221 | F1 Micro => 0.7047 | F1 Macro => 0.5023 | Top 3 => 0.9387\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 24\n",
      "Best Val Loss => 0.177211825736\n",
      "Coverage Error => 1.5612 | F1 Micro => 0.7096 | F1 Macro => 0.5282 | Top 3 => 0.9537\n",
      "Coverage Error => 1.5519 | F1 Micro => 0.7001 | F1 Macro => 0.5391 | Top 3 => 0.9564\n",
      "========== NN: nn_1st-size_500_1st-act_relu_2nd-size_50_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 37\n",
      "Best Val Loss => 0.182871406887\n",
      "Coverage Error => 1.5657 | F1 Micro => 0.6919 | F1 Macro => 0.4956 | Top 3 => 0.9543\n",
      "Coverage Error => 1.5669 | F1 Micro => 0.6938 | F1 Macro => 0.5057 | Top 3 => 0.9543\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_500_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 40\n",
      "Best Val Loss => 0.14467293148\n",
      "Coverage Error => 1.4431 | F1 Micro => 0.7800 | F1 Macro => 0.7153 | Top 3 => 0.9714\n",
      "Coverage Error => 1.4431 | F1 Micro => 0.7821 | F1 Macro => 0.7181 | Top 3 => 0.9713\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_50_2nd-act_relu_in-drop_True_hid-drop_True\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.19802413061\n",
      "Coverage Error => 1.6223 | F1 Micro => 0.6572 | F1 Macro => 0.4326 | Top 3 => 0.9455\n",
      "Coverage Error => 1.6197 | F1 Micro => 0.6594 | F1 Macro => 0.4412 | Top 3 => 0.9467\n",
      "========== NN: nn_1st-size_200_1st-act_sigmoid_2nd-size_None_2nd-act_relu_in-drop_False_hid-drop_False\n",
      "Epochs => 50\n",
      "Best Val Loss => 0.154267980102\n",
      "Coverage Error => 1.4724 | F1 Micro => 0.7650 | F1 Macro => 0.6873 | Top 3 => 0.9668\n",
      "Coverage Error => 1.4724 | F1 Micro => 0.7629 | F1 Macro => 0.6759 | Top 3 => 0.9670\n",
      "========== NN: nn_1st-size_200_1st-act_tanh_2nd-size_1000_2nd-act_relu_in-drop_False_hid-drop_True\n",
      "Epochs => 33\n",
      "Best Val Loss => 0.142855885915\n",
      "Coverage Error => 1.4374 | F1 Micro => 0.7837 | F1 Macro => 0.7206 | Top 3 => 0.9723\n",
      "Coverage Error => 1.4351 | F1 Micro => 0.7844 | F1 Macro => 0.7225 | Top 3 => 0.9724\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_None_2nd-act_softmax_in-drop_True_hid-drop_False\n",
      "Epochs => 64\n",
      "Best Val Loss => 0.166171306583\n",
      "Coverage Error => 1.4945 | F1 Micro => 0.7443 | F1 Macro => 0.6440 | Top 3 => 0.9635\n",
      "Coverage Error => 1.4932 | F1 Micro => 0.7445 | F1 Macro => 0.6436 | Top 3 => 0.9636\n",
      "========== NN: nn_1st-size_500_1st-act_softmax_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_True\n",
      "Epochs => 30\n",
      "Best Val Loss => 0.179389482992\n",
      "Coverage Error => 1.5448 | F1 Micro => 0.7084 | F1 Macro => 0.5527 | Top 3 => 0.9560\n",
      "Coverage Error => 1.5430 | F1 Micro => 0.7015 | F1 Macro => 0.5343 | Top 3 => 0.9566\n",
      "========== NN: nn_1st-size_500_1st-act_sigmoid_2nd-size_500_2nd-act_sigmoid_in-drop_True_hid-drop_False\n",
      "Epochs => 25\n",
      "Best Val Loss => 0.166892905616\n",
      "Coverage Error => 1.5206 | F1 Micro => 0.7352 | F1 Macro => 0.6247 | Top 3 => 0.9605\n",
      "Coverage Error => 1.5179 | F1 Micro => 0.7295 | F1 Macro => 0.6038 | Top 3 => 0.9610\n"
     ]
    }
   ],
   "source": [
    "for key in param_results_dict.keys():\n",
    "    print('========== NN: {}'.format(key))\n",
    "    val = param_results_dict[key]\n",
    "    val_metrics = val['validation_metrics']\n",
    "    val_metrics2 =  val['metrics_callback'].metrics_dict[sorted(val['metrics_callback'].metrics_dict.keys())[-1]]\n",
    "    \n",
    "    print('Epochs => {}'.format(len(val['history'].history['val_loss'])))\n",
    "    print('Best Val Loss => {}'.format(val[\"metrics_callback\"].best_val_loss))\n",
    "    print('Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics['coverage_error'], \n",
    "                                                                                        val_metrics['f1_micro'], val_metrics['f1_macro'],\n",
    "                                                                                        val_metrics['top_3']))\n",
    "    print('Coverage Error => {:.4f} | F1 Micro => {:.4f} | F1 Macro => {:.4f} | Top 3 => {:.4f}'.format(val_metrics2['coverage_error'], \n",
    "                                                                                        val_metrics2['f1_micro'], val_metrics2['f1_macro'],\n",
    "                                                                                        val_metrics2['top_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
