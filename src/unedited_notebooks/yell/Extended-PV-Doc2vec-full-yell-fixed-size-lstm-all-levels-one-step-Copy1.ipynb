{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of fixed size paragraph vectors using LSTM\n",
    "should be able to deal with all levels using the PARTS_LEVEL param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: TITAN X (Pascal) (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple, defaultdict\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "import seaborn\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Masking\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.convolutional import MaxPooling1D, Convolution1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables used throughout the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234\n",
    "NN_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "VALIDATION_DICT = \"validation_dict.pkl\"\n",
    "TEST_MATRIX = \"test_matrix.pkl\"\n",
    "TEST_DICT = \"test_dict.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\"\n",
    "TYPE_CLASSIFIER= \"{}_classifier.pkl\"\n",
    "\n",
    "TRAINING_DATA_MATRIX = \"X_level_{}.npy\"\n",
    "TRAINING_LABELS_MATRIX = \"y_{}.npy\"\n",
    "VALIDATION_DATA_MATRIX = \"Xv_level_{}.npy\"\n",
    "VALIDATION_LABELS_MATRIX = \"yv_{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"lstm_{}_level_{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATIO = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "big_data_location = \"/mnt/data/shalaby/\"\n",
    "\n",
    "doc_vec_types = \"extended_abs_desc_claims_large_sample_chunks\"\n",
    "doc_vec_preprocessed_data_types = \"extended_pv_abs_desc_claims_large_sample_chunks\"\n",
    "\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "doc2vec_model_save_location = os.path.join(big_data_location, \"parameter_search_doc2vec_models_\" + doc_vec_types, \"full\")\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_parameter_search_\" + doc_vec_types)\n",
    "if not os.path.exists(doc2vec_model_save_location):\n",
    "    os.makedirs(doc2vec_model_save_location)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL)):\n",
    "    os.makedirs(os.path.join(doc2vec_model_save_location, VOCAB_MODEL))\n",
    "\n",
    "#training_file = root_location + \"docs_output.json\"\n",
    "training_file = root_location + 'docs_output.json'\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "# training_docs_list_file = exports_location + \"extended_pv_training_docs_list.pkl\"\n",
    "# validation_docs_list_file = exports_location + \"extended_pv_validation_docs_list.pkl\"\n",
    "# test_docs_list_file = exports_location + \"extended_pv_test_docs_list.pkl\"\n",
    "training_docs_list_file = exports_location + \"extended_pv_training_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "validation_docs_list_file = exports_location + \"extended_pv_validation_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "test_docs_list_file = exports_location + \"extended_pv_test_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "\n",
    "preprocessed_location = os.path.join(big_data_location, \"preprocessed_data\", doc_vec_preprocessed_data_types) + \"/\"\n",
    "\n",
    "training_preprocessed_files_prefix = preprocessed_location + \"extended_pv_training_docs_data_preprocessed-\"\n",
    "validation_preprocessed_files_prefix = preprocessed_location + \"extended_pv_validation_docs_data_preprocessed-\"\n",
    "test_preprocessed_files_prefix = preprocessed_location + \"extended_pv_test_docs_data_preprocessed-\"\n",
    "\n",
    "word2vec_questions_file = result = root_location + 'tensorflow/word2vec/questions-words.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load general data required for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 944 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254767"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60957"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79785"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "    \n",
    "def ensure_disk_location_exists(location):\n",
    "    if not os.path.exists(location):\n",
    "        os.makedirs(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FixedDocumentsStatsGenerator(object):\n",
    "    def __init__(self, filename_prefix):\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.docids = []\n",
    "        self.doc_parts = defaultdict(list)\n",
    "        self.doc_part_chunks = defaultdict(list)\n",
    "        self.curr_doc_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_doc_index))\n",
    "        true_docs_count = 0\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_doc_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    line_array = line.split(\" \", 1)\n",
    "                    entity_id = line_array[0].strip()\n",
    "                    if self.is_doc(entity_id):\n",
    "                        self.docids.append(entity_id)\n",
    "                        true_docs_count+= 1\n",
    "                    elif self.is_doc_part(entity_id):\n",
    "                        self.doc_parts[self.get_doc_id(entity_id)].append(entity_id)\n",
    "                    elif self.is_doc_part_chunk(entity_id):\n",
    "                        self.doc_part_chunks[self.get_doc_id(entity_id)].append(entity_id)\n",
    "            self.batch_end = self.curr_doc_index + true_docs_count - 1 \n",
    "            info(\"Finished loading new batch of {} documents\".format(true_docs_count))\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_doc_index))\n",
    "            raise StopIteration()\n",
    "    def get_stats(self):\n",
    "        try:\n",
    "            while True:\n",
    "                if self.curr_doc_index > self.batch_end:\n",
    "                    self.load_new_batch_in_memory()\n",
    "                self.curr_doc_index = self.batch_end + 1\n",
    "        except StopIteration:\n",
    "            pass\n",
    "            \n",
    "    def get_doc_id(self, entity_id):\n",
    "        return entity_id.split(\"_\")[0]\n",
    "    def get_entity_parts(self, entity_id):\n",
    "        return entity_id.split(\"_\")\n",
    "    def is_doc(self, entity_id):\n",
    "        parts = self.get_entity_parts(entity_id)\n",
    "        if len(parts) == 1:\n",
    "            return True\n",
    "        return False\n",
    "    def is_doc_part(self, entity_id):\n",
    "        parts = self.get_entity_parts(entity_id)\n",
    "        if len(parts) == 2:\n",
    "            return True\n",
    "        return False\n",
    "    def is_doc_part_chunk(self, entity_id):\n",
    "        parts = self.get_entity_parts(entity_id)\n",
    "        if len(parts) == 3:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_doc_vector(entity_id):\n",
    "    if entity_id in doc2vec_model.docvecs:\n",
    "        if DOC2VEC_MMAP:\n",
    "            normal_array = []\n",
    "            normal_array[:] = doc2vec_model.docvecs[entity_id][:]\n",
    "            return normal_array\n",
    "        else:\n",
    "            return doc2vec_model.docvecs[entity_id]\n",
    "    else:\n",
    "        # some claims have low token count, so they cant fill out the whole 16 spots\n",
    "        return ZERO_VECTOR\n",
    "\n",
    "def data_generator(doc_stats, doc_id):\n",
    "    yield get_doc_vector(doc_id)\n",
    "    if PARTS_LEVEL >= LEVEL_DIVISIONS:\n",
    "        for part_id in doc_stats.doc_parts[doc_id]:\n",
    "            yield get_doc_vector(part_id)\n",
    "    if PARTS_LEVEL >= LEVEL_CHUNKS:\n",
    "        for part_id in doc_stats.doc_part_chunks[doc_id]:\n",
    "            yield get_doc_vector(part_id)\n",
    "    while True:\n",
    "        yield ZERO_VECTOR\n",
    "\n",
    "def validation_data_generator(doc_stats, validation_dict, doc_id):\n",
    "    yield validation_dict[doc_id]\n",
    "    if PARTS_LEVEL >= LEVEL_DIVISIONS:\n",
    "        for part_id in doc_stats.doc_parts[doc_id]:\n",
    "            yield validation_dict[part_id]\n",
    "    if PARTS_LEVEL >= LEVEL_CHUNKS:\n",
    "        for part_id in doc_stats.doc_part_chunks[doc_id]:\n",
    "            yield validation_dict[part_id]\n",
    "    while True:\n",
    "        yield ZERO_VECTOR\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(doc2vec_model, classifications, classifications_type, doc_stats, sequence_size, embedding_size):\n",
    "    \"\"\"\n",
    "    Creates or loads the X and y matrices used for training\n",
    "    \"\"\"\n",
    "    def get_training_y_labels():\n",
    "        \"\"\"\n",
    "        Creates or loads the y matrix used for training\n",
    "        \"\"\"\n",
    "        if not os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                       TRAINING_LABELS_MATRIX.format(classifications_type))):\n",
    "            info(\"Creating Training Labels\")\n",
    "            one_hot_encoder = OneHotEncoder(classifications)\n",
    "            classifications_set = set(classifications)\n",
    "            training_labels_mat = np.zeros((len(training_docs_list), len(classifications)), dtype=np.int8)\n",
    "            for i, doc_id in enumerate(training_docs_list):\n",
    "                eligible_classifications = set(doc_classification_map[doc_id]) & classifications_set\n",
    "                training_labels_mat[i][:] = one_hot_encoder.get_label_vector(eligible_classifications)\n",
    "        else:    \n",
    "            training_labels_mat = np.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                            TRAINING_LABELS_MATRIX.format(classifications_type))))\n",
    "        return training_labels_mat\n",
    "\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                       TRAINING_DATA_MATRIX.format(PARTS_LEVEL))):\n",
    "        info(\"Creating Training Data\")\n",
    "        one_hot_encoder = OneHotEncoder(classifications)\n",
    "        classifications_set = set(classifications)\n",
    "        # 1st level: document level\n",
    "        training_data = np.ndarray((len(training_docs_list), sequence_size, embedding_size), dtype=np.float32)\n",
    "        info(\"Training Data shape: {}\".format(training_data.shape))\n",
    "        training_labels_mat = np.zeros((len(training_docs_list), len(classifications)), dtype=np.int8)\n",
    "        for i, doc_id in enumerate(training_docs_list):\n",
    "            data_gen = data_generator(doc_stats, doc_id)\n",
    "            # 2nd level: constituents\n",
    "            for j in range(sequence_size):\n",
    "                #3rd level: feature vectors\n",
    "                training_data[i][j] = data_gen.next()\n",
    "            eligible_classifications = set(doc_classification_map[doc_id]) & classifications_set\n",
    "            training_labels_mat[i][:] = one_hot_encoder.get_label_vector(eligible_classifications)\n",
    "            if i % 10000 == 0:\n",
    "                info(\"Finished {} in training\".format(i))\n",
    "        \n",
    "        info(\"Saving Training Data to file...\")\n",
    "        np.save(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                  TRAINING_DATA_MATRIX.format(PARTS_LEVEL)), \"w\"), training_data)\n",
    "        np.save(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                  TRAINING_LABELS_MATRIX.format(classifications_type)), \"w\"), training_labels_mat)\n",
    "    else:\n",
    "        info(\"Loading Training Data from file\")\n",
    "        training_data = np.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  TRAINING_DATA_MATRIX.format(PARTS_LEVEL))))\n",
    "        training_labels_mat = get_training_y_labels()\n",
    "        \n",
    "    return training_data, training_labels_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_data(validation_dict, classifications, classifications_type, doc_stats, sequence_size, embedding_size):\n",
    "    \"\"\"\n",
    "    Creates or loads the X and y matrices used for validation\n",
    "    \"\"\"\n",
    "    def get_validation_y_labels():\n",
    "        \"\"\"\n",
    "        Creates or loads the y matrix used for validation\n",
    "        \"\"\"\n",
    "        if not os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                       VALIDATION_LABELS_MATRIX.format(classifications_type))):\n",
    "            info(\"Creating Validation Labels\")\n",
    "            one_hot_encoder = OneHotEncoder(classifications)\n",
    "            classifications_set = set(classifications)\n",
    "            validation_labels_mat = np.zeros((len(validation_docs_list), len(classifications)), dtype=np.int8)\n",
    "            for i, doc_id in enumerate(validation_docs_list):\n",
    "                eligible_classifications = set(doc_classification_map[doc_id]) & classifications_set\n",
    "                validation_labels_mat[i][:] = one_hot_encoder.get_label_vector(eligible_classifications)\n",
    "        else:    \n",
    "            info(\"Loading Validation Labels\")\n",
    "            validation_labels_mat = np.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                        VALIDATION_LABELS_MATRIX.format(classifications_type))))\n",
    "        return validation_labels_mat\n",
    "\n",
    "    \n",
    "    if not os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                       VALIDATION_DATA_MATRIX.format(PARTS_LEVEL))):\n",
    "        info(\"Creating Validation Data\")\n",
    "        one_hot_encoder = OneHotEncoder(classifications)\n",
    "        classifications_set = set(classifications)\n",
    "        # 1st level: document level\n",
    "        validation_data = np.ndarray((len(validation_docs_list), sequence_size, embedding_size), dtype=np.float32)\n",
    "        info(\"Validation Data shape: {}\".format(validation_data.shape))\n",
    "        validation_labels_mat = np.zeros((len(validation_docs_list), len(classifications)), dtype=np.int8)\n",
    "        for i, doc_id in enumerate(validation_docs_list):\n",
    "            data_gen = validation_data_generator(doc_stats, validation_dict, doc_id)\n",
    "            # 2nd level: constituents\n",
    "            for j in range(sequence_size):\n",
    "                #3d level: feature vectors\n",
    "                validation_data[i][j] = data_gen.next()\n",
    "            eligible_classifications = set(doc_classification_map[doc_id]) & classifications_set\n",
    "            validation_labels_mat[i][:] = one_hot_encoder.get_label_vector(eligible_classifications)\n",
    "            if i % 10000 == 0:\n",
    "                info(\"Finished {} in validation\".format(i))\n",
    "        \n",
    "        info(\"Saving Validation Data to file...\")\n",
    "        np.save(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                  VALIDATION_DATA_MATRIX.format(PARTS_LEVEL)), \"w\"), validation_data)\n",
    "        np.save(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                  VALIDATION_LABELS_MATRIX.format(classifications_type)), \"w\"), validation_labels_mat)\n",
    "    else:\n",
    "        info(\"Loading Validation Data from file\")\n",
    "        validation_data = np.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  VALIDATION_DATA_MATRIX.format(PARTS_LEVEL))))\n",
    "        validation_labels_mat = get_validation_y_labels()\n",
    "        \n",
    "    return validation_data, validation_labels_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the \n",
    "    validation metrics\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        MetricsCallback.EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "        MetricsCallback.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
    "        MetricsCallback.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
    "        self.ax = plt.subplot(111)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
    "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
    "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
    "        self.ax.set_ylim((MetricsCallback.GRAPH_MIN, MetricsCallback.GRAPH_MAX))\n",
    "        self.fig.canvas.draw()\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            #print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            #time.sleep(0.1)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                yvp = self.model.predict(Xv)\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_keras_rnn_model(input_size, output_size, lstm_output_size, w_dropout_do, u_dropout_do, \n",
    "                           stack_layers=1, conv_size=None):\n",
    "    \n",
    "    model= Sequential()\n",
    "#     model.add(Masking(mask_value=0., input_shape=(MAX_SIZE, input_size)))\n",
    "    if conv_size:\n",
    "        model.add(Convolution1D(nb_filter=conv_size, input_shape=(MAX_SIZE, input_size), filter_length=3, \n",
    "                                border_mode='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_length=2))\n",
    "    for i in range(stack_layers):\n",
    "        model.add(LSTM(lstm_output_size, input_dim=input_size, dropout_W=w_dropout_do, dropout_U=u_dropout_do,\n",
    "                       return_sequences=False if i+1 == stack_layers else True,\n",
    "                  name='lstm_{}_w-drop_{}_u-drop_{}_layer_{}'.format(lstm_output_size, str(u_dropout_do), str(w_dropout_do), str(i+1))))\n",
    "    model.add(Dense(output_size, activation='sigmoid', name='sigmoid_output'))\n",
    "    model.compile(optimizer=NN_OPTIMIZER, loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Param Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum change in val_loss from previous epoch to register as a decrease\n",
    "early_stopper_deltas = {\n",
    "    'sections': 0.00001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "# how many epochs to wait when there is no decrease in val_loss before early stopping\n",
    "early_stopper_patience = {\n",
    "    'sections': 15,\n",
    "    'classes': 15,\n",
    "    'subclasses': 15\n",
    "}\n",
    "# number of epochs after which we do periodic evaluation of validation metrics\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 20,\n",
    "    'subclasses': 20\n",
    "}\n",
    "\n",
    "# ranges for learning graph shown\n",
    "metrics_graph_ranges = {\n",
    "    'sections': {'min':0, 'max': 0.5},\n",
    "    'classes': {'min':0, 'max': 0.05},\n",
    "    'subclasses': {'min':0, 'max': 0.05}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEVEL_DOC = 0\n",
    "LEVEL_DIVISIONS = 1\n",
    "LEVEL_CHUNKS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_MMAP = 'r'\n",
    "# DOC2VEC_MMAP = None\n",
    "\n",
    "ZERO_VECTOR = [0] * DOC2VEC_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_PARMS_TO_RUN = [\n",
    "#     {\n",
    "#         'doc2vec_epoch': 3,\n",
    "#         'classifications': sections,\n",
    "#         'classifications_type': 'sections',\n",
    "#         'parts_level': LEVEL_CHUNKS,\n",
    "#         'nn_batch_size': 2048,\n",
    "#         'lstm_output_size': 500,\n",
    "#         'lstm_w_dropout': 0.5,\n",
    "#         'lstm_u_dropout': 0.5,\n",
    "#         'lstm_stack_layers': 1,\n",
    "#         'lstm_conv_size': None\n",
    "#     }, \n",
    "#     {\n",
    "#         'doc2vec_epoch': 12,\n",
    "#         'classifications': sections,\n",
    "#         'classifications_type': 'sections',\n",
    "#         'parts_level': LEVEL_CHUNKS,\n",
    "#         'nn_batch_size': 2048,\n",
    "#         'lstm_output_size': 500,\n",
    "#         'lstm_w_dropout': 0.5,\n",
    "#         'lstm_u_dropout': 0.5,\n",
    "#         'lstm_stack_layers': 1,\n",
    "#         'lstm_conv_size': None\n",
    "#     }\n",
    "#     {\n",
    "#         'doc2vec_epoch': 8,\n",
    "#         'classifications': sections,\n",
    "#         'classifications_type': 'sections',\n",
    "#         'parts_level': LEVEL_DOC,\n",
    "#         'nn_batch_size': 2048,\n",
    "#         'lstm_output_size': 500,\n",
    "#         'lstm_w_dropout': 0.5,\n",
    "#         'lstm_u_dropout': 0.5,\n",
    "#         'lstm_stack_layers': 2,\n",
    "#         'lstm_conv_size': None\n",
    "#     },{\n",
    "#         'doc2vec_epoch': 8,\n",
    "#         'classifications': sections,\n",
    "#         'classifications_type': 'sections',\n",
    "#         'parts_level': LEVEL_DOC,\n",
    "#         'nn_batch_size': 2048,\n",
    "#         'lstm_output_size': 500,\n",
    "#         'lstm_w_dropout': 0.5,\n",
    "#         'lstm_u_dropout': 0.5,\n",
    "#         'lstm_stack_layers': 3,\n",
    "#         'lstm_conv_size': None\n",
    "#     },\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_DIVISIONS,\n",
    "        'nn_batch_size': 2048,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 2,\n",
    "        'lstm_conv_size': None\n",
    "    },{\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_DIVISIONS,\n",
    "        'nn_batch_size': 2048,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 3,\n",
    "        'lstm_conv_size': None\n",
    "    },{\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_CHUNKS,\n",
    "        'nn_batch_size': 2048,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 2,\n",
    "        'lstm_conv_size': None\n",
    "    },\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': sections,\n",
    "        'classifications_type': 'sections',\n",
    "        'parts_level': LEVEL_CHUNKS,\n",
    "        'nn_batch_size': 1024,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 3,\n",
    "        'lstm_conv_size': None\n",
    "    },\n",
    "#     {\n",
    "#         'doc2vec_epoch': 8,\n",
    "#         'classifications': valid_classes,\n",
    "#         'classifications_type': 'classes',\n",
    "#         'parts_level': LEVEL_DOC,\n",
    "#         'nn_batch_size': 2048,\n",
    "#         'lstm_output_size': 500,\n",
    "#         'lstm_w_dropout': 0.5,\n",
    "#         'lstm_u_dropout': 0.5,\n",
    "#         'lstm_stack_layers': 2,\n",
    "#         'lstm_conv_size': None\n",
    "#     },{\n",
    "#         'doc2vec_epoch': 8,\n",
    "#         'classifications': valid_classes,\n",
    "#         'classifications_type': 'classes',\n",
    "#         'parts_level': LEVEL_DOC,\n",
    "#         'nn_batch_size': 2048,\n",
    "#         'lstm_output_size': 500,\n",
    "#         'lstm_w_dropout': 0.5,\n",
    "#         'lstm_u_dropout': 0.5,\n",
    "#         'lstm_stack_layers': 3,\n",
    "#         'lstm_conv_size': None\n",
    "#     },\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': valid_classes,\n",
    "        'classifications_type': 'classes',\n",
    "        'parts_level': LEVEL_DIVISIONS,\n",
    "        'nn_batch_size': 2048,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 2,\n",
    "        'lstm_conv_size': None\n",
    "    },{\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': valid_classes,\n",
    "        'classifications_type': 'classes',\n",
    "        'parts_level': LEVEL_DIVISIONS,\n",
    "        'nn_batch_size': 2048,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 3,\n",
    "        'lstm_conv_size': None\n",
    "    },\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': valid_classes,\n",
    "        'classifications_type': 'classes',\n",
    "        'parts_level': LEVEL_CHUNKS,\n",
    "        'nn_batch_size': 2048,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 2,\n",
    "        'lstm_conv_size': None\n",
    "    },\n",
    "    {\n",
    "        'doc2vec_epoch': 8,\n",
    "        'classifications': valid_classes,\n",
    "        'classifications_type': 'classes',\n",
    "        'parts_level': LEVEL_CHUNKS,\n",
    "        'nn_batch_size': 1024,\n",
    "        'lstm_output_size': 500,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 3,\n",
    "        'lstm_conv_size': None\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== NEW PARAM SET ============================================\n",
      "{'lstm_stack_layers': 2, 'nn_batch_size': 2048, 'classifications_type': 'sections', 'lstm_w_dropout': 0.5, 'lstm_u_dropout': 0.5, 'parts_level': 1, 'lstm_output_size': 500, 'doc2vec_epoch': 8, 'lstm_conv_size': None}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:08:07,727 : INFO : Loading Training Document Stats\n",
      "2017-03-29 04:08:26,796 : INFO : Loading Training Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:08:33,339 : INFO : Loading Validation Document Stats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254767, 4, 200)\n",
      "(254767, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:08:37,345 : INFO : Loading Validation Data from file\n",
      "2017-03-29 04:08:37,411 : INFO : Loading Validation Labels\n",
      "2017-03-29 04:08:37,412 : INFO : Loading Previous results from /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_large_sample_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_1_batch_2048_nn_parameter_searches.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60957, 4, 200)\n",
      "(60957, 8)\n",
      "skipping: lstm_optimizer_rmsprop_size_500_w-drop_0.5_u-drop_0.5_stack_2_conv_None\n",
      "==================================== NEW PARAM SET ============================================\n",
      "{'lstm_stack_layers': 3, 'nn_batch_size': 2048, 'classifications_type': 'sections', 'lstm_w_dropout': 0.5, 'lstm_u_dropout': 0.5, 'parts_level': 1, 'lstm_output_size': 500, 'doc2vec_epoch': 8, 'lstm_conv_size': None}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:09:52,492 : INFO : Loading Training Document Stats\n",
      "2017-03-29 04:10:11,025 : INFO : Loading Training Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:10:11,291 : INFO : Loading Validation Document Stats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254767, 4, 200)\n",
      "(254767, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:10:15,196 : INFO : Loading Validation Data from file\n",
      "2017-03-29 04:10:15,264 : INFO : Loading Validation Labels\n",
      "2017-03-29 04:10:15,268 : INFO : Loading Previous results from /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_large_sample_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_1_batch_2048_nn_parameter_searches.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60957, 4, 200)\n",
      "(60957, 8)\n",
      "skipping: lstm_optimizer_rmsprop_size_500_w-drop_0.5_u-drop_0.5_stack_3_conv_None\n",
      "==================================== NEW PARAM SET ============================================\n",
      "{'lstm_stack_layers': 2, 'nn_batch_size': 2048, 'classifications_type': 'sections', 'lstm_w_dropout': 0.5, 'lstm_u_dropout': 0.5, 'parts_level': 2, 'lstm_output_size': 500, 'doc2vec_epoch': 8, 'lstm_conv_size': None}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:11:30,219 : INFO : Loading Training Document Stats\n",
      "2017-03-29 04:11:49,832 : INFO : Loading Training Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Size: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:11:52,065 : INFO : Loading Validation Document Stats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254767, 34, 200)\n",
      "(254767, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:11:55,963 : INFO : Loading Validation Data from file\n",
      "2017-03-29 04:11:56,519 : INFO : Loading Validation Labels\n",
      "2017-03-29 04:11:56,523 : INFO : Loading Previous results from /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_large_sample_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_2_batch_2048_nn_parameter_searches.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60957, 34, 200)\n",
      "(60957, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:12:52,602 : INFO : ***************************************************************************************\n",
      "2017-03-29 04:12:52,603 : INFO : lstm_optimizer_rmsprop_size_500_w-drop_0.5_u-drop_0.5_stack_2_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, None, 500)     1402000     lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, 500)           2002000     lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 8)             4008        lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "====================================================================================================\n",
      "Total params: 3408008\n",
      "____________________________________________________________________________________________________\n",
      "Train on 254767 samples, validate on 60957 samples\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.3602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:16:07,286 : INFO : Found lower val loss for epoch 1 => 0.35237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 160s - loss: 0.3601 - val_loss: 0.3524\n",
      "Epoch 2/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.3070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:18:37,245 : INFO : Found lower val loss for epoch 2 => 0.30315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 149s - loss: 0.3069 - val_loss: 0.3031\n",
      "Epoch 3/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:21:08,167 : INFO : Found lower val loss for epoch 3 => 0.27714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 150s - loss: 0.2816 - val_loss: 0.2771\n",
      "Epoch 4/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:23:39,591 : INFO : Found lower val loss for epoch 4 => 0.26943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2657 - val_loss: 0.2694\n",
      "Epoch 5/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:26:10,861 : INFO : Found lower val loss for epoch 5 => 0.26399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2537 - val_loss: 0.2640\n",
      "Epoch 6/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:28:41,456 : INFO : Found lower val loss for epoch 6 => 0.25743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 150s - loss: 0.2446 - val_loss: 0.2574\n",
      "Epoch 7/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:31:13,198 : INFO : Found lower val loss for epoch 7 => 0.24843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2369 - val_loss: 0.2484\n",
      "Epoch 8/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2311"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:33:45,071 : INFO : Found lower val loss for epoch 8 => 0.24703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2311 - val_loss: 0.2470\n",
      "Epoch 9/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:36:16,206 : INFO : Found lower val loss for epoch 9 => 0.2413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2261 - val_loss: 0.2413\n",
      "Epoch 10/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:38:47,965 : INFO : Found lower val loss for epoch 10 => 0.23363\n",
      "2017-03-29 04:38:47,967 : INFO : Validation Loss Reduced 10 times\n",
      "2017-03-29 04:38:47,968 : INFO : Evaluating on Validation Data\n",
      "2017-03-29 04:40:24,756 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.820 | Top 3: 0.914 | Top 5: 0.980 | F1 Micro: 0.635 | F1 Macro: 0.538\n",
      "254767/254767 [==============================] - 250s - loss: 0.2219 - val_loss: 0.2336\n",
      "Epoch 11/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.2178 - val_loss: 0.2345\n",
      "Epoch 12/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.2141 - val_loss: 0.2370\n",
      "Epoch 13/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:48:02,550 : INFO : Found lower val loss for epoch 13 => 0.22348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2116 - val_loss: 0.2235\n",
      "Epoch 14/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:50:34,149 : INFO : Found lower val loss for epoch 14 => 0.21844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2086 - val_loss: 0.2184\n",
      "Epoch 15/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.2060 - val_loss: 0.2235\n",
      "Epoch 16/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.2038 - val_loss: 0.2208\n",
      "Epoch 17/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 04:58:09,049 : INFO : Found lower val loss for epoch 17 => 0.21702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.2015 - val_loss: 0.2170\n",
      "Epoch 18/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:00:39,835 : INFO : Found lower val loss for epoch 18 => 0.21281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 150s - loss: 0.1995 - val_loss: 0.2128\n",
      "Epoch 19/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1977 - val_loss: 0.2156\n",
      "Epoch 20/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1955 - val_loss: 0.2152\n",
      "Epoch 21/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:08:14,660 : INFO : Found lower val loss for epoch 21 => 0.20729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1942 - val_loss: 0.2073\n",
      "Epoch 22/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1924 - val_loss: 0.2087\n",
      "Epoch 23/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:13:18,966 : INFO : Found lower val loss for epoch 23 => 0.20697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 152s - loss: 0.1911 - val_loss: 0.2070\n",
      "Epoch 24/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1895 - val_loss: 0.2078\n",
      "Epoch 25/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1881 - val_loss: 0.2087\n",
      "Epoch 26/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1872 - val_loss: 0.2076\n",
      "Epoch 27/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:23:24,172 : INFO : Found lower val loss for epoch 27 => 0.20423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1858 - val_loss: 0.2042\n",
      "Epoch 28/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:25:56,713 : INFO : Found lower val loss for epoch 28 => 0.20092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 152s - loss: 0.1848 - val_loss: 0.2009\n",
      "Epoch 29/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1836 - val_loss: 0.2053\n",
      "Epoch 30/200\n",
      "254767/254767 [==============================] - 148s - loss: 0.1829 - val_loss: 0.2076\n",
      "Epoch 31/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1817 - val_loss: 0.2055\n",
      "Epoch 32/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:35:58,641 : INFO : Found lower val loss for epoch 32 => 0.19885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1805 - val_loss: 0.1989\n",
      "Epoch 33/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1800 - val_loss: 0.2008\n",
      "Epoch 34/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1790 - val_loss: 0.2027\n",
      "Epoch 35/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:43:34,112 : INFO : Found lower val loss for epoch 35 => 0.19863\n",
      "2017-03-29 05:43:34,114 : INFO : Validation Loss Reduced 20 times\n",
      "2017-03-29 05:43:34,115 : INFO : Evaluating on Validation Data\n",
      "2017-03-29 05:45:06,959 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.598 | Top 3: 0.954 | Top 5: 0.991 | F1 Micro: 0.713 | F1 Macro: 0.646\n",
      "254767/254767 [==============================] - 246s - loss: 0.1782 - val_loss: 0.1986\n",
      "Epoch 36/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1773 - val_loss: 0.2000\n",
      "Epoch 37/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:50:13,135 : INFO : Found lower val loss for epoch 37 => 0.19791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 152s - loss: 0.1768 - val_loss: 0.1979\n",
      "Epoch 38/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:52:49,377 : INFO : Found lower val loss for epoch 38 => 0.19723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 156s - loss: 0.1756 - val_loss: 0.1972\n",
      "Epoch 39/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 05:55:21,445 : INFO : Found lower val loss for epoch 39 => 0.1938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 152s - loss: 0.1750 - val_loss: 0.1938\n",
      "Epoch 40/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1743 - val_loss: 0.1967\n",
      "Epoch 41/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1737 - val_loss: 0.1992\n",
      "Epoch 42/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1727 - val_loss: 0.1956\n",
      "Epoch 43/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1723 - val_loss: 0.1944\n",
      "Epoch 44/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1717 - val_loss: 0.1948\n",
      "Epoch 45/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1710 - val_loss: 0.1951\n",
      "Epoch 46/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 06:13:00,897 : INFO : Found lower val loss for epoch 46 => 0.19334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1705 - val_loss: 0.1933\n",
      "Epoch 47/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1701 - val_loss: 0.1955\n",
      "Epoch 48/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1692 - val_loss: 0.1963\n",
      "Epoch 49/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1692 - val_loss: 0.1972\n",
      "Epoch 50/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 06:23:07,905 : INFO : Found lower val loss for epoch 50 => 0.19195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1688 - val_loss: 0.1919\n",
      "Epoch 51/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 06:25:40,508 : INFO : Found lower val loss for epoch 51 => 0.19085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 152s - loss: 0.1683 - val_loss: 0.1908\n",
      "Epoch 52/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1678 - val_loss: 0.1950\n",
      "Epoch 53/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1669 - val_loss: 0.1925\n",
      "Epoch 54/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1666 - val_loss: 0.1921\n",
      "Epoch 55/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1663 - val_loss: 0.1940\n",
      "Epoch 56/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1663 - val_loss: 0.1955\n",
      "Epoch 57/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1655 - val_loss: 0.1925\n",
      "Epoch 58/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1646"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 06:43:20,799 : INFO : Found lower val loss for epoch 58 => 0.1907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 152s - loss: 0.1646 - val_loss: 0.1907\n",
      "Epoch 59/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1641 - val_loss: 0.1916\n",
      "Epoch 60/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 06:48:22,961 : INFO : Found lower val loss for epoch 60 => 0.18906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1641 - val_loss: 0.1891\n",
      "Epoch 61/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1635 - val_loss: 0.1939\n",
      "Epoch 62/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1632 - val_loss: 0.1904\n",
      "Epoch 63/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1631 - val_loss: 0.1895\n",
      "Epoch 64/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1627 - val_loss: 0.1919\n",
      "Epoch 65/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1622 - val_loss: 0.1930\n",
      "Epoch 66/200\n",
      "254767/254767 [==============================] - 149s - loss: 0.1618 - val_loss: 0.1899\n",
      "Epoch 67/200\n",
      "254767/254767 [==============================] - 149s - loss: 0.1616 - val_loss: 0.1899\n",
      "Epoch 68/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1611 - val_loss: 0.1931\n",
      "Epoch 69/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1610 - val_loss: 0.1892\n",
      "Epoch 70/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 07:13:28,992 : INFO : Found lower val loss for epoch 70 => 0.1889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 150s - loss: 0.1605 - val_loss: 0.1889\n",
      "Epoch 71/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1601 - val_loss: 0.1890\n",
      "Epoch 72/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1599 - val_loss: 0.1913\n",
      "Epoch 73/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 07:21:02,217 : INFO : Found lower val loss for epoch 73 => 0.18677\n",
      "2017-03-29 07:21:02,218 : INFO : Validation Loss Reduced 30 times\n",
      "2017-03-29 07:21:02,219 : INFO : Evaluating on Validation Data\n",
      "2017-03-29 07:22:34,928 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.549 | Top 3: 0.960 | Top 5: 0.993 | F1 Micro: 0.735 | F1 Macro: 0.675\n",
      "254767/254767 [==============================] - 244s - loss: 0.1596 - val_loss: 0.1868\n",
      "Epoch 74/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1592 - val_loss: 0.1883\n",
      "Epoch 75/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1594 - val_loss: 0.1908\n",
      "Epoch 76/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1588 - val_loss: 0.1892\n",
      "Epoch 77/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1585 - val_loss: 0.1884\n",
      "Epoch 78/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1584 - val_loss: 0.1905\n",
      "Epoch 79/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1580 - val_loss: 0.1872\n",
      "Epoch 80/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1578 - val_loss: 0.1900\n",
      "Epoch 81/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1575 - val_loss: 0.1897\n",
      "Epoch 82/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1573 - val_loss: 0.1898\n",
      "Epoch 83/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 07:47:48,710 : INFO : Found lower val loss for epoch 83 => 0.1862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1570 - val_loss: 0.1862\n",
      "Epoch 84/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1568 - val_loss: 0.1878\n",
      "Epoch 85/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1565 - val_loss: 0.1864\n",
      "Epoch 86/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 07:55:24,550 : INFO : Found lower val loss for epoch 86 => 0.18422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1561 - val_loss: 0.1842\n",
      "Epoch 87/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1561 - val_loss: 0.1868\n",
      "Epoch 88/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 08:00:26,176 : INFO : Found lower val loss for epoch 88 => 0.18416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1559 - val_loss: 0.1842\n",
      "Epoch 89/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1557 - val_loss: 0.1866\n",
      "Epoch 90/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1556 - val_loss: 0.1853\n",
      "Epoch 91/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 08:08:00,328 : INFO : Found lower val loss for epoch 91 => 0.18291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1553 - val_loss: 0.1829\n",
      "Epoch 92/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 08:10:30,932 : INFO : Found lower val loss for epoch 92 => 0.1815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 150s - loss: 0.1549 - val_loss: 0.1815\n",
      "Epoch 93/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1551 - val_loss: 0.1845\n",
      "Epoch 94/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1545 - val_loss: 0.1879\n",
      "Epoch 95/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1544 - val_loss: 0.1849\n",
      "Epoch 96/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1540 - val_loss: 0.1858\n",
      "Epoch 97/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1540 - val_loss: 0.1859\n",
      "Epoch 98/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1539 - val_loss: 0.1843\n",
      "Epoch 99/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1536 - val_loss: 0.1841\n",
      "Epoch 100/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1537 - val_loss: 0.1834\n",
      "Epoch 101/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1533 - val_loss: 0.1853\n",
      "Epoch 102/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1532 - val_loss: 0.1832\n",
      "Epoch 103/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1530 - val_loss: 0.1860\n",
      "Epoch 104/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1528 - val_loss: 0.1840\n",
      "Epoch 105/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1524 - val_loss: 0.1832\n",
      "Epoch 106/200\n",
      "254767/254767 [==============================] - 149s - loss: 0.1522 - val_loss: 0.1846\n",
      "Epoch 107/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 08:48:13,542 : INFO : Found lower val loss for epoch 107 => 0.18146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 150s - loss: 0.1522 - val_loss: 0.1815\n",
      "Epoch 108/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1516 - val_loss: 0.1854\n",
      "Epoch 109/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1522 - val_loss: 0.1837\n",
      "Epoch 110/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1517 - val_loss: 0.1875\n",
      "Epoch 111/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1515 - val_loss: 0.1852\n",
      "Epoch 112/200\n",
      "254767/254767 [==============================] - 149s - loss: 0.1516 - val_loss: 0.1819\n",
      "Epoch 113/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1513 - val_loss: 0.1825\n",
      "Epoch 114/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1510 - val_loss: 0.1864\n",
      "Epoch 115/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 09:08:17,562 : INFO : Found lower val loss for epoch 115 => 0.18135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 149s - loss: 0.1508 - val_loss: 0.1814\n",
      "Epoch 116/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 09:10:49,059 : INFO : Found lower val loss for epoch 116 => 0.17766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 151s - loss: 0.1502 - val_loss: 0.1777\n",
      "Epoch 117/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1507 - val_loss: 0.1820\n",
      "Epoch 118/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1504 - val_loss: 0.1816\n",
      "Epoch 119/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1502 - val_loss: 0.1824\n",
      "Epoch 120/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1503 - val_loss: 0.1823\n",
      "Epoch 121/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1499 - val_loss: 0.1823\n",
      "Epoch 122/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1500 - val_loss: 0.1819\n",
      "Epoch 123/200\n",
      "254767/254767 [==============================] - 149s - loss: 0.1501 - val_loss: 0.1826\n",
      "Epoch 124/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1496 - val_loss: 0.1823\n",
      "Epoch 125/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1492 - val_loss: 0.1798\n",
      "Epoch 126/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1494 - val_loss: 0.1824\n",
      "Epoch 127/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1489 - val_loss: 0.1812\n",
      "Epoch 128/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1491 - val_loss: 0.1791\n",
      "Epoch 129/200\n",
      "254767/254767 [==============================] - 151s - loss: 0.1487 - val_loss: 0.1811\n",
      "Epoch 130/200\n",
      "254767/254767 [==============================] - 152s - loss: 0.1487 - val_loss: 0.1805\n",
      "Epoch 131/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1486 - val_loss: 0.1797\n",
      "Epoch 132/200\n",
      "254767/254767 [==============================] - 150s - loss: 0.1489 - val_loss: 0.1829\n",
      "Epoch 00131: early stopping\n",
      "CPU times: user 1h 56min 1s, sys: 3h 25min 57s, total: 5h 21min 58s\n",
      "Wall time: 5h 38min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 09:51:00,836 : INFO : Evaluating on Training Data\n",
      "2017-03-29 09:57:26,374 : INFO : Generating Training Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Training Metrics: Cov Err: 1.441 | Top 3: 0.978 | Top 5: 0.997 | F1 Micro: 0.849 | F1 Macro: 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 09:57:32,830 : INFO : Evaluating on Validation Data using saved best weights\n",
      "2017-03-29 09:59:04,673 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.526 | Top 3: 0.964 | Top 5: 0.993 | F1 Micro: 0.746 | F1 Macro: 0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 09:59:06,353 : INFO : Loading Previous results from /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_large_sample_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_2_batch_2048_nn_parameter_searches.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== NEW PARAM SET ============================================\n",
      "{'lstm_stack_layers': 3, 'nn_batch_size': 1024, 'classifications_type': 'sections', 'lstm_w_dropout': 0.5, 'lstm_u_dropout': 0.5, 'parts_level': 2, 'lstm_output_size': 500, 'doc2vec_epoch': 8, 'lstm_conv_size': None}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:00:32,090 : INFO : Loading Training Document Stats\n",
      "2017-03-29 10:00:51,780 : INFO : Loading Training Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Size: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:01:04,613 : INFO : Loading Validation Document Stats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254767, 34, 200)\n",
      "(254767, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:01:08,461 : INFO : Loading Validation Data from file\n",
      "2017-03-29 10:01:09,033 : INFO : Loading Validation Labels\n",
      "2017-03-29 10:01:09,035 : INFO : Loading Previous results from /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_large_sample_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_2_batch_1024_nn_parameter_searches.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60957, 34, 200)\n",
      "(60957, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:01:11,725 : INFO : ***************************************************************************************\n",
      "2017-03-29 10:01:11,726 : INFO : lstm_optimizer_rmsprop_size_500_w-drop_0.5_u-drop_0.5_stack_3_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, None, 500)     1402000     lstm_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, None, 500)     2002000     lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "____________________________________________________________________________________________________\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, 500)           2002000     lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 8)             4008        lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "====================================================================================================\n",
      "Total params: 5410008\n",
      "____________________________________________________________________________________________________\n",
      "Train on 254767 samples, validate on 60957 samples\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.3545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:06:39,461 : INFO : Found lower val loss for epoch 1 => 0.33374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 270s - loss: 0.3544 - val_loss: 0.3337\n",
      "Epoch 2/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.3070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:11:20,566 : INFO : Found lower val loss for epoch 2 => 0.31182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 281s - loss: 0.3070 - val_loss: 0.3118\n",
      "Epoch 3/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:15:59,492 : INFO : Found lower val loss for epoch 3 => 0.27352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 278s - loss: 0.2781 - val_loss: 0.2735\n",
      "Epoch 4/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:20:40,350 : INFO : Found lower val loss for epoch 4 => 0.27094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 280s - loss: 0.2599 - val_loss: 0.2709\n",
      "Epoch 5/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:25:19,556 : INFO : Found lower val loss for epoch 5 => 0.25106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 279s - loss: 0.2476 - val_loss: 0.2511\n",
      "Epoch 6/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:29:59,123 : INFO : Found lower val loss for epoch 6 => 0.25013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 279s - loss: 0.2390 - val_loss: 0.2501\n",
      "Epoch 7/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:34:35,867 : INFO : Found lower val loss for epoch 7 => 0.24481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 276s - loss: 0.2316 - val_loss: 0.2448\n",
      "Epoch 8/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:39:15,743 : INFO : Found lower val loss for epoch 8 => 0.23762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 279s - loss: 0.2259 - val_loss: 0.2376\n",
      "Epoch 9/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:43:54,549 : INFO : Found lower val loss for epoch 9 => 0.2235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 278s - loss: 0.2211 - val_loss: 0.2235\n",
      "Epoch 10/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.2170 - val_loss: 0.2262\n",
      "Epoch 11/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2129"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 10:53:15,399 : INFO : Found lower val loss for epoch 11 => 0.22208\n",
      "2017-03-29 10:53:15,401 : INFO : Validation Loss Reduced 10 times\n",
      "2017-03-29 10:53:15,403 : INFO : Evaluating on Validation Data\n",
      "2017-03-29 10:55:42,858 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.756 | Top 3: 0.925 | Top 5: 0.984 | F1 Micro: 0.656 | F1 Macro: 0.569\n",
      "254767/254767 [==============================] - 426s - loss: 0.2129 - val_loss: 0.2221\n",
      "Epoch 12/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 11:00:26,724 : INFO : Found lower val loss for epoch 12 => 0.21756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 282s - loss: 0.2097 - val_loss: 0.2176\n",
      "Epoch 13/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 11:05:10,727 : INFO : Found lower val loss for epoch 13 => 0.21607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 284s - loss: 0.2068 - val_loss: 0.2161\n",
      "Epoch 14/200\n",
      "254767/254767 [==============================] - 284s - loss: 0.2038 - val_loss: 0.2167\n",
      "Epoch 15/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 11:14:37,603 : INFO : Found lower val loss for epoch 15 => 0.21543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 282s - loss: 0.2014 - val_loss: 0.2154\n",
      "Epoch 16/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 11:19:19,737 : INFO : Found lower val loss for epoch 16 => 0.20875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 282s - loss: 0.1992 - val_loss: 0.2088\n",
      "Epoch 17/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1972 - val_loss: 0.2129\n",
      "Epoch 18/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1950 - val_loss: 0.2103\n",
      "Epoch 19/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1934 - val_loss: 0.2088\n",
      "Epoch 20/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1917 - val_loss: 0.2117\n",
      "Epoch 21/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 11:42:56,065 : INFO : Found lower val loss for epoch 21 => 0.20652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 284s - loss: 0.1904 - val_loss: 0.2065\n",
      "Epoch 22/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 11:47:40,157 : INFO : Found lower val loss for epoch 22 => 0.20231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 284s - loss: 0.1888 - val_loss: 0.2023\n",
      "Epoch 23/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 11:52:24,515 : INFO : Found lower val loss for epoch 23 => 0.19897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 284s - loss: 0.1872 - val_loss: 0.1990\n",
      "Epoch 24/200\n",
      "254767/254767 [==============================] - 286s - loss: 0.1860 - val_loss: 0.2066\n",
      "Epoch 25/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1853 - val_loss: 0.2027\n",
      "Epoch 26/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1837 - val_loss: 0.2017\n",
      "Epoch 27/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1826 - val_loss: 0.2034\n",
      "Epoch 28/200\n",
      "254767/254767 [==============================] - 284s - loss: 0.1816 - val_loss: 0.2036\n",
      "Epoch 29/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1804 - val_loss: 0.2010\n",
      "Epoch 30/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 12:25:29,987 : INFO : Found lower val loss for epoch 30 => 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 282s - loss: 0.1795 - val_loss: 0.1962\n",
      "Epoch 31/200\n",
      "254767/254767 [==============================] - 284s - loss: 0.1786 - val_loss: 0.1980\n",
      "Epoch 32/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 12:34:57,602 : INFO : Found lower val loss for epoch 32 => 0.19564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 283s - loss: 0.1778 - val_loss: 0.1956\n",
      "Epoch 33/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1770 - val_loss: 0.1995\n",
      "Epoch 34/200\n",
      "254767/254767 [==============================] - 285s - loss: 0.1762 - val_loss: 0.1969\n",
      "Epoch 35/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1752 - val_loss: 0.1962\n",
      "Epoch 36/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1748 - val_loss: 0.1957\n",
      "Epoch 37/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1740 - val_loss: 0.1963\n",
      "Epoch 38/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 13:03:18,773 : INFO : Found lower val loss for epoch 38 => 0.19313\n",
      "2017-03-29 13:03:18,774 : INFO : Validation Loss Reduced 20 times\n",
      "2017-03-29 13:03:18,775 : INFO : Evaluating on Validation Data\n",
      "2017-03-29 13:05:58,765 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.585 | Top 3: 0.956 | Top 5: 0.991 | F1 Micro: 0.720 | F1 Macro: 0.652\n",
      "254767/254767 [==============================] - 443s - loss: 0.1733 - val_loss: 0.1931\n",
      "Epoch 39/200\n",
      "254767/254767 [==============================] - 289s - loss: 0.1722 - val_loss: 0.1970\n",
      "Epoch 40/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1719 - val_loss: 0.1963\n",
      "Epoch 41/200\n",
      "254767/254767 [==============================] - 279s - loss: 0.1711 - val_loss: 0.1936\n",
      "Epoch 42/200\n",
      "254767/254767 [==============================] - 255s - loss: 0.1711 - val_loss: 0.1933\n",
      "Epoch 43/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 13:28:31,114 : INFO : Found lower val loss for epoch 43 => 0.19154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 243s - loss: 0.1702 - val_loss: 0.1915\n",
      "Epoch 44/200\n",
      "254767/254767 [==============================] - 242s - loss: 0.1697 - val_loss: 0.1977\n",
      "Epoch 45/200\n",
      "254767/254767 [==============================] - 241s - loss: 0.1693 - val_loss: 0.1940\n",
      "Epoch 46/200\n",
      "254767/254767 [==============================] - 241s - loss: 0.1687 - val_loss: 0.1955\n",
      "Epoch 47/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1686"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 13:44:38,493 : INFO : Found lower val loss for epoch 47 => 0.1891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 241s - loss: 0.1685 - val_loss: 0.1891\n",
      "Epoch 48/200\n",
      "254767/254767 [==============================] - 242s - loss: 0.1679 - val_loss: 0.1957\n",
      "Epoch 49/200\n",
      "254767/254767 [==============================] - 239s - loss: 0.1670 - val_loss: 0.1902\n",
      "Epoch 50/200\n",
      "254767/254767 [==============================] - 241s - loss: 0.1669 - val_loss: 0.1921\n",
      "Epoch 51/200\n",
      "254767/254767 [==============================] - 240s - loss: 0.1664 - val_loss: 0.1905\n",
      "Epoch 52/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 14:04:43,426 : INFO : Found lower val loss for epoch 52 => 0.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 240s - loss: 0.1658 - val_loss: 0.1890\n",
      "Epoch 53/200\n",
      "254767/254767 [==============================] - 241s - loss: 0.1660 - val_loss: 0.1950\n",
      "Epoch 54/200\n",
      "254767/254767 [==============================] - 241s - loss: 0.1653 - val_loss: 0.1893\n",
      "Epoch 55/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 14:16:48,237 : INFO : Found lower val loss for epoch 55 => 0.18868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 241s - loss: 0.1645 - val_loss: 0.1887\n",
      "Epoch 56/200\n",
      "254767/254767 [==============================] - 239s - loss: 0.1645 - val_loss: 0.1901\n",
      "Epoch 57/200\n",
      "254767/254767 [==============================] - 241s - loss: 0.1638 - val_loss: 0.1895\n",
      "Epoch 58/200\n",
      "254767/254767 [==============================] - 240s - loss: 0.1634 - val_loss: 0.1945\n",
      "Epoch 59/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 14:32:50,625 : INFO : Found lower val loss for epoch 59 => 0.18794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 240s - loss: 0.1635 - val_loss: 0.1879\n",
      "Epoch 60/200\n",
      "254767/254767 [==============================] - 256s - loss: 0.1632 - val_loss: 0.1907\n",
      "Epoch 61/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 14:41:48,618 : INFO : Found lower val loss for epoch 61 => 0.18769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 281s - loss: 0.1625 - val_loss: 0.1877\n",
      "Epoch 62/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1628 - val_loss: 0.1891\n",
      "Epoch 63/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1621 - val_loss: 0.1887\n",
      "Epoch 64/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1617 - val_loss: 0.1887\n",
      "Epoch 65/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 15:00:38,566 : INFO : Found lower val loss for epoch 65 => 0.18632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 282s - loss: 0.1618 - val_loss: 0.1863\n",
      "Epoch 66/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 15:05:20,437 : INFO : Found lower val loss for epoch 66 => 0.18616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 281s - loss: 0.1613 - val_loss: 0.1862\n",
      "Epoch 67/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1610 - val_loss: 0.1866\n",
      "Epoch 68/200\n",
      "254767/254767 [==============================] - 280s - loss: 0.1609 - val_loss: 0.1875\n",
      "Epoch 69/200\n",
      "254767/254767 [==============================] - 284s - loss: 0.1604 - val_loss: 0.1903\n",
      "Epoch 70/200\n",
      "254767/254767 [==============================] - 281s - loss: 0.1603 - val_loss: 0.1921\n",
      "Epoch 71/200\n",
      "254767/254767 [==============================] - 284s - loss: 0.1597 - val_loss: 0.1918\n",
      "Epoch 72/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 15:33:36,665 : INFO : Found lower val loss for epoch 72 => 0.18525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 281s - loss: 0.1598 - val_loss: 0.1853\n",
      "Epoch 73/200\n",
      "254767/254767 [==============================] - 282s - loss: 0.1597 - val_loss: 0.1878\n",
      "Epoch 74/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-29 15:43:00,589 : INFO : Found lower val loss for epoch 74 => 0.18467\n",
      "2017-03-29 15:43:00,590 : INFO : Validation Loss Reduced 30 times\n",
      "2017-03-29 15:43:00,591 : INFO : Evaluating on Validation Data\n",
      "2017-03-29 15:45:23,219 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.550 | Top 3: 0.960 | Top 5: 0.992 | F1 Micro: 0.738 | F1 Macro: 0.678\n",
      "254767/254767 [==============================] - 425s - loss: 0.1588 - val_loss: 0.1847\n",
      "Epoch 75/200\n",
      "254767/254767 [==============================] - 283s - loss: 0.1591 - val_loss: 0.1874\n",
      "Epoch 76/200\n",
      "254767/254767 [==============================] - 293s - loss: 0.1590 - val_loss: 0.1911\n",
      "Epoch 77/200\n",
      "254767/254767 [==============================] - 293s - loss: 0.1585 - val_loss: 0.1855\n",
      "Epoch 78/200\n",
      "254767/254767 [==============================] - 294s - loss: 0.1583 - val_loss: 0.1887\n",
      "Epoch 79/200\n",
      "254767/254767 [==============================] - 294s - loss: 0.1583 - val_loss: 0.1884\n",
      "Epoch 80/200\n",
      "254767/254767 [==============================] - 295s - loss: 0.1578 - val_loss: 0.1880\n",
      "Epoch 81/200\n",
      "254767/254767 [==============================] - 295s - loss: 0.1576 - val_loss: 0.1864\n",
      "Epoch 82/200\n",
      " 37888/254767 [===>..........................] - ETA: 244s - loss: 0.1561"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "for GLOBAL_PARAMS in GLOBAL_PARMS_TO_RUN:\n",
    "    \n",
    "    print '==================================== NEW PARAM SET ============================================'\n",
    "    print {k:v for k,v in GLOBAL_PARAMS.items() if k != 'classifications'}\n",
    "    \n",
    "    classifications = GLOBAL_PARAMS['classifications']\n",
    "    classifications_type = GLOBAL_PARAMS['classifications_type']\n",
    "    classifier_file = TYPE_CLASSIFIER.format(classifications_type)\n",
    "    \n",
    "    PARTS_LEVEL = GLOBAL_PARAMS['parts_level']\n",
    "    \n",
    "    \n",
    "    placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "    placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "    epoch = GLOBAL_PARAMS['doc2vec_epoch']\n",
    "\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    doc2vec_model = None\n",
    "\n",
    "    training_doc_stats_file = os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \"extended_pv_training_doc_stats.pkl\")\n",
    "    validation_doc_stats_file = os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \"extended_pv_validation_doc_stats.pkl\")\n",
    "\n",
    "    print GLOBAL_VARS.MODEL_NAME\n",
    "    \n",
    "#     print os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)\n",
    "#     if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "#         doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX), mmap=DOC2VEC_MMAP)\n",
    "#         doc2vec_model.workers = NUM_CORES\n",
    "#         GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "#     else:\n",
    "#         info(\"Couldnt find the doc2vec model with epoch {}\".format(epoch))\n",
    "#         raise Exception()\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    info(\"Loading Training Document Stats\")\n",
    "    doc_stats = pickle.load(open(training_doc_stats_file, \"r\"))\n",
    "    \n",
    "    MAX_SIZE = 1 # for document vector\n",
    "    if PARTS_LEVEL >= LEVEL_DIVISIONS:\n",
    "        MAX_PARTS = int(np.max([len(doc_stats.doc_parts[d]) for d in doc_stats.docids]))\n",
    "        MAX_SIZE += MAX_PARTS\n",
    "\n",
    "    if PARTS_LEVEL >= LEVEL_CHUNKS:\n",
    "        MAX_PART_CHUNKS = int(np.max([len(doc_stats.doc_part_chunks[d]) for d in doc_stats.docids]))\n",
    "        MAX_SIZE += MAX_PART_CHUNKS\n",
    "\n",
    "    print \"Max Size: {}\".format(MAX_SIZE)\n",
    "    \n",
    "    X, y = get_training_data(doc2vec_model, classifications, classifications_type, doc_stats, MAX_SIZE, DOC2VEC_SIZE)\n",
    "    print X.shape\n",
    "    print y.shape\n",
    "    \n",
    "    validation_dict = None\n",
    "#     validation_dict = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_DICT)))\n",
    "    info(\"Loading Validation Document Stats\")\n",
    "    validation_doc_stats = pickle.load(open(validation_doc_stats_file, \"r\"))\n",
    "    Xv, yv = get_validation_data(validation_dict, classifications, classifications_type, validation_doc_stats, \n",
    "                             MAX_SIZE, DOC2VEC_SIZE)\n",
    "    print Xv.shape\n",
    "    print yv.shape\n",
    "    \n",
    "    \n",
    "    NN_OUTPUT_NEURONS = len(classifications)\n",
    "    EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "    EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "\n",
    "    NN_MAX_EPOCHS = 200\n",
    "    NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "    NN_BATCH_SIZE = GLOBAL_PARAMS['nn_batch_size']\n",
    "\n",
    "    MODEL_VERBOSITY = 1\n",
    "\n",
    "    NN_OPTIMIZER = 'rmsprop'\n",
    "    # NN_OPTIMIZER = 'adam'\n",
    "\n",
    "    to_skip = []\n",
    "\n",
    "    load_existing_results = True\n",
    "    save_results = True\n",
    "\n",
    "\n",
    "    np.random.seed(NN_SEED)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    ############### Actual Training\n",
    "\n",
    "\n",
    "    # load previous finshed results so we dont redo them\n",
    "    param_results_dict = {}\n",
    "    if load_existing_results:\n",
    "        param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results from {}'.format(param_results_path))\n",
    "            param_results_dict = pickle.load(open(param_results_path))\n",
    "        else:\n",
    "            info('No Previous results exist in {}'.format(param_results_path))\n",
    "\n",
    "\n",
    "    # create nn parameter search directory\n",
    "    if not os.path.exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME)):\n",
    "        os.makedirs(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "    start_time = time.time()\n",
    "    lstm_output_size = GLOBAL_PARAMS['lstm_output_size']\n",
    "    w_dropout_do = GLOBAL_PARAMS['lstm_w_dropout']\n",
    "    u_dropout_do = GLOBAL_PARAMS['lstm_u_dropout']\n",
    "    stack_layers = GLOBAL_PARAMS['lstm_stack_layers']\n",
    "    conv_size = GLOBAL_PARAMS['lstm_conv_size']\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "        lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    "    )\n",
    "\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "\n",
    "    info('***************************************************************************************')\n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "    # creating the actual keras model\n",
    "    model = create_keras_rnn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size)\n",
    "    model.summary()\n",
    "\n",
    "    # callbacks for early stopping and for generating validation metrics\n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                              nb_epoch=NN_MAX_EPOCHS, verbose=MODEL_VERBOSITY, \\\n",
    "                              callbacks=[early_stopper, metrics_callback])\n",
    "    \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Training Data')\n",
    "    yp = model.predict(X) # get raw probability for predicted labels\n",
    "    yp_binary = get_binary_0_5(yp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    #print yvp\n",
    "    info('Generating Training Metrics')\n",
    "    training_metrics = get_metrics(y, yp, yp_binary)\n",
    "    print \"****** Training Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    training_metrics['coverage_error'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "    training_metrics['f1_micro'], training_metrics['f1_macro'])\n",
    "    \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Validation Data using saved best weights')\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    yvp = model.predict(Xv) # get raw probability for predicted labels\n",
    "    yvp_binary = get_binary_0_5(yvp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    best_validation_metrics = validation_metrics\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "    del history, metrics_callback, model\n",
    "\n",
    "    if save_results:\n",
    "        if load_existing_results:\n",
    "            if os.path.exists(param_results_path):\n",
    "                info('Loading Previous results from {}'.format(param_results_path))\n",
    "                loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "                param_results_dict.update(loaded_param_results_dict)\n",
    "\n",
    "        pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                                       NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE))), 'w'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = valid_classes\n",
    "classifications_type = 'sections'\n",
    "classifier_file = TYPE_CLASSIFIER.format(classifications_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is where we set which level we want to train for\n",
    "0 -> Use only the document vector  \n",
    "1 -> Use the document vector and the vectors for abstract, description, claims  \n",
    "2 -> Use the document vector and the vectors for abstract, description, claims plus the chunk vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEVEL_DOC = 0\n",
    "LEVEL_DIVISIONS = 1\n",
    "LEVEL_CHUNKS = 2\n",
    "\n",
    "PARTS_LEVEL = LEVEL_DIVISIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_MMAP = 'r'\n",
    "# DOC2VEC_MMAP = None\n",
    "\n",
    "ZERO_VECTOR = [0] * DOC2VEC_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = 8\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "doc2vec_model = None\n",
    "\n",
    "training_doc_stats_file = os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \"extended_pv_training_doc_stats.pkl\")\n",
    "validation_doc_stats_file = os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \"extended_pv_validation_doc_stats.pkl\")\n",
    "\n",
    "print GLOBAL_VARS.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-26 05:38:34,135 : INFO : loading Doc2Vec object from /mnt/data/shalaby/parameter_search_doc2vec_models_extended_abs_desc_claims_large_sample_chunks/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/shalaby/parameter_search_doc2vec_models_extended_abs_desc_claims_large_sample_chunks/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-26 05:39:08,359 : INFO : loading docvecs recursively from /mnt/data/shalaby/parameter_search_doc2vec_models_extended_abs_desc_claims_large_sample_chunks/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.docvecs.* with mmap=r\n",
      "2017-03-26 05:39:08,361 : INFO : loading doctag_syn0 from /mnt/data/shalaby/parameter_search_doc2vec_models_extended_abs_desc_claims_large_sample_chunks/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.docvecs.doctag_syn0.npy with mmap=r\n",
      "2017-03-26 05:39:08,398 : INFO : loading syn1neg from /mnt/data/shalaby/parameter_search_doc2vec_models_extended_abs_desc_claims_large_sample_chunks/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn1neg.npy with mmap=r\n",
      "2017-03-26 05:39:08,444 : INFO : loading syn0 from /mnt/data/shalaby/parameter_search_doc2vec_models_extended_abs_desc_claims_large_sample_chunks/full/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn0.npy with mmap=r\n",
      "2017-03-26 05:39:08,458 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-03-26 05:39:08,459 : INFO : setting ignored attribute cum_table to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 5.38 s, total: 34.9 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)\n",
    "if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "    doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX), mmap=DOC2VEC_MMAP)\n",
    "    doc2vec_model.workers = NUM_CORES\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "else:\n",
    "    info(\"Couldnt find the doc2vec model with epoch {}\".format(epoch))\n",
    "    raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data to use for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create/Load Training Document Stats \n",
    "these contain references to the ids of the parts of each document \n",
    "\n",
    "(ex. 059884 -> [\"059884_abstract\", \"059884_abstract\", \"059884_abstract\", \"059884_abstract_part-1\",...]) \n",
    "\n",
    "so we know what to load when constructing the training and validation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 20:39:48,969 : INFO : Loading Training Document Stats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 1.78 s, total: 22.3 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.exists(training_doc_stats_file):\n",
    "    info(\"Creating Training Document Stats\")\n",
    "    doc_stats = FixedDocumentsStatsGenerator(training_preprocessed_files_prefix)\n",
    "    doc_stats.get_stats()\n",
    "    pickle.dump(doc_stats, open(training_doc_stats_file, \"w\"))\n",
    "else:\n",
    "    info(\"Loading Training Document Stats\")\n",
    "    doc_stats = pickle.load(open(training_doc_stats_file, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Size: 4\n"
     ]
    }
   ],
   "source": [
    "MAX_SIZE = 1 # for document vector\n",
    "if PARTS_LEVEL >= LEVEL_DIVISIONS:\n",
    "    MAX_PARTS = int(np.max([len(doc_stats.doc_parts[d]) for d in doc_stats.docids]))\n",
    "    MAX_SIZE += MAX_PARTS\n",
    "\n",
    "if PARTS_LEVEL >= LEVEL_CHUNKS:\n",
    "    MAX_PART_CHUNKS = int(np.max([len(doc_stats.doc_part_chunks[d]) for d in doc_stats.docids]))\n",
    "    MAX_SIZE += MAX_PART_CHUNKS\n",
    "    \n",
    "print \"Max Size: {}\".format(MAX_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Training Data Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 23:42:43,521 : INFO : Loading Training Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 3.46 s, total: 3.46 s\n",
      "Wall time: 3.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = get_training_data(doc2vec_model, classifications, classifications_type, doc_stats, MAX_SIZE, DOC2VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815254528\n",
      "(254767, 4, 200)\n",
      "(254767, 8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.getsizeof(X)\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create/Load Validation Doc Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_dict = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Validation Dict. This is the dictionary that contains the precomputed doc2vec vectors for each document, document part and chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 3.98 s, total: 3min\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_dict = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_DICT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 20:40:11,431 : INFO : Loading Validation Document Stats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.13 s, sys: 152 ms, total: 4.28 s\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.exists(validation_doc_stats_file):\n",
    "    validation_doc_stats = FixedDocumentsStatsGenerator(validation_preprocessed_files_prefix)\n",
    "    validation_doc_stats.get_stats()\n",
    "    pickle.dump(validation_doc_stats, open(validation_doc_stats_file, \"w\"))\n",
    "else:\n",
    "    info(\"Loading Validation Document Stats\")\n",
    "    validation_doc_stats = pickle.load(open(validation_doc_stats_file, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Validation Data Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 23:42:58,506 : INFO : Loading Validation Data from file\n",
      "2017-03-27 23:42:59,195 : INFO : Loading Validation Labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 664 ms, total: 664 ms\n",
      "Wall time: 691 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Xv, yv = get_validation_data(validation_dict, classifications, classifications_type, validation_doc_stats, \n",
    "                             MAX_SIZE, DOC2VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del validation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60957, 4, 200)\n",
      "(60957, 8)\n"
     ]
    }
   ],
   "source": [
    "print Xv.shape\n",
    "print yv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Parameters and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_keras_rnn_model(input_size, output_size, lstm_output_size, w_dropout_do, u_dropout_do, \n",
    "                           stack_layers=1, conv_size=None):\n",
    "    \n",
    "    model= Sequential()\n",
    "#     model.add(Masking(mask_value=0., input_shape=(MAX_SIZE, input_size)))\n",
    "    if conv_size:\n",
    "        model.add(Convolution1D(nb_filter=conv_size, input_shape=(MAX_SIZE, input_size), filter_length=3, \n",
    "                                border_mode='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_length=2))\n",
    "    for i in range(stack_layers):\n",
    "        model.add(LSTM(lstm_output_size, input_dim=input_size, dropout_W=w_dropout_do, dropout_U=u_dropout_do,\n",
    "                       return_sequences=False if i+1 == stack_layers else True,\n",
    "                  name='lstm_{}_w-drop_{}_u-drop_{}_layer_{}'.format(lstm_output_size, str(u_dropout_do), str(w_dropout_do), str(i+1))))\n",
    "    model.add(Dense(output_size, activation='sigmoid', name='sigmoid_output'))\n",
    "    model.compile(optimizer=NN_OPTIMIZER, loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum change in val_loss from previous epoch to register as a decrease\n",
    "early_stopper_deltas = {\n",
    "    'sections': 0.00001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "# how many epochs to wait when there is no decrease in val_loss before early stopping\n",
    "early_stopper_patience = {\n",
    "    'sections': 15,\n",
    "    'classes': 15,\n",
    "    'subclasses': 15\n",
    "}\n",
    "# number of epochs after which we do periodic evaluation of validation metrics\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 20,\n",
    "    'subclasses': 20\n",
    "}\n",
    "\n",
    "# ranges for learning graph shown\n",
    "metrics_graph_ranges = {\n",
    "    'sections': {'min':0, 'max': 0.5},\n",
    "    'classes': {'min':0, 'max': 0.05},\n",
    "    'subclasses': {'min':0, 'max': 0.05}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the \n",
    "    validation metrics\n",
    "    \"\"\"\n",
    "    def __init__():\n",
    "        MetricsCallback.EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "        MetricsCallback.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
    "        MetricsCallback.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
    "        self.ax = plt.subplot(111)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
    "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
    "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
    "        self.ax.set_ylim((MetricsCallback.GRAPH_MIN, MetricsCallback.GRAPH_MAX))\n",
    "        self.fig.canvas.draw()\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            #print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            #time.sleep(0.1)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                yvp = self.model.predict(Xv)\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "\n",
    "EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "\n",
    "NN_MAX_EPOCHS = 200\n",
    "NN_RANDOM_SEARCH_BUDGET = 30\n",
    "NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "NN_BATCH_SIZE = 2048\n",
    "\n",
    "MODEL_VERBOSITY = 1\n",
    "\n",
    "NN_OPTIMIZER = 'rmsprop'\n",
    "# NN_OPTIMIZER = 'adam'\n",
    "\n",
    "to_skip = []\n",
    "\n",
    "load_existing_results = True\n",
    "save_results = True\n",
    "\n",
    "# parameters to use when doing random hyperparameter search\n",
    "lstm_output_sizes = [200,500,1000]\n",
    "w_dropout_options = [0.2,None,0.5]\n",
    "u_dropout_options = [0.2,None,0.5]\n",
    "stack_layers_options = [1,2]\n",
    "conv_size_options = [None]\n",
    "# conv_size_options = [None, 32,100,200,300]\n",
    "\n",
    "\n",
    "# Uncomment for Specific Configuration\n",
    "NN_RANDOM_SEARCH_BUDGET = 2\n",
    "lstm_output_sizes = [500,1000]\n",
    "w_dropout_options = [0.5]\n",
    "u_dropout_options = [0.5]\n",
    "stack_layers_options = [3]\n",
    "conv_size_options = [None]\n",
    "\n",
    "np.random.seed(NN_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 23:55:07,969 : INFO : Loading Previous results from /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_large_sample_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_1_batch_2048_nn_parameter_searches.pkl\n",
      "2017-03-27 23:56:22,986 : INFO : ***************************************************************************************\n",
      "2017-03-27 23:56:22,988 : INFO : lstm_optimizer_rmsprop_size_500_w-drop_0.5_u-drop_0.5_stack_3_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, None, 500)     1402000     lstm_input_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, None, 500)     2002000     lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "____________________________________________________________________________________________________\n",
      "lstm_500_w-drop_0.5_u-drop_0.5_l (None, 500)           2002000     lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 8)             4008        lstm_500_w-drop_0.5_u-drop_0.5_la\n",
      "====================================================================================================\n",
      "Total params: 5410008\n",
      "____________________________________________________________________________________________________\n",
      "Train on 254767 samples, validate on 60957 samples\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8AAAAHgCAYAAABq5QSEAAAgAElEQVR4nO3deXxddZ3w8W/SlEKbpBtdgZalVMoyCIhah7KpxVF8ZF4wijOCoCIwxaXK4zg8UsJaEHABGRkWEdAZFBXUGSk4ZS9LUcsum4h0WBxGMKK0LO33+eOmaZKmaZLek3vSvt+v1+/Fzbkn95x7T2/IJ2e5EQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMYtMiYlFEPBoRd0fEjG7m2SciXomIX0XEkrb/DhuoFQQAAIBqWBgRh7XdPjgiFnczzz5RiV4AAAAYlMZFxB8jor7DtOciYtsu8+0TlT2/AAAAMCjtHhG/7jLt7ojYt8u0fSKiNSJ+0Xb/sYWvGQAAAFRRbwO4MSKa2m5vERH3RcQh3TxeXdv9zYZhGIZhGIZhlGJsEZXf02Gj19tDoLv6YkR8vZvpW0REGoZhGIZhGIZRqrFFABERcWNEfLTt9iHR/UWwJsbqvxo1RcTtEXFEN/M1R0QuXbo0W1tbjRKPOXPm1HwdDNtqQxq20+AYttPgGLbT4Bm2VfnH0qVLVwVwc1ULAgax6RFxR1Q+BmlxROzYNv3iiDiw7faciHgwKhfCeiAiTlzLYzVHRLa2tiblNnfu3FqvAr1kWw0OttPgYDsNDrbT4GFblV9ra6sAhgIJ4EHC/7AGD9tqcLCdBgfbaXCwnQYP26r8BDAUSwAPEgsWLKj1KtBLttXgYDsNDrbT4GA7DR62VfkJYCiWAAYAgJIQwFAsAQwAsA7Lli2r+cWRjA1rLFu2rNt/a62tAhiKJIABAHqwbNmynDhxYq0/EsfYwMbEiRO7jWABDMUSwAAAPVgVJD420qjWWPVRR62ta/4O3toqgKFIAhgAoAergsTvS1RLT/+mBDAUSwADAPRAAFNtAhhqRwADAPRAAFNtAhhqRwADAPRAAK92xBFH5Kc+9alez3/ppZfmm9/85gLXaHASwFA7AhgAoAeDLYAbGxuzqakpm5qacpNNNskhQ4ZkU1NT+/Tbb7+91qtYVRdeeGFOmzat1qvRJwIYakcAAwD0YLAFcEdf+tKXcr/99lvnfK+99toArE0xLrzwwtx+++1rvRp9IoChdgQwAEAPNsQA/uIXv5jvfOc784tf/GJOmjQp99hjj/bp06ZNy8bGxpw6dWrOnTs3X3311fbvO/TQQ/Ooo45q/3rixIk5f/78nD17djY2Nub06dPzP/7jP9rv77p39tBDD83DDz88jz766BwzZkxOmjQpTz311E7rdu211+aOO+6YTU1NecABB+QJJ5yQO+yww1qf47oC+IEHHsjZs2fn2LFjc8qUKTlnzpx8+eWX2+//yle+kttss002NzfnpEmT8uijj+70Om2xxRbZ3NycU6ZMyVNOOWWty+kLAQy1I4ABAHrQ2wBeuXJlti5vrdpYuXLleq97TwE8dOjQPPvss/O1117LZcuWZWbmFVdckc8++2xmVsJx6tSpnaKvuwDebrvt8sEHH8yVK1fmGWeckaNHj25/vK5xeuihh+Zmm22W1157ba5cuTJvueWWHDJkSN51112Zmfnwww/n0KFD86qrrsoVK1bk7bffnmPHjs0ZM2as9Tn2FMAvvfRSjh8/Pr/0pS/lq6++ms8++2y+4x3vyA9/+MPtz7G5uTkfe+yxzMx8+eWX2w8R/+lPf5rbbLNNPvfcc5mZ+eKLL+bixYt7erl7TQBD7QhgAIAe9DaAW5e3ZrRE1Ubr8vX//aynAN5uu+3W+f3z58/Pvfbaq/3r7gL4nHPOaf/6D3/4Q9bV1eX999+fmd0H8Pve975Oy9hll13yvPPOa1/fffbZp9P9xx13XL8D+LLLLsstt9yy07Q777wz6+vrs7W1NR955JFsbGzMH/7wh532CmdmXn/99Tlp0qS84YYbcvny5Wtdfn8IYKgdAQwA0IMNdQ/wO9/5zjWmn3/++fnmN785x4wZk6NGjcrhw4fn9OnT2+/vLoC/+93vtn+9fPnyrKury0WLFmVm9wHc8fszM9/+9rfn6aefnpmZRx55ZB5++OGd7j/nnHP6HcCnnHJKzpo1q9O0F154Ievq6vKBBx7IzMwf/vCHOXv27Bw5cmTOnDkzf/CDH7TPe9FFF+WsWbOyubk5999//7zpppvWuh59IYChdgQwAEAPNtRzgN/97nd3mnbTTTflZpttlosWLco33ngjMyt7gHsK2GoHcBF7gLfaaqtO0zruAe7ojTfeyCuvvDKHDBmSTz/9dKf7Xn311TzjjDNyxIgRVblgmACG2hHAAAA92FgC+Nprr82mpqZ89NFHMzNz8eLFOWXKlAEN4Icffjg32WST/N73vpcrVqzIRYsW5eabb77OAJ42bVouX76803jjjTfazwGeN29eLl++PJ955pnca6+98tBDD83MzIceeiivv/76/Mtf/pKZmT/+8Y+zoaEhn3nmmbzzzjvz9ttvz+XLl+eKFSvyvPPOy+bm5nz99dd7eMV7RwBD7QhgAIAebCwBvGLFijzuuONy7NixOWrUqHz/+9+fJ510Uo8BO2nSpDUCuL6+vk8BPHPmzPYAzsy85pprcsaMGe1Xgf7CF76Qu+2221qf44UXXpj19fVrjFXLuf/++/Nd73pXjh07NrfaaqucM2dO/ulPf8rMzF/96lc5c+bMHDVqVI4cOTJ33XXXvPrqqzMzc8GCBbnbbrtlc3Nzjh49OmfOnOkQaNgACGAAgB4M5gDeEBxzzDF50EEH1Xo1qkoAQ+0IYACAHgjggfWTn/wkX3zxxVyxYkX+7Gc/y8bGxk4XptoQCGCoHQEMANADATywjj/++Nx8882zsbExd9hhhzz//PNrvUpVJ4ChdgQwAEAPBDDVJoChdgQwAEAPBDDVJoChdgQwAEAPBDDVJoChdgQwAEAPBDDVJoChdgQwAEAPBDDVJoChdgQwAEAPBDDVJoChdgQwAEAPBDDVJoChdgQwAEAPNtYAvuSSS3Lrrbdu//oTn/hEHnvssWud/5FHHsm6urp85pln1mu5s2fPzvnz56/XY5SdAIbaEcAAAD0YbAH8t3/7t3nQQQd1e98//dM/5U477dSrx7nkkktym2226fVyH3nkkayvr+91AD/xxBNZV1eXv/vd73q9jGp44403sq6uLm+55ZYBXW5HAhhqRwADAPRgsAXwDTfckEOHDl0jRF977bUcP358XnDBBb16nKID+PHHH8/6+noBvJb7QgBDIQQwAEAPBlsAZ2ZOnz49W1paOk377ne/m01NTfnyyy9nZuZVV12Vu+++e44aNSrHjx+fBx10UKcY7RrAH/nIR/LII49s//rxxx/P/fbbL5ubm3PnnXfOiy66qFMA33fffbn//vvnuHHjctSoUfn2t7+9PTpXrFiRI0aMyPr6+mxsbMympqb81Kc+lZmZe+21V5588snty3n44YfzgAMOyLFjx+ZWW22Vxx57bP7pT39qv3+vvfbKuXPn5qGHHprNzc05ZcqUvOiii9b62qwrgJctW5bHH398br311jlmzJjcd99985577mm/f8mSJTlr1qwcNWpUjh49Ovfcc8/8zW9+k5mZP//5z3OPPfbIkSNH5pgxY3LWrFmd1nUVAQy1I4ABAHrQ6wBeuTKztbV6Y+XKfq/zV77yldxyyy1zxYoV7dP23nvvTufwXnfddfnAAw9kZuYLL7yQBx54YM6aNav9/p4C+I033sg3velN+clPfjKXL1+eS5cuzbe85S2dAvj+++/PhQsX5quvvpqvvvpqzps3L0eNGpUvvvhiZlYOga6vr8+nn36607p3DODW1tacNGlS/vM//3O++uqr+dxzz+Vee+2VhxxySKf5x4wZk7feemtmZn7ve9/LhoaGfOqpp7p9bdYVwMccc0zutttu+dRTT+Vrr72WZ511Vo4cOTKfe+65zMx829velmeccUZmVkL+3nvvzf/93//NzMwJEybkd77znczMfP311/OOO+7I5cuXr7EMAQy1I4ABAHrQ6wBubc2MqN5Yj9/PXnrppRw+fHhec801mZn54IMPZl1dXXvwdmfx4sU5ZMiQXLZsWWb2HMA333xzDh06NP/yl7+033/NNdf0eAj0ypUrs7GxMRcsWJCZqwO46yHQHQP4iiuuyEmTJuXKDn8MuOeee7Kuri7/8Ic/tM9/9NFHd3qM0aNH549+9KNu16OnAF6xYkUOGzYsr7vuuk7Td9pppzz33HMzM3PWrFl5zDHH5JNPPrnG90+ZMiVbWlry2Wef7XbZqwhgqB0BDADQg8G4Bzgz88gjj8wDDjggMzOPO+64/Ou//utO9y9cuDD333//nDhxYo4cOTKbm5s77ZHtKYC/+93v5qRJkzo93r333tspgJ966qn80Ic+lFOmTMmRI0fmqFGjcsiQIXnFFVdkZu8C+IwzzsiZM2d2uv+ll17Kurq6XLJkyRrzr7Llllvm5Zdf3u3r0lMAP/vss1lXV5ePPvpop+kf+MAH8jOf+UxmZv7ud7/Lj3/84zllypScMmVKzp07t/0PAffff39++MMfzgkTJuT06dPz5JNP7hTvqwhgqB0BDADQg8F4DnBmZU/pkCFD8r777stRo0blv/3bv7Xft3z58hwxYkR+7Wtfy1deeaV9/o5B2lMA33LLLevcA/zOd74z//7v/z5feOGFzKzsAW5qamoP0yeffLLbq0B3DNorr7wyJ0+evMYe4Pr6+k57gKsVwKv2AP/sZz/rNH3nnXdu3wPc0eOPP5477LDDGudbZ1bOFR43blx++9vfXuM+AQy1I4ABAHowWAM4M3PPPffM7bbbLidMmJCvvfZa+/TW1tZsaGhoj8SlS5fme97znl4H8Ouvv57Tp0/PY445Jl955ZV8+umn861vfWunAH7LW96Sn/zkJ/P111/Pl19+OY8//vhOy/zzn/+cDQ0NecMNN3Ra567nAE+cODFPOOGEXLZsWT777LO59957r3EOcH8C+Oc//3kuX76808jMPProo3P33XdvPwf47LPPzpEjR7Yf1nzZZZe1P8fnn38+d9555zz99NNz2bJlefnll7efD/zEE0/kpEmT2s8J7kgAQ+0IYACAHgzmAL7sssuyvr4+TzjhhDXu+9a3vpVTp07Npqam3G233drn7U0AZ2Y+9thjue+++2ZTU1PutNNOefHFF3cK4Lvuuit32223HDFiRG6zzTb5zW9+M7faaqtOYTp//vycOHFijh49uv0Q41mzZnUK2gcffDBnz56dY8eOzS233DKPPfbYTtui6/yZucZyOnrjjTeyvr6+06irq8v6+vrMzHzllVfy85//fE6dOjXHjBmTe++9dy5evLjT6zB58uRsbGzMyZMn55w5c3L58uW5bNmyfO9735vjx4/PpqamnDp1as6bN6/bdRDAUDsCGACgB4M5gCknAQy1I4ABAHoggKk2AQy1I4ABAHoggKk2AQy1I4ABAHoggKk2AQy1I4ABAHoggKk2AQy1I4ABAHoggKk2AQy1I4ABAHoggKk2AQy1I4ABAHqwKkiWLl2ara2thrHeY+nSpQIYakQAAwD0YNmyZTlx4sRVUWIYVRkTJ07MZcuWrfHvTQBDsQQwAMA6LFu2rOZ7DY0Na3QXv5kCGIomgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFAsAQwAACUhgKFYAhgAAEpCAEOxBDAAAJSEAIZiCWAAACgJAQzFEsAAAFASAhiKJYABAKAkBDAUSwADAEBJCGAolgAGAICSEMBQLAEMAAAlIYChWAIYAABKQgBDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwrGlaRCyKiEcj4u6ImLGO+W+MiBfXcp8ABgCAkhDAsKaFEXFY2+2DI2JxD/POjYh/DQEMAAClJ4Chs3ER8ceIqO8w7bmI2LabeXeKiJsjYpsQwAAAUHoCGDrbPSJ+3WXa3RGxb5dpDVE5THp6REwNAQwAAKUngKGz3gbwqRHxubbbW4cABgCA0hPA0FlvD4G+NSJ+GxFPRsTSiFjRdntsl/maIyLnzJmTc+fOzblz5+aCBQtq/b4HAICNxoIFC9p/F58zZ44Ahi5ujIiPtt0+JHq+CFaEQ6ABAGBQsAcY1jQ9Iu6IyscgLY6IHdumXxwRB3YzvwAGAIBBQABDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwFEsAAwBASQhgKJYABgCAkhDAUCwBDAAAJSGAoVgCGAAASkIAQ7EEMAAAlIQAhmIJYAAAKAkBDMUSwAAAUBICGIolgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFAsAQwAACUhgKFYAhgAAEpCAEOxBDAAAJSEAIZiCWAAACgJAQzFEsAAAFASAhiKJYABAKAkBDAUSwADAEBJCGAolgAGAICSEMBQLAEMAAAlIYChWAIYAABKQgBDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwFEsAAwBASQhgKJYABgCAkhDAUCwBDAAAJSGAoVgCGAAASkIAQ7EEMAAAlIQAhmIJYAAAKAkBDMUSwAAAUBICGIolgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFCsXgXwwoULM1oidz9v9wF66wMAwMZHAEOxehXAJy48MaMlMlpigN76AACw8RHAUKxeHwItgAEAoFgCGIrV5wAe0jJkAN76AACw8RHAUKxeB/Cq84DtBQYAgGIIYChWn64CLYABAKA4AhiK1a8AFsEAAFB9AhiK1efPARbAAABQDAEMxRLAAABQEgIYitXvABbBAABQXQIYitXnAM60FxgAAIoggKFY6xXACxcuLOitDwAAGx8BDMXqVwAPaxlmLzAAAFSZAIZi9SuAMx0GDQAA1SaAoVjrHcCHX3V4AW99AADY+AhgKFa/A/jdl77bXmAAAKgiAQzF6ncAZzoMGgAAqkkAQ7GqEsBjW8ZW+a0PAAAbHwEMxVqvAF64cKG9wAAAUCUCGIq1XgGc6TBoAACoFgEMxapaAItgAABYPwIYirXeAZxpLzAAAFSDAIZiCWAAACgJAQzFqmoAi2AAAOg/AQzFqkoAZ9oLDAAA60sAQ7EEMAAAlIQAhmJVPYBFMAAA9I8AhmJVLYAz7QUGAID1IYChWIUE8IkLT6zK4wEAwMZEAMOapkXEooh4NCLujogZ3czz9ohYEhG/iogHIuKbETG0m/mqGsDbn729vcAAANBPAhjWtDAiDmu7fXBELO5mnk0jYkiHr38UEZ/pZr6qBnCmw6ABAKC/BDB0Ni4i/hgR9R2mPRcR2/bwPZtGxHUR8elu7issgEUwAAD0jQCGznaPiF93mXZ3ROzbzbxTI+LeiPhTRPx7RDR0M0/VAzhTBAMAQH8IYOisLwG8yvCoHAL9wW7uKySAM0UwAAD0lQCGzvpzCHRExIci4sfdTG+OiJwzZ07OnTs3586dmwsWLKjKm3fejfPaA3j6OdOr8pgAALChWbBgQfvv4nPmzBHA0MWNEfHRttuHRPcXwdouVh/yvElEXBURp3YzX2F7gDMzG1oa2iP4xhtvLGQZAACwobAHGNY0PSLuiMrHIC2OiB3bpl8cEQe23T4qKh9/tKTtv1+LSgh3VWgAZzoUGgAAeksAQ7EKD+BMEQwAAL0hgKFYAxLAmSIYAADWRQBDsQYsgDNFMAAA9EQAQ7EGNIBvvPFGEQwAAGshgKFYAxrAmZl7nL9HewAf8b0jBmy5AABQdgIYijXgAZzpUGgAAOiOAIZi1SSAM0UwAAB0JYChWDUL4EwRDAAAHQlgKFZNAzhTBAMAwCoCGIpV8wDOFMEAAJApgKFopQjgTBEMAAACGIpVmgDOFMEAAGzcBDAUq1QBnCmCAQDYeAlgKFbpAjhTBAMAsHESwFCs3gXwiSdmRmQ2NQ3MOz9FMAAAGx8BDMXqXQDvvnslgGPgYvSmm24SwQAAbFQEMBSr94dArwrgAYzglptaRDAAABsNAQzF6ts5wDWI4I99/2MiGACAjYIAhmL1/SJYNYjgPb+xZ3sA17XUDdhyAQBgIAlgKFbfA/jww1cH8MKFxb37uxh/yvj2CB5/yvgBWy4AAAwUAQzF6t/HINVgL3BmZl1LXXsEv+2Ctw3osgEAoGgCGIrV/88BrlEEdzwf+BNXf2JAlw0AAEUSwFCs/gdwZiki+Oabbx7QZQMAQFEEMBRr/QL4xBNrcj5wpggGAGDDI4ChWOsXwJk12wucmT4eCQCADYoAhmKtfwBnimAAAKgCAQzFqk4AZ4pgAABYTwIYilW9AF64cHUAn3ji+j9eH4lgAAAGOwEMxapeAGd23gvc0FCdx+zL4kUwAACDmACGYlU3gDM7R/CqceON1Xv8dS2+QwTP/JeZA7ZcAABYXwIYilX9AM6sBG93ITxA5wd3jGB7gwEAGCwEMBSrmADuqKGh+xCeN6+4ZWbm6JbRIhgAgEFFAEOxig/gjta2V7i3Y8WKvi+yQwRPPXNq9Z8TAABUiQCGYg1sAK+yxx7rF8J95JBoAAAGAwEMxapNAPdHdyF88829/vapZ04VwQAAlJoAhmINngBepbsQft/7ev/tHSJ4RMuIAlcUAAD6RgBDsQZfAK8yfvyaITx8eK++1SHRAACUkQCGYg3eAF7lfe/r13nCM/9l5hohfOuttw7ACgMAQPcEMBRr8AfwKjff3K+LZXWN4GiJPP3W0wteWQAAWJMAhmJtOAG8yqmn9uuK0Y0tjWuE8F9/868LXFEAAOhMAEOxNrwAzsycOXN1AE+Y0Kdv3elrO60RwmNaxhS0ogAAsJoAhmJtmAGcmTls2OoIfv/7+/ztx/zwmG4PjwYAgKIIYCjWhhvAmZ0Phb7lln49xK233tptCN96mwtmAQBQXQIYirVhB3Bmv84HXutDdRPC9goDAFAtAhiKteEHcGZVIzgzc5svb9NtCM+/bX5VHh8AgI2TAIZibRwBnFn1CG5/WHuFAQCoEgEMxdp4AjizsAjOzNzl67t0G8Kbn7J51ZcFAMCGSQBDsTauAM4sNILbF7GWvcJn3X5WYcsEAGDwE8BQrI0vgDMHJIIzM2+//XaHSAMA0GsCGIq1cQZwZucIXjVuLe6jjXY9b1cxDABAjwQwFGvjDeBbbuk+gtc2MjPnz+/9/Juv/dzftYVwtEQuWrRogF4AAADKRgBDsTbeAO5qyJC+BXFfwrkHPcXwp6/99AA8cQAAykIAQ7EE8LrcemvnoK2ry7zttp6/57jj+hzCmZkjWkasNYZHtIyowpMBAKDMBDAUSwAXqWsEH3xwr7/109d+use9w84dBgDY8AhgKJYAHgj92Bvc0aJFi9YZw9ESeccddxSw8gAADBQBDMUSwANl223XO4Q76k0QN7U0VWnlAQAYCAIYiiWAB1rXCB5RnXN7p507rVdRfOedd1ZleQAAVJ8AhmIJ4Fq4/fZ1Xz367LPXaxF33nlnr4LYucQAAOUhgKFYAriWbryx+h+7NH585oQJmZtuusZ9D46KPOp9kft/JPItn4ic9qnIOKn7KD7+p8fX+tUBANjoCGAolgAuo912K+YzibsZb9RF3rZl5A7/uO49xWNPHVvrVwYAYIMmgKFYAnhD8NnPZm65ZeUzijsGbn19ZlNT5lZbZb773Zlf/Wrn72tu7jaKP/WpHXt9+PTYU8dm3n13/yN82rTavGYAACUkgKFYApiKtQVqm7vvvnt1+M6L/KtjIo95b+R3d458fkTkq/WRT46MvHdC5Iub9DOGAQA2cgIYiiWA6eyAA3odrCsj8r8bI0/ZK7Lpi73bY7x48eLVy7rnnu4fu7Gxds8fAKCGBDAUSwCzdj0F8NjuzwfutKe4D+O2SWtZzj33rHs9hw1b8/v+9m+Lfw26jlGjMi+7rDrLLdoDD2Reckmt1wIA6EIAQ7EEMOv29a9XzjFeTyNaRqw7hudFHvTByLu2iHy9rnJo9Yr+nl/ccfzyl71byZEjq3uhsSp9znNVOAwdAEpPAEOxBDA19817vtltDDf+c+SR/yfyzi0i/2d45KNjIn85MfKuyZH3jY9sbegQbr/4xeoHvPji3ofepZf2PF9vD8f+u7/LbGhY93I33bS6L15PRo9e/4D/6Eersy7veMfal7HXXtVZBgBsAAQwrGlaRCyKiEcj4u6ImNHNPPu13fdgRDwQEWeu5bEEMKU27vRx/Tqk+pcd9/hOmdK36Kumviy3vj7zjDP69vj33585aVLvHn/YsJ4fa+jQ6u79rtYYMyZz880rr09v5j/wwP5vLwCoMQEMa1oYEYe13T44IhZ3M8+uEbF12+1NIuK2iDi8m/kEMIPSv/7iX/sVxtES+YtxXYLp4IMHbsUHOh7Xx/e+V9116e51vuaaYp//QMVwT4fOb7JJ5i67ZD7xxMCsCwCDmgCGzsZFxB8jor7DtOciYtt1fN/5ETGvm+kCmA1O88nN/Y7jaIk8+MoBDOJV7ruvsqezP5E3ZEjmP/zDwK/zQPj1ryuHoW++eeahh2Y+8kjP8z/66Npfp/32W//12WmnYoN9s80yf/Ob9V9PAAYtAQyd7R4Rv+4y7e6I2LeH75kYlUjevZv7BDAblXkL5q1XHK8aS5YsqfVTYV16iuG3vW31fBdemNncvH7hurZzxZ94onJ++IgR1QnkpqbMJ58cmNeP2lq4sHLawhZb1HpNgAEmgKGzvgZwc1QOkf5MD/cLYGjTcn1LVQI5WiJP+/lptX46rNJTDPdl1NdnPv54cev55jcXu4e5vlEkYXQAABSpSURBVL5yrvdmm2VOnZr52c9mPvVU79fvLW/p/bLW56PIerpoWl+e6/jxmZ//fP/XYyAcd1zfn9vIkZn/8z+1XnOqbeHC7q/psMMOma+8Uuu1YwAJYOisL4dAN0blYln/3MPjNUdEzpkzJ+fOnZtz587NBQsW1Pp9D6XW1NJUtUiOlsgxp4+p9VPauHQXw1ttlfnYY7Ves3Ur+hDsoscBB3R+PldfXft16ng0wPpYsSLzy1/O3H777j+bvK+joaHyWd0HHNC7+YcOzfzxj6vzXMrsmGMyhw9f++swbFjmQw/Vei3X7Wc/q/yBpq//LpqaMm+7rdZrTwEWLFjQ/rv4nDlzBDB0cWNEfLTt9iHR/UWwRkQlfr+0jseyBxgK8PZvvr2qkRwtkXUtdXn//ffX+qkxmP32t5lf/Wrm4YdnTpvWc0h0N8aPz/zd79a9nKefrpyb3t/4a2rKXLly/Z7rM89kfuQjlY8D6+0VxCMq8/fkuuv69ni9eU1///u+PbfPfrb3j19Xl/mJT/T/dayVbbetzuu79dbFrufKlZnf/nbm+9+fOX165VoOw4b1/d9IQ0PljzF/+cuay/iv/+r+vTpkSOaXvlTs81ubE0/MnDCh8u9r1foMG5b51rdmLl5cm3XagNgDDGuaHhF3ROVjkBZHxI5t0y+OiAPbbp8QEa9GxK8iYknbf7vbEyyAoYbuu+++HNoytGqRPOmsSbV+StC9p5/u/qO2rr66tutVrfOzIzInTqz8ceH55wf+eVxzTeXQ9mo9l/UZM2b0ff1feqlyxfSeHnfTTTM/9KHMP/5x7Y/z0EM974H/2Mcq8/3pT5k/+EHmYYdl7rpr5Q8Rw4dXorJj1BUxhgzJ3Gef7mN3XV55JXObbbp/3Lq6SnhvumklxKdPz/ybv8k888zMZ5/t+7JWueWWzL/6q7V/VF5TU+Ww/K6vW0NDZR2uuqr/y3711cpFIq+8shL7H/lI5v77V66sP2VK5XkOH145pePv/i7z3HMrHw+4YkXflrNiReUChD/5Seb8+ZXlnHxy/9d7PQlgKJYAhkFi7Bljq75XOVoiG09uzAcffLDWTw/KYeede46X+vrMf//3Wq9l773wQvX2pvZ3bLtt9+t26aVr/57Zs6vz/L/whWKeU0ND5eJ506dXrsJ/++3VWd+++vu/Lz7YO46hQyvxuXDh2tfptNMyJ09ecy94XV1lr/H221fuHzOm8geoYcN6/4eHurrKvMOGVV7/iRMr22DHHTPHjVt95EldXSXM3/SmzA98oLJOd9yR+frrlQsJ/vSnlT8MHHZY5h57VCK6oaFymskHP5jZ0tLzcyyYAIZiCWDYQNx///2FBHLXceT3j6z1UwXK7AMf6F9cXXpp8eu2666VcNp228r51WefXTlcfkO1bFnlfOOjjqocnjx5ciVCx4ypvA7Dh1f2vDc0VOKxa7SOH595wgmVPbH9ddVVlQt5NTR0/kNSQ0MlZBsbM8eOzdxyy8rRAzNnVg4pnzMn8/vfr1y34Y03er+83/++ssf4mGMqjzVxYue91w0NlWA+5JDMk06qLOOhhzJfe63/z7HKBDAUSwDDRuzBBx/MkaeOLDSYN2vZLB9++OFaP1WgVtYWxJtsUjn0GQZCa2vm9devX8wPEAEMxRLAQK/tf8n+A7KXuetoaGnIHz+yEVzhFjYG63uBM9jACWAolgAGCvPwww/nuPnjBjyYx585Ph999NFaP30A6DMBDMUSwEDp7XzezgMa0JvP3zwvXHRhrZ82ABshAQzFEsDABuWnj/40m09rrsmh2qvGpi2b5nu/9d584oknav1yADDICGAolgAG6ODCRRfm5vM3r2lAr21s/9Xt88knn6z1SwRAgQQwFEsAA1TRE088ke/91ntz05ZNax7M6xqbnbJZtixoqfVLBkAHAhiKJYABBoGFTy7MCWdNqHk0dx2btGyS235l2zz1hlNr/RIBbBAEMBRLAANspI68+sgc2jK05hHdddS31OeEsybkP/74H/O///u/a/0yAQwoAQzFEsAA9NsFt12QO3xthxzWMqzm4dyfMbRlaI4+Y3TufP7O+YXrvpDPPvtsrV9SYCMngKFYAhiAUlm6dGnuf+n+2XR6U80DeX3HsFOG5ZZf3jLf/533533P31frlxYYBAQwFEsAA7DRWrlyZZ53+3m598V758QvT8xhpwzLupa6mofz+o76lvocdsqwnPzlyTn727Pzp7/+aa1faqCXBDAUSwADQEGef/75nPfzeTnjvBnZeFpj1rfU1zyOixhDWobk8NOG57izxuVO5++UH7zqg3nlkivzxRdfrPUmgEFHAEOxBDAAbKC+86vv5Oxvz87JX56cw04ZtkEFeF1LXQ45eUhueuqmOXr+6Nzzwj3zC9d9IZe2Lq31yw7rRQBDsQQwAFAVL774Yl655Mr84FUfzF0v2DXHnzU+h582PBtObhh0h5avCuyGkxty6ClDc9ipw3L4acOz6fSmHDV/VI49c2xO+PKE3OrcrXLa16blrv+ya77torflfpftl++78n15yFWH5BE/PCI/8x+fyZMWnpTn3Xle/vt9/57Pv/x8rTcTJSeAoVgCGAAY9O5cemd+7JqP5YzzZ+TIM0bm0FOGDrro7kuc17fU55CTh+TQk4fmpqdtmmPPGptTvjold71g13zX5e/Kj137sTz7trPztt/elsuWLav15qEPBDAUSwADAFTJn//853zy90/mXU/dldc8dE1euPjCPP3m0/P/Lvi/+fFrP56zL5+dO1+wc046Z1I2ndGUw04ZNij3kHcM8aGnDM3hpw3PxjMaK3vHzxqbE86ekFt9Zavc7uvb5Y4X7Ji7X7h7zrp0Vn7w+x/Mo35yVH5uwefyxIUn5jmLzsmLf3lxXv3Q1bnwNwvzl8/8Mpe+tDRfe/21Wm/KmhHAUCwBDACwgXlp2Uv5n4/+Z55808n5Dz/8h9znsn1yxjdm5M7f2Dl3umCnnPGNGfmm89+U074+Lbf92ra59Ve3zilfmZJbnLtFTj53ck48e2JOPmdyjj1rbDaf0ZzDTxuew04dlkNPGZpDTh6S9S317dFe11I3YAFf11KX9SfXZ8MpDbnJKZu07/2eeM7EHP/l8Tn2rLE55qwxOerMUdk8vzkbz2jMEaePyM1O2yw3PW3TnHnJzHzPd96Th3z/kDzy2iPz0z/7dP6/hf8vz7ztzPzG3d/Iy++9PH/08I9yyXNLarbtBDAUSwADAFAzr7/+er7w8gv5yAuP5G2/uy2vffjavGLJFXn5ksvz3DvOzXk3zsvPXPeZPPLaI/OQ7x+S7/3Oe3Ofb+2Tb734rbnLv+yS+317vzzk+4fkoVcfmof98LA84toj8qifHJXH/sex+emffTo/d/3n8os//2Ke8F8n5BX3XpEX3nNhnrPonDzpppPycws+l5/8ySfzwz/4cB74bwfmPpftk3v86x45d8Hcmr0eAhiKJYABAKAkBDAUSwADAEBJCGAolgAGAICSEMBQLAEMAAAlIYChWAIYAABKQgBDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwFEsAAwBASQhgKJYABgCAkhDAUCwBDAAAJSGAoVgCGAAASkIAQ7EEMAAAlIQAhmIJYAAAKAkBDMUSwAAAUBICGIolgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFAsAQwAACUhgKFYAhgAAEpCAEOxBDAAAJSEAIZiCWAAACgJAQzFEsAAAFASAhiKJYABAKAkBDAUSwADAEBJCGAolgAGAICSEMBQLAEMAAAlIYChWAIYAABKQgBDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwFEsAAwBASQhgKJYABgCAkhDAUCwBDAAAJSGAoVgCGAAASkIAQ7EEMAAAlIQAhmIJYAAAKAkBDMUSwAAAUBICGIolgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFAsAQwAACUhgKFYAhgAAEpCAEOxBDAAAJSEAIY1TYuIRRHxaETcHREzuplnakTcFBF/jIhf9fBYAhgAAEpCAMOaFkbEYW23D46Ixd3MMzoi3hERfxMCGAAABgUBDJ2Ni8pe3foO056LiG3XMv8+IYABAGBQEMDQ2e4R8esu0+6OiH3XMr8ABgCAQUIAQ2cCGAAANlACGDor5BDoOXPm5Ny5c3Pu3Lm5YMGCWr/vAQBgo7FgwYL238XnzJkjgKGLGyPio223D4nuL4K1yr4RsaSH++0BBgCAkrAHGNY0PSLuiMrHIC2OiB3bpl8cEQe23d4sIpZGxO8jYnlEPB0Rp3fzWAIYAABKQgBDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwFEsAAwBASQhgKJYABgCAkhDAUCwBDAAAJSGAoVgCGAAASkIAQ7EEMAAAlIQAhmIJYAAAKAkBDMUSwAAAUBICGIolgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFAsAQwAACUhgKFYAhgAAEpCAEOxBDAAAJSEAIZiCWAAACgJAQzFEsAAAFASAhiKJYABAKAkBDAUSwADAEBJCGAolgAGAICSEMBQLAEMAAAlIYChWAIYAABKQgBDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwFEsAAwBASQhgKJYABgCAkhDAUCwBDAAAJSGAoVgCGAAASkIAQ7EEMAAAlIQAhmIJYAAAKAkBDMUSwAAAUBICGIolgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFAsAQwAACUhgKFYAhgAAEpCAEOxBDAAAJSEAIZiCWAAACgJAQzFEsAAAFASAhiKJYABAKAkBDAUSwADAEBJCGAolgAGAICSEMBQLAEMAAAlIYChWAIYAABKQgBDsQQwAACUhACGYglgAAAoCQEMxRLAAABQEgIYiiWAAQCgJAQwFEsAAwBASQhgKJYABgCAkhDAUCwBDAAAJSGAoVgCGAAASkIAQ7EEMAAAlIQAhmIJYAAAKAkBDMUSwAAAUBICGIolgAEAoCQEMBRLAAMAQEkIYCiWAAYAgJIQwFAsAQwAACUhgKFYAhgAAEpCAEOxBDAAAJSEAIZiCWAAACgJAQxrmhYRiyLi0Yi4OyJmrGW+j0fEYxHxeET8a0QM6WYeAQwAACUhgGFNCyPisLbbB0fE4m7m2ToinomIcW1f/zgiju1mPgE8SCxYsKDWq0Av2VaDg+00ONhOg4PtNHjYVuUngKGzcRHxx4io7zDtuYjYtst8x0fEv3T4+m8i4tZuHk8ADxJz586t9SrQS7bV4GA7DQ620+BgOw0etlX5CWDobPeI+HWXaXdHxL5dpp0XEf/U4esZEfFUN48ngAcJ/8MaPGyrwcF2Ghxsp8HBdho8bKvyE8DQWSEBvHTp0mxtbTVKPObMmVPzdTBsqw1p2E6DY9hOg2PYToNn2FblH0uXLhXA0EG1D4HeIipvMMMwDMMwDMMwyjO2CCAiIm6MiI+23T4kur8I1jYR8d8RMT4i6qJyEax/7Ga+uqi8uZoNwzAMwzAMwyjF2CIqv6cDETE9Iu6IyscgLY6IHdumXxwRB3aY7+MR8URUPgbpouj+Y5AAAAAAAAAA2BBMi4hFUdmTfHdULpRF7X09In4bESsj4q86TLe9ymVYRFwTEY9ExJKIuD4itmu7b1xEXBcRj0XE/RExqxYrSCfXR8S9UdlWt0TEm9ume1+V05FR+Rn4f9q+9p4ql6eickHOJRHxq4j4u7bp3k/lsklEnB+V9819EXFF23TbqVzGxOr30q+isl1ei4hR4WcfVN3CiDis7fbB0f25xAy8vSJickQ8GZ0D2PYql2ER8Z4OX8+JiJvabn8rIua13X5LRCwNpyDUWnOH2wdFJYYjvK/KaGpUfjlfFKsD+NLwniqTJyNil26mez+Vy1ej8kf1Vca3/dd2KrfPR+XaPRF+n4Cq6u3VpKmd38bqALa9ym+PqPxSGBHxcqz+RSMi4q6I2H/A14i1OSIqf2UfFxGt4X1VJnUR8fOI2C0qf1BaFcDeU+XS8f9Pq/j/VLkMj8rPt8Yu022n8ns4It7fdtvPPqii3n6eMLXT8RcM26v8roiIr0TlUKZlXe77XlSii9q6PCKejojfRcRO4X1VRp+P1Xs7VgWw91T5/DYqR1HcF5ULcG4e3k9ls0tUttP8iLgnKqd+7B+2U9m9IyKejcofKPzsgyrzA7D8BPDgcUJUDtfcNPwPazA4LCL+Myrvq0e63Od9VTs7ReUTDlYd3ieAy2vLtv8OiYgzw/upjHaLynn0/9D29Zsj4oWIeGvYTmV2SVTeUxF+9kHVOQSm/BwCPTgcH5Xzp5o6TOt6yNLd4ZClsnklHAJdNsdExDNROZXgt1H5xe/5tuneU+U1MSrvo83D+6lMxkbE69H5c2QXR+WCZX6fKKcREfGnqHzc6Sp+9kGV3RgRH227fUi4CELZdD3HyvYqn89FxC8iYmSX6d+KiJPabu8ZLlpRayMjYlKHrw+KyqHQEd5XZXZTrD4PznuqPIZH5595n4vVFwD0fiqXBRHxN223t4mI/4nKz0LbqZw+HhG3dpnmZx9U2fSoHG72aFR++O1U29WhzYVR+QH3WlT+KvtY23Tbq1y2iMrhZY9H5YJKSyLizrb7xkflY3cei4gHImLvWqwg7aZE5a/m90XlvMUbYvUfl7yvyuvGWH0RLO+p8tgmKj/zVp0DfE1U3mMR3k9ls01U3kf3R+X/UQe1Tbedyun2iDi8yzQ/+wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACANfx/Yhz3i5GDWx8AAAAASUVORK5CYII=\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 23:58:07,017 : INFO : Found lower val loss for epoch 1 => 0.27536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 36s - loss: 0.3437 - val_loss: 0.2754\n",
      "Epoch 2/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.3035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 23:58:43,064 : INFO : Found lower val loss for epoch 2 => 0.25655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 36s - loss: 0.3035 - val_loss: 0.2565\n",
      "Epoch 3/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 23:59:18,920 : INFO : Found lower val loss for epoch 3 => 0.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 35s - loss: 0.2866 - val_loss: 0.2510\n",
      "Epoch 4/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-27 23:59:54,595 : INFO : Found lower val loss for epoch 4 => 0.25074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 35s - loss: 0.2716 - val_loss: 0.2507\n",
      "Epoch 5/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2566"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:00:31,194 : INFO : Found lower val loss for epoch 5 => 0.24403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 36s - loss: 0.2565 - val_loss: 0.2440\n",
      "Epoch 6/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:01:07,502 : INFO : Found lower val loss for epoch 6 => 0.22839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 36s - loss: 0.2459 - val_loss: 0.2284\n",
      "Epoch 7/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:01:46,688 : INFO : Found lower val loss for epoch 7 => 0.22628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 39s - loss: 0.2391 - val_loss: 0.2263\n",
      "Epoch 8/200\n",
      "254767/254767 [==============================] - 39s - loss: 0.2334 - val_loss: 0.2273\n",
      "Epoch 9/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:03:09,669 : INFO : Found lower val loss for epoch 9 => 0.21857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 42s - loss: 0.2282 - val_loss: 0.2186\n",
      "Epoch 10/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:03:52,888 : INFO : Found lower val loss for epoch 10 => 0.21601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 43s - loss: 0.2238 - val_loss: 0.2160\n",
      "Epoch 11/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:04:38,136 : INFO : Found lower val loss for epoch 11 => 0.21568\n",
      "2017-03-28 00:04:38,137 : INFO : Validation Loss Reduced 10 times\n",
      "2017-03-28 00:04:38,138 : INFO : Evaluating on Validation Data\n",
      "2017-03-28 00:05:09,389 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.712 | Top 3: 0.933 | Top 5: 0.987 | F1 Micro: 0.674 | F1 Macro: 0.597\n",
      "254767/254767 [==============================] - 78s - loss: 0.2205 - val_loss: 0.2157\n",
      "Epoch 12/200\n",
      "254767/254767 [==============================] - 36s - loss: 0.2173 - val_loss: 0.2159\n",
      "Epoch 13/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:06:32,478 : INFO : Found lower val loss for epoch 13 => 0.2103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 44s - loss: 0.2147 - val_loss: 0.2103\n",
      "Epoch 14/200\n",
      "254767/254767 [==============================] - 44s - loss: 0.2118 - val_loss: 0.2139\n",
      "Epoch 15/200\n",
      "254767/254767 [==============================] - 46s - loss: 0.2095 - val_loss: 0.2134\n",
      "Epoch 16/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:08:49,522 : INFO : Found lower val loss for epoch 16 => 0.2078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 45s - loss: 0.2074 - val_loss: 0.2078\n",
      "Epoch 17/200\n",
      "254767/254767 [==============================] - 46s - loss: 0.2051 - val_loss: 0.2095\n",
      "Epoch 18/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:10:21,122 : INFO : Found lower val loss for epoch 18 => 0.20566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 45s - loss: 0.2032 - val_loss: 0.2057\n",
      "Epoch 19/200\n",
      "254767/254767 [==============================] - 46s - loss: 0.2015 - val_loss: 0.2096\n",
      "Epoch 20/200\n",
      "254767/254767 [==============================] - 45s - loss: 0.1999 - val_loss: 0.2089\n",
      "Epoch 21/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:12:38,664 : INFO : Found lower val loss for epoch 21 => 0.20538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 45s - loss: 0.1985 - val_loss: 0.2054\n",
      "Epoch 22/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:13:23,584 : INFO : Found lower val loss for epoch 22 => 0.20442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 44s - loss: 0.1972 - val_loss: 0.2044\n",
      "Epoch 23/200\n",
      "254767/254767 [==============================] - 45s - loss: 0.1955 - val_loss: 0.2052\n",
      "Epoch 24/200\n",
      "254767/254767 [==============================] - 47s - loss: 0.1945 - val_loss: 0.2090\n",
      "Epoch 25/200\n",
      "254767/254767 [==============================] - 68s - loss: 0.1932 - val_loss: 0.2058\n",
      "Epoch 26/200\n",
      "254767/254767 [==============================] - 65s - loss: 0.1921 - val_loss: 0.2057\n",
      "Epoch 27/200\n",
      "254767/254767 [==============================] - 49s - loss: 0.1909 - val_loss: 0.2067\n",
      "Epoch 28/200\n",
      "254767/254767 [==============================] - 63s - loss: 0.1903 - val_loss: 0.2049\n",
      "Epoch 29/200\n",
      "254767/254767 [==============================] - 57s - loss: 0.1891 - val_loss: 0.2054\n",
      "Epoch 30/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:21:02,708 : INFO : Found lower val loss for epoch 30 => 0.20064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 63s - loss: 0.1880 - val_loss: 0.2006\n",
      "Epoch 31/200\n",
      "254767/254767 [==============================] - 63s - loss: 0.1873 - val_loss: 0.2015\n",
      "Epoch 32/200\n",
      "254767/254767 [==============================] - 57s - loss: 0.1863 - val_loss: 0.2040\n",
      "Epoch 33/200\n",
      "254767/254767 [==============================] - 68s - loss: 0.1856 - val_loss: 0.2033\n",
      "Epoch 34/200\n",
      "254767/254767 [==============================] - 62s - loss: 0.1851 - val_loss: 0.2014\n",
      "Epoch 35/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:26:14,837 : INFO : Found lower val loss for epoch 35 => 0.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 60s - loss: 0.1841 - val_loss: 0.1998\n",
      "Epoch 36/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:27:24,470 : INFO : Found lower val loss for epoch 36 => 0.19964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 69s - loss: 0.1837 - val_loss: 0.1996\n",
      "Epoch 37/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:28:16,583 : INFO : Found lower val loss for epoch 37 => 0.19917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 52s - loss: 0.1826 - val_loss: 0.1992\n",
      "Epoch 38/200\n",
      "254767/254767 [==============================] - 77s - loss: 0.1821 - val_loss: 0.2005\n",
      "Epoch 39/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:30:48,429 : INFO : Found lower val loss for epoch 39 => 0.19766\n",
      "2017-03-28 00:30:48,431 : INFO : Validation Loss Reduced 20 times\n",
      "2017-03-28 00:30:48,433 : INFO : Evaluating on Validation Data\n",
      "2017-03-28 00:31:38,168 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.613 | Top 3: 0.950 | Top 5: 0.991 | F1 Micro: 0.712 | F1 Macro: 0.647\n",
      "254767/254767 [==============================] - 126s - loss: 0.1814 - val_loss: 0.1977\n",
      "Epoch 40/200\n",
      "254767/254767 [==============================] - 57s - loss: 0.1807 - val_loss: 0.2002\n",
      "Epoch 41/200\n",
      "254767/254767 [==============================] - 70s - loss: 0.1799 - val_loss: 0.2000\n",
      "Epoch 42/200\n",
      "254767/254767 [==============================] - 61s - loss: 0.1797 - val_loss: 0.1992\n",
      "Epoch 43/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:35:53,229 : INFO : Found lower val loss for epoch 43 => 0.19581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 63s - loss: 0.1792 - val_loss: 0.1958\n",
      "Epoch 44/200\n",
      "254767/254767 [==============================] - 67s - loss: 0.1785 - val_loss: 0.1981\n",
      "Epoch 45/200\n",
      "254767/254767 [==============================] - 56s - loss: 0.1779 - val_loss: 0.1989\n",
      "Epoch 46/200\n",
      "254767/254767 [==============================] - 64s - loss: 0.1777 - val_loss: 0.2011\n",
      "Epoch 47/200\n",
      "254767/254767 [==============================] - 56s - loss: 0.1771 - val_loss: 0.1983\n",
      "Epoch 48/200\n",
      "254767/254767 [==============================] - 69s - loss: 0.1765 - val_loss: 0.1961\n",
      "Epoch 49/200\n",
      "254767/254767 [==============================] - 69s - loss: 0.1759 - val_loss: 0.1961\n",
      "Epoch 50/200\n",
      "254767/254767 [==============================] - 55s - loss: 0.1756 - val_loss: 0.1966\n",
      "Epoch 51/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:44:15,888 : INFO : Found lower val loss for epoch 51 => 0.19307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 64s - loss: 0.1751 - val_loss: 0.1931\n",
      "Epoch 52/200\n",
      "254767/254767 [==============================] - 53s - loss: 0.1746 - val_loss: 0.1974\n",
      "Epoch 53/200\n",
      "254767/254767 [==============================] - 67s - loss: 0.1742 - val_loss: 0.1992\n",
      "Epoch 54/200\n",
      "254767/254767 [==============================] - 59s - loss: 0.1734 - val_loss: 0.1954\n",
      "Epoch 55/200\n",
      "254767/254767 [==============================] - 61s - loss: 0.1730 - val_loss: 0.1960\n",
      "Epoch 56/200\n",
      "254767/254767 [==============================] - 76s - loss: 0.1728 - val_loss: 0.1969\n",
      "Epoch 57/200\n",
      "254767/254767 [==============================] - 73s - loss: 0.1727 - val_loss: 0.1977\n",
      "Epoch 58/200\n",
      "254767/254767 [==============================] - 48s - loss: 0.1721 - val_loss: 0.2006\n",
      "Epoch 59/200\n",
      "254767/254767 [==============================] - 71s - loss: 0.1717 - val_loss: 0.1962\n",
      "Epoch 60/200\n",
      "254767/254767 [==============================] - 71s - loss: 0.1712 - val_loss: 0.1953\n",
      "Epoch 61/200\n",
      "254767/254767 [==============================] - 55s - loss: 0.1711 - val_loss: 0.1949\n",
      "Epoch 62/200\n",
      "254767/254767 [==============================] - 64s - loss: 0.1706 - val_loss: 0.1980\n",
      "Epoch 63/200\n",
      "254767/254767 [==============================] - 63s - loss: 0.1703 - val_loss: 0.1946\n",
      "Epoch 64/200\n",
      "254767/254767 [==============================] - 58s - loss: 0.1700 - val_loss: 0.1953\n",
      "Epoch 65/200\n",
      "254767/254767 [==============================] - 76s - loss: 0.1695 - val_loss: 0.1964\n",
      "Epoch 66/200\n",
      "254767/254767 [==============================] - 62s - loss: 0.1697 - val_loss: 0.1941\n",
      "Epoch 67/200\n",
      "254767/254767 [==============================] - 46s - loss: 0.1690 - val_loss: 0.1965\n",
      "Epoch 00066: early stopping\n",
      "CPU times: user 21min 14s, sys: 36min 11s, total: 57min 25s\n",
      "Wall time: 1h 4min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 01:01:06,960 : INFO : Evaluating on Training Data\n",
      "2017-03-28 01:04:06,041 : INFO : Generating Training Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Training Metrics: Cov Err: 1.501 | Top 3: 0.971 | Top 5: 0.995 | F1 Micro: 0.819 | F1 Macro: 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 01:04:13,577 : INFO : Evaluating on Validation Data using saved best weights\n",
      "2017-03-28 01:04:56,049 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.586 | Top 3: 0.953 | Top 5: 0.991 | F1 Micro: 0.724 | F1 Macro: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-28 01:04:57,811 : INFO : Loading Previous results from /mnt/data2/shalaby/nn_parameter_search_extended_abs_desc_claims_large_sample_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_sections_level_1_batch_2048_nn_parameter_searches.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping: lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_3_conv_None\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# random search for parameters\n",
    "param_sampler = ParameterSampler({\n",
    "    'lstm_output_size':lstm_output_sizes,\n",
    "    'w_dropout':w_dropout_options,\n",
    "    'u_dropout':u_dropout_options,\n",
    "    'stack_layers':stack_layers_options,\n",
    "    'conv_size':conv_size_options,\n",
    "}, n_iter=NN_RANDOM_SEARCH_BUDGET, random_state=NN_PARAM_SAMPLE_SEED)\n",
    "\n",
    "# load previous finshed results so we dont redo them\n",
    "param_results_dict = {}\n",
    "if load_existing_results:\n",
    "    param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                       NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "    if os.path.exists(param_results_path):\n",
    "        info('Loading Previous results from {}'.format(param_results_path))\n",
    "        param_results_dict = pickle.load(open(param_results_path))\n",
    "    else:\n",
    "        info('No Previous results exist in {}'.format(param_results_path))\n",
    "        \n",
    "\n",
    "# create nn parameter search directory\n",
    "if not os.path.exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME)):\n",
    "    os.makedirs(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "# for every parameter set picked by random search, use it to train the model and output the metrics\n",
    "for parameters in param_sampler:\n",
    "    start_time = time.time()\n",
    "    lstm_output_size = parameters['lstm_output_size']\n",
    "    w_dropout_do = parameters['w_dropout']\n",
    "    u_dropout_do = parameters['u_dropout']\n",
    "    stack_layers = parameters['stack_layers']\n",
    "    conv_size = parameters['conv_size']\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "        lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    "    )\n",
    "\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "\n",
    "    info('***************************************************************************************')\n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "    # creating the actual keras model\n",
    "    model = create_keras_rnn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size)\n",
    "    model.summary()\n",
    "\n",
    "    # callbacks for early stopping and for generating validation metrics\n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                              nb_epoch=NN_MAX_EPOCHS, verbose=MODEL_VERBOSITY, \\\n",
    "                              callbacks=[early_stopper, metrics_callback])\n",
    "    \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Training Data')\n",
    "    yp = model.predict(X) # get raw probability for predicted labels\n",
    "    yp_binary = get_binary_0_5(yp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    #print yvp\n",
    "    info('Generating Training Metrics')\n",
    "    training_metrics = get_metrics(y, yp, yp_binary)\n",
    "    print \"****** Training Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    training_metrics['coverage_error'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "    training_metrics['f1_micro'], training_metrics['f1_macro'])\n",
    "    \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Validation Data using saved best weights')\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    yvp = model.predict(Xv) # get raw probability for predicted labels\n",
    "    yvp_binary = get_binary_0_5(yvp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    best_validation_metrics = validation_metrics\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "    del history, metrics_callback, model\n",
    "\n",
    "if save_results:\n",
    "    if load_existing_results:\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results from {}'.format(param_results_path))\n",
    "            loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "            param_results_dict.update(loaded_param_results_dict)\n",
    "            \n",
    "    pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                                   NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_optimizer_rmsprop_size_200_w-drop_0.4_u-drop_0.2',\n",
       " 'lstm_optimizer_adam_size_300_w-drop_0.2_u-drop_0.3',\n",
       " 'lstm_optimizer_adam_size_200_w-drop_0.3_u-drop_0.2',\n",
       " 'lstm_optimizer_adam_size_200_w-drop_0.2_u-drop_0.3',\n",
       " 'lstm_optimizer_adam_size_200_w-drop_0.2_u-drop_0.2',\n",
       " 'lstm_optimizer_rmsprop_size_200_w-drop_0.2_u-drop_0.4']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%xdel model\n",
    "import gc\n",
    "for i in range(3): gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                                   NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # create nn parameter search directory\n",
    "    if not os.path.exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME)):\n",
    "        os.makedirs(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
