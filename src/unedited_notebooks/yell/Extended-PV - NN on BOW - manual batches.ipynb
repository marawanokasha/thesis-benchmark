{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: TITAN X (Pascal) (CNMeM is disabled, cuDNN 5105)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import namedtuple, defaultdict\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 10000\n",
    "NN_SEED = 1234\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "MAX_TERMS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"nn_bow_{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATIO = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_location = \"/mnt/data2/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_bow_parameter_search_extended_manual_batch\")\n",
    "\n",
    "training_file = root_location + \"docs_output.json\"\n",
    "\n",
    "classifications_index_file = exports_location + \"classifications_index.pkl\"\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"extended_pv_training_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "validation_docs_list_file = exports_location + \"extended_pv_validation_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "test_docs_list_file = exports_location + \"extended_pv_test_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "\n",
    "def get_label_data(classifications, doc_ids, doc_classification_map):\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    classifications_set = set(classifications)\n",
    "    data_labels = []\n",
    "    for i, doc_id in enumerate(doc_ids):\n",
    "        eligible_classifications = set(doc_classification_map[doc_id]) & classifications_set\n",
    "        data_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))\n",
    "        #if i % 1000 == 0: info(i)\n",
    "    data_labels = np.array(data_labels, dtype=np.int8)\n",
    "    return data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_keras_nn_model(input_size, output_size, \n",
    "                          first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                          second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                          input_dropout_do, hidden_dropout_do, second_hidden_dropout_do=False):\n",
    "    \n",
    "    doc_input = Input(shape=(input_size,), name='doc_input')\n",
    "    if input_dropout_do:\n",
    "        hidden = Dropout(0.7)(doc_input)\n",
    "    hidden = Dense(first_hidden_layer_size, activation=first_hidden_layer_activation, \n",
    "                   name='hidden_layer_{}'.format(first_hidden_layer_activation))(doc_input if not input_dropout_do else hidden)\n",
    "    if hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    if second_hidden_layer_size is not None:\n",
    "        hidden = Dense(second_hidden_layer_size, activation=second_hidden_layer_activation, \n",
    "                       name='hidden_layer2_{}'.format(second_hidden_layer_activation))(hidden)\n",
    "    if second_hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    softmax_output = Dense(output_size, activation='sigmoid', name='softmax_output')(hidden)\n",
    "\n",
    "    model = Model(input=doc_input, output=softmax_output)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 988 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopper_deltas = {\n",
    "    'sections': 0.00001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "early_stopper_patience = {\n",
    "    'sections': 10,\n",
    "    'classes': 15,\n",
    "    'subclasses': 15\n",
    "}\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 20,\n",
    "    'subclasses': 20\n",
    "}\n",
    "\n",
    "# ranges for learning graph shown\n",
    "metrics_graph_ranges = {\n",
    "    'sections': {'min':0, 'max': 0.5},\n",
    "    'classes': {'min':0, 'max': 0.05},\n",
    "    'subclasses': {'min':0, 'max': 0.05}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MetricsCallbackWithGenerator(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the \n",
    "    validation metrics\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        MetricsCallbackWithGenerator.EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "        MetricsCallbackWithGenerator.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
    "        MetricsCallbackWithGenerator.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
    "        self.ax = plt.subplot(111)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
    "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
    "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
    "        self.ax.set_ylim((MetricsCallbackWithGenerator.GRAPH_MIN, MetricsCallbackWithGenerator.GRAPH_MAX))\n",
    "        self.fig.canvas.draw()\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            #print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            #time.sleep(0.1)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallbackWithGenerator.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                yvp = self.model.predict_generator(generator=nn_batch_generator_no_shuffle(Xv, yv, NN_BATCH_SIZE), \n",
    "                                                   val_samples=Xv.shape[0])\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_batch_generator(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(y_data)[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    X_data =  X_data[shuffle_index, :]\n",
    "    y_data =  y_data[shuffle_index]\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].todense()\n",
    "        y_batch = y_data[index_batch]\n",
    "        counter += 1\n",
    "        yield np.array(X_batch),y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_batch_generator_no_shuffle(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].todense()\n",
    "        y_batch = y_data[index_batch]\n",
    "        counter += 1\n",
    "        yield np.array(X_batch),y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_batch_generator_sample(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(y_data)[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    X_data =  X_data[shuffle_index, :]\n",
    "    y_data =  y_data[shuffle_index, :]\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "#         X_batch = X_data[index_batch,:].todense()\n",
    "#         y_batch = y_data[index_batch]\n",
    "        counter += 1\n",
    "        yield index_batch\n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_batch_generator_sample_no_shuffle(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "#         X_batch = X_data[index_batch,:].todense()\n",
    "#         y_batch = y_data[index_batch]\n",
    "        counter += 1\n",
    "        yield index_batch\n",
    "        if (counter > number_of_batches):\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78 76 18 32 54 66 96 94 91 60 59 16]\n",
      "[95 99 64 81 38 28 53 68 71 13 25 10]\n",
      "[20 69 14 49 39 29 24 40 12  7 98  1]\n",
      "[ 3 57 42 50 55  6 22 11 33 84 21 37]\n",
      "[93 86 79 17 80 75 15  0  2 89 35 63]\n",
      "[56 31 48 62 46 47 52 27 73 44 90 97]\n",
      "[92 41 83 70 34 85 74 77 65 61 88 45]\n",
      "[82 58 43 67 30 23 72 36 51  4  9  8]\n",
      "[19 26  5 87]\n",
      "[70 27 54 42 98 15 13 51 32 31 87 76]\n",
      "[61 28  2  6 94 58 73 40  8 86 14 33]\n",
      "[ 3 77 53 10 23 80 50 55 93 22 67 78]\n",
      "[21 43 20  7 64 24 79 19 63 29 52 91]\n",
      "[11 90 81 82 84 71  5 41 35  0 45 34]\n",
      "[66 36 68 62 38 18 30 17 69 74 37 48]\n",
      "[92 99 56  4 47 46 59 12 85 89 57 25]\n",
      "[95 88 39 97 26 49 60 83 16 96 65  9]\n",
      "[ 1 75 72 44]\n",
      "[64  7 59 39 11 38 75 87 20  5  3 19]\n",
      "[92 22 78 85 27 88 25 56  2  0 69 73]\n",
      "[26 94 71 66 31 37 74 49 48 61 80 35]\n"
     ]
    }
   ],
   "source": [
    "X_sample = np.zeros((100,20))\n",
    "y_sample = np.zeros(100)\n",
    "gen = nn_batch_generator_sample(X_sample, y_sample, 12)\n",
    "for i,d in enumerate(gen):\n",
    "    if i> 20:\n",
    "        break\n",
    "    print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "[12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "[24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "[36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "[48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "[60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "[72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "[84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "[96 97 98 99]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "[12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "[24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "[36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "[48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "[60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "[72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "[84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "[96 97 98 99]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "[12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "[24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    }
   ],
   "source": [
    "X_sample = np.zeros((100,20))\n",
    "y_sample = np.zeros(100)\n",
    "gen = nn_batch_generator_sample_no_shuffle(X_sample, y_sample, 12)\n",
    "for i,d in enumerate(gen):\n",
    "    if i> 20:\n",
    "        break\n",
    "    print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = sections\n",
    "classifications_type = \"sections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "# NN_INPUT_NEURONS = DOC2VEC_SIZE\n",
    "\n",
    "EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "\n",
    "NN_MAX_EPOCHS = 200\n",
    "NN_RANDOM_SEARCH_BUDGET = 30\n",
    "NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "NN_BATCH_SIZE = 2048\n",
    "\n",
    "MODEL_VERBOSITY = 1\n",
    "\n",
    "to_skip = []\n",
    "\n",
    "load_existing_results = False\n",
    "save_results = False\n",
    "\n",
    "\n",
    "first_hidden_layer_sizes = [100,200,500,1000]\n",
    "# first_hidden_layer_sizes = [1000,2000]\n",
    "# second_hidden_layer_sizes = [1000,2000,3000,4000]\n",
    "second_hidden_layer_sizes = [None,500,1000,2000]\n",
    "first_hidden_layer_activations = ['relu','sigmoid', 'tanh']\n",
    "second_hidden_layer_activations = ['relu','sigmoid', 'tanh']\n",
    "# first_hidden_layer_activations = ['relu']\n",
    "# second_hidden_layer_activations = ['relu']\n",
    "# input_dropout_options = [False, True]\n",
    "# hidden_dropout_options = [False, True]\n",
    "input_dropout_options = [False]\n",
    "hidden_dropout_options = [True]\n",
    "second_hidden_dropout_options = [False]\n",
    "\n",
    "\n",
    "np.random.seed(NN_SEED)\n",
    "\n",
    "\n",
    "# Uncomment for Specific Configuration\n",
    "# NN_RANDOM_SEARCH_BUDGET = 1\n",
    "# first_hidden_layer_sizes = [500]\n",
    "# second_hidden_layer_sizes = [2000]\n",
    "# first_hidden_layer_activations = ['relu']\n",
    "# second_hidden_layer_activations = ['relu']\n",
    "# input_dropout_options = [False]\n",
    "# hidden_dropout_options = [True]\n",
    "# second_hidden_dropout_options = [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 01:01:59,691 : INFO : =============== bm25 Being Evaluated ================\n",
      "2017-04-03 01:01:59,692 : INFO : ***************************************************************************************\n",
      "2017-04-03 01:01:59,693 : INFO : nn_1st-size_500_1st-act_relu_2nd-size_2000_2nd-act_relu_in-drop_False_hid-drop_True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 10000)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           5000500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 500)           0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer2_relu (Dense)       (None, 2000)          1002000     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             16008       hidden_layer2_relu[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 6018508\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.2313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 01:02:18,641 : INFO : Found lower val loss for epoch 1 => 0.16988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 17s - loss: 0.2311 - val_loss: 0.1699\n",
      "Epoch 2/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 01:02:34,610 : INFO : Found lower val loss for epoch 2 => 0.16822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 15s - loss: 0.1789 - val_loss: 0.1682\n",
      "Epoch 3/200\n",
      "253952/254767 [============================>.] - ETA: 0s - loss: 0.1632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 01:02:51,213 : INFO : Found lower val loss for epoch 3 => 0.16313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254767/254767 [==============================] - 16s - loss: 0.1631 - val_loss: 0.1631\n",
      "Epoch 4/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.1509 - val_loss: 0.1638\n",
      "Epoch 5/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.1401 - val_loss: 0.1640\n",
      "Epoch 6/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.1298 - val_loss: 0.1733\n",
      "Epoch 7/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.1212 - val_loss: 0.1715\n",
      "Epoch 8/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.1132 - val_loss: 0.1785\n",
      "Epoch 9/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.1063 - val_loss: 0.1810\n",
      "Epoch 10/200\n",
      "254767/254767 [==============================] - 15s - loss: 0.1001 - val_loss: 0.1884\n",
      "Epoch 11/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.0951 - val_loss: 0.1943\n",
      "Epoch 12/200\n",
      "254767/254767 [==============================] - 17s - loss: 0.0904 - val_loss: 0.2013\n",
      "Epoch 13/200\n",
      "254767/254767 [==============================] - 16s - loss: 0.0865 - val_loss: 0.1999\n",
      "Epoch 14/200\n",
      "254767/254767 [==============================] - 15s - loss: 0.0830 - val_loss: 0.2048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 01:05:53,476 : INFO : Evaluating on Validation Data using saved best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: early stopping\n",
      "CPU times: user 3min 14s, sys: 3min 55s, total: 7min 10s\n",
      "Wall time: 3min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 01:05:57,043 : INFO : Generating Validation Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation Metrics: Cov Err: 1.501 | Top 3: 0.963 | Top 5: 0.993 | F1 Micro: 0.766 | F1 Macro: 0.671\n",
      "CPU times: user 3min 19s, sys: 3min 59s, total: 7min 18s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_types = [\"bm25\"]\n",
    "# data_types = [\"tf\"]\n",
    "for data_type in data_types:\n",
    "    info(\"=============== {} Being Evaluated ================\".format(data_type))\n",
    "    \n",
    "    GLOBAL_VARS.MODEL_NAME = data_type + \"/size_{}\".format(MAX_TERMS)\n",
    "    \n",
    "    data_training_location = exports_location + \"extended_pv_benchmarking_data/\" + \"{}_training_sparse_data.pkl\".format(data_type)\n",
    "    data_training_docids_location = exports_location + \"extended_pv_benchmarking_data/\" + \"{}_training_sparse_docids.pkl\".format(data_type)\n",
    "    data_validation_location = exports_location + \"extended_pv_benchmarking_data/\" + \"{}_validation_sparse_data.pkl\".format(data_type)\n",
    "    data_validation_docids_location = exports_location + \"extended_pv_benchmarking_data/\" + \"{}_validation_sparse_docids.pkl\".format(data_type)\n",
    "    \n",
    "#     # Get the training data\n",
    "#     info('Getting Training Data')\n",
    "#     %time X = pickle.load(open(data_training_location, \"r\"))\n",
    "#     training_data_docids = pickle.load(open(data_training_docids_location, \"r\"))\n",
    "#     %time y = get_label_data(classifications, training_data_docids, doc_classification_map)\n",
    "    \n",
    "#     print X.shape\n",
    "#     print y.shape\n",
    "\n",
    "#     # Get the validation data\n",
    "#     info('Getting Validation Data')\n",
    "#     %time Xv = pickle.load(open(data_validation_location,'r'))\n",
    "#     validation_data_docids = pickle.load(open(data_validation_docids_location, \"r\"))\n",
    "#     %time yv = get_label_data(classifications, validation_data_docids, doc_classification_map)\n",
    "    \n",
    "    NN_INPUT_NEURONS = X.shape[1]\n",
    "\n",
    "\n",
    "    param_sampler = ParameterSampler({\n",
    "        'first_hidden_layer_size':first_hidden_layer_sizes,\n",
    "        'first_hidden_layer_activation':first_hidden_layer_activations,\n",
    "        'second_hidden_layer_size':second_hidden_layer_sizes,\n",
    "        'second_hidden_layer_activation':second_hidden_layer_activations,\n",
    "        'input_dropout':input_dropout_options,\n",
    "        'hidden_dropout':hidden_dropout_options,\n",
    "        'second_hidden_dropout':second_hidden_dropout_options\n",
    "    }, n_iter=NN_RANDOM_SEARCH_BUDGET, random_state=NN_PARAM_SAMPLE_SEED)\n",
    "\n",
    "    param_results_dict = {}\n",
    "\n",
    "    param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE)))\n",
    "\n",
    "    if load_existing_results:\n",
    "        param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE)))\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results in {}'.format(param_results_path))\n",
    "            param_results_dict = pickle.load(open(param_results_path))\n",
    "        else:\n",
    "            info('No Previous results exist in {}'.format(param_results_path))\n",
    "\n",
    "    # create nn parameter search directory\n",
    "    if not os.path.exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME)):\n",
    "        os.makedirs(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "    for parameters in param_sampler:\n",
    "        start_time = time.time()\n",
    "        first_hidden_layer_size = parameters['first_hidden_layer_size']\n",
    "        first_hidden_layer_activation = parameters['first_hidden_layer_activation']\n",
    "        second_hidden_layer_size = parameters['second_hidden_layer_size']\n",
    "        second_hidden_layer_activation = parameters['second_hidden_layer_activation']\n",
    "        input_dropout_do = parameters['input_dropout']\n",
    "        hidden_dropout_do = parameters['hidden_dropout']\n",
    "        second_hidden_dropout_do = parameters['second_hidden_dropout']\n",
    "\n",
    "        GLOBAL_VARS.NN_MODEL_NAME = 'nn_1st-size_{}_1st-act_{}_2nd-size_{}_2nd-act_{}_in-drop_{}_hid-drop_{}'.format(\n",
    "            first_hidden_layer_size, first_hidden_layer_activation, second_hidden_layer_size, \n",
    "            second_hidden_layer_activation, input_dropout_do, hidden_dropout_do\n",
    "        )\n",
    "        if second_hidden_dropout_do:\n",
    "            GLOBAL_VARS.NN_MODEL_NAME = GLOBAL_VARS.NN_MODEL_NAME + '_2nd-hid-drop_{}'.format(str(second_hidden_dropout_do))\n",
    "\n",
    "        if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "            print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "            continue\n",
    "    #         if first_hidden_layer_size < DOC2VEC_SIZE or second_hidden_layer_size < NN_OUTPUT_NEURONS:\n",
    "    #             print \"skipping: {} due to 1st layer size {} < {} or 2nd layer size {} < {}\".format(GLOBAL_VARS.NN_MODEL_NAME,\n",
    "    #                                                                                                 first_hidden_layer_size, DOC2VEC_SIZE, \n",
    "    #                                                                                                 second_hidden_layer_size, NN_OUTPUT_NEURONS)\n",
    "    #             continue\n",
    "\n",
    "\n",
    "        info('***************************************************************************************')\n",
    "        info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "        model = create_keras_nn_model(NN_INPUT_NEURONS, NN_OUTPUT_NEURONS, \n",
    "                                      first_hidden_layer_size, first_hidden_layer_activation, \n",
    "                                      second_hidden_layer_size, second_hidden_layer_activation, \n",
    "                                      input_dropout_do, hidden_dropout_do, second_hidden_dropout_do)\n",
    "        model.summary()\n",
    "\n",
    "        early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                      patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "        metrics_callback = MetricsCallbackWithGenerator()\n",
    "\n",
    "        # Model Fitting\n",
    "#         %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "#                                   nb_epoch=NN_MAX_EPOCHS, verbose=MODEL_VERBOSITY, callbacks=[early_stopper, metrics_callback])\n",
    "\n",
    "        %time history = model.fit_generator(generator=nn_batch_generator_no_shuffle(X, y, NN_BATCH_SIZE), \\\n",
    "                                            samples_per_epoch=X.shape[0],\\\n",
    "                                            validation_data=nn_batch_generator_no_shuffle(Xv, yv, NN_BATCH_SIZE),\\\n",
    "                                            nb_val_samples=Xv.shape[0],\\\n",
    "                                            nb_epoch=NN_MAX_EPOCHS, callbacks=[early_stopper, metrics_callback])\n",
    "\n",
    "        # using the recorded weights of the best recorded validation loss\n",
    "        last_model_weights = model.get_weights()\n",
    "        info('Evaluating on Validation Data using saved best weights')\n",
    "        model.set_weights(metrics_callback.best_weights)\n",
    "        yvp = model.predict_generator(generator=nn_batch_generator_no_shuffle(Xv, yv, NN_BATCH_SIZE), \n",
    "                                                   val_samples=Xv.shape[0])\n",
    "        yvp_binary = get_binary_0_5(yvp)\n",
    "        #print yvp\n",
    "        info('Generating Validation Metrics')\n",
    "        validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "        print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "            validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "            validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "        best_validation_metrics = validation_metrics\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "        del history, last_model_weights, metrics_callback\n",
    "\n",
    "    if save_results:\n",
    "        if load_existing_results:\n",
    "            if os.path.exists(param_results_path):\n",
    "                info('Loading Previous results from {}'.format(param_results_path))\n",
    "                loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "                param_results_dict.update(loaded_param_results_dict)\n",
    "\n",
    "        pickle.dump(param_results_dict, open(os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                                       NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, NN_BATCH_SIZE))), 'w'))\n",
    "    #del X, Xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
