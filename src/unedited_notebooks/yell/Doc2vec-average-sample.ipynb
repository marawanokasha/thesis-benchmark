{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_WORD_COUNT = 5\n",
    "MIN_SIZE = 0\n",
    "NUM_CORES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATIO = 0.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_file = \"/home/local/shalaby/docs_output_sample_100.json\"\n",
    "training_file = \"/home/local/shalaby/docs_output.json\"\n",
    "doc_classifications_map_file = \"/home/local/shalaby/doc_classification_map.pkl\"\n",
    "sections_file = \"/home/local/shalaby/sections.pkl\"\n",
    "training_docs_list_file = \"/home/local/shalaby/training_documents_\" + str(SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "validation_docs_list_file = \"/home/local/shalaby/validation_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_save_location = \"/home/local/shalaby/models/scikit-svm/sample_\" + str(SAMPLE_RATIO) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 1min 6s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classifications_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "#open(sections_file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49544"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            elif is_stopword(stem):\n",
    "                stem = None\n",
    "            else:\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append(stem)\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_stopword(word):\n",
    "  return word in STOP_WORDS\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 400\n",
    "DOC2VEC_WINDOW = 8\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-5\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 0\n",
    "DOC2VEC_EPOCHS = 1\n",
    "DOC2VEC_MAX_EPOCHS = 20\n",
    "REPORT_DELAY = 30 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 1000 # report the progress every x terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_ITERATIONS = 1000\n",
    "SVM_CONVERGENCE = 0.001\n",
    "SVM_REG = 1/0.1 # scikit uses a C parameter not a lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename):\n",
    "            (doc_id, text) = eval(line)\n",
    "            if doc_id in training_docs_list:\n",
    "                yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(size=DOC2VEC_SIZE , window=DOC2VEC_WINDOW, min_count=MIN_WORD_COUNT, \n",
    "                max_vocab_size= DOC2VEC_MAX_VOCAB_SIZE,\n",
    "                sample=DOC2VEC_SAMPLE, seed=DOC2VEC_SEED, workers=NUM_CORES,\n",
    "                # doc2vec algorithm dm=1 => PV-DM, dm=2 => PV-DBOW, PV-DM dictates CBOW for words\n",
    "                dm=DOC2VEC_TYPE,\n",
    "                # hs=0 => negative sampling, hs=1 => hierarchical softmax\n",
    "                hs=DOC2VEC_HIERARCHICAL_SAMPLE, negative=DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                dm_concat=DOC2VEC_CONCAT,\n",
    "                # would train words with skip-gram on top of cbow, we don't need that for now\n",
    "                dbow_words=0,\n",
    "                iter=DOC2VEC_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-09-01 01:38:02,198 : INFO : collecting all words and their counts\n",
      "2016-09-01 01:38:02,337 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2016-09-01 01:42:31,289 : INFO : PROGRESS: at example #1000, processed 5129048 words (19070/s), 139924 word types, 1000 tags\n",
      "2016-09-01 01:46:53,692 : INFO : PROGRESS: at example #2000, processed 9805080 words (17820/s), 227427 word types, 2000 tags\n",
      "2016-09-01 01:51:20,712 : INFO : PROGRESS: at example #3000, processed 14569369 words (17842/s), 290517 word types, 3000 tags\n",
      "2016-09-01 01:55:36,396 : INFO : PROGRESS: at example #4000, processed 19027847 words (17437/s), 343413 word types, 4000 tags\n",
      "2016-09-01 02:00:02,483 : INFO : PROGRESS: at example #5000, processed 24491779 words (20534/s), 506953 word types, 5000 tags\n",
      "2016-09-01 02:04:28,990 : INFO : PROGRESS: at example #6000, processed 29393944 words (18394/s), 572595 word types, 6000 tags\n",
      "2016-09-01 02:08:47,034 : INFO : PROGRESS: at example #7000, processed 34087324 words (18188/s), 625001 word types, 7000 tags\n",
      "2016-09-01 02:13:18,272 : INFO : PROGRESS: at example #8000, processed 38847052 words (17548/s), 673234 word types, 8000 tags\n",
      "2016-09-01 02:17:48,511 : INFO : PROGRESS: at example #9000, processed 43485312 words (17163/s), 734764 word types, 9000 tags\n",
      "2016-09-01 02:22:11,221 : INFO : PROGRESS: at example #10000, processed 48326923 words (18429/s), 787649 word types, 10000 tags\n",
      "2016-09-01 02:26:29,630 : INFO : PROGRESS: at example #11000, processed 53151607 words (18670/s), 837880 word types, 11000 tags\n",
      "2016-09-01 02:30:46,260 : INFO : PROGRESS: at example #12000, processed 57940401 words (18660/s), 888317 word types, 12000 tags\n",
      "2016-09-01 02:35:16,992 : INFO : PROGRESS: at example #13000, processed 62632677 words (17331/s), 928354 word types, 13000 tags\n",
      "2016-09-01 02:39:32,523 : INFO : PROGRESS: at example #14000, processed 67260822 words (18112/s), 969959 word types, 14000 tags\n",
      "2016-09-01 02:43:56,574 : INFO : PROGRESS: at example #15000, processed 71976364 words (17858/s), 1012195 word types, 15000 tags\n",
      "2016-09-01 02:48:26,630 : INFO : PROGRESS: at example #16000, processed 76785936 words (17809/s), 1053042 word types, 16000 tags\n",
      "2016-09-01 02:52:46,140 : INFO : PROGRESS: at example #17000, processed 81606875 words (18577/s), 1094916 word types, 17000 tags\n",
      "2016-09-01 02:57:09,734 : INFO : PROGRESS: at example #18000, processed 86253702 words (17628/s), 1132146 word types, 18000 tags\n",
      "2016-09-01 03:01:42,842 : INFO : PROGRESS: at example #19000, processed 91335286 words (18606/s), 1181468 word types, 19000 tags\n",
      "2016-09-01 03:06:12,880 : INFO : PROGRESS: at example #20000, processed 96305771 words (18406/s), 1226311 word types, 20000 tags\n",
      "2016-09-01 03:10:40,050 : INFO : PROGRESS: at example #21000, processed 101274210 words (18596/s), 1272365 word types, 21000 tags\n",
      "2016-09-01 03:15:08,015 : INFO : PROGRESS: at example #22000, processed 106062407 words (17868/s), 1314255 word types, 22000 tags\n",
      "2016-09-01 03:19:42,309 : INFO : PROGRESS: at example #23000, processed 111021458 words (18079/s), 1358127 word types, 23000 tags\n",
      "2016-09-01 03:24:11,139 : INFO : PROGRESS: at example #24000, processed 115849688 words (17960/s), 1410539 word types, 24000 tags\n",
      "2016-09-01 03:28:31,562 : INFO : PROGRESS: at example #25000, processed 120604198 words (18257/s), 1448413 word types, 25000 tags\n",
      "2016-09-01 03:32:56,952 : INFO : PROGRESS: at example #26000, processed 125317704 words (17760/s), 1484103 word types, 26000 tags\n",
      "2016-09-01 03:37:20,173 : INFO : PROGRESS: at example #27000, processed 129904328 words (17425/s), 1521760 word types, 27000 tags\n",
      "2016-09-01 03:41:41,169 : INFO : PROGRESS: at example #28000, processed 134717626 words (18442/s), 1563744 word types, 28000 tags\n",
      "2016-09-01 03:46:12,643 : INFO : PROGRESS: at example #29000, processed 139563448 words (17850/s), 1602871 word types, 29000 tags\n",
      "2016-09-01 03:50:36,622 : INFO : PROGRESS: at example #30000, processed 143882424 words (16361/s), 1631417 word types, 30000 tags\n",
      "2016-09-01 03:54:56,029 : INFO : PROGRESS: at example #31000, processed 148898826 words (19338/s), 1672709 word types, 31000 tags\n",
      "2016-09-01 03:59:32,957 : INFO : PROGRESS: at example #32000, processed 154025413 words (18512/s), 1718412 word types, 32000 tags\n",
      "2016-09-01 04:03:57,068 : INFO : PROGRESS: at example #33000, processed 158682264 words (17632/s), 1754954 word types, 33000 tags\n",
      "2016-09-01 04:08:10,797 : INFO : PROGRESS: at example #34000, processed 163455388 words (18812/s), 1792295 word types, 34000 tags\n",
      "2016-09-01 04:12:31,532 : INFO : PROGRESS: at example #35000, processed 168375103 words (18868/s), 1830793 word types, 35000 tags\n",
      "2016-09-01 04:16:58,256 : INFO : PROGRESS: at example #36000, processed 173173596 words (17990/s), 1873002 word types, 36000 tags\n",
      "2016-09-01 04:21:23,295 : INFO : PROGRESS: at example #37000, processed 177838349 words (17600/s), 1907631 word types, 37000 tags\n",
      "2016-09-01 04:25:46,340 : INFO : PROGRESS: at example #38000, processed 182416930 words (17406/s), 1942823 word types, 38000 tags\n",
      "2016-09-01 04:30:16,002 : INFO : PROGRESS: at example #39000, processed 187164811 words (17606/s), 1977250 word types, 39000 tags\n",
      "2016-09-01 04:34:44,684 : INFO : PROGRESS: at example #40000, processed 192038879 words (18140/s), 2023932 word types, 40000 tags\n",
      "2016-09-01 04:39:12,838 : INFO : PROGRESS: at example #41000, processed 196663240 words (17245/s), 2058486 word types, 41000 tags\n",
      "2016-09-01 04:43:25,379 : INFO : PROGRESS: at example #42000, processed 201139939 words (17726/s), 2088700 word types, 42000 tags\n",
      "2016-09-01 04:47:50,056 : INFO : PROGRESS: at example #43000, processed 205855609 words (17816/s), 2117600 word types, 43000 tags\n",
      "2016-09-01 04:52:35,710 : INFO : PROGRESS: at example #44000, processed 210607973 words (16636/s), 2152613 word types, 44000 tags\n",
      "2016-09-01 04:56:57,357 : INFO : PROGRESS: at example #45000, processed 215178002 words (17466/s), 2185535 word types, 45000 tags\n",
      "2016-09-01 05:01:12,054 : INFO : PROGRESS: at example #46000, processed 220019861 words (19010/s), 2219394 word types, 46000 tags\n",
      "2016-09-01 05:05:26,905 : INFO : PROGRESS: at example #47000, processed 224788373 words (18711/s), 2252897 word types, 47000 tags\n",
      "2016-09-01 05:09:48,911 : INFO : PROGRESS: at example #48000, processed 229689686 words (18707/s), 2285430 word types, 48000 tags\n",
      "2016-09-01 05:14:08,001 : INFO : PROGRESS: at example #49000, processed 234296193 words (17779/s), 2312541 word types, 49000 tags\n",
      "2016-09-01 05:16:26,777 : INFO : collected 2329203 word types and 49544 unique tags from a corpus of 49544 examples and 236667245 words\n",
      "2016-09-01 05:16:30,960 : INFO : min_count=5 retains 412602 unique words (drops 1916601)\n",
      "2016-09-01 05:16:30,962 : INFO : min_count leaves 233833789 word corpus (98% of original 236667245)\n",
      "2016-09-01 05:16:33,031 : INFO : deleting the raw counts dictionary of 2329203 items\n",
      "2016-09-01 05:16:33,553 : INFO : sample=1e-05 downsamples 4358 most-common words\n",
      "2016-09-01 05:16:33,555 : INFO : downsampling leaves estimated 83314102 word corpus (35.6% of prior 233833789)\n",
      "2016-09-01 05:16:33,556 : INFO : estimated required memory for 412602 words and 400 dimensions: 1615806600 bytes\n",
      "2016-09-01 05:16:35,515 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 35min 44s, sys: 5min 3s, total: 3h 40min 47s\n",
      "Wall time: 3h 41min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc2vec_model.build_vocab(sentences=LabeledLineSentence(training_file), progress_per=REPORT_VOCAB_PROGRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-09-01 09:59:07,251 : INFO : training model with 7 workers on 412602 vocabulary and 400 features, using sg=0 hs=0 sample=1e-05 negative=10\n",
      "2016-09-01 09:59:07,253 : INFO : expecting 49544 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-09-01 09:59:14,954 : INFO : PROGRESS: at 0.00% examples, 175 words/s, in_qsize 5, out_qsize 0\n",
      "2016-09-01 09:59:45,674 : INFO : PROGRESS: at 0.22% examples, 5039 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:00:15,696 : INFO : PROGRESS: at 0.44% examples, 5682 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:00:46,135 : INFO : PROGRESS: at 0.65% examples, 5660 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:01:17,187 : INFO : PROGRESS: at 0.87% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:01:47,403 : INFO : PROGRESS: at 1.11% examples, 6013 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:02:18,318 : INFO : PROGRESS: at 1.30% examples, 6039 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:02:49,311 : INFO : PROGRESS: at 1.53% examples, 5926 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:03:19,592 : INFO : PROGRESS: at 1.76% examples, 5953 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:03:49,683 : INFO : PROGRESS: at 1.99% examples, 5947 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:04:19,920 : INFO : PROGRESS: at 2.23% examples, 5975 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:04:50,056 : INFO : PROGRESS: at 2.46% examples, 5966 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:05:20,303 : INFO : PROGRESS: at 2.65% examples, 5939 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:05:51,127 : INFO : PROGRESS: at 2.87% examples, 5878 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:06:21,325 : INFO : PROGRESS: at 3.11% examples, 5837 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:06:51,755 : INFO : PROGRESS: at 3.34% examples, 5821 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:07:21,997 : INFO : PROGRESS: at 3.54% examples, 5786 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:07:52,856 : INFO : PROGRESS: at 3.77% examples, 5828 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:08:23,056 : INFO : PROGRESS: at 3.98% examples, 5829 words/s, in_qsize 0, out_qsize 1\n",
      "2016-09-01 10:08:53,207 : INFO : PROGRESS: at 4.22% examples, 5842 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:09:23,524 : INFO : PROGRESS: at 4.43% examples, 5839 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:09:53,562 : INFO : PROGRESS: at 4.65% examples, 5870 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:10:23,609 : INFO : PROGRESS: at 4.84% examples, 5853 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:10:54,417 : INFO : PROGRESS: at 5.06% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:11:25,544 : INFO : PROGRESS: at 5.28% examples, 5852 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:11:55,817 : INFO : PROGRESS: at 5.48% examples, 5833 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:12:26,016 : INFO : PROGRESS: at 5.73% examples, 5814 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:12:56,665 : INFO : PROGRESS: at 5.97% examples, 5797 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:13:26,678 : INFO : PROGRESS: at 6.19% examples, 5806 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:13:57,238 : INFO : PROGRESS: at 6.42% examples, 5797 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:14:27,328 : INFO : PROGRESS: at 6.66% examples, 5770 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:14:57,386 : INFO : PROGRESS: at 6.87% examples, 5745 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:15:27,664 : INFO : PROGRESS: at 7.08% examples, 5748 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:15:57,795 : INFO : PROGRESS: at 7.30% examples, 5764 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:16:28,020 : INFO : PROGRESS: at 7.53% examples, 5789 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:16:58,101 : INFO : PROGRESS: at 7.76% examples, 5784 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:17:28,251 : INFO : PROGRESS: at 7.99% examples, 5780 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:17:58,374 : INFO : PROGRESS: at 8.22% examples, 5796 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:18:30,138 : INFO : PROGRESS: at 8.46% examples, 5815 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:19:00,213 : INFO : PROGRESS: at 8.69% examples, 5817 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:19:30,345 : INFO : PROGRESS: at 8.91% examples, 5821 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:20:00,882 : INFO : PROGRESS: at 9.13% examples, 5834 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:20:30,904 : INFO : PROGRESS: at 9.35% examples, 5836 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:21:01,329 : INFO : PROGRESS: at 9.60% examples, 5827 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:21:31,730 : INFO : PROGRESS: at 9.76% examples, 5790 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:22:01,836 : INFO : PROGRESS: at 9.98% examples, 5775 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:22:32,596 : INFO : PROGRESS: at 10.22% examples, 5777 words/s, in_qsize 0, out_qsize 1\n",
      "2016-09-01 10:23:02,844 : INFO : PROGRESS: at 10.43% examples, 5785 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:23:33,096 : INFO : PROGRESS: at 10.68% examples, 5791 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:24:03,238 : INFO : PROGRESS: at 10.93% examples, 5831 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:24:33,588 : INFO : PROGRESS: at 11.15% examples, 5835 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:25:04,166 : INFO : PROGRESS: at 11.37% examples, 5833 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:25:34,634 : INFO : PROGRESS: at 11.55% examples, 5830 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:26:04,875 : INFO : PROGRESS: at 11.76% examples, 5820 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:26:35,034 : INFO : PROGRESS: at 11.96% examples, 5806 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:27:05,100 : INFO : PROGRESS: at 12.18% examples, 5813 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:27:35,203 : INFO : PROGRESS: at 12.38% examples, 5796 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:28:05,716 : INFO : PROGRESS: at 12.63% examples, 5788 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:28:36,247 : INFO : PROGRESS: at 12.88% examples, 5820 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:29:06,371 : INFO : PROGRESS: at 13.11% examples, 5820 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:29:37,080 : INFO : PROGRESS: at 13.37% examples, 5829 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:30:07,969 : INFO : PROGRESS: at 13.58% examples, 5825 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:30:38,152 : INFO : PROGRESS: at 13.79% examples, 5830 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:31:08,202 : INFO : PROGRESS: at 14.02% examples, 5837 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:31:38,381 : INFO : PROGRESS: at 14.22% examples, 5833 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:32:09,444 : INFO : PROGRESS: at 14.44% examples, 5828 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:32:39,523 : INFO : PROGRESS: at 14.65% examples, 5841 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:33:09,664 : INFO : PROGRESS: at 14.87% examples, 5845 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:33:40,186 : INFO : PROGRESS: at 15.09% examples, 5852 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:34:10,920 : INFO : PROGRESS: at 15.32% examples, 5847 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:34:41,292 : INFO : PROGRESS: at 15.52% examples, 5832 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:35:11,444 : INFO : PROGRESS: at 15.74% examples, 5836 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:35:41,495 : INFO : PROGRESS: at 15.96% examples, 5838 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:36:11,518 : INFO : PROGRESS: at 16.18% examples, 5834 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:36:42,325 : INFO : PROGRESS: at 16.39% examples, 5836 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:37:12,344 : INFO : PROGRESS: at 16.60% examples, 5832 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:37:43,210 : INFO : PROGRESS: at 16.82% examples, 5834 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:38:13,354 : INFO : PROGRESS: at 17.04% examples, 5833 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:38:43,404 : INFO : PROGRESS: at 17.28% examples, 5831 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:39:13,820 : INFO : PROGRESS: at 17.53% examples, 5822 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:39:44,332 : INFO : PROGRESS: at 17.73% examples, 5819 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:40:14,988 : INFO : PROGRESS: at 17.95% examples, 5824 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:40:45,431 : INFO : PROGRESS: at 18.17% examples, 5824 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:41:15,750 : INFO : PROGRESS: at 18.40% examples, 5822 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:41:47,022 : INFO : PROGRESS: at 18.63% examples, 5828 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:42:17,791 : INFO : PROGRESS: at 18.87% examples, 5835 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:42:48,253 : INFO : PROGRESS: at 19.08% examples, 5847 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:43:18,727 : INFO : PROGRESS: at 19.31% examples, 5842 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:43:49,522 : INFO : PROGRESS: at 19.55% examples, 5839 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:44:19,724 : INFO : PROGRESS: at 19.77% examples, 5841 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:44:50,179 : INFO : PROGRESS: at 19.98% examples, 5838 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:45:20,275 : INFO : PROGRESS: at 20.22% examples, 5842 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:45:50,540 : INFO : PROGRESS: at 20.46% examples, 5850 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:46:20,550 : INFO : PROGRESS: at 20.71% examples, 5858 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:46:50,785 : INFO : PROGRESS: at 20.91% examples, 5866 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:47:21,213 : INFO : PROGRESS: at 21.12% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:47:51,299 : INFO : PROGRESS: at 21.38% examples, 5866 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:48:21,456 : INFO : PROGRESS: at 21.59% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:48:51,948 : INFO : PROGRESS: at 21.79% examples, 5861 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:49:22,547 : INFO : PROGRESS: at 22.01% examples, 5858 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:49:52,814 : INFO : PROGRESS: at 22.29% examples, 5867 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:50:22,869 : INFO : PROGRESS: at 22.51% examples, 5869 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:50:53,188 : INFO : PROGRESS: at 22.75% examples, 5873 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:51:23,248 : INFO : PROGRESS: at 22.96% examples, 5872 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:51:53,893 : INFO : PROGRESS: at 23.19% examples, 5870 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:52:24,163 : INFO : PROGRESS: at 23.42% examples, 5868 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:52:54,307 : INFO : PROGRESS: at 23.63% examples, 5868 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:53:25,391 : INFO : PROGRESS: at 23.89% examples, 5872 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:53:56,258 : INFO : PROGRESS: at 24.14% examples, 5880 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:54:26,278 : INFO : PROGRESS: at 24.36% examples, 5883 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:54:56,323 : INFO : PROGRESS: at 24.58% examples, 5880 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:55:26,473 : INFO : PROGRESS: at 24.79% examples, 5874 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:55:56,817 : INFO : PROGRESS: at 25.00% examples, 5869 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:56:27,401 : INFO : PROGRESS: at 25.22% examples, 5873 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:56:58,105 : INFO : PROGRESS: at 25.42% examples, 5870 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:57:28,497 : INFO : PROGRESS: at 25.63% examples, 5865 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:57:58,566 : INFO : PROGRESS: at 25.87% examples, 5867 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:58:29,809 : INFO : PROGRESS: at 26.10% examples, 5868 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:59:00,777 : INFO : PROGRESS: at 26.35% examples, 5871 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 10:59:30,815 : INFO : PROGRESS: at 26.61% examples, 5872 words/s, in_qsize 1, out_qsize 0\n",
      "2016-09-01 11:00:01,598 : INFO : PROGRESS: at 26.85% examples, 5873 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:00:31,658 : INFO : PROGRESS: at 27.08% examples, 5878 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:01:01,887 : INFO : PROGRESS: at 27.29% examples, 5878 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:01:32,479 : INFO : PROGRESS: at 27.50% examples, 5880 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:02:02,648 : INFO : PROGRESS: at 27.70% examples, 5879 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:02:32,914 : INFO : PROGRESS: at 27.93% examples, 5880 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:03:03,597 : INFO : PROGRESS: at 28.18% examples, 5879 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:03:33,664 : INFO : PROGRESS: at 28.44% examples, 5882 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:04:04,064 : INFO : PROGRESS: at 28.68% examples, 5891 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:04:34,140 : INFO : PROGRESS: at 28.89% examples, 5884 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:05:04,134 : INFO : PROGRESS: at 29.13% examples, 5889 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:05:34,341 : INFO : PROGRESS: at 29.36% examples, 5890 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:06:04,762 : INFO : PROGRESS: at 29.56% examples, 5892 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:06:35,253 : INFO : PROGRESS: at 29.77% examples, 5893 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:07:05,459 : INFO : PROGRESS: at 30.00% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:07:35,821 : INFO : PROGRESS: at 30.23% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:08:06,334 : INFO : PROGRESS: at 30.43% examples, 5891 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:08:36,507 : INFO : PROGRESS: at 30.65% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:09:06,538 : INFO : PROGRESS: at 30.88% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:09:36,766 : INFO : PROGRESS: at 31.11% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:10:07,037 : INFO : PROGRESS: at 31.38% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:10:37,058 : INFO : PROGRESS: at 31.58% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:11:07,997 : INFO : PROGRESS: at 31.79% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:11:38,046 : INFO : PROGRESS: at 31.99% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:12:08,211 : INFO : PROGRESS: at 32.20% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:12:38,435 : INFO : PROGRESS: at 32.44% examples, 5890 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:13:08,682 : INFO : PROGRESS: at 32.64% examples, 5886 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:13:39,409 : INFO : PROGRESS: at 32.85% examples, 5888 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:14:09,614 : INFO : PROGRESS: at 33.08% examples, 5887 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:14:40,314 : INFO : PROGRESS: at 33.31% examples, 5889 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:15:10,480 : INFO : PROGRESS: at 33.55% examples, 5888 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:15:41,029 : INFO : PROGRESS: at 33.78% examples, 5899 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:16:11,069 : INFO : PROGRESS: at 34.02% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:16:41,536 : INFO : PROGRESS: at 34.27% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:17:12,477 : INFO : PROGRESS: at 34.48% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:17:42,740 : INFO : PROGRESS: at 34.71% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:18:12,875 : INFO : PROGRESS: at 34.92% examples, 5903 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:18:43,762 : INFO : PROGRESS: at 35.12% examples, 5899 words/s, in_qsize 0, out_qsize 1\n",
      "2016-09-01 11:19:13,802 : INFO : PROGRESS: at 35.35% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:19:44,192 : INFO : PROGRESS: at 35.59% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:20:14,363 : INFO : PROGRESS: at 35.84% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:20:45,244 : INFO : PROGRESS: at 36.05% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:21:15,976 : INFO : PROGRESS: at 36.26% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:21:46,062 : INFO : PROGRESS: at 36.48% examples, 5899 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:22:16,081 : INFO : PROGRESS: at 36.71% examples, 5903 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:22:47,441 : INFO : PROGRESS: at 36.93% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:23:17,628 : INFO : PROGRESS: at 37.10% examples, 5893 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:23:47,865 : INFO : PROGRESS: at 37.35% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:24:17,961 : INFO : PROGRESS: at 37.57% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:24:48,897 : INFO : PROGRESS: at 37.80% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:25:19,506 : INFO : PROGRESS: at 38.02% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:25:49,660 : INFO : PROGRESS: at 38.23% examples, 5903 words/s, in_qsize 1, out_qsize 0\n",
      "2016-09-01 11:26:19,979 : INFO : PROGRESS: at 38.44% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:26:50,138 : INFO : PROGRESS: at 38.66% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:27:20,944 : INFO : PROGRESS: at 38.85% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:27:51,014 : INFO : PROGRESS: at 39.06% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:28:21,235 : INFO : PROGRESS: at 39.29% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:28:52,215 : INFO : PROGRESS: at 39.53% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:29:22,501 : INFO : PROGRESS: at 39.73% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:29:52,679 : INFO : PROGRESS: at 39.97% examples, 5905 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:30:22,725 : INFO : PROGRESS: at 40.21% examples, 5906 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:30:53,118 : INFO : PROGRESS: at 40.42% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:31:23,577 : INFO : PROGRESS: at 40.63% examples, 5905 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:31:54,083 : INFO : PROGRESS: at 40.87% examples, 5909 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:32:24,184 : INFO : PROGRESS: at 41.08% examples, 5910 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:32:54,296 : INFO : PROGRESS: at 41.31% examples, 5913 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:33:24,465 : INFO : PROGRESS: at 41.53% examples, 5911 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:33:54,748 : INFO : PROGRESS: at 41.75% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:34:25,383 : INFO : PROGRESS: at 41.99% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:34:56,109 : INFO : PROGRESS: at 42.18% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:35:26,887 : INFO : PROGRESS: at 42.39% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:35:57,236 : INFO : PROGRESS: at 42.59% examples, 5913 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:36:27,366 : INFO : PROGRESS: at 42.80% examples, 5910 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:36:58,057 : INFO : PROGRESS: at 43.03% examples, 5905 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:37:29,189 : INFO : PROGRESS: at 43.25% examples, 5906 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:37:59,223 : INFO : PROGRESS: at 43.50% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:38:30,157 : INFO : PROGRESS: at 43.74% examples, 5908 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:39:00,683 : INFO : PROGRESS: at 43.96% examples, 5910 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:39:30,865 : INFO : PROGRESS: at 44.18% examples, 5908 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:40:01,100 : INFO : PROGRESS: at 44.40% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:40:31,788 : INFO : PROGRESS: at 44.64% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:41:02,008 : INFO : PROGRESS: at 44.83% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:41:32,409 : INFO : PROGRESS: at 45.04% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:42:03,036 : INFO : PROGRESS: at 45.27% examples, 5923 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:42:33,086 : INFO : PROGRESS: at 45.46% examples, 5921 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:43:03,655 : INFO : PROGRESS: at 45.70% examples, 5923 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:43:34,503 : INFO : PROGRESS: at 45.93% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:44:04,516 : INFO : PROGRESS: at 46.15% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:44:34,897 : INFO : PROGRESS: at 46.35% examples, 5916 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:45:05,466 : INFO : PROGRESS: at 46.56% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:45:35,742 : INFO : PROGRESS: at 46.81% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:46:05,956 : INFO : PROGRESS: at 47.03% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:46:36,221 : INFO : PROGRESS: at 47.26% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:47:06,702 : INFO : PROGRESS: at 47.46% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:47:36,756 : INFO : PROGRESS: at 47.68% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:48:07,130 : INFO : PROGRESS: at 47.88% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:48:38,188 : INFO : PROGRESS: at 48.09% examples, 5916 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:49:08,499 : INFO : PROGRESS: at 48.34% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:49:38,596 : INFO : PROGRESS: at 48.57% examples, 5916 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:50:09,003 : INFO : PROGRESS: at 48.80% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:50:39,324 : INFO : PROGRESS: at 49.00% examples, 5918 words/s, in_qsize 1, out_qsize 0\n",
      "2016-09-01 11:51:10,812 : INFO : PROGRESS: at 49.25% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:51:41,056 : INFO : PROGRESS: at 49.47% examples, 5921 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:52:11,865 : INFO : PROGRESS: at 49.69% examples, 5921 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:52:42,402 : INFO : PROGRESS: at 49.94% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:53:12,542 : INFO : PROGRESS: at 50.16% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:53:43,212 : INFO : PROGRESS: at 50.39% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:54:13,453 : INFO : PROGRESS: at 50.64% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:54:43,618 : INFO : PROGRESS: at 50.87% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:55:14,673 : INFO : PROGRESS: at 51.09% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:55:44,814 : INFO : PROGRESS: at 51.33% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:56:15,284 : INFO : PROGRESS: at 51.53% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:56:45,519 : INFO : PROGRESS: at 51.72% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:57:15,532 : INFO : PROGRESS: at 51.95% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:57:46,122 : INFO : PROGRESS: at 52.20% examples, 5920 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:58:16,122 : INFO : PROGRESS: at 52.41% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:58:47,423 : INFO : PROGRESS: at 52.62% examples, 5916 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:59:18,904 : INFO : PROGRESS: at 52.84% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 11:59:49,255 : INFO : PROGRESS: at 53.07% examples, 5911 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:00:19,334 : INFO : PROGRESS: at 53.29% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:00:49,493 : INFO : PROGRESS: at 53.53% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:01:19,938 : INFO : PROGRESS: at 53.76% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:01:50,873 : INFO : PROGRESS: at 54.00% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:02:21,360 : INFO : PROGRESS: at 54.20% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:02:52,006 : INFO : PROGRESS: at 54.45% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:03:22,203 : INFO : PROGRESS: at 54.65% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:03:52,321 : INFO : PROGRESS: at 54.86% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:04:22,392 : INFO : PROGRESS: at 55.08% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:04:52,595 : INFO : PROGRESS: at 55.30% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:05:23,461 : INFO : PROGRESS: at 55.53% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:05:54,168 : INFO : PROGRESS: at 55.78% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:06:24,244 : INFO : PROGRESS: at 56.01% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:06:54,487 : INFO : PROGRESS: at 56.26% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:07:25,022 : INFO : PROGRESS: at 56.47% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:07:55,062 : INFO : PROGRESS: at 56.70% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:08:26,273 : INFO : PROGRESS: at 56.92% examples, 5917 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:08:56,342 : INFO : PROGRESS: at 57.14% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:09:26,919 : INFO : PROGRESS: at 57.35% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:09:58,371 : INFO : PROGRESS: at 57.58% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:10:28,447 : INFO : PROGRESS: at 57.80% examples, 5919 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:10:58,455 : INFO : PROGRESS: at 58.03% examples, 5921 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:11:29,051 : INFO : PROGRESS: at 58.22% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:11:59,560 : INFO : PROGRESS: at 58.46% examples, 5918 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:12:29,987 : INFO : PROGRESS: at 58.67% examples, 5915 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:13:00,089 : INFO : PROGRESS: at 58.91% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:13:30,145 : INFO : PROGRESS: at 59.14% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:14:00,311 : INFO : PROGRESS: at 59.37% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:14:30,592 : INFO : PROGRESS: at 59.60% examples, 5909 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:15:01,183 : INFO : PROGRESS: at 59.80% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:15:31,627 : INFO : PROGRESS: at 60.01% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:16:02,291 : INFO : PROGRESS: at 60.22% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:16:33,419 : INFO : PROGRESS: at 60.45% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:17:03,773 : INFO : PROGRESS: at 60.68% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:17:34,012 : INFO : PROGRESS: at 60.90% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:18:04,332 : INFO : PROGRESS: at 61.12% examples, 5899 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:18:34,469 : INFO : PROGRESS: at 61.34% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:19:05,235 : INFO : PROGRESS: at 61.57% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:19:36,515 : INFO : PROGRESS: at 61.80% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:20:06,589 : INFO : PROGRESS: at 62.03% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:20:36,942 : INFO : PROGRESS: at 62.26% examples, 5904 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:21:06,989 : INFO : PROGRESS: at 62.47% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:21:37,859 : INFO : PROGRESS: at 62.69% examples, 5903 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:22:08,142 : INFO : PROGRESS: at 62.90% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:22:38,323 : INFO : PROGRESS: at 63.09% examples, 5899 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:23:09,289 : INFO : PROGRESS: at 63.31% examples, 5899 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:23:39,411 : INFO : PROGRESS: at 63.51% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:24:09,453 : INFO : PROGRESS: at 63.71% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:24:39,515 : INFO : PROGRESS: at 63.93% examples, 5896 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:25:09,647 : INFO : PROGRESS: at 64.16% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:25:39,908 : INFO : PROGRESS: at 64.39% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:26:09,912 : INFO : PROGRESS: at 64.59% examples, 5899 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:26:40,428 : INFO : PROGRESS: at 64.79% examples, 5899 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:27:10,597 : INFO : PROGRESS: at 65.06% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:27:41,219 : INFO : PROGRESS: at 65.25% examples, 5896 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:28:11,488 : INFO : PROGRESS: at 65.46% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:28:41,516 : INFO : PROGRESS: at 65.67% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:29:11,603 : INFO : PROGRESS: at 65.87% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:29:41,834 : INFO : PROGRESS: at 66.09% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:30:11,923 : INFO : PROGRESS: at 66.32% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:30:42,672 : INFO : PROGRESS: at 66.57% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:31:12,883 : INFO : PROGRESS: at 66.77% examples, 5892 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:31:43,262 : INFO : PROGRESS: at 67.01% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:32:14,644 : INFO : PROGRESS: at 67.25% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:32:45,123 : INFO : PROGRESS: at 67.48% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:33:15,239 : INFO : PROGRESS: at 67.69% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:33:45,436 : INFO : PROGRESS: at 67.92% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:34:15,852 : INFO : PROGRESS: at 68.15% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:34:47,507 : INFO : PROGRESS: at 68.42% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:35:17,924 : INFO : PROGRESS: at 68.65% examples, 5904 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:35:48,148 : INFO : PROGRESS: at 68.88% examples, 5905 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:36:18,638 : INFO : PROGRESS: at 69.09% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:36:48,694 : INFO : PROGRESS: at 69.30% examples, 5903 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:37:19,114 : INFO : PROGRESS: at 69.53% examples, 5903 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:37:49,427 : INFO : PROGRESS: at 69.76% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:38:19,541 : INFO : PROGRESS: at 70.00% examples, 5906 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:38:50,582 : INFO : PROGRESS: at 70.27% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:39:20,914 : INFO : PROGRESS: at 70.48% examples, 5910 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:39:50,916 : INFO : PROGRESS: at 70.68% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:40:21,676 : INFO : PROGRESS: at 70.89% examples, 5912 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:40:52,014 : INFO : PROGRESS: at 71.10% examples, 5913 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:41:22,155 : INFO : PROGRESS: at 71.32% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:41:52,287 : INFO : PROGRESS: at 71.55% examples, 5916 words/s, in_qsize 1, out_qsize 0\n",
      "2016-09-01 12:42:22,353 : INFO : PROGRESS: at 71.74% examples, 5916 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:42:52,483 : INFO : PROGRESS: at 71.97% examples, 5914 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:43:22,964 : INFO : PROGRESS: at 72.18% examples, 5911 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:43:53,018 : INFO : PROGRESS: at 72.41% examples, 5911 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:44:23,074 : INFO : PROGRESS: at 72.65% examples, 5911 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:44:53,090 : INFO : PROGRESS: at 72.87% examples, 5910 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:45:23,279 : INFO : PROGRESS: at 73.11% examples, 5909 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:45:54,458 : INFO : PROGRESS: at 73.39% examples, 5908 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:46:25,428 : INFO : PROGRESS: at 73.61% examples, 5906 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:46:55,916 : INFO : PROGRESS: at 73.84% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:47:28,226 : INFO : PROGRESS: at 74.06% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:47:58,418 : INFO : PROGRESS: at 74.27% examples, 5906 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:48:28,958 : INFO : PROGRESS: at 74.47% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:48:58,969 : INFO : PROGRESS: at 74.65% examples, 5904 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:49:29,144 : INFO : PROGRESS: at 74.90% examples, 5904 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:50:00,351 : INFO : PROGRESS: at 75.12% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:50:31,200 : INFO : PROGRESS: at 75.34% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:51:02,179 : INFO : PROGRESS: at 75.56% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:51:32,536 : INFO : PROGRESS: at 75.78% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:52:02,833 : INFO : PROGRESS: at 76.00% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:52:33,250 : INFO : PROGRESS: at 76.21% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:53:03,710 : INFO : PROGRESS: at 76.45% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:53:34,149 : INFO : PROGRESS: at 76.69% examples, 5903 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:54:04,777 : INFO : PROGRESS: at 76.90% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:54:35,018 : INFO : PROGRESS: at 77.12% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:55:05,336 : INFO : PROGRESS: at 77.32% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:55:35,990 : INFO : PROGRESS: at 77.56% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:56:06,298 : INFO : PROGRESS: at 77.76% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:56:36,498 : INFO : PROGRESS: at 77.99% examples, 5904 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:57:06,606 : INFO : PROGRESS: at 78.25% examples, 5907 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:57:36,621 : INFO : PROGRESS: at 78.48% examples, 5906 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:58:06,758 : INFO : PROGRESS: at 78.66% examples, 5901 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:58:36,998 : INFO : PROGRESS: at 78.89% examples, 5902 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:59:07,750 : INFO : PROGRESS: at 79.11% examples, 5900 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 12:59:37,831 : INFO : PROGRESS: at 79.33% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:00:08,321 : INFO : PROGRESS: at 79.56% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:00:40,482 : INFO : PROGRESS: at 79.76% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:01:10,653 : INFO : PROGRESS: at 79.98% examples, 5896 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:01:41,034 : INFO : PROGRESS: at 80.22% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:02:11,339 : INFO : PROGRESS: at 80.46% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:02:41,805 : INFO : PROGRESS: at 80.68% examples, 5897 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:03:12,628 : INFO : PROGRESS: at 80.89% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:03:42,735 : INFO : PROGRESS: at 81.11% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:04:12,853 : INFO : PROGRESS: at 81.32% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:04:43,700 : INFO : PROGRESS: at 81.53% examples, 5892 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:05:14,533 : INFO : PROGRESS: at 81.75% examples, 5893 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:05:45,124 : INFO : PROGRESS: at 81.98% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:06:15,668 : INFO : PROGRESS: at 82.21% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:06:45,730 : INFO : PROGRESS: at 82.43% examples, 5892 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:07:16,111 : INFO : PROGRESS: at 82.65% examples, 5891 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:07:46,119 : INFO : PROGRESS: at 82.90% examples, 5892 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:08:16,905 : INFO : PROGRESS: at 83.13% examples, 5893 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:08:47,050 : INFO : PROGRESS: at 83.37% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:09:17,172 : INFO : PROGRESS: at 83.60% examples, 5898 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:09:47,463 : INFO : PROGRESS: at 83.82% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:10:17,801 : INFO : PROGRESS: at 84.05% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:10:48,274 : INFO : PROGRESS: at 84.28% examples, 5891 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:11:19,161 : INFO : PROGRESS: at 84.52% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:11:49,181 : INFO : PROGRESS: at 84.77% examples, 5893 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:12:19,552 : INFO : PROGRESS: at 84.96% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:12:49,552 : INFO : PROGRESS: at 85.20% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:13:19,851 : INFO : PROGRESS: at 85.43% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:13:49,971 : INFO : PROGRESS: at 85.66% examples, 5895 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:14:20,103 : INFO : PROGRESS: at 85.88% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:14:50,442 : INFO : PROGRESS: at 86.11% examples, 5893 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:15:20,740 : INFO : PROGRESS: at 86.34% examples, 5894 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:15:51,634 : INFO : PROGRESS: at 86.55% examples, 5891 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:16:21,788 : INFO : PROGRESS: at 86.78% examples, 5891 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:16:51,866 : INFO : PROGRESS: at 86.99% examples, 5890 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:17:21,943 : INFO : PROGRESS: at 87.22% examples, 5891 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:17:52,213 : INFO : PROGRESS: at 87.43% examples, 5889 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:18:22,512 : INFO : PROGRESS: at 87.64% examples, 5888 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:18:52,543 : INFO : PROGRESS: at 87.85% examples, 5888 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:19:22,919 : INFO : PROGRESS: at 88.08% examples, 5887 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:20:23,976 : INFO : PROGRESS: at 88.18% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:20:54,295 : INFO : PROGRESS: at 88.38% examples, 5860 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:21:24,291 : INFO : PROGRESS: at 88.58% examples, 5860 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:21:54,735 : INFO : PROGRESS: at 88.79% examples, 5858 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:22:25,014 : INFO : PROGRESS: at 89.03% examples, 5858 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:22:55,065 : INFO : PROGRESS: at 89.28% examples, 5856 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:23:25,298 : INFO : PROGRESS: at 89.52% examples, 5856 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:23:55,491 : INFO : PROGRESS: at 89.75% examples, 5856 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:24:26,020 : INFO : PROGRESS: at 89.97% examples, 5855 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:24:56,202 : INFO : PROGRESS: at 90.17% examples, 5854 words/s, in_qsize 1, out_qsize 0\n",
      "2016-09-01 13:25:26,407 : INFO : PROGRESS: at 90.39% examples, 5856 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:25:56,454 : INFO : PROGRESS: at 90.59% examples, 5856 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:26:26,680 : INFO : PROGRESS: at 90.80% examples, 5856 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:26:56,726 : INFO : PROGRESS: at 91.01% examples, 5857 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:27:26,839 : INFO : PROGRESS: at 91.24% examples, 5859 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:27:57,654 : INFO : PROGRESS: at 91.46% examples, 5859 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:28:27,929 : INFO : PROGRESS: at 91.68% examples, 5861 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:28:58,286 : INFO : PROGRESS: at 91.90% examples, 5861 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:29:28,446 : INFO : PROGRESS: at 92.15% examples, 5860 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:29:58,968 : INFO : PROGRESS: at 92.35% examples, 5859 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:30:29,126 : INFO : PROGRESS: at 92.62% examples, 5860 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:30:59,612 : INFO : PROGRESS: at 92.86% examples, 5861 words/s, in_qsize 0, out_qsize 1\n",
      "2016-09-01 13:31:29,709 : INFO : PROGRESS: at 93.10% examples, 5862 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:31:59,991 : INFO : PROGRESS: at 93.34% examples, 5862 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:32:30,108 : INFO : PROGRESS: at 93.56% examples, 5862 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:33:00,116 : INFO : PROGRESS: at 93.79% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:33:30,484 : INFO : PROGRESS: at 94.04% examples, 5865 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:34:01,051 : INFO : PROGRESS: at 94.25% examples, 5866 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:34:31,585 : INFO : PROGRESS: at 94.48% examples, 5865 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:35:01,889 : INFO : PROGRESS: at 94.71% examples, 5866 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:35:32,211 : INFO : PROGRESS: at 94.92% examples, 5866 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:36:02,880 : INFO : PROGRESS: at 95.13% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:36:33,241 : INFO : PROGRESS: at 95.41% examples, 5865 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:37:03,772 : INFO : PROGRESS: at 95.65% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:37:34,016 : INFO : PROGRESS: at 95.86% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:38:04,066 : INFO : PROGRESS: at 96.06% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:38:34,666 : INFO : PROGRESS: at 96.27% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:39:05,419 : INFO : PROGRESS: at 96.48% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:39:35,775 : INFO : PROGRESS: at 96.71% examples, 5865 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:40:06,238 : INFO : PROGRESS: at 96.94% examples, 5865 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:40:36,294 : INFO : PROGRESS: at 97.18% examples, 5865 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:41:06,580 : INFO : PROGRESS: at 97.44% examples, 5866 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:41:36,584 : INFO : PROGRESS: at 97.65% examples, 5867 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:42:06,833 : INFO : PROGRESS: at 97.86% examples, 5866 words/s, in_qsize 1, out_qsize 0\n",
      "2016-09-01 13:42:36,874 : INFO : PROGRESS: at 98.08% examples, 5866 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:43:07,144 : INFO : PROGRESS: at 98.30% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:43:37,403 : INFO : PROGRESS: at 98.51% examples, 5862 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:44:07,642 : INFO : PROGRESS: at 98.76% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:44:37,898 : INFO : PROGRESS: at 98.96% examples, 5864 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:45:08,297 : INFO : PROGRESS: at 99.16% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:45:38,816 : INFO : PROGRESS: at 99.39% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:46:08,835 : INFO : PROGRESS: at 99.64% examples, 5862 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:46:38,913 : INFO : PROGRESS: at 99.87% examples, 5863 words/s, in_qsize 0, out_qsize 0\n",
      "2016-09-01 13:46:55,188 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2016-09-01 13:46:55,193 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2016-09-01 13:46:55,195 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2016-09-01 13:46:55,197 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-09-01 13:46:55,198 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-09-01 13:46:55,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-09-01 13:46:55,239 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-09-01 13:46:55,240 : INFO : training on 236667245 raw words (80138603 effective words) took 13667.9s, 5863 effective words/s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1016dbf104d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'DOC2VEC_MAX_EPOCHS = 1\\ndoc2vec_model.min_alpha = 0.025\\nfor epoch in range(DOC2VEC_MAX_EPOCHS):\\n    doc2vec_model.train(sentences=LabeledLineSentence(training_file), report_delay=REPORT_DELAY)\\n    doc2vec_model.alpha -= 0.001  # decrease the learning rate\\n    doc2vec_model.min_alpha = model.alpha  # fix the learning rate, no decay'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DOC2VEC_MAX_EPOCHS = 1\n",
    "doc2vec_model.min_alpha = 0.025\n",
    "for epoch in range(DOC2VEC_MAX_EPOCHS):\n",
    "    doc2vec_model.train(sentences=LabeledLineSentence(training_file), report_delay=REPORT_DELAY)\n",
    "    doc2vec_model.alpha -= 0.001  # decrease the learning rate\n",
    "    doc2vec_model.min_alpha = doc2vec_model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_model.min_alpha = doc2vec_model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Doc2vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-23 03:34:43,130 : INFO : loading Doc2Vec object from /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10\n",
      "2016-08-23 03:39:37,655 : INFO : loading docvecs recursively from /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.docvecs.* with mmap=r\n",
      "2016-08-23 03:39:37,657 : INFO : loading doctag_syn0 from /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.docvecs.doctag_syn0.npy with mmap=r\n",
      "2016-08-23 03:39:37,659 : INFO : loading syn1neg from /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn1neg.npy with mmap=r\n",
      "2016-08-23 03:39:37,715 : INFO : loading syn0 from /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn0.npy with mmap=r\n",
      "2016-08-23 03:39:55,534 : INFO : setting ignored attribute syn0norm to None\n",
      "2016-08-23 03:39:55,535 : INFO : setting ignored attribute cum_table to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 4min 24s, total: 5min 27s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_hs_{}_iter_{}'.format(DOC2VEC_SIZE, DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE)\n",
    "\n",
    "doc2vec_model = Doc2Vec.load('/home/local/shalaby/models/{}'.format(file_name), mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x7f9fec2e3b90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.DocvecsArray at 0x7f9f33a08310>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model.docvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiLabelBinarizer().fit_transform([[\"B\",\"C\"],[\"D\"],[\"E\"],[\"A\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_vectors = []\n",
    "training_labels = []\n",
    "for doc_id in training_docs_list:\n",
    "    training_vectors.append(doc2vec_model.docvecs[doc_id])\n",
    "    training_labels.append([classf for classf in doc_classifications_map[doc_id] if classf in sections])\n",
    "training_vectors = np.array(training_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_labels = MultiLabelBinarizer().fit_transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286325, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286325, 400)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_model = OneVsRestClassifier(LinearSVC(penalty='l2', tol=SVM_CONVERGENCE, \n",
    "                                          C=SVM_REG, verbose=1, random_state=SVM_SEED, max_iter=SVM_ITERATIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]CPU times: user 6h 10min 21s, sys: 1h 10min 58s, total: 7h 21min 19s\n",
      "Wall time: 7h 21min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_model.fit(training_vectors, binary_labels)\n",
    "pickle.dump(svm_model, open(model_save_location + file_name + \"_mmap\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Step for Validation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ValidationDocumentGenerator(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename):\n",
    "            (doc_id, text) = eval(line)\n",
    "            if doc_id in validation_docs_list:\n",
    "                yield doc_id, stemtokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_documents_reps = {}\n",
    "i = 0\n",
    "for (doc_id, doc_contents_array) in ValidationDocumentGenerator(training_file):\n",
    "    i += 1\n",
    "    if i % 1000 == 0: print i\n",
    "    validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lksjdflsjkdf\n"
     ]
    }
   ],
   "source": [
    "print \"lksjdflsjkdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.93 s, sys: 1min 17s, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_vectors = []\n",
    "validation_labels = []\n",
    "for validation_doc_id in validation_docs_list:\n",
    "    validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "    validation_labels.append([classf for classf in doc_classifications_map[validation_doc_id] if classf in sections])\n",
    "validation_vectors = np.array(validation_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321473, 400)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(validation_vectors, open('/home/local/shalaby/validation_data/' + file_name + \"_validation_vectors\",'w'))\n",
    "pickle.dump(validation_labels, open('/home/local/shalaby/validation_data/' + file_name + \"_validation_labels\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_binary_labels = MultiLabelBinarizer().fit_transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validation_prediction = svm_model.predict(validation_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "svm_model2 = OneVsRestClassifier(LinearSVC(penalty='l2', tol=SVM_CONVERGENCE, \n",
    "                                          C=SVM_REG, verbose=1, random_state=SVM_SEED, max_iter=10000))\n",
    "svm_model2.fit(training_vectors, binary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d400,n10,w8,mc5,s1e-05,t7)\n"
     ]
    }
   ],
   "source": [
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model using the vocab from the previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-16 15:49:28,921 : INFO : using concatenative 6800-dimensional layer1\n",
      "using concatenative 6800-dimensional layer1\n",
      "2016-08-16 15:49:28,925 : INFO : resetting layer weights\n",
      "resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.reset_from(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now for the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-21 05:36:43,143 : INFO : collecting all words and their counts\n",
      "2016-08-21 05:36:43,576 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.build_vocab(sentences=LabeledLineSentence(training_file), progress_per=REPORT_VOCAB_PROGRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-21 05:32:48,403 : INFO : training model with 7 workers on 5794 vocabulary and 6800 features, using sg=0 hs=0 sample=1e-05 negative=10\n",
      "2016-08-21 05:32:48,405 : INFO : expecting 65 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-08-21 05:32:51,066 : INFO : PROGRESS: at 1.54% examples, 658 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-21 05:33:05,759 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2016-08-21 05:33:05,762 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2016-08-21 05:33:05,763 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2016-08-21 05:33:05,865 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-08-21 05:33:05,894 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-08-21 05:33:06,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-08-21 05:33:06,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-08-21 05:33:06,553 : INFO : training on 326384 raw words (70839 effective words) took 18.1s, 3905 effective words/s\n",
      "2016-08-21 05:33:06,554 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.1 s, sys: 2.58 s, total: 34.7 s\n",
      "Wall time: 18.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70839"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.train(sentences=LabeledLineSentence(training_file), report_delay=REPORT_DELAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-20 15:22:45,778 : INFO : saving Doc2Vec object under /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10, separately None\n",
      "saving Doc2Vec object under /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10, separately None\n",
      "2016-08-20 15:22:45,783 : INFO : storing numpy array 'doctag_syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.docvecs.doctag_syn0.npy\n",
      "storing numpy array 'doctag_syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.docvecs.doctag_syn0.npy\n",
      "2016-08-20 15:22:50,011 : INFO : storing numpy array 'syn1neg' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn1neg.npy\n",
      "storing numpy array 'syn1neg' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn1neg.npy\n",
      "2016-08-20 15:40:39,540 : INFO : not storing attribute syn0norm\n",
      "not storing attribute syn0norm\n",
      "2016-08-20 15:40:39,545 : INFO : storing numpy array 'syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn0.npy\n",
      "storing numpy array 'syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn0.npy\n",
      "2016-08-20 15:42:06,912 : INFO : not storing attribute cum_table\n",
      "not storing attribute cum_table\n"
     ]
    }
   ],
   "source": [
    "# file_name = 'doc2vec_size_{}_w_{}_type_{}_hs_{}_iter_{}'.format(DOC2VEC_SIZE, DOC2VEC_WINDOW, \n",
    "#                                                                 'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "#                                                                 DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE)\n",
    "file_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_hs_{}_neg_{}_vocabsize_{}_iter_{}'.format(DOC2VEC_SIZE, DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE), DOC2VEC_EPOCHS)\n",
    "model.save('/home/local/shalaby/models/{}'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-16 14:34:05,764 : INFO : precomputing L2-norms of word weight vectors\n",
      "precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'syn0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-aa93d828dd27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'08887671'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \"\"\"\n\u001b[1;32m-> 1208\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36minit_sims\u001b[1;34m(self, replace)\u001b[0m\n\u001b[0;32m   1536\u001b[0m                     \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1537\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1538\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mestimate_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'syn0'"
     ]
    }
   ],
   "source": [
    "model.most_similar('08887671')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'syn0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-717e96f4d1c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'08887671'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m   1474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'syn0'"
     ]
    }
   ],
   "source": [
    "model['08887671']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6147817"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "model.raw_vocab = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.raw_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__hash__',\n",
       " '__ignoreds',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__numpys',\n",
       " '__recursive_saveloads',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__scipys',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_do_train_job',\n",
       " '_load_specials',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " 'accuracy',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'cbow_mean',\n",
       " 'clear_sims',\n",
       " 'comment',\n",
       " 'corpus_count',\n",
       " 'create_binary_tree',\n",
       " 'dbow',\n",
       " 'dbow_words',\n",
       " 'dm',\n",
       " 'dm_concat',\n",
       " 'dm_tag_count',\n",
       " 'docvecs',\n",
       " 'doesnt_match',\n",
       " 'estimate_memory',\n",
       " 'finalize_vocab',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'index2word',\n",
       " 'infer_vector',\n",
       " 'init_sims',\n",
       " 'intersect_word2vec_format',\n",
       " 'iter',\n",
       " 'layer1_size',\n",
       " 'load',\n",
       " 'load_word2vec_format',\n",
       " 'log_accuracy',\n",
       " 'make_cum_table',\n",
       " 'max_vocab_size',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'n_similarity',\n",
       " 'negative',\n",
       " 'null_word',\n",
       " 'random',\n",
       " 'raw_vocab',\n",
       " 'reset_from',\n",
       " 'reset_weights',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'scale_vocab',\n",
       " 'scan_vocab',\n",
       " 'score',\n",
       " 'seed',\n",
       " 'seeded_vector',\n",
       " 'sg',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'sort_vocab',\n",
       " 'sorted_vocab',\n",
       " 'syn0_lockf',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'vector_size',\n",
       " 'vocab',\n",
       " 'window',\n",
       " 'wmdistance',\n",
       " 'workers']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6147817"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Doc2Vec.wmdistance of <gensim.models.doc2vec.Doc2Vec object at 0x7fd85f134210>>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wmdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
