{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import cPickle as pickle\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import urllib2\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import nltk\n",
    "\n",
    "from thesis.utils.text import get_sentences, sentence_wordtokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATIO = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# root_location = \"/mnt/data2/shalaby/\"\n",
    "root_location = \"/home/local/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "# training_file = root_location + 'docs_output_training_validation_documents_' + str(SAMPLE_RATIO)\n",
    "training_file = root_location + 'docs_output.json'\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "# training_docs_list_file = exports_location + \"training_documents_\" + str(SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "# validation_docs_list_file = exports_location + \"validation_documents_\" + str(SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "training_docs_list_file = exports_location + \"extended_pv_training_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "validation_docs_list_file = exports_location + \"extended_pv_validation_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\"\n",
    "test_docs_list_file = exports_location + \"extended_pv_test_docs_list_\" + str(SAMPLE_RATIO) + \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.9 s, sys: 1.3 s, total: 26.2 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254767"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Extraction Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ES_URL = 'http://localhost:9200/patents/patent/{}'\n",
    "ES_URL = 'http://yell.dbs.ifi.lmu.de:9200/patents/patent/{}'\n",
    "HEADING_TAG = 'heading'\n",
    "PARAGRAPH_TAG = 'p'\n",
    "UL_TAG = 'ul'\n",
    "LI_TAG = 'li'\n",
    "OL_TAG = 'ol'\n",
    "DESC_OF_DRAWINGS_TAG = 'description-of-drawings'\n",
    "MIN_PARAGRAPH_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_with_previous(curr_node_tag, previous_node_tag, previous_node_text):\n",
    "    if curr_node_tag == PARAGRAPH_TAG and previous_node_tag == HEADING_TAG:\n",
    "        return True\n",
    "    if previous_node_text and len(previous_node_text) < MIN_PARAGRAPH_LENGTH:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def get_paragraphs(root):\n",
    "    paragraphs = []\n",
    "    previous_node_text = None\n",
    "    previous_tag = None\n",
    "    for child in root:\n",
    "        node_text = None\n",
    "        if child.tag != DESC_OF_DRAWINGS_TAG:\n",
    "            node_text = get_node_text(child)\n",
    "            if node_text.strip():\n",
    "                if merge_with_previous(child.tag, previous_tag, previous_node_text) and len(paragraphs) > 0:\n",
    "                    paragraphs[-1] += ' ' + node_text\n",
    "                else:\n",
    "                    paragraphs.append(node_text)\n",
    "        else:\n",
    "            node_text = extract_desc_of_drawings_paragraph(child)\n",
    "            paragraphs.append(node_text)\n",
    "            \n",
    "        previous_tag = child.tag\n",
    "        previous_node_text = node_text\n",
    "    return paragraphs\n",
    "    \n",
    "def extract_desc_of_drawings_paragraph(node):\n",
    "    previous_tag = None\n",
    "    sentences = []\n",
    "    for child in node:\n",
    "        node_text = get_node_text(child)\n",
    "        if child.tag == PARAGRAPH_TAG and previous_tag == HEADING_TAG:\n",
    "            sentences[-1] += ' ' + node_text\n",
    "        else:\n",
    "            # a paragraph in drawings descriptions is treated as a sentence\n",
    "            if child.tag == PARAGRAPH_TAG:\n",
    "                node_text = apply_sentence_end(node_text)\n",
    "            sentences.append(node_text)\n",
    "        previous_tag = child.tag\n",
    "    \n",
    "    return ' '.join(sentences)\n",
    "\n",
    "def apply_sentence_end(text):\n",
    "    if text and text.strip():\n",
    "        text = text.strip().strip(';.')\n",
    "        text += '. '\n",
    "    return text\n",
    "\n",
    "def itertext_custom(self):\n",
    "    tag = self.tag\n",
    "    if not isinstance(tag, basestring) and tag is not None:\n",
    "        return\n",
    "    if self.text:\n",
    "        if tag == LI_TAG:\n",
    "            yield apply_sentence_end(self.text)\n",
    "        else:\n",
    "            yield self.text.replace('\\n',' ')\n",
    "    for e in self:\n",
    "        for s in e.itertext_custom():\n",
    "            yield s\n",
    "        if e.tail:\n",
    "            yield e.tail\n",
    "\n",
    "ET.Element.itertext_custom = itertext_custom\n",
    "# def get_node_text(node):\n",
    "#     node_text = ''\n",
    "#     for child in node:\n",
    "#         # for ul tags, get li tags as sentences\n",
    "#         if child.tag == UL_TAG:\n",
    "#             li_sentences = [apply_sentence_end(get_node_text_iterative(c)) for c in child]\n",
    "#             child_text = ' '.join(li_sentences)\n",
    "#         else:\n",
    "#             child_text = get_node_text_iterative(child)\n",
    "#         node_text += child_text\n",
    "#     return node_text\n",
    "        \n",
    "get_node_text = lambda node: ''.join(node.itertext_custom()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conc_paragraphs(parag1, parag2):\n",
    "    return parag1.strip('.') + '.' + ' ' + parag2\n",
    "\n",
    "def concatenate_sentences_to_paragraphs(paragraphs):\n",
    "    \"\"\"\n",
    "    for 1 sentence paragraphs, concatenate them to the next or previous paragraph depending on context\n",
    "    \"\"\"\n",
    "    for i in range(len(paragraphs)):\n",
    "        if i >= len((paragraphs)): break\n",
    "        parag = paragraphs[i]\n",
    "        sentences = get_sentences(parag)\n",
    "        \n",
    "        if len(sentences) == 1:\n",
    "            prev_paragraph = paragraphs[i-1] if i-1 >= 0 else None\n",
    "            next_paragraph = paragraphs[i+1] if i+1 < len(paragraphs) else None\n",
    "\n",
    "            if (next_paragraph and len(get_sentences(next_paragraph)) == 1):\n",
    "                # If a series of 1 sentence length paragraphs exist, conc all of them in one paragraph\n",
    "                while True:\n",
    "                    if next_paragraph and len(get_sentences(next_paragraph)) == 1:\n",
    "                        parag = conc_paragraphs(parag, next_paragraph)\n",
    "                        paragraphs[i] = parag\n",
    "                        del paragraphs[i+1]\n",
    "\n",
    "                        # reinitialize for loop\n",
    "                        next_paragraph = paragraphs[i+1] if i+1 < len(paragraphs) else None\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            # otherwise, just concatenate the 1 sentence paragraph to the previous paragraph\n",
    "            elif prev_paragraph:\n",
    "#                 print '============== Found prev eligible paragraph'\n",
    "                prev_paragraph = conc_paragraphs(prev_paragraph, parag)\n",
    "                paragraphs[i-1] = prev_paragraph\n",
    "                del paragraphs[i]\n",
    "\n",
    "            # if this is the first paragraph, then just concatenate it with the next one\n",
    "            elif next_paragraph:\n",
    "                parag = conc_paragraphs(parag, next_paragraph)\n",
    "                paragraphs[i] = parag\n",
    "                del paragraphs[i+1]\n",
    "\n",
    "def get_adjusted_paragraphs(root, conc_sentences=True):\n",
    "    paragraphs = get_paragraphs(root)\n",
    "    if conc_sentences:\n",
    "        concatenate_sentences_to_paragraphs(paragraphs)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_patent(doc_id):\n",
    "    url_to_fetch = ES_URL.format(doc_id)\n",
    "\n",
    "    response = urllib2.urlopen(url_to_fetch)\n",
    "    patent_content = response.read()\n",
    "\n",
    "    patent_object = json.loads(patent_content)['_source']\n",
    "    return patent_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Actual Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ABSTRACT_ID = \"{}_abstract\"\n",
    "DESC_ID = \"{}_description\"\n",
    "CLAIMS_ID = \"{}_claims\"\n",
    "\n",
    "ABSTRACT_PART_ID = \"{}_abstract_part-{}\"\n",
    "DESC_PART_ID = \"{}_description_part-{}\"\n",
    "CLAIMS_PART_ID = \"{}_claims_part-{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10000\n",
    "\n",
    "preprocessed_location = \"/home/local/shalaby/\" + \"preprocessed_data/extended_pv_abs_desc_claims_large_sample_chunks/\"\n",
    "TRAINING_PREPROCESSED_FILES_PREFIX = preprocessed_location + \"extended_pv_training_docs_data_preprocessed-\"\n",
    "VALIDATION_PREPROCESSED_FILES_PREFIX = preprocessed_location + \"extended_pv_validation_docs_data_preprocessed-\"\n",
    "TEST_PREPROCESSED_FILES_PREFIX = preprocessed_location + \"extended_pv_test_docs_data_preprocessed-\"\n",
    "\n",
    "if not os.path.exists(preprocessed_location):\n",
    "    os.makedirs(preprocessed_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_ABSTRACT_PARTS = 3\n",
    "NUM_DESC_PARTS = 23\n",
    "NUM_CLAIMS_PARTS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def multithreaded_extended_batch_creation(start_index):\n",
    "\n",
    "    if os.path.exists(FILE_PREFIX + str(start_index)):\n",
    "        info(\"Batch {} already exists, skipping..\".format(start_index))\n",
    "        return\n",
    "    \n",
    "    info(\"Batch creation working on {}\\n\".format(start_index))\n",
    "    token_lines = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    len_abs_sentences = 0\n",
    "    len_desc_sentences = 0\n",
    "    len_desc_paragraphs = 0\n",
    "    len_claims_sentences = 0\n",
    "    \n",
    "    len_abs_tokens = []\n",
    "    len_desc_tokens = []\n",
    "    len_claims_tokens = []\n",
    "\n",
    "    for doc_index, doc_id in enumerate(DOCS_LIST[start_index:]):\n",
    "        patent_doc = get_patent(doc_id)\n",
    "        \n",
    "        # Abstract\n",
    "        abstract = patent_doc['abstract'][0]\n",
    "        root = ET.fromstring(abstract.encode('utf-8'))\n",
    "        abs_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Description\n",
    "        desc = patent_doc['description'][0]\n",
    "        root = ET.fromstring(desc.encode('utf-8'))\n",
    "        desc_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Claims\n",
    "        claims = patent_doc['claims'][0]\n",
    "        root = ET.fromstring(claims.encode('utf-8'))\n",
    "        claims_paragraphs = get_adjusted_paragraphs(root, conc_sentences=False)\n",
    "#         claims_paragraphs = []\n",
    "#         for claim in patent_doc['claims']:\n",
    "#             claims_paragraphs.append(claim.strip())\n",
    "\n",
    "#         abstract_sentences = sum([get_sentences(abs_parag) for abs_parag in abs_paragraphs], [])\n",
    "#         desc_sentences = sum([get_sentences(desc_parag) for desc_parag in desc_paragraphs], [])\n",
    "#         claims_sentences = sum([get_sentences(claim_parag) for claim_parag in claims_paragraphs], [])\n",
    "        \n",
    "\n",
    "        abstract_tokens = sum([sentence_wordtokenizer(parag) for parag in abs_paragraphs], [])\n",
    "        desc_tokens = sum([sentence_wordtokenizer(parag) for parag in desc_paragraphs], [])\n",
    "        claims_tokens = sum([sentence_wordtokenizer(parag) for parag in claims_paragraphs], [])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # lists of list of tokens\n",
    "        doc_tokens_list = [doc_id]  + abstract_tokens + desc_tokens + claims_tokens\n",
    "        abstract_tokens_list = [ABSTRACT_ID.format(doc_id)] + abstract_tokens\n",
    "        description_tokens_list = [DESC_ID.format(doc_id)] + desc_tokens\n",
    "        claims_tokens_list = [CLAIMS_ID.format(doc_id)] + claims_tokens\n",
    "        \n",
    "        # now add the tokens lists that will be written to the file\n",
    "        token_lines.append(doc_tokens_list)\n",
    "        token_lines.append(abstract_tokens_list)\n",
    "        token_lines.append(description_tokens_list)\n",
    "        token_lines.append(claims_tokens_list)\n",
    "        \n",
    "        for i in range(NUM_ABSTRACT_PARTS):\n",
    "            start, end = get_doc_range(i, len(abstract_tokens), NUM_ABSTRACT_PARTS)\n",
    "            token_lines.append([ABSTRACT_PART_ID.format(doc_id, i+1)] + abstract_tokens[start: end])\n",
    "        \n",
    "        for i in range(NUM_DESC_PARTS):\n",
    "            start, end = get_doc_range(i, len(desc_tokens), NUM_DESC_PARTS)\n",
    "            token_lines.append([DESC_PART_ID.format(doc_id, i+1)] + desc_tokens[start: end])    \n",
    "        \n",
    "        for i in range(NUM_CLAIMS_PARTS):\n",
    "            start, end = get_doc_range(i, len(claims_tokens), NUM_CLAIMS_PARTS)\n",
    "            token_lines.append([CLAIMS_PART_ID.format(doc_id, i+1)] + claims_tokens[start: end])\n",
    "            \n",
    "        if doc_index % 1000 == 0: info(\"Doc: {:6} -> Total Lines to write: {:8}\".format(start_index + doc_index, len(token_lines)))\n",
    "        if doc_index >= BATCH_SIZE - 1:\n",
    "            break\n",
    "    duration = time.time() - start_time\n",
    "    info(\"Finished batch {} of size {:d} in {:.0f}m {:.0f}s\".format(start_index, BATCH_SIZE, * divmod(duration, 60)))\n",
    "    info(\"For index {}, the actual number of lines written is: {}\".format(start_index, len(token_lines)))\n",
    "    \n",
    "    write_batch(FILE_PREFIX, token_lines, start_index)\n",
    "    del token_lines\n",
    "    \n",
    "def get_doc_range(i, number_of_tokens, number_of_parts):\n",
    "    start, end = 0,0\n",
    "    if number_of_tokens < number_of_parts:\n",
    "        if i==0:\n",
    "            return 0, None\n",
    "        else:\n",
    "            return number_of_tokens,None\n",
    "    if i == 0:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = (number_of_tokens / number_of_parts) * i\n",
    "    if i+1 == number_of_parts:\n",
    "        end = None\n",
    "    else:\n",
    "        end = (number_of_tokens / number_of_parts) * (i+1)\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_batch(file_prefix, batch_lines, batch_start):\n",
    "    if len(batch_lines):\n",
    "        print \"writing batch %d\" % batch_start\n",
    "        with open(file_prefix + str(batch_start), 'w') as batch_file:\n",
    "            for line in batch_lines:\n",
    "                batch_file.write((u\" \".join(line) + \"\\n\").encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = training_docs_list\n",
    "FILE_PREFIX = TRAINING_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 10000,\n",
       " 20000,\n",
       " 30000,\n",
       " 40000,\n",
       " 50000,\n",
       " 60000,\n",
       " 70000,\n",
       " 80000,\n",
       " 90000,\n",
       " 100000,\n",
       " 110000,\n",
       " 120000,\n",
       " 130000,\n",
       " 140000,\n",
       " 150000,\n",
       " 160000,\n",
       " 170000,\n",
       " 180000,\n",
       " 190000,\n",
       " 200000,\n",
       " 210000,\n",
       " 220000,\n",
       " 230000,\n",
       " 240000,\n",
       " 250000]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 00:57:06,749 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-22 00:57:06,752 : INFO : Batch creation working on 40000\n",
      "\n",
      "2017-03-22 00:57:06,750 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-22 00:57:06,753 : INFO : Batch creation working on 50000\n",
      "\n",
      "2017-03-22 00:57:06,749 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-22 00:57:06,754 : INFO : Batch creation working on 80000\n",
      "\n",
      "2017-03-22 00:57:06,753 : INFO : Batch creation working on 60000\n",
      "\n",
      "2017-03-22 00:57:06,749 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-22 00:57:06,754 : INFO : Batch creation working on 70000\n",
      "\n",
      "2017-03-22 00:57:13,067 : INFO : Doc:      0 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:13,087 : INFO : Doc:  30000 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:13,101 : INFO : Doc:  40000 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:13,114 : INFO : Doc:  60000 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:13,217 : INFO : Doc:  10000 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:13,296 : INFO : Doc:  70000 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:13,534 : INFO : Doc:  50000 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:13,872 : INFO : Doc:  80000 -> Total Lines to write:       34\n",
      "2017-03-22 00:57:14,390 : INFO : Doc:  20000 -> Total Lines to write:       34\n",
      "2017-03-22 01:00:59,080 : INFO : Doc:   1000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:04,564 : INFO : Doc:  21000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:09,385 : INFO : Doc:  11000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:13,038 : INFO : Doc:  31000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:13,961 : INFO : Doc:  81000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:17,271 : INFO : Doc:  51000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:19,121 : INFO : Doc:  61000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:22,057 : INFO : Doc:  41000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:01:41,792 : INFO : Doc:  71000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:04:36,522 : INFO : Doc:   2000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:04:52,402 : INFO : Doc:  42000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:04:58,379 : INFO : Doc:  22000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:05:01,563 : INFO : Doc:  52000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:05:03,180 : INFO : Doc:  32000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:05:08,320 : INFO : Doc:  82000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:05:08,684 : INFO : Doc:  12000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:05:14,236 : INFO : Doc:  62000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:06:14,390 : INFO : Doc:  72000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:08:04,884 : INFO : Doc:   3000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:08:47,857 : INFO : Doc:  43000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:09:03,332 : INFO : Doc:  33000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:09:07,388 : INFO : Doc:  63000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:09:08,704 : INFO : Doc:  23000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:09:12,782 : INFO : Doc:  83000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:09:21,769 : INFO : Doc:  53000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:09:37,369 : INFO : Doc:  13000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:10:17,816 : INFO : Doc:  73000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:11:37,791 : INFO : Doc:   4000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:12:23,728 : INFO : Doc:  44000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:12:54,302 : INFO : Doc:  24000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:13:08,457 : INFO : Doc:  34000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:13:15,853 : INFO : Doc:  14000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:13:19,058 : INFO : Doc:  64000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:13:39,754 : INFO : Doc:  54000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:13:43,603 : INFO : Doc:  84000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:14:23,498 : INFO : Doc:  74000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:15:23,296 : INFO : Doc:   5000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:15:59,357 : INFO : Doc:  45000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:17:13,677 : INFO : Doc:  15000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:17:17,453 : INFO : Doc:  25000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:17:22,883 : INFO : Doc:  35000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:17:23,152 : INFO : Doc:  55000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:17:35,564 : INFO : Doc:  65000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:17:38,703 : INFO : Doc:  85000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:18:59,677 : INFO : Doc:  75000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:19:31,764 : INFO : Doc:   6000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:19:50,699 : INFO : Doc:  46000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:21:07,002 : INFO : Doc:  36000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:21:07,692 : INFO : Doc:  26000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:21:19,178 : INFO : Doc:  56000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:21:35,977 : INFO : Doc:  16000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:21:39,752 : INFO : Doc:  86000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:21:50,315 : INFO : Doc:  66000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:23:20,450 : INFO : Doc:  76000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:23:34,842 : INFO : Doc:   7000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:23:55,637 : INFO : Doc:  47000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:25:02,366 : INFO : Doc:  37000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:25:07,618 : INFO : Doc:  57000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:25:09,644 : INFO : Doc:  27000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:25:35,687 : INFO : Doc:  17000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:25:52,267 : INFO : Doc:  87000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:25:55,129 : INFO : Doc:  67000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:27:16,544 : INFO : Doc:   8000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:27:41,826 : INFO : Doc:  77000 -> Total Lines to write:   238034\n",
      "2017-03-22 01:28:28,522 : INFO : Doc:  48000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:29:11,874 : INFO : Doc:  28000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:29:15,799 : INFO : Doc:  38000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:29:16,118 : INFO : Doc:  58000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:29:40,514 : INFO : Doc:  18000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:29:52,003 : INFO : Doc:  68000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:30:01,915 : INFO : Doc:  88000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:30:58,114 : INFO : Doc:   9000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:31:52,955 : INFO : Doc:  78000 -> Total Lines to write:   272034\n",
      "2017-03-22 01:33:08,793 : INFO : Doc:  59000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:33:17,620 : INFO : Doc:  29000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:33:20,972 : INFO : Doc:  39000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:33:38,503 : INFO : Doc:  49000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:33:51,729 : INFO : Doc:  19000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:34:34,418 : INFO : Finished batch 0 of size 10000 in 37m 28s\n",
      "2017-03-22 01:34:34,430 : INFO : For index 0, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:34:39,276 : INFO : Doc:  69000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:34:55,892 : INFO : Doc:  89000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:35:05,018 : INFO : Batch creation working on 90000\n",
      "\n",
      "2017-03-22 01:35:05,238 : INFO : Doc:  90000 -> Total Lines to write:       34\n",
      "2017-03-22 01:36:18,382 : INFO : Doc:  79000 -> Total Lines to write:   306034\n",
      "2017-03-22 01:36:58,889 : INFO : Finished batch 50000 of size 10000 in 39m 52s\n",
      "2017-03-22 01:36:58,892 : INFO : For index 50000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:37:23,118 : INFO : Finished batch 30000 of size 10000 in 40m 16s\n",
      "2017-03-22 01:37:23,121 : INFO : For index 30000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:37:25,757 : INFO : Finished batch 20000 of size 10000 in 40m 19s\n",
      "2017-03-22 01:37:25,760 : INFO : For index 20000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:37:31,328 : INFO : Batch creation working on 100000\n",
      "\n",
      "2017-03-22 01:37:31,795 : INFO : Doc: 100000 -> Total Lines to write:       34\n",
      "2017-03-22 01:37:32,520 : INFO : Finished batch 40000 of size 10000 in 40m 26s\n",
      "2017-03-22 01:37:32,539 : INFO : For index 40000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:38:07,037 : INFO : Finished batch 10000 of size 10000 in 41m 0s\n",
      "2017-03-22 01:38:07,040 : INFO : For index 10000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:38:20,528 : INFO : Batch creation working on 110000\n",
      "\n",
      "2017-03-22 01:38:20,528 : INFO : Batch creation working on 120000\n",
      "\n",
      "2017-03-22 01:38:20,770 : INFO : Doc: 110000 -> Total Lines to write:       34\n",
      "2017-03-22 01:38:20,772 : INFO : Doc: 120000 -> Total Lines to write:       34\n",
      "2017-03-22 01:38:20,531 : INFO : Batch creation working on 130000\n",
      "\n",
      "2017-03-22 01:38:21,470 : INFO : Doc: 130000 -> Total Lines to write:       34\n",
      "2017-03-22 01:38:40,224 : INFO : Finished batch 80000 of size 10000 in 41m 33s\n",
      "2017-03-22 01:38:40,227 : INFO : For index 80000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:38:59,486 : INFO : Finished batch 60000 of size 10000 in 41m 53s\n",
      "2017-03-22 01:38:59,488 : INFO : For index 60000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:39:00,053 : INFO : Doc:  91000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:40:22,803 : INFO : Finished batch 70000 of size 10000 in 43m 16s\n",
      "2017-03-22 01:40:22,849 : INFO : For index 70000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 01:40:23,286 : INFO : Batch creation working on 140000\n",
      "\n",
      "2017-03-22 01:40:23,588 : INFO : Doc: 140000 -> Total Lines to write:       34\n",
      "2017-03-22 01:40:46,576 : INFO : Batch creation working on 150000\n",
      "\n",
      "2017-03-22 01:40:46,713 : INFO : Doc: 150000 -> Total Lines to write:       34\n",
      "2017-03-22 01:40:46,576 : INFO : Batch creation working on 160000\n",
      "\n",
      "2017-03-22 01:40:47,052 : INFO : Doc: 160000 -> Total Lines to write:       34\n",
      "2017-03-22 01:40:58,678 : INFO : Batch creation working on 170000\n",
      "\n",
      "2017-03-22 01:40:59,009 : INFO : Doc: 170000 -> Total Lines to write:       34\n",
      "2017-03-22 01:41:24,933 : INFO : Doc: 101000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:41:52,876 : INFO : Doc: 131000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:41:55,147 : INFO : Doc: 121000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:42:10,684 : INFO : Doc: 111000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:42:50,911 : INFO : Doc:  92000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:44:31,688 : INFO : Doc: 141000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:44:46,001 : INFO : Doc: 151000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:44:49,737 : INFO : Doc: 171000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:44:58,172 : INFO : Doc: 161000 -> Total Lines to write:    34034\n",
      "2017-03-22 01:45:25,151 : INFO : Doc: 102000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:45:49,808 : INFO : Doc: 132000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:45:51,546 : INFO : Doc: 112000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:46:13,623 : INFO : Doc: 122000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:46:54,911 : INFO : Doc:  93000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:48:33,934 : INFO : Doc: 142000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:48:48,534 : INFO : Doc: 162000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:48:50,594 : INFO : Doc: 152000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:49:09,229 : INFO : Doc: 172000 -> Total Lines to write:    68034\n",
      "2017-03-22 01:49:16,862 : INFO : Doc: 103000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:49:54,316 : INFO : Doc: 113000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:50:02,205 : INFO : Doc: 133000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:50:26,005 : INFO : Doc: 123000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:50:59,791 : INFO : Doc:  94000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:52:28,979 : INFO : Doc: 143000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:52:39,011 : INFO : Doc: 153000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:52:44,698 : INFO : Doc: 163000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:53:04,134 : INFO : Doc: 173000 -> Total Lines to write:   102034\n",
      "2017-03-22 01:53:37,849 : INFO : Doc: 104000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:53:54,423 : INFO : Doc: 114000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:54:00,671 : INFO : Doc: 134000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:54:40,835 : INFO : Doc:  95000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:54:43,145 : INFO : Doc: 124000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:56:02,866 : INFO : Doc: 144000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:56:46,165 : INFO : Doc: 154000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:56:59,257 : INFO : Doc: 164000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:57:20,786 : INFO : Doc: 174000 -> Total Lines to write:   136034\n",
      "2017-03-22 01:57:30,938 : INFO : Doc: 115000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:58:07,901 : INFO : Doc: 135000 -> Total Lines to write:   170034\n",
      "2017-03-22 01:58:36,698 : INFO : Doc:  96000 -> Total Lines to write:   204034\n",
      "2017-03-22 01:58:47,532 : INFO : Doc: 125000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:00:34,664 : INFO : Doc: 155000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:00:43,855 : INFO : Doc: 105000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:01:14,954 : INFO : Doc: 165000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:01:21,428 : INFO : Doc: 175000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:01:44,973 : INFO : Doc: 116000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:02:21,470 : INFO : Doc: 136000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:02:37,388 : INFO : Doc: 126000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:02:48,127 : INFO : Doc:  97000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:04:41,105 : INFO : Doc: 156000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:04:55,352 : INFO : Doc: 106000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:05:24,530 : INFO : Doc: 166000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:05:58,334 : INFO : Doc: 176000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:06:29,600 : INFO : Doc: 137000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:07:03,615 : INFO : Doc:  98000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:07:20,171 : INFO : Doc: 127000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:08:15,046 : INFO : Doc: 117000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:08:45,473 : INFO : Doc: 157000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:09:24,152 : INFO : Doc: 107000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:09:38,053 : INFO : Doc: 167000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:10:07,897 : INFO : Doc: 177000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:11:05,158 : INFO : Doc: 138000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:11:29,794 : INFO : Doc: 128000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:11:33,045 : INFO : Doc:  99000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:12:51,021 : INFO : Doc: 118000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:12:56,829 : INFO : Doc: 158000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:13:27,753 : INFO : Doc: 108000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:13:47,960 : INFO : Doc: 168000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:14:59,943 : INFO : Doc: 178000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:15:10,673 : INFO : Doc: 139000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:15:35,717 : INFO : Doc: 129000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:15:35,800 : INFO : Finished batch 90000 of size 10000 in 40m 31s\n",
      "2017-03-22 02:15:35,805 : INFO : For index 90000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:16:12,538 : INFO : Batch creation working on 180000\n",
      "\n",
      "2017-03-22 02:16:13,186 : INFO : Doc: 180000 -> Total Lines to write:       34\n",
      "2017-03-22 02:16:51,911 : INFO : Doc: 119000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:17:17,579 : INFO : Doc: 109000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:17:21,439 : INFO : Doc: 159000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:17:48,873 : INFO : Doc: 169000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:19:21,192 : INFO : Finished batch 130000 of size 10000 in 41m 0s\n",
      "2017-03-22 02:19:21,196 : INFO : For index 130000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 130000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:19:29,659 : INFO : Doc: 179000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:19:42,564 : INFO : Finished batch 120000 of size 10000 in 41m 22s\n",
      "2017-03-22 02:19:42,566 : INFO : For index 120000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:20:00,967 : INFO : Batch creation working on 190000\n",
      "\n",
      "2017-03-22 02:20:01,191 : INFO : Doc: 190000 -> Total Lines to write:       34\n",
      "2017-03-22 02:20:21,276 : INFO : Batch creation working on 200000\n",
      "\n",
      "2017-03-22 02:20:21,621 : INFO : Doc: 200000 -> Total Lines to write:       34\n",
      "2017-03-22 02:20:38,956 : INFO : Doc: 181000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:21:19,550 : INFO : Finished batch 110000 of size 10000 in 42m 59s\n",
      "2017-03-22 02:21:19,566 : INFO : For index 110000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:21:31,650 : INFO : Finished batch 150000 of size 10000 in 40m 45s\n",
      "2017-03-22 02:21:31,653 : INFO : For index 150000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:21:35,781 : INFO : Finished batch 100000 of size 10000 in 44m 4s\n",
      "2017-03-22 02:21:35,783 : INFO : For index 100000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:22:03,009 : INFO : Batch creation working on 210000\n",
      "\n",
      "2017-03-22 02:22:03,406 : INFO : Doc: 210000 -> Total Lines to write:       34\n",
      "2017-03-22 02:22:12,410 : INFO : Batch creation working on 220000\n",
      "\n",
      "2017-03-22 02:22:12,784 : INFO : Doc: 220000 -> Total Lines to write:       34\n",
      "2017-03-22 02:22:18,052 : INFO : Batch creation working on 230000\n",
      "\n",
      "2017-03-22 02:22:18,697 : INFO : Doc: 230000 -> Total Lines to write:       34\n",
      "2017-03-22 02:22:34,255 : INFO : Finished batch 160000 of size 10000 in 41m 48s\n",
      "2017-03-22 02:22:34,263 : INFO : For index 160000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:23:10,387 : INFO : Batch creation working on 240000\n",
      "\n",
      "2017-03-22 02:23:10,620 : INFO : Doc: 240000 -> Total Lines to write:       34\n",
      "2017-03-22 02:23:41,342 : INFO : Finished batch 170000 of size 10000 in 42m 43s\n",
      "2017-03-22 02:23:41,344 : INFO : For index 170000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 170000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:24:13,706 : INFO : Doc: 191000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:24:17,772 : INFO : Batch creation working on 250000\n",
      "\n",
      "2017-03-22 02:24:17,901 : INFO : Doc: 250000 -> Total Lines to write:       34\n",
      "2017-03-22 02:24:49,179 : INFO : Doc: 182000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:25:01,448 : INFO : Doc: 201000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:26:18,664 : INFO : Doc: 231000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:26:18,683 : INFO : Doc: 211000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:26:24,282 : INFO : Doc: 221000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:27:22,697 : INFO : Doc: 241000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:28:07,126 : INFO : Doc: 251000 -> Total Lines to write:    34034\n",
      "2017-03-22 02:28:52,947 : INFO : Doc: 192000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:29:12,838 : INFO : Doc: 202000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:29:19,431 : INFO : Doc: 183000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:30:08,970 : INFO : Doc: 212000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:30:40,032 : INFO : Doc: 232000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:30:50,272 : INFO : Doc: 222000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:31:32,139 : INFO : Doc: 242000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:31:58,439 : INFO : Doc: 252000 -> Total Lines to write:    68034\n",
      "2017-03-22 02:32:58,311 : INFO : Doc: 193000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:33:19,627 : INFO : Doc: 203000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:33:26,080 : INFO : Doc: 184000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:34:25,688 : INFO : Doc: 213000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:34:56,021 : INFO : Doc: 233000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:35:12,598 : INFO : Doc: 223000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:35:23,296 : INFO : Doc: 243000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:36:15,516 : INFO : Doc: 253000 -> Total Lines to write:   102034\n",
      "2017-03-22 02:37:05,474 : INFO : Doc: 194000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:37:42,521 : INFO : Doc: 204000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:37:43,043 : INFO : Doc: 185000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:37:43,080 : INFO : Doc: 254000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:38:39,236 : INFO : Doc: 214000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:38:59,769 : INFO : Doc: 224000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:39:04,805 : INFO : Doc: 234000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:39:42,174 : INFO : Doc: 244000 -> Total Lines to write:   136034\n",
      "2017-03-22 02:40:42,507 : INFO : Finished batch 250000 of size 10000 in 16m 25s\n",
      "2017-03-22 02:40:42,509 : INFO : For index 250000, the actual number of lines written is: 162078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:41:35,353 : INFO : Doc: 205000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:41:41,281 : INFO : Doc: 195000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:41:49,932 : INFO : Doc: 186000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:42:42,483 : INFO : Doc: 215000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:42:44,377 : INFO : Doc: 145000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:42:51,146 : INFO : Doc: 225000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:42:57,285 : INFO : Doc: 235000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:43:56,025 : INFO : Doc: 245000 -> Total Lines to write:   170034\n",
      "2017-03-22 02:45:18,821 : INFO : Doc: 196000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:45:21,321 : INFO : Doc: 206000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:45:24,851 : INFO : Doc: 187000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:46:18,287 : INFO : Doc: 216000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:46:32,974 : INFO : Doc: 226000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:46:39,089 : INFO : Doc: 146000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:46:44,587 : INFO : Doc: 236000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:47:48,294 : INFO : Doc: 246000 -> Total Lines to write:   204034\n",
      "2017-03-22 02:49:11,593 : INFO : Doc: 197000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:49:21,061 : INFO : Doc: 207000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:49:42,559 : INFO : Doc: 188000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:50:18,860 : INFO : Doc: 217000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:50:24,647 : INFO : Doc: 147000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:50:27,714 : INFO : Doc: 227000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:51:04,053 : INFO : Doc: 237000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:51:50,142 : INFO : Doc: 247000 -> Total Lines to write:   238034\n",
      "2017-03-22 02:52:54,836 : INFO : Doc: 198000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:53:18,455 : INFO : Doc: 208000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:53:39,133 : INFO : Doc: 189000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:54:06,030 : INFO : Doc: 218000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:54:11,597 : INFO : Doc: 228000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:54:27,527 : INFO : Doc: 148000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:54:56,698 : INFO : Doc: 238000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:56:38,480 : INFO : Doc: 199000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:56:38,641 : INFO : Doc: 248000 -> Total Lines to write:   272034\n",
      "2017-03-22 02:57:03,658 : INFO : Doc: 209000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:57:08,633 : INFO : Finished batch 180000 of size 10000 in 40m 56s\n",
      "2017-03-22 02:57:08,636 : INFO : For index 180000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 180000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 02:57:48,805 : INFO : Doc: 229000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:58:06,970 : INFO : Doc: 219000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:58:14,372 : INFO : Doc: 149000 -> Total Lines to write:   306034\n",
      "2017-03-22 02:58:41,933 : INFO : Doc: 239000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:00:35,314 : INFO : Doc: 249000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:00:40,809 : INFO : Finished batch 190000 of size 10000 in 40m 40s\n",
      "2017-03-22 03:00:40,811 : INFO : For index 190000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 190000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:01:04,847 : INFO : Finished batch 200000 of size 10000 in 40m 43s\n",
      "2017-03-22 03:01:04,850 : INFO : For index 200000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:01:45,252 : INFO : Finished batch 210000 of size 10000 in 39m 42s\n",
      "2017-03-22 03:01:45,255 : INFO : For index 210000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 210000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:01:59,204 : INFO : Finished batch 140000 of size 10000 in 81m 36s\n",
      "2017-03-22 03:01:59,207 : INFO : For index 140000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 140000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:02:17,960 : INFO : Finished batch 220000 of size 10000 in 40m 6s\n",
      "2017-03-22 03:02:17,964 : INFO : For index 220000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 220000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:03:03,237 : INFO : Finished batch 230000 of size 10000 in 40m 45s\n",
      "2017-03-22 03:03:03,240 : INFO : For index 230000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 230000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:04:34,720 : INFO : Finished batch 240000 of size 10000 in 41m 24s\n",
      "2017-03-22 03:04:34,723 : INFO : For index 240000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 240000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(9)\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 10:44:02,083 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-16 10:44:02,175 : INFO : Doc:      0 -> Total Lines to write:       78\n",
      "2017-03-16 10:44:18,155 : INFO : Finished batch 0 of size 100 in 0m 16s\n",
      "2017-03-16 10:44:18,160 : INFO : For index 0, the actual number of lines written is: 7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    }
   ],
   "source": [
    "multithreaded_extended_batch_creation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = validation_docs_list\n",
    "FILE_PREFIX = VALIDATION_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:05:13,003 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-22 03:05:13,003 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-22 03:05:13,005 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-22 03:05:13,004 : INFO : Batch creation working on 40000\n",
      "\n",
      "2017-03-22 03:05:13,006 : INFO : Batch creation working on 50000\n",
      "\n",
      "2017-03-22 03:05:13,005 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-22 03:05:13,007 : INFO : Batch creation working on 60000\n",
      "\n",
      "2017-03-22 03:05:13,133 : INFO : Doc:  10000 -> Total Lines to write:       34\n",
      "2017-03-22 03:05:13,204 : INFO : Doc:      0 -> Total Lines to write:       34\n",
      "2017-03-22 03:05:13,216 : INFO : Doc:  50000 -> Total Lines to write:       34\n",
      "2017-03-22 03:05:13,228 : INFO : Doc:  30000 -> Total Lines to write:       34\n",
      "2017-03-22 03:05:13,274 : INFO : Doc:  60000 -> Total Lines to write:       34\n",
      "2017-03-22 03:05:13,284 : INFO : Doc:  40000 -> Total Lines to write:       34\n",
      "2017-03-22 03:05:13,357 : INFO : Doc:  20000 -> Total Lines to write:       34\n",
      "2017-03-22 03:07:54,586 : INFO : Finished batch 60000 of size 10000 in 2m 42s\n",
      "2017-03-22 03:07:54,588 : INFO : For index 60000, the actual number of lines written is: 32538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:07:58,696 : INFO : Doc:   1000 -> Total Lines to write:    34034\n",
      "2017-03-22 03:08:08,130 : INFO : Doc:  11000 -> Total Lines to write:    34034\n",
      "2017-03-22 03:08:23,847 : INFO : Doc:  41000 -> Total Lines to write:    34034\n",
      "2017-03-22 03:08:31,979 : INFO : Doc:  31000 -> Total Lines to write:    34034\n",
      "2017-03-22 03:08:34,890 : INFO : Doc:  21000 -> Total Lines to write:    34034\n",
      "2017-03-22 03:08:46,368 : INFO : Doc:  51000 -> Total Lines to write:    34034\n",
      "2017-03-22 03:10:57,926 : INFO : Doc:   2000 -> Total Lines to write:    68034\n",
      "2017-03-22 03:11:03,000 : INFO : Doc:  12000 -> Total Lines to write:    68034\n",
      "2017-03-22 03:11:39,653 : INFO : Doc:  32000 -> Total Lines to write:    68034\n",
      "2017-03-22 03:11:41,248 : INFO : Doc:  42000 -> Total Lines to write:    68034\n",
      "2017-03-22 03:11:50,615 : INFO : Doc:  22000 -> Total Lines to write:    68034\n",
      "2017-03-22 03:11:59,586 : INFO : Doc:  52000 -> Total Lines to write:    68034\n",
      "2017-03-22 03:14:03,612 : INFO : Doc:   3000 -> Total Lines to write:   102034\n",
      "2017-03-22 03:14:06,534 : INFO : Doc:  13000 -> Total Lines to write:   102034\n",
      "2017-03-22 03:14:52,032 : INFO : Doc:  33000 -> Total Lines to write:   102034\n",
      "2017-03-22 03:14:59,140 : INFO : Doc:  43000 -> Total Lines to write:   102034\n",
      "2017-03-22 03:15:11,432 : INFO : Doc:  23000 -> Total Lines to write:   102034\n",
      "2017-03-22 03:15:26,239 : INFO : Doc:  53000 -> Total Lines to write:   102034\n",
      "2017-03-22 03:17:08,679 : INFO : Doc:  14000 -> Total Lines to write:   136034\n",
      "2017-03-22 03:17:19,316 : INFO : Doc:   4000 -> Total Lines to write:   136034\n",
      "2017-03-22 03:18:07,065 : INFO : Doc:  34000 -> Total Lines to write:   136034\n",
      "2017-03-22 03:18:18,542 : INFO : Doc:  44000 -> Total Lines to write:   136034\n",
      "2017-03-22 03:18:33,180 : INFO : Doc:  24000 -> Total Lines to write:   136034\n",
      "2017-03-22 03:19:06,417 : INFO : Doc:  54000 -> Total Lines to write:   136034\n",
      "2017-03-22 03:20:21,899 : INFO : Doc:  15000 -> Total Lines to write:   170034\n",
      "2017-03-22 03:20:25,356 : INFO : Doc:   5000 -> Total Lines to write:   170034\n",
      "2017-03-22 03:21:35,804 : INFO : Doc:  35000 -> Total Lines to write:   170034\n",
      "2017-03-22 03:21:53,069 : INFO : Doc:  45000 -> Total Lines to write:   170034\n",
      "2017-03-22 03:22:04,156 : INFO : Doc:  25000 -> Total Lines to write:   170034\n",
      "2017-03-22 03:22:40,856 : INFO : Doc:  55000 -> Total Lines to write:   170034\n",
      "2017-03-22 03:23:39,271 : INFO : Doc:   6000 -> Total Lines to write:   204034\n",
      "2017-03-22 03:23:42,306 : INFO : Doc:  16000 -> Total Lines to write:   204034\n",
      "2017-03-22 03:25:18,034 : INFO : Doc:  36000 -> Total Lines to write:   204034\n",
      "2017-03-22 03:25:20,191 : INFO : Doc:  26000 -> Total Lines to write:   204034\n",
      "2017-03-22 03:25:29,426 : INFO : Doc:  46000 -> Total Lines to write:   204034\n",
      "2017-03-22 03:26:14,054 : INFO : Doc:  56000 -> Total Lines to write:   204034\n",
      "2017-03-22 03:26:37,766 : INFO : Doc:   7000 -> Total Lines to write:   238034\n",
      "2017-03-22 03:27:01,491 : INFO : Doc:  17000 -> Total Lines to write:   238034\n",
      "2017-03-22 03:28:24,653 : INFO : Doc:  27000 -> Total Lines to write:   238034\n",
      "2017-03-22 03:28:52,844 : INFO : Doc:  37000 -> Total Lines to write:   238034\n",
      "2017-03-22 03:29:09,232 : INFO : Doc:  47000 -> Total Lines to write:   238034\n",
      "2017-03-22 03:29:35,872 : INFO : Doc:   8000 -> Total Lines to write:   272034\n",
      "2017-03-22 03:29:54,241 : INFO : Doc:  57000 -> Total Lines to write:   238034\n",
      "2017-03-22 03:30:19,772 : INFO : Doc:  18000 -> Total Lines to write:   272034\n",
      "2017-03-22 03:31:38,758 : INFO : Doc:  28000 -> Total Lines to write:   272034\n",
      "2017-03-22 03:32:35,478 : INFO : Doc:  38000 -> Total Lines to write:   272034\n",
      "2017-03-22 03:32:38,320 : INFO : Doc:  48000 -> Total Lines to write:   272034\n",
      "2017-03-22 03:32:46,003 : INFO : Doc:   9000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:33:32,902 : INFO : Doc:  19000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:33:43,601 : INFO : Doc:  58000 -> Total Lines to write:   272034\n",
      "2017-03-22 03:34:52,785 : INFO : Doc:  29000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:36:08,347 : INFO : Finished batch 0 of size 10000 in 30m 55s\n",
      "2017-03-22 03:36:08,349 : INFO : For index 0, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:36:08,866 : INFO : Doc:  39000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:36:09,796 : INFO : Doc:  49000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:36:52,540 : INFO : Finished batch 10000 of size 10000 in 31m 40s\n",
      "2017-03-22 03:36:52,543 : INFO : For index 10000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:37:05,098 : INFO : Doc:  59000 -> Total Lines to write:   306034\n",
      "2017-03-22 03:38:23,020 : INFO : Finished batch 20000 of size 10000 in 33m 10s\n",
      "2017-03-22 03:38:23,023 : INFO : For index 20000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:39:55,337 : INFO : Finished batch 40000 of size 10000 in 34m 42s\n",
      "2017-03-22 03:39:55,339 : INFO : For index 40000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:40:00,576 : INFO : Finished batch 30000 of size 10000 in 34m 48s\n",
      "2017-03-22 03:40:00,579 : INFO : For index 30000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-22 03:40:49,468 : INFO : Finished batch 50000 of size 10000 in 35m 36s\n",
      "2017-03-22 03:40:49,471 : INFO : For index 50000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 50000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(8)\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = test_docs_list\n",
    "FILE_PREFIX = TEST_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(test_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 01:52:57,499 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-30 01:52:57,500 : INFO : Batch creation working on 50000\n",
      "\n",
      "2017-03-30 01:52:57,501 : INFO : Batch creation working on 40000\n",
      "\n",
      "2017-03-30 01:52:57,500 : INFO : Batch creation working on 60000\n",
      "\n",
      "2017-03-30 01:52:57,501 : INFO : Batch creation working on 70000\n",
      "\n",
      "2017-03-30 01:52:57,500 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-30 01:52:57,499 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-30 01:52:57,499 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-30 01:53:05,477 : INFO : Doc:  60000 -> Total Lines to write:       34\n",
      "2017-03-30 01:53:05,484 : INFO : Doc:  40000 -> Total Lines to write:       34\n",
      "2017-03-30 01:53:05,514 : INFO : Doc:  10000 -> Total Lines to write:       34\n",
      "2017-03-30 01:53:05,528 : INFO : Doc:      0 -> Total Lines to write:       34\n",
      "2017-03-30 01:53:05,534 : INFO : Doc:  20000 -> Total Lines to write:       34\n",
      "2017-03-30 01:53:05,561 : INFO : Doc:  50000 -> Total Lines to write:       34\n",
      "2017-03-30 01:53:05,649 : INFO : Doc:  30000 -> Total Lines to write:       34\n",
      "2017-03-30 01:53:07,042 : INFO : Doc:  70000 -> Total Lines to write:       34\n",
      "2017-03-30 01:57:01,519 : INFO : Doc:   1000 -> Total Lines to write:    34034\n",
      "2017-03-30 01:57:10,097 : INFO : Doc:  11000 -> Total Lines to write:    34034\n",
      "2017-03-30 01:57:17,927 : INFO : Doc:  41000 -> Total Lines to write:    34034\n",
      "2017-03-30 01:57:19,177 : INFO : Doc:  51000 -> Total Lines to write:    34034\n",
      "2017-03-30 01:57:32,183 : INFO : Doc:  21000 -> Total Lines to write:    34034\n",
      "2017-03-30 01:57:39,829 : INFO : Doc:  31000 -> Total Lines to write:    34034\n",
      "2017-03-30 01:57:49,491 : INFO : Doc:  71000 -> Total Lines to write:    34034\n",
      "2017-03-30 01:57:50,790 : INFO : Doc:  61000 -> Total Lines to write:    34034\n",
      "2017-03-30 02:01:09,923 : INFO : Doc:  12000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:01:10,163 : INFO : Doc:  52000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:01:24,434 : INFO : Doc:   2000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:01:25,694 : INFO : Doc:  42000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:01:31,868 : INFO : Doc:  22000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:01:51,516 : INFO : Doc:  32000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:01:57,935 : INFO : Doc:  62000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:02:18,625 : INFO : Doc:  72000 -> Total Lines to write:    68034\n",
      "2017-03-30 02:05:01,415 : INFO : Doc:  13000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:05:12,018 : INFO : Doc:   3000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:05:20,559 : INFO : Doc:  53000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:05:32,433 : INFO : Doc:  43000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:05:42,932 : INFO : Doc:  23000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:06:04,019 : INFO : Doc:  33000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:06:37,570 : INFO : Doc:  63000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:06:47,977 : INFO : Doc:  73000 -> Total Lines to write:   102034\n",
      "2017-03-30 02:09:07,805 : INFO : Doc:  14000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:09:14,513 : INFO : Doc:   4000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:09:28,167 : INFO : Doc:  54000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:09:42,365 : INFO : Doc:  44000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:09:51,948 : INFO : Doc:  24000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:10:15,404 : INFO : Doc:  34000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:10:57,595 : INFO : Doc:  64000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:11:29,598 : INFO : Doc:  74000 -> Total Lines to write:   136034\n",
      "2017-03-30 02:13:01,734 : INFO : Doc:   5000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:13:13,955 : INFO : Doc:  15000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:13:43,471 : INFO : Doc:  55000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:13:56,991 : INFO : Doc:  25000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:14:14,393 : INFO : Doc:  45000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:14:28,979 : INFO : Doc:  35000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:15:23,243 : INFO : Doc:  65000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:15:59,871 : INFO : Doc:  75000 -> Total Lines to write:   170034\n",
      "2017-03-30 02:16:57,600 : INFO : Doc:   6000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:17:18,562 : INFO : Doc:  16000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:18:01,126 : INFO : Doc:  56000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:18:12,977 : INFO : Doc:  26000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:18:21,450 : INFO : Doc:  46000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:18:37,413 : INFO : Doc:  36000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:20:02,980 : INFO : Doc:  66000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:20:06,109 : INFO : Doc:  76000 -> Total Lines to write:   204034\n",
      "2017-03-30 02:21:05,096 : INFO : Doc:  17000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:21:07,989 : INFO : Doc:   7000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:22:07,785 : INFO : Doc:  57000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:22:13,639 : INFO : Doc:  47000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:22:20,980 : INFO : Doc:  27000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:22:57,332 : INFO : Doc:  37000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:24:25,080 : INFO : Doc:  77000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:24:35,677 : INFO : Doc:  67000 -> Total Lines to write:   238034\n",
      "2017-03-30 02:24:47,574 : INFO : Doc:  18000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:25:11,714 : INFO : Doc:   8000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:26:06,384 : INFO : Doc:  48000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:26:14,937 : INFO : Doc:  58000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:26:31,207 : INFO : Doc:  28000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:27:22,479 : INFO : Doc:  38000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:28:42,806 : INFO : Doc:  19000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:28:50,270 : INFO : Doc:  68000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:29:01,664 : INFO : Doc:   9000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:29:08,195 : INFO : Doc:  78000 -> Total Lines to write:   272034\n",
      "2017-03-30 02:30:23,082 : INFO : Doc:  49000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:30:24,847 : INFO : Doc:  59000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:30:42,500 : INFO : Doc:  29000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:31:39,575 : INFO : Doc:  39000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:32:40,853 : INFO : Finished batch 10000 of size 10000 in 39m 43s\n",
      "2017-03-30 02:32:40,869 : INFO : For index 10000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 02:32:56,419 : INFO : Finished batch 0 of size 10000 in 39m 59s\n",
      "2017-03-30 02:32:56,421 : INFO : For index 0, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 02:33:15,904 : INFO : Doc:  79000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:33:27,040 : INFO : Doc:  69000 -> Total Lines to write:   306034\n",
      "2017-03-30 02:34:25,339 : INFO : Finished batch 50000 of size 10000 in 41m 28s\n",
      "2017-03-30 02:34:25,345 : INFO : For index 50000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 02:34:37,595 : INFO : Finished batch 20000 of size 10000 in 41m 40s\n",
      "2017-03-30 02:34:37,597 : INFO : For index 20000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 02:34:38,041 : INFO : Finished batch 40000 of size 10000 in 41m 41s\n",
      "2017-03-30 02:34:38,044 : INFO : For index 40000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 02:35:33,765 : INFO : Finished batch 30000 of size 10000 in 42m 36s\n",
      "2017-03-30 02:35:33,768 : INFO : For index 30000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 02:35:55,922 : INFO : Finished batch 70000 of size 10000 in 42m 58s\n",
      "2017-03-30 02:35:55,925 : INFO : For index 70000, the actual number of lines written is: 332690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 02:37:12,736 : INFO : Finished batch 60000 of size 10000 in 44m 15s\n",
      "2017-03-30 02:37:12,739 : INFO : For index 60000, the actual number of lines written is: 340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing batch 60000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(8)\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def multithreaded_extended_batch_creation(start_index):\n",
    "\n",
    "#     if os.path.exists(FILE_PREFIX + str(start_index)):\n",
    "#         info(\"Batch {} already exists, skipping..\".format(start_index))\n",
    "#         return\n",
    "    \n",
    "    info(\"Batch creation working on {}\\n\".format(start_index))\n",
    "    token_lines = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    len_abs_sentences = 0\n",
    "    len_desc_sentences = 0\n",
    "    len_desc_paragraphs = 0\n",
    "    len_claims_sentences = 0\n",
    "    \n",
    "    len_abs_tokens = []\n",
    "    len_desc_tokens = []\n",
    "    len_claims_tokens = []\n",
    "    \n",
    "    \n",
    "    len_desc_parag_tokens = []\n",
    "\n",
    "    len_claims_paragraphs = []\n",
    "    \n",
    "    for doc_index, doc_id in enumerate(DOCS_LIST[start_index:]):\n",
    "        patent_doc = get_patent(doc_id)\n",
    "        \n",
    "        # Abstract\n",
    "        abstract = patent_doc['abstract'][0]\n",
    "        root = ET.fromstring(abstract.encode('utf-8'))\n",
    "        abs_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Description\n",
    "        desc = patent_doc['description'][0]\n",
    "        root = ET.fromstring(desc.encode('utf-8'))\n",
    "        desc_paragraphs = get_adjusted_paragraphs(root)\n",
    "        \n",
    "        # Claims\n",
    "        claims = patent_doc['claims'][0]\n",
    "        root = ET.fromstring(claims.encode('utf-8'))\n",
    "        claims_paragraphs = get_adjusted_paragraphs(root, conc_sentences=False)\n",
    "#         claims_paragraphs = []\n",
    "#         for claim in patent_doc['claims']:\n",
    "#             claims_paragraphs.append(claim.strip())\n",
    "\n",
    "        len_claims_paragraphs.append(len(claims_paragraphs))\n",
    "    \n",
    "        abstract_sentences = sum([get_sentences(abs_parag) for abs_parag in abs_paragraphs], [])\n",
    "        desc_sentences = sum([get_sentences(desc_parag) for desc_parag in desc_paragraphs], [])\n",
    "        claims_sentences = sum([get_sentences(claim_parag) for claim_parag in claims_paragraphs], [])\n",
    "        \n",
    "        len_abs_sentences += len(abstract_sentences)\n",
    "        len_desc_sentences += len(desc_sentences)\n",
    "        len_claims_sentences += len(claims_sentences)\n",
    "        \n",
    "        len_desc_paragraphs += len(desc_paragraphs)\n",
    "        \n",
    "\n",
    "        abstract_tokens = sum([sentence_wordtokenizer(parag) for parag in abs_paragraphs], [])\n",
    "        \n",
    "        len_desc_parag_tokens.extend([len(sentence_wordtokenizer(parag)) for parag in desc_paragraphs])\n",
    "        desc_tokens = sum([sentence_wordtokenizer(parag) for parag in desc_paragraphs], [])\n",
    "        \n",
    "        claims_tokens = sum([sentence_wordtokenizer(parag) for parag in claims_paragraphs], [])\n",
    "        \n",
    "        \n",
    "        len_abs_tokens.append(len(abstract_tokens))\n",
    "        len_desc_tokens.append(len(desc_tokens))\n",
    "        len_claims_tokens.append(len(claims_tokens))\n",
    "        \n",
    "        # lists of list of tokens\n",
    "        doc_tokens_list = [doc_id]  + abstract_tokens + desc_tokens + claims_tokens\n",
    "        abstract_tokens_list = [ABSTRACT_ID.format(doc_id)] + abstract_tokens\n",
    "        description_tokens_list = [DESC_ID.format(doc_id)] + desc_tokens\n",
    "        claims_tokens_list = [CLAIMS_ID.format(doc_id)] + claims_tokens\n",
    "        \n",
    "        # now add the tokens lists that will be written to the file\n",
    "        token_lines.append(doc_tokens_list)\n",
    "        token_lines.append(abstract_tokens_list)\n",
    "        token_lines.append(description_tokens_list)\n",
    "        token_lines.append(claims_tokens_list)\n",
    "        \n",
    "        if doc_index % 1000 == 0: info(\"Doc: {:6} -> Total Lines to write: {:8}\".format(start_index + doc_index, len(token_lines)))\n",
    "        if doc_index >= BATCH_SIZE - 1:\n",
    "            break\n",
    "    duration = time.time() - start_time\n",
    "    info(\"Finished batch {} of size {:d} in {:.0f}m {:.0f}s\".format(start_index, BATCH_SIZE, * divmod(duration, 60)))\n",
    "    info(\"For index {}, the actual number of lines written is: {}\".format(start_index, len(token_lines)))\n",
    "    \n",
    "    print \"Average Abstract Sentences: {}\".format(len_abs_sentences/doc_index)\n",
    "    print \"Average Desc Sentences: {}\".format(len_desc_sentences/doc_index)\n",
    "    print \"Average Desc Paragraphs: {}\".format(len_desc_paragraphs/doc_index)\n",
    "    print \"Average Claims Sentences: {}\".format(len_claims_sentences/doc_index)\n",
    "    \n",
    "    \n",
    "    print \"Abstract Tokens: Mean: {} - Median: {}\".format(np.mean(len_abs_tokens), np.median(len_abs_tokens))\n",
    "    print \"Description Tokens: Mean: {} - Median: {}\".format(np.mean(len_desc_tokens), np.median(len_desc_tokens))\n",
    "    print \"Claims Tokens: Mean: {} - Median: {}\".format(np.mean(len_claims_tokens), np.median(len_claims_tokens))\n",
    "    print \"Description Paragraphs Tokens: Mean: {} - Median: {}\".format(np.mean(len_desc_parag_tokens), \n",
    "                                                                        np.median(len_desc_parag_tokens))\n",
    "    \n",
    "    print \"Claims Paragraphs: Mean: {} - Median: {}\".format(np.mean(len_claims_paragraphs), \n",
    "                                                                        np.median(len_claims_paragraphs))\n",
    "#     write_batch(FILE_PREFIX, token_lines, start_index)\n",
    "    del token_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOCS_LIST = training_docs_list\n",
    "FILE_PREFIX = TRAINING_PREPROCESSED_FILES_PREFIX\n",
    "SAMPLE_SIZE = len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:00:43,555 : INFO : Batch creation working on 0\n",
      "\n",
      "2017-03-16 01:00:43,555 : INFO : Batch creation working on 10000\n",
      "\n",
      "2017-03-16 01:00:43,558 : INFO : Batch creation working on 40000\n",
      "\n",
      "2017-03-16 01:00:43,555 : INFO : Batch creation working on 20000\n",
      "\n",
      "2017-03-16 01:00:43,558 : INFO : Batch creation working on 50000\n",
      "\n",
      "2017-03-16 01:00:43,559 : INFO : Batch creation working on 30000\n",
      "\n",
      "2017-03-16 01:00:43,591 : INFO : Batch creation working on 60000\n",
      "\n",
      "2017-03-16 01:00:43,601 : INFO : Batch creation working on 70000\n",
      "\n",
      "2017-03-16 01:00:43,690 : INFO : Doc:  50000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,742 : INFO : Doc:  60000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,767 : INFO : Doc:      0 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,806 : INFO : Doc:  40000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,846 : INFO : Doc:  20000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,904 : INFO : Doc:  10000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,900 : INFO : Doc:  30000 -> Total Lines to write:        4\n",
      "2017-03-16 01:00:43,927 : INFO : Doc:  70000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:30,660 : INFO : Finished batch 0 of size 1000 in 4m 47s\n",
      "2017-03-16 01:05:30,663 : INFO : For index 0, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 236\n",
      "Average Desc Paragraphs: 56\n",
      "Average Claims Sentences: 19\n",
      "Abstract Tokens: Mean: 118.576 - Median: 114.0\n",
      "Description Tokens: Mean: 7694.354 - Median: 5256.5\n",
      "Claims Tokens: Mean: 1101.352 - Median: 828.0\n",
      "Description Paragraphs Tokens: Mean: 137.372194747 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 19.411 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:31,749 : INFO : Batch creation working on 80000\n",
      "\n",
      "2017-03-16 01:05:33,147 : INFO : Doc:  80000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:49,041 : INFO : Finished batch 40000 of size 1000 in 5m 5s\n",
      "2017-03-16 01:05:49,060 : INFO : For index 40000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 261\n",
      "Average Desc Paragraphs: 61\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 119.666 - Median: 119.0\n",
      "Description Tokens: Mean: 8411.443 - Median: 6107.0\n",
      "Claims Tokens: Mean: 1111.596 - Median: 944.0\n",
      "Description Paragraphs Tokens: Mean: 137.076788944 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 17.226 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:49,886 : INFO : Batch creation working on 90000\n",
      "\n",
      "2017-03-16 01:05:50,033 : INFO : Doc:  90000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:56,244 : INFO : Finished batch 50000 of size 1000 in 5m 13s\n",
      "2017-03-16 01:05:56,248 : INFO : For index 50000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 265\n",
      "Average Desc Paragraphs: 62\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 116.916 - Median: 118.0\n",
      "Description Tokens: Mean: 8561.637 - Median: 5910.0\n",
      "Claims Tokens: Mean: 1082.717 - Median: 892.0\n",
      "Description Paragraphs Tokens: Mean: 137.32235713 - Median: 112.0\n",
      "Claims Paragraphs: Mean: 17.019 - Median: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:57,120 : INFO : Batch creation working on 100000\n",
      "\n",
      "2017-03-16 01:05:57,343 : INFO : Doc: 100000 -> Total Lines to write:        4\n",
      "2017-03-16 01:05:58,003 : INFO : Finished batch 20000 of size 1000 in 5m 14s\n",
      "2017-03-16 01:05:58,006 : INFO : For index 20000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 266\n",
      "Average Desc Paragraphs: 61\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 118.616 - Median: 121.0\n",
      "Description Tokens: Mean: 8539.343 - Median: 5729.0\n",
      "Claims Tokens: Mean: 1096.825 - Median: 894.0\n",
      "Description Paragraphs Tokens: Mean: 138.749581607 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 17.846 - Median: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:05:59,193 : INFO : Batch creation working on 110000\n",
      "\n",
      "2017-03-16 01:06:00,006 : INFO : Doc: 110000 -> Total Lines to write:        4\n",
      "2017-03-16 01:06:07,053 : INFO : Finished batch 30000 of size 1000 in 5m 23s\n",
      "2017-03-16 01:06:07,059 : INFO : For index 30000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 271\n",
      "Average Desc Paragraphs: 64\n",
      "Average Claims Sentences: 17\n",
      "Abstract Tokens: Mean: 118.392 - Median: 118.0\n",
      "Description Tokens: Mean: 8803.666 - Median: 6171.5\n",
      "Claims Tokens: Mean: 1099.404 - Median: 923.0\n",
      "Description Paragraphs Tokens: Mean: 137.510012183 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 17.875 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:06:08,003 : INFO : Batch creation working on 120000\n",
      "\n",
      "2017-03-16 01:06:08,152 : INFO : Doc: 120000 -> Total Lines to write:        4\n",
      "2017-03-16 01:06:14,886 : INFO : Finished batch 10000 of size 1000 in 5m 31s\n",
      "2017-03-16 01:06:14,891 : INFO : For index 10000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 272\n",
      "Average Desc Paragraphs: 63\n",
      "Average Claims Sentences: 19\n",
      "Abstract Tokens: Mean: 117.434 - Median: 116.0\n",
      "Description Tokens: Mean: 8971.263 - Median: 5658.5\n",
      "Claims Tokens: Mean: 1131.289 - Median: 896.0\n",
      "Description Paragraphs Tokens: Mean: 141.313113334 - Median: 114.0\n",
      "Claims Paragraphs: Mean: 19.008 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:06:18,493 : INFO : Finished batch 70000 of size 1000 in 5m 35s\n",
      "2017-03-16 01:06:18,497 : INFO : For index 70000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 282\n",
      "Average Desc Paragraphs: 66\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 116.501 - Median: 117.0\n",
      "Description Tokens: Mean: 9176.843 - Median: 6447.5\n",
      "Claims Tokens: Mean: 1058.939 - Median: 924.5\n",
      "Description Paragraphs Tokens: Mean: 137.616864615 - Median: 112.0\n",
      "Claims Paragraphs: Mean: 16.587 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:06:41,087 : INFO : Finished batch 60000 of size 1000 in 5m 57s\n",
      "2017-03-16 01:06:41,089 : INFO : For index 60000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 295\n",
      "Average Desc Paragraphs: 71\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 116.293 - Median: 118.0\n",
      "Description Tokens: Mean: 9770.952 - Median: 6617.0\n",
      "Claims Tokens: Mean: 1059.014 - Median: 906.5\n",
      "Description Paragraphs Tokens: Mean: 137.735438399 - Median: 112.0\n",
      "Claims Paragraphs: Mean: 16.633 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:07:02,979 : INFO : Finished batch 120000 of size 1000 in 0m 55s\n",
      "2017-03-16 01:07:02,982 : INFO : For index 120000, the actual number of lines written is: 624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 295\n",
      "Average Desc Paragraphs: 67\n",
      "Average Claims Sentences: 34\n",
      "Abstract Tokens: Mean: 123.487179487 - Median: 123.5\n",
      "Description Tokens: Mean: 9056.32051282 - Median: 6444.0\n",
      "Claims Tokens: Mean: 2129.06410256 - Median: 1735.0\n",
      "Description Paragraphs Tokens: Mean: 135.207771079 - Median: 111.0\n",
      "Claims Paragraphs: Mean: 34.3141025641 - Median: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:10:54,091 : INFO : Finished batch 80000 of size 1000 in 5m 22s\n",
      "2017-03-16 01:10:54,093 : INFO : For index 80000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 277\n",
      "Average Desc Paragraphs: 65\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 114.978 - Median: 118.0\n",
      "Description Tokens: Mean: 9035.3 - Median: 6557.0\n",
      "Claims Tokens: Mean: 1052.833 - Median: 908.0\n",
      "Description Paragraphs Tokens: Mean: 137.333373866 - Median: 113.0\n",
      "Claims Paragraphs: Mean: 16.561 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:11:22,433 : INFO : Finished batch 90000 of size 1000 in 5m 33s\n",
      "2017-03-16 01:11:22,436 : INFO : For index 90000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 276\n",
      "Average Desc Paragraphs: 65\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 116.039 - Median: 118.0\n",
      "Description Tokens: Mean: 9215.904 - Median: 6593.5\n",
      "Claims Tokens: Mean: 1066.299 - Median: 932.5\n",
      "Description Paragraphs Tokens: Mean: 141.239908046 - Median: 116.0\n",
      "Claims Paragraphs: Mean: 16.451 - Median: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:11:36,285 : INFO : Finished batch 100000 of size 1000 in 5m 39s\n",
      "2017-03-16 01:11:36,288 : INFO : For index 100000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 287\n",
      "Average Desc Paragraphs: 67\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 113.675 - Median: 117.0\n",
      "Description Tokens: Mean: 9544.564 - Median: 6973.5\n",
      "Claims Tokens: Mean: 1108.746 - Median: 977.5\n",
      "Description Paragraphs Tokens: Mean: 141.208486211 - Median: 116.0\n",
      "Claims Paragraphs: Mean: 16.438 - Median: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-16 01:11:54,205 : INFO : Finished batch 110000 of size 1000 in 5m 55s\n",
      "2017-03-16 01:11:54,208 : INFO : For index 110000, the actual number of lines written is: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abstract Sentences: 3\n",
      "Average Desc Sentences: 311\n",
      "Average Desc Paragraphs: 73\n",
      "Average Claims Sentences: 16\n",
      "Abstract Tokens: Mean: 114.923 - Median: 118.0\n",
      "Description Tokens: Mean: 10124.423 - Median: 7225.5\n",
      "Claims Tokens: Mean: 1053.8 - Median: 936.5\n",
      "Description Paragraphs Tokens: Mean: 138.761056974 - Median: 115.0\n",
      "Claims Paragraphs: Mean: 16.433 - Median: 16.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pool = ThreadPool(8) # use just 6 because every batch requires a lot of memory\n",
    "    # +1 since range is end-exclusive\n",
    "    batches = range(0, (divmod(SAMPLE_SIZE, BATCH_SIZE)[0]+1) * BATCH_SIZE, BATCH_SIZE*10 )\n",
    "    indices = pool.map(multithreaded_extended_batch_creation, batches)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "finally:\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
