{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of fixed size paragraph vectors using LSTM\n",
    "should be able to deal with all levels using the PARTS_LEVEL param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple, defaultdict\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "import seaborn\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Masking\n",
    "from keras.layers.convolutional import MaxPooling1D, Convolution1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from thesis.utils.metrics import *\n",
    "from thesis.utils.file import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables used throughout the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234\n",
    "NN_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "VALIDATION_DICT = \"validation_dict.pkl\"\n",
    "TEST_MATRIX = \"test_matrix.pkl\"\n",
    "TEST_DICT = \"test_dict.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\"\n",
    "TYPE_CLASSIFIER= \"{}_classifier.pkl\"\n",
    "\n",
    "TRAINING_DATA_MATRIX = \"X_level_{}.npy\"\n",
    "TRAINING_LABELS_MATRIX = \"y_{}.npy\"\n",
    "VALIDATION_DATA_MATRIX = \"Xv_level_{}.npy\"\n",
    "VALIDATION_LABELS_MATRIX = \"yv_{}.npy\"\n",
    "TEST_DATA_MATRIX = \"Xt_level_{}.npy\"\n",
    "TEST_LABELS_MATRIX = \"yt_{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_PARAMETER_SEARCH_PREFIX = \"lstm_{}_level_{}_batch_{}_nn_parameter_searches.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_location = \"/mnt/virtual-machines/data/\"\n",
    "big_data_location = \"/mnt/virtual-machines/data/\"\n",
    "\n",
    "matrices_save_location = big_data_location + \"extended_pv_matrices/\"\n",
    "# matrices_save_location = big_data_location + \"extended_pv_matrices/one_model/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "nn_parameter_search_location = os.path.join(root_location, \"nn_parameter_search_extended_abs_desc_claims_full_chunks\")\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "valid_classes_file = exports_location + \"valid_classes.pkl\"\n",
    "valid_subclasses_file = exports_location + \"valid_subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load general data required for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 1.22 s, total: 18.5 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "valid_classes = pickle.load(open(valid_classes_file))\n",
    "valid_subclasses = pickle.load(open(valid_subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401877"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(classifications_type, level):\n",
    "    info(\"Loading Training Data from file\")\n",
    "    training_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                              TRAINING_DATA_MATRIX.format(level))))\n",
    "    training_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                TRAINING_LABELS_MATRIX.format(classifications_type))))\n",
    "    return training_data, training_labels\n",
    "\n",
    "def get_validation_data(classifications_type, level):\n",
    "    info(\"Loading Validation Data from file\")\n",
    "    validation_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                VALIDATION_DATA_MATRIX.format(level))))\n",
    "    validation_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  VALIDATION_LABELS_MATRIX.format(classifications_type))))\n",
    "    return validation_data, validation_labels\n",
    "\n",
    "def get_test_data(classifications_type, level):\n",
    "    info(\"Loading Test Data from file\")\n",
    "    test_data = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                TEST_DATA_MATRIX.format(level))))\n",
    "    test_labels = np.load(open(os.path.join(matrices_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                  TEST_LABELS_MATRIX.format(classifications_type))))\n",
    "    return test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the \n",
    "    validation metrics\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        MetricsCallback.EPOCHS_BEFORE_VALIDATION = epochs_before_validation[classifications_type]\n",
    "        MetricsCallback.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
    "        MetricsCallback.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_index = 0\n",
    "        self.val_loss_reductions = 0\n",
    "        self.metrics_dict = {}\n",
    "        self.best_val_loss = np.iinfo(np.int32).max\n",
    "        self.best_weights = None\n",
    "        self.best_validation_metrics = None\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
    "        self.ax = plt.subplot(111)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_index += 1\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
    "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
    "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
    "        self.ax.set_ylim((MetricsCallback.GRAPH_MIN, MetricsCallback.GRAPH_MAX))\n",
    "        self.fig.canvas.draw()\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.val_loss_reductions += 1\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print '\\r    \\r' # to remove the previous line of verbose output of model fit\n",
    "            #time.sleep(0.1)\n",
    "            info('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
    "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
    "                \n",
    "                info('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
    "                info('Evaluating on Validation Data')\n",
    "                yvp = self.model.predict(Xv)\n",
    "                yvp_binary = get_binary_0_5(yvp)\n",
    "                info('Generating Validation Metrics')\n",
    "                validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "                print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "                    validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "                self.metrics_dict[self.epoch_index] = validation_metrics\n",
    "#                 self.best_validation_metrics = validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_keras_rnn_model(input_size, output_size, lstm_output_size, w_dropout_do, u_dropout_do, \n",
    "                           stack_layers=1, conv_size=None, conv_filter_length=3, max_pooling_length=None):\n",
    "    \n",
    "    model= Sequential()\n",
    "#     model.add(Masking(mask_value=0., input_shape=(MAX_SIZE, input_size)))\n",
    "    if conv_size:\n",
    "        model.add(Convolution1D(nb_filter=conv_size, input_shape=(MAX_SIZE, input_size), filter_length=conv_filter_length, \n",
    "                                border_mode='same', activation='relu'))\n",
    "        if max_pooling_length is not None:\n",
    "            model.add(MaxPooling1D(pool_length=max_pooling_length))\n",
    "    for i in range(stack_layers):\n",
    "        model.add(LSTM(lstm_output_size, input_dim=input_size, dropout_W=w_dropout_do, dropout_U=u_dropout_do,\n",
    "                       return_sequences=False if i+1 == stack_layers else True,\n",
    "                  name='lstm_{}_w-drop_{}_u-drop_{}_layer_{}'.format(lstm_output_size, str(u_dropout_do), str(w_dropout_do), str(i+1))))\n",
    "    model.add(Dense(output_size, activation='sigmoid', name='sigmoid_output'))\n",
    "    model.compile(optimizer=NN_OPTIMIZER, loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Param Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum change in val_loss from previous epoch to register as a decrease\n",
    "early_stopper_deltas = {\n",
    "    'sections': 0.00001,\n",
    "    'classes': 0.00001,\n",
    "    'subclasses': 0.00001\n",
    "}\n",
    "# how many epochs to wait when there is no decrease in val_loss before early stopping\n",
    "early_stopper_patience = {\n",
    "    'sections': 15,\n",
    "    'classes': 15,\n",
    "    'subclasses': 15\n",
    "}\n",
    "# number of epochs after which we do periodic evaluation of validation metrics\n",
    "epochs_before_validation = {\n",
    "    'sections': 10,\n",
    "    'classes': 20,\n",
    "    'subclasses': 20\n",
    "}\n",
    "\n",
    "# ranges for learning graph shown\n",
    "metrics_graph_ranges = {\n",
    "    'sections': {'min':0, 'max': 0.3},\n",
    "    'classes': {'min':0, 'max': 0.05},\n",
    "    'subclasses': {'min':0, 'max': 0.05}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEVEL_DOC = 1\n",
    "LEVEL_DIVISIONS = 2\n",
    "LEVEL_CHUNKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 2\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 8\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 100000 # report vocab progress every x documents\n",
    "\n",
    "DOC2VEC_EPOCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_PARMS_TO_RUN = [\n",
    "    {\n",
    "        'doc2vec_epoch': DOC2VEC_EPOCH,\n",
    "        'classifications': valid_subclasses,\n",
    "        'classifications_type': 'subclasses',\n",
    "        'parts_level': LEVEL_DOC,\n",
    "        'nn_batch_size': 4096,\n",
    "        'lstm_output_size': 1000,\n",
    "        'lstm_w_dropout': 0.5,\n",
    "        'lstm_u_dropout': 0.5,\n",
    "        'lstm_stack_layers': 1,\n",
    "        'lstm_conv_size': None,\n",
    "        'lstm_conv_filter_length': None,\n",
    "        'lstm_max_pooling_length': None\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== NEW PARAM SET ============================================\n",
      "{'lstm_conv_filter_length': None, 'lstm_stack_layers': 1, 'nn_batch_size': 4096, 'classifications_type': 'subclasses', 'lstm_w_dropout': 0.5, 'lstm_max_pooling_length': None, 'lstm_u_dropout': 0.5, 'parts_level': 1, 'lstm_output_size': 1000, 'doc2vec_epoch': 8, 'lstm_conv_size': None}\n",
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 05:10:25,567 : INFO : Loading Training Documents\n",
      "2017-04-15 05:10:25,568 : INFO : Loading Training Data from file\n",
      "2017-04-15 05:10:38,862 : INFO : Loading Validation Documents\n",
      "2017-04-15 05:10:38,863 : INFO : Loading Validation Data from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1286325, 1, 200)\n",
      "(1286325, 940)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 05:10:42,389 : INFO : No Previous results exist in /mnt/virtual-machines/data/nn_parameter_search_extended_abs_desc_claims_full_chunks/doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/lstm_subclasses_level_1_batch_4096_nn_parameter_searches.pkl\n",
      "2017-04-15 05:10:42,390 : INFO : ***************************************************************************************\n",
      "2017-04-15 05:10:42,391 : INFO : lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(321473, 1, 200)\n",
      "(321473, 940)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, 1000)          4804000     lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 940)           940940      lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "====================================================================================================\n",
      "Total params: 5744940\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1286325 samples, validate on 321473 samples\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0759 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 06:10:59,700 : INFO : Found lower val loss for epoch 1 => 0.00639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3597s - loss: 0.0759 - val_loss: 0.0064\n",
      "Epoch 2/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0071 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 07:11:10,938 : INFO : Found lower val loss for epoch 2 => 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3611s - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 3/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0068 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 08:11:21,517 : INFO : Found lower val loss for epoch 3 => 0.00472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3610s - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 4/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0067 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 09:11:38,785 : INFO : Found lower val loss for epoch 4 => 0.00456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3617s - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 5/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0066 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 10:12:02,578 : INFO : Found lower val loss for epoch 5 => 0.00445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3623s - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 6/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0066 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 11:12:38,458 : INFO : Found lower val loss for epoch 6 => 0.00438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3635s - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 7/200\n",
      "1286325/1286325 [==============================] - 3642s - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 8/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0065 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 13:14:04,618 : INFO : Found lower val loss for epoch 8 => 0.00436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3643s - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 9/200\n",
      "1286325/1286325 [==============================] - 3646s - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 10/200\n",
      "1286144/1286325 [============================>.] - ETA: 0s - loss: 0.0064 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-15 15:15:43,685 : INFO : Found lower val loss for epoch 10 => 0.00424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "1286325/1286325 [==============================] - 3652s - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 11/200\n",
      "1286325/1286325 [==============================] - 3655s - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 12/200\n",
      "1286325/1286325 [==============================] - 3649s - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 13/200\n",
      "1286325/1286325 [==============================] - 3653s - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 14/200\n",
      "1286325/1286325 [==============================] - 3651s - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 15/200\n",
      "1286325/1286325 [==============================] - 3649s - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 16/200\n",
      "1286325/1286325 [==============================] - 3654s - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 17/200\n",
      "1286325/1286325 [==============================] - 3653s - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 18/200\n",
      "1286325/1286325 [==============================] - 3658s - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 19/200\n",
      "1286325/1286325 [==============================] - 3660s - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 20/200\n",
      "1286325/1286325 [==============================] - 3664s - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 21/200\n",
      "1286325/1286325 [==============================] - 3663s - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 22/200\n",
      "1286325/1286325 [==============================] - 3661s - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 23/200\n",
      "1183744/1286325 [==========================>...] - ETA: 270s - loss: 0.0063"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "for GLOBAL_PARAMS in GLOBAL_PARMS_TO_RUN:\n",
    "    \n",
    "    print '==================================== NEW PARAM SET ============================================'\n",
    "    print {k:v for k,v in GLOBAL_PARAMS.items() if k != 'classifications'}\n",
    "    \n",
    "    classifications = GLOBAL_PARAMS['classifications']\n",
    "    classifications_type = GLOBAL_PARAMS['classifications_type']\n",
    "    classifier_file = TYPE_CLASSIFIER.format(classifications_type)\n",
    "    \n",
    "    PARTS_LEVEL = GLOBAL_PARAMS['parts_level']\n",
    "    \n",
    "    \n",
    "    placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "    GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "    placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "    epoch = GLOBAL_PARAMS['doc2vec_epoch']\n",
    "\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    print GLOBAL_VARS.MODEL_NAME\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    info(\"Loading Training Documents\")\n",
    "    X, y = get_training_data(classifications_type, PARTS_LEVEL)\n",
    "    print X.shape\n",
    "    print y.shape\n",
    "    \n",
    "    info(\"Loading Validation Documents\")\n",
    "    Xv, yv = get_validation_data(classifications_type, PARTS_LEVEL)\n",
    "    print Xv.shape\n",
    "    print yv.shape\n",
    "    \n",
    "    \n",
    "    NN_OUTPUT_NEURONS = len(classifications)\n",
    "    EARLY_STOPPER_MIN_DELTA = early_stopper_deltas[classifications_type]\n",
    "    EARLY_STOPPER_PATIENCE = early_stopper_patience[classifications_type]\n",
    "\n",
    "    NN_MAX_EPOCHS = 200\n",
    "    NN_PARAM_SAMPLE_SEED = 1234\n",
    "\n",
    "    NN_BATCH_SIZE = GLOBAL_PARAMS['nn_batch_size']\n",
    "\n",
    "    MODEL_VERBOSITY = 1\n",
    "\n",
    "    NN_OPTIMIZER = 'rmsprop'\n",
    "    # NN_OPTIMIZER = 'adam'\n",
    "\n",
    "    to_skip = []\n",
    "\n",
    "    load_existing_results = True\n",
    "    save_results = True\n",
    "\n",
    "\n",
    "    np.random.seed(NN_SEED)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    ############### Actual Training\n",
    "\n",
    "\n",
    "    # load previous finshed results so we dont redo them\n",
    "    param_results_dict = {}\n",
    "    \n",
    "    param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                   NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "        \n",
    "    if load_existing_results:\n",
    "        if os.path.exists(param_results_path):\n",
    "            info('Loading Previous results from {}'.format(param_results_path))\n",
    "            param_results_dict = pickle.load(open(param_results_path))\n",
    "        else:\n",
    "            info('No Previous results exist in {}'.format(param_results_path))\n",
    "\n",
    "    ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "    start_time = time.time()\n",
    "    lstm_output_size = GLOBAL_PARAMS['lstm_output_size']\n",
    "    w_dropout_do = GLOBAL_PARAMS['lstm_w_dropout']\n",
    "    u_dropout_do = GLOBAL_PARAMS['lstm_u_dropout']\n",
    "    stack_layers = GLOBAL_PARAMS['lstm_stack_layers']\n",
    "    conv_size = GLOBAL_PARAMS['lstm_conv_size']\n",
    "    conv_filter_length = GLOBAL_PARAMS['lstm_conv_filter_length']\n",
    "    conv_max_pooling_length = GLOBAL_PARAMS['lstm_max_pooling_length']\n",
    "\n",
    "    GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "        lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    "    )\n",
    "    if conv_size:\n",
    "        GLOBAL_VARS.NN_MODEL_NAME += '_conv-filter-length_{}_max-pooling-size_{}'.format(conv_filter_length, \n",
    "                                                                                         conv_max_pooling_length)\n",
    "\n",
    "    if GLOBAL_VARS.NN_MODEL_NAME in param_results_dict.keys() or GLOBAL_VARS.NN_MODEL_NAME in to_skip:\n",
    "        print \"skipping: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "        continue\n",
    "\n",
    "    info('***************************************************************************************')\n",
    "    info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "    # creating the actual keras model\n",
    "    model = create_keras_rnn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                                  lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size, \n",
    "                                   conv_filter_length, conv_max_pooling_length)\n",
    "    model.summary()\n",
    "\n",
    "    # callbacks for early stopping and for generating validation metrics\n",
    "    early_stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=EARLY_STOPPER_MIN_DELTA, \\\n",
    "                                                  patience=EARLY_STOPPER_PATIENCE, verbose=1, mode='auto')\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "\n",
    "    # Model Fitting\n",
    "    %time history = model.fit(x=X, y=y, validation_data=(Xv,yv), batch_size=NN_BATCH_SIZE, \\\n",
    "                              nb_epoch=NN_MAX_EPOCHS, verbose=MODEL_VERBOSITY, \\\n",
    "                              callbacks=[early_stopper, metrics_callback])\n",
    "    \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Training Data')\n",
    "    yp = model.predict(X) # get raw probability for predicted labels\n",
    "    yp_binary = get_binary_0_5(yp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    #print yvp\n",
    "    info('Generating Training Metrics')\n",
    "    training_metrics = get_metrics(y, yp, yp_binary)\n",
    "    print \"****** Training Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "    training_metrics['coverage_error'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "    training_metrics['f1_micro'], training_metrics['f1_macro'])\n",
    "    \n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    info('Evaluating on Validation Data using saved best weights')\n",
    "    model.set_weights(metrics_callback.best_weights)\n",
    "    yvp = model.predict(Xv) # get raw probability for predicted labels\n",
    "    yvp_binary = get_binary_0_5(yvp) # use 0.5 as threshold for setting labels to 0 or 1\n",
    "    #print yvp\n",
    "    info('Generating Validation Metrics')\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp_binary)\n",
    "    print \"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'])\n",
    "    best_validation_metrics = validation_metrics\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME] = dict()\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_validation_metrics'] = best_validation_metrics\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['epochs'] = len(history.history['val_loss'])\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights'] = metrics_callback.best_weights\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_val_loss'] = metrics_callback.best_val_loss\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['training_loss'] = metrics_callback.losses\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['validation_loss'] = metrics_callback.val_losses\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['duration'] =  duration\n",
    "\n",
    "    del history, metrics_callback, model\n",
    "\n",
    "    if save_results:\n",
    "        if load_existing_results:\n",
    "            if os.path.exists(param_results_path):\n",
    "                info('Loading Previous results from {}'.format(param_results_path))\n",
    "                loaded_param_results_dict = pickle.load(open(param_results_path))\n",
    "                param_results_dict.update(loaded_param_results_dict)\n",
    "\n",
    "        pickle.dump(param_results_dict, open(param_results_path, 'w'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_results_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-51df4c3b2e51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparam_results_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'param_results_path' is not defined"
     ]
    }
   ],
   "source": [
    "param_results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None': {'best_val_loss': 0.0042405138176450589,\n",
       "  'best_validation_metrics': {'average_num_of_labels': 1.34,\n",
       "   'coverage_error': 11.536828909426298,\n",
       "   'f1_macro': 0.061518653935442237,\n",
       "   'f1_micro': 0.39861919327976425,\n",
       "   'precision_macro': 0.19371251528014369,\n",
       "   'precision_micro': 0.70343547650550919,\n",
       "   'recall_macro': 0.046290286518774988,\n",
       "   'recall_micro': 0.27810800175913708,\n",
       "   'top_1': 0.5019142189199824,\n",
       "   'top_3': 0.6487095803532162,\n",
       "   'top_5': 0.7380459690299285,\n",
       "   'total_positive': 170806},\n",
       "  'best_weights': [array([[-0.03445173,  0.14710119, -0.23219067, ..., -0.39580068,\n",
       "           -0.15396556, -0.32569778],\n",
       "          [ 0.14210089, -0.02386677,  0.07652503, ..., -0.38713658,\n",
       "            0.45727694,  0.0065327 ],\n",
       "          [ 0.13615593,  0.03888382,  0.02307924, ..., -0.2404063 ,\n",
       "            0.13866499,  0.08601573],\n",
       "          ..., \n",
       "          [ 0.17266287, -0.04258944, -0.01333085, ..., -0.1426546 ,\n",
       "           -0.44876766,  0.18774809],\n",
       "          [-0.11497737, -0.17699222,  0.22071689, ..., -0.08619889,\n",
       "           -0.36179909, -0.00963318],\n",
       "          [ 0.05978811, -0.030391  ,  0.11668782, ...,  0.07263604,\n",
       "           -0.05636615,  0.15699475]], dtype=float32),\n",
       "   array([[-0.03471683,  0.0027497 ,  0.01622912, ...,  0.01896122,\n",
       "            0.00207856,  0.02039083],\n",
       "          [ 0.0100515 , -0.03519686,  0.00607722, ...,  0.0762981 ,\n",
       "            0.03364754, -0.04258512],\n",
       "          [ 0.04656178, -0.0171722 ,  0.01914293, ...,  0.01426165,\n",
       "            0.00065805, -0.04705968],\n",
       "          ..., \n",
       "          [ 0.02925964,  0.0140187 ,  0.02504473, ..., -0.00910366,\n",
       "           -0.04294857,  0.06861982],\n",
       "          [ 0.01156709,  0.04001261,  0.05914405, ..., -0.02732967,\n",
       "            0.00071479,  0.04066467],\n",
       "          [ 0.01042324, -0.05387119, -0.00505159, ...,  0.04320848,\n",
       "            0.01476992,  0.0453904 ]], dtype=float32),\n",
       "   array([ 0.13041814,  0.20702505,  0.3839308 ,  0.1555723 ,  0.56150103,\n",
       "           0.10891771,  0.17879622,  0.14235115,  0.16389635,  0.18529744,\n",
       "           0.14360885,  0.31847897,  0.1556969 ,  0.18535222,  0.49003682,\n",
       "           0.15021133,  0.44022605,  0.22790556,  0.24507989,  0.1651887 ,\n",
       "           0.1623396 ,  0.14967111,  0.16248246,  0.20687279,  0.39738297,\n",
       "           0.13539681,  0.159325  ,  0.07623231,  0.17293417,  0.15012544,\n",
       "           0.13871767,  0.41937026,  0.54742718,  0.09065544,  0.1382401 ,\n",
       "           0.11461286,  0.28976351,  0.1573073 ,  0.47211954,  0.16287278,\n",
       "           0.12694646,  0.1727796 ,  0.14500578,  0.38256142,  0.12769581,\n",
       "           0.16732888,  0.12969667,  0.13455576,  0.45878562,  0.14084399,\n",
       "           0.13754705,  0.12059319,  0.08824231,  0.18281133,  0.31710774,\n",
       "           0.39097881,  0.37632674,  0.28291169,  0.146035  ,  0.13820904,\n",
       "           0.1559186 ,  0.21987298,  0.11942082,  0.12470706,  0.1147762 ,\n",
       "           0.1476254 ,  0.15664537,  0.18143351,  0.17961414,  0.16929324,\n",
       "           0.16819194,  0.23335877,  0.19305426,  0.19307759,  0.16088431,\n",
       "           0.14738728,  0.12496566,  0.30341682,  0.18857898,  0.45116085,\n",
       "           0.43334544,  0.22505264,  0.12319221,  0.22478455,  0.53299397,\n",
       "           0.47479478,  0.12082361,  0.21163385,  0.18207692,  0.16683082,\n",
       "           0.52277964,  0.12858418,  0.40547058,  0.41040096,  0.18425916,\n",
       "           0.13715819,  0.3488113 ,  0.5186829 ,  0.18221658,  0.13481498,\n",
       "           0.40941346,  0.17039916,  0.25628978,  0.33733246,  0.1595197 ,\n",
       "           0.17781745,  0.11130571,  0.17221805,  0.40624356,  0.15903305,\n",
       "           0.16106409,  0.18706258,  0.13307942,  0.165372  ,  0.12704144,\n",
       "           0.142042  ,  0.4478516 ,  0.17844388,  0.1763881 ,  0.11296281,\n",
       "           0.17407206,  0.13566138,  0.57450223,  0.13300185,  0.15291381,\n",
       "           0.18087018,  0.13853374,  0.16835973,  0.14763328,  0.36254084,\n",
       "           0.46361408,  0.15706868,  0.31266212,  0.17594209,  0.17854142,\n",
       "           0.16047706,  0.13969681,  0.59698707,  0.16465983,  0.23844998,\n",
       "           0.35461852,  0.11238433,  0.13702367,  0.62540191,  0.37574542,\n",
       "           0.24729617,  0.12827066,  0.35716131,  0.16984676,  0.12831946,\n",
       "           0.17265412,  0.17690198,  0.10593971,  0.39286035,  0.19581324,\n",
       "           0.29893485,  0.16269737,  0.48242271,  0.13326509,  0.17884704,\n",
       "           0.11502186,  0.13090354,  0.13725179,  0.16506244,  0.15724635,\n",
       "           0.29607552,  0.30774188,  0.10517768,  0.42838427,  0.1957255 ,\n",
       "           0.12897569,  0.13169396,  0.15272009,  0.10308337,  0.2260557 ,\n",
       "           0.14508368,  0.12357154,  0.3271707 ,  0.18268068,  0.29886597,\n",
       "           0.1461921 ,  0.13985184,  0.19360541,  0.15361759,  0.20305403,\n",
       "           0.18297137,  0.15638681,  0.18049149,  0.12298352,  0.1507643 ,\n",
       "           0.15429986,  0.3906306 ,  0.20089035,  0.16218379,  0.11778383,\n",
       "           0.18102722,  0.17125963,  0.39196342,  0.12224244,  0.17132065,\n",
       "           0.12125898,  0.1501592 ,  0.11785223,  0.17735772,  0.13018802,\n",
       "           0.13243668,  0.34987694,  0.46070921,  0.3484948 ,  0.14049025,\n",
       "           0.08443701,  0.14212486,  0.17684639,  0.0979622 ,  0.16277215,\n",
       "           0.15727474,  0.37963873,  0.10931356,  0.4773601 ,  0.4143911 ,\n",
       "           0.38146165,  0.11065487,  0.23690334,  0.18334062,  0.17962259,\n",
       "           0.45414987,  0.48729694,  0.43783453,  0.47320935,  0.16898815,\n",
       "           0.12534907,  0.1627676 ,  0.20185502,  0.14410721,  0.13662156,\n",
       "           0.38105515,  0.15662712,  0.1322865 ,  0.49044761,  0.21452248,\n",
       "           0.13653372,  0.37311873,  0.11992221,  0.50170332,  0.17493214,\n",
       "           0.18725191,  0.12864468,  0.33646426,  0.1900903 ,  0.1013522 ,\n",
       "           0.14308451,  0.18616569,  0.15307742,  0.37439224,  0.12787472,\n",
       "           0.13120647,  0.20816034,  0.26815727,  0.13442917,  0.20522904,\n",
       "           0.17545371,  0.23581071,  0.17094421,  0.62696904,  0.28655216,\n",
       "           0.44115594,  0.18130015,  0.19669914,  0.22935534,  0.14052232,\n",
       "           0.10973927,  0.11808135,  0.14689979,  0.11842467,  0.46289873,\n",
       "           0.10553005,  0.31575456,  0.37546736,  0.43502933,  0.13848865,\n",
       "           0.12796843,  0.35558891,  0.14423086,  0.20405069,  0.59207237,\n",
       "           0.49620253,  0.15936489,  0.25902542,  0.14365342,  0.60988808,\n",
       "           0.13540459,  0.17431553,  0.16804686,  0.34519601,  0.14140938,\n",
       "           0.1284177 ,  0.15569066,  0.13673681,  0.12757197,  0.39632493,\n",
       "           0.54212135,  0.29648656,  0.20142192,  0.22433829,  0.28711721,\n",
       "           0.18390876,  0.17111716,  0.13641146,  0.4024547 ,  0.53547949,\n",
       "           0.55089176,  0.47365645,  0.24976672,  0.16905037,  0.20274612,\n",
       "           0.30909553,  0.28552645,  0.13419276,  0.17218381,  0.11204789,\n",
       "           0.57820207,  0.1326635 ,  0.39344037,  0.19442274,  0.13834439,\n",
       "           0.43170089,  0.16155472,  0.41232654,  0.13562326,  0.38287562,\n",
       "           0.17380485,  0.14534688,  0.16049752,  0.22469848,  0.3254891 ,\n",
       "           0.17216751,  0.14069055,  0.34437108,  0.39679354,  0.14937171,\n",
       "           0.14430377,  0.11543166,  0.1121266 ,  0.5521456 ,  0.17445348,\n",
       "           0.48966882,  0.3421427 ,  0.13327348,  0.53888679,  0.24169533,\n",
       "           0.09782124,  0.14827017,  0.17656137,  0.18208933,  0.27544877,\n",
       "           0.38950899,  0.22474088,  0.160836  ,  0.2725153 ,  0.18179348,\n",
       "           0.19864106,  0.10794226,  0.1859203 ,  0.12021743,  0.2736406 ,\n",
       "           0.42055386,  0.16420676,  0.3887971 ,  0.47763163,  0.53216708,\n",
       "           0.34112009,  0.11456038,  0.44136059,  0.11408347,  0.14295684,\n",
       "           0.13500381,  0.28863826,  0.10452476,  0.32445601,  0.13279775,\n",
       "           0.1530688 ,  0.21480112,  0.42721459,  0.33123586,  0.19655722,\n",
       "           0.12839919,  0.16274439,  0.19696921,  0.16557708,  0.12275013,\n",
       "           0.17606919,  0.36451137,  0.15801755,  0.13337375,  0.4237341 ,\n",
       "           0.43446627,  0.42513582,  0.56163597,  0.13268045,  0.30202961,\n",
       "           0.1753463 ,  0.59058934,  0.21018293,  0.50552976,  0.13953124,\n",
       "           0.14260551,  0.15363924,  0.62258101,  0.17258121,  0.12299077,\n",
       "           0.62752563,  0.21766137,  0.17222278,  0.18454574,  0.15339325,\n",
       "           0.14146619,  0.28763577,  0.16438279,  0.08790988,  0.20587526,\n",
       "           0.13277227,  0.14875591,  0.13889897,  0.61494398,  0.34778583,\n",
       "           0.61063248,  0.13515167,  0.54850185,  0.30925405,  0.45224285,\n",
       "           0.17291096,  0.13491052,  0.15707479,  0.4812136 ,  0.14778174,\n",
       "           0.26299542,  0.1795222 ,  0.10363974,  0.17489843,  0.14894661,\n",
       "           0.49589321,  0.12742145,  0.12693162,  0.3252984 ,  0.15426268,\n",
       "           0.50360465,  0.41090503,  0.48261786,  0.37857139,  0.11678185,\n",
       "           0.14996246,  0.14736544,  0.23216948,  0.31032842,  0.50782186,\n",
       "           0.39991739,  0.1165583 ,  0.21286353,  0.47481132,  0.30517057,\n",
       "           0.17961618,  0.15456066,  0.43499339,  0.16626708,  0.12413252,\n",
       "           0.29072383,  0.20780933,  0.21164976,  0.4517709 ,  0.1236408 ,\n",
       "           0.38422161,  0.15061091,  0.72374272,  0.17498049,  0.14273448,\n",
       "           0.45981318,  0.16021782,  0.10849155,  0.29903454,  0.27572924,\n",
       "           0.1500898 ,  0.30473152,  0.16259673,  0.31934172,  0.45085829,\n",
       "           0.10766795,  0.14346902,  0.14451921,  0.11559761,  0.27226651,\n",
       "           0.13942674,  0.15302624,  0.18030807,  0.16748859,  0.12252507,\n",
       "           0.18168658,  0.36501664,  0.13505359,  0.40466115,  0.22361414,\n",
       "           0.21680644,  0.32458597,  0.39242873,  0.12741016,  0.17239039,\n",
       "           0.4098371 ,  0.20009817,  0.22045037,  0.14795835,  0.14360464,\n",
       "           0.13671744,  0.46282497,  0.16942449,  0.15243721,  0.13508396,\n",
       "           0.13435188,  0.1776641 ,  0.37122428,  0.20529082,  0.16491765,\n",
       "           0.16270149,  0.11864576,  0.13187976,  0.48510846,  0.18262996,\n",
       "           0.41863129,  0.44053051,  0.13146633,  0.58972931,  0.22710103,\n",
       "           0.15701415,  0.21215661,  0.13969313,  0.17583141,  0.14466475,\n",
       "           0.1835538 ,  0.44589698,  0.40541261,  0.12039899,  0.37443334,\n",
       "           0.15477154,  0.13176045,  0.45086646,  0.5739724 ,  0.54924697,\n",
       "           0.13901478,  0.41252548,  0.15837868,  0.33649006,  0.4482078 ,\n",
       "           0.14422797,  0.29680958,  0.12661625,  0.10383067,  0.13844095,\n",
       "           0.5814935 ,  0.09948703,  0.1231655 ,  0.35786551,  0.33261037,\n",
       "           0.35460815,  0.14576055,  0.43271568,  0.22438151,  0.18460822,\n",
       "           0.16102093,  0.13387851,  0.16236548,  0.28872734,  0.14396419,\n",
       "           0.17360757,  0.16350894,  0.20687395,  0.11953039,  0.13514502,\n",
       "           0.37035882,  0.4786562 ,  0.48690885,  0.13300267,  0.16187848,\n",
       "           0.19047593,  0.38372397,  0.41224101,  0.142258  ,  0.17177558,\n",
       "           0.39544731,  0.12712875,  0.45369247,  0.1366121 ,  0.18980061,\n",
       "           0.50896174,  0.31400833,  0.13880299,  0.46541509,  0.17158724,\n",
       "           0.48331782,  0.19688955,  0.39663783,  0.57349652,  0.15122345,\n",
       "           0.49866107,  0.179821  ,  0.13905127,  0.48454329,  0.16683145,\n",
       "           0.17652257,  0.13331255,  0.42849901,  0.17517748,  0.27907953,\n",
       "           0.26363239,  0.24264474,  0.1377424 ,  0.19166318,  0.4849565 ,\n",
       "           0.52276433,  0.35327777,  0.15343867,  0.31785846,  0.1354821 ,\n",
       "           0.14920945,  0.28787032,  0.12743317,  0.16482906,  0.11590227,\n",
       "           0.463819  ,  0.17096625,  0.13706002,  0.11483191,  0.63132221,\n",
       "           0.46032137,  0.12941301,  0.28717726,  0.40681696,  0.14755194,\n",
       "           0.18154265,  0.19170539,  0.52022094,  0.34238973,  0.13299669,\n",
       "           0.14919317,  0.49732149,  0.15587769,  0.3879914 ,  0.20574719,\n",
       "           0.15012935,  0.10687541,  0.21432777,  0.15694205,  0.39404976,\n",
       "           0.13892172,  0.14797151,  0.17265578,  0.52198374,  0.18471146,\n",
       "           0.16530298,  0.19959725,  0.18999602,  0.54339451,  0.17245667,\n",
       "           0.20343   ,  0.20144697,  0.21498483,  0.16222988,  0.48995075,\n",
       "           0.35195434,  0.19767182,  0.13778596,  0.17895173,  0.53491217,\n",
       "           0.15857095,  0.15217386,  0.12806736,  0.13386048,  0.42747873,\n",
       "           0.27455324,  0.51126987,  0.35524914,  0.4455865 ,  0.46516192,\n",
       "           0.29675874,  0.25799906,  0.53513217,  0.11893533,  0.13181843,\n",
       "           0.33068994,  0.25535655,  0.22066098,  0.36143869,  0.1252905 ,\n",
       "           0.15433341,  0.46827394,  0.45203537,  0.22797358,  0.38312384,\n",
       "           0.22008948,  0.11568797,  0.30682671,  0.13204789,  0.29494271,\n",
       "           0.51395178,  0.1559829 ,  0.23177783,  0.12097967,  0.12154212,\n",
       "           0.0826455 ,  0.43639013,  0.11905567,  0.12637222,  0.16054466,\n",
       "           0.13068247,  0.39011106,  0.31246823,  0.17816663,  0.44930971,\n",
       "           0.15580469,  0.20460191,  0.11460689,  0.40385538,  0.19766977,\n",
       "           0.12408961,  0.15874371,  0.50978273,  0.21637435,  0.15448982,\n",
       "           0.11701018,  0.49621087,  0.46746352,  0.20624828,  0.15204905,\n",
       "           0.12833934,  0.19180179,  0.16886777,  0.16757749,  0.16969724,\n",
       "           0.14413393,  0.20817693,  0.22331235,  0.1834079 ,  0.14067368,\n",
       "           0.22101001,  0.1609256 ,  0.44076857,  0.20050049,  0.70131356,\n",
       "           0.21503207,  0.14257096,  0.15970825,  0.19796279,  0.1828059 ,\n",
       "           0.49965808,  0.16965587,  0.10810354,  0.38690883,  0.254024  ,\n",
       "           0.16831057,  0.16220619,  0.40504786,  0.17397609,  0.15053485,\n",
       "           0.51388419,  0.10921677,  0.29986686,  0.56774706,  0.17076188,\n",
       "           0.14433992,  0.14795975,  0.25302312,  0.3727701 ,  0.29905641,\n",
       "           0.18765895,  0.4153443 ,  0.16381021,  0.11306795,  0.48379657,\n",
       "           0.19262171,  0.63758183,  0.14062262,  0.12938516,  0.16165721,\n",
       "           0.22295535,  0.38797164,  0.15010577,  0.16526784,  0.14254852,\n",
       "           0.18298347,  0.16914707,  0.14215213,  0.19459043,  0.14852482,\n",
       "           0.52236277,  0.40899947,  0.42918915,  0.20974393,  0.15583174,\n",
       "           0.49930969,  0.25389016,  0.15538001,  0.14959992,  0.47548944,\n",
       "           0.28802189,  0.18098384,  0.15710604,  0.11198474,  0.51133025,\n",
       "           0.33123791,  0.53775758,  0.55389059,  0.14932002,  0.14221486,\n",
       "           0.14545235,  0.40968081,  0.1500199 ,  0.11575592,  0.35670939,\n",
       "           0.20526305,  0.43468127,  0.19561404,  0.18514806,  0.16921154,\n",
       "           0.18650904,  0.23815402,  0.40441057,  0.35845149,  0.14552082,\n",
       "           0.1338146 ,  0.14659669,  0.15276322,  0.42966485,  0.39882264,\n",
       "           0.2216178 ,  0.17387179,  0.1673283 ,  0.2713677 ,  0.3679691 ,\n",
       "           0.48637411,  0.19580387,  0.39974111,  0.11829212,  0.16877992,\n",
       "           0.13403237,  0.14315544,  0.35690811,  0.29087341,  0.31881946,\n",
       "           0.13816775,  0.11902315,  0.19371755,  0.13045096,  0.18810263,\n",
       "           0.62338012,  0.1765551 ,  0.16842705,  0.52973568,  0.51888567,\n",
       "           0.15918477,  0.15358216,  0.15769768,  0.16072577,  0.11051851,\n",
       "           0.18277864,  0.25623319,  0.19875303,  0.43466079,  0.14895211,\n",
       "           0.19120924,  0.18981791,  0.24231678,  0.13555586,  0.1990841 ,\n",
       "           0.37874117,  0.12882587,  0.1464306 ,  0.15504389,  0.23893197,\n",
       "           0.11736625,  0.16605915,  0.40607518,  0.1650929 ,  0.42688698,\n",
       "           0.13727336,  0.10752257,  0.14586034,  0.17569011,  0.21063112,\n",
       "           0.64861107,  0.22804859,  0.21728086,  0.32249993,  0.24534766,\n",
       "           0.57638192,  0.16436489,  0.35850272,  0.13534382,  0.54493523,\n",
       "           0.13181214,  0.18528889,  0.11799667,  0.15609927,  0.41356149,\n",
       "           0.13526399,  0.16232783,  0.10178943,  0.45897433,  0.60451156,\n",
       "           0.52037114,  0.33973643,  0.14921857,  0.5705477 ,  0.42751884,\n",
       "           0.13109726,  0.12434205,  0.13963087,  0.27411193,  0.15124717,\n",
       "           0.17148992,  0.30029559,  0.62859064,  0.62655944,  0.16463417,\n",
       "           0.14839043,  0.15664153,  0.12092292,  0.32654822,  0.1442917 ,\n",
       "           0.1066081 ,  0.22569987,  0.11885043,  0.14774169,  0.15306173,\n",
       "           0.21342626,  0.56958026,  0.13992681,  0.35112178,  0.49018753,\n",
       "           0.17771946,  0.16205651,  0.18535683,  0.32883257,  0.2214722 ,\n",
       "           0.43784431,  0.1596445 ,  0.21058017,  0.08297287,  0.16465043,\n",
       "           0.46685946,  0.35517934,  0.17680344,  0.1487758 ,  0.11924289,\n",
       "           0.13172774,  0.21294434,  0.17025052,  0.33727762,  0.30514374,\n",
       "           0.31704888,  0.09339242,  0.17418283,  0.12574106,  0.09955546,\n",
       "           0.15166271,  0.13504496,  0.59748334,  0.44091156,  0.39355931,\n",
       "           0.46056789,  0.48957232,  0.09491849,  0.50971562,  0.11308402,\n",
       "           0.14039552,  0.18982139,  0.39686853,  0.45182607,  0.1461685 ,\n",
       "           0.15522929,  0.19682327,  0.51319438,  0.42174724,  0.12207081,\n",
       "           0.1244299 ,  0.13289481,  0.12409481,  0.23921971,  0.14010923,\n",
       "           0.53480333,  0.14899781,  0.18613723,  0.60083205,  0.17167202,\n",
       "           0.14380936,  0.21545631,  0.27496976,  0.37242308,  0.11708751,\n",
       "           0.22240214,  0.50885117,  0.13870172,  0.14004682,  0.39206481], dtype=float32),\n",
       "   array([[-0.00952746,  0.09230374,  0.03920511, ..., -0.14138348,\n",
       "           -0.08098073, -0.14973965],\n",
       "          [-0.12412772,  0.05266326, -0.0372453 , ..., -0.0452973 ,\n",
       "            0.09155407, -0.02164446],\n",
       "          [-0.02658583, -0.06641168,  0.00881298, ..., -0.0753989 ,\n",
       "            0.0240614 ,  0.13040411],\n",
       "          ..., \n",
       "          [-0.02340817,  0.13412936, -0.01401269, ..., -0.05348763,\n",
       "           -0.17349014,  0.04602573],\n",
       "          [ 0.00306201,  0.04593765, -0.15106158, ..., -0.05743726,\n",
       "           -0.05135289,  0.06017494],\n",
       "          [-0.05675852,  0.0859102 , -0.21363844, ...,  0.04189748,\n",
       "           -0.01039178,  0.16330867]], dtype=float32),\n",
       "   array([[ 0.0387481 ,  0.02573139,  0.02089083, ...,  0.03178865,\n",
       "            0.00828913,  0.02839646],\n",
       "          [-0.02195158,  0.02433233,  0.01269031, ..., -0.01574755,\n",
       "           -0.0339696 ,  0.0374044 ],\n",
       "          [-0.00496437,  0.03620088,  0.01062447, ..., -0.04073476,\n",
       "            0.06395229,  0.02777268],\n",
       "          ..., \n",
       "          [-0.08224893,  0.03813897, -0.04094067, ..., -0.04490616,\n",
       "            0.00865213, -0.00582505],\n",
       "          [ 0.04891623, -0.01566724, -0.00579283, ..., -0.00293211,\n",
       "           -0.02316931, -0.01515231],\n",
       "          [-0.0239202 ,  0.01286003,  0.00102337, ...,  0.02241703,\n",
       "            0.03810085,  0.05069743]], dtype=float32),\n",
       "   array([-0.16904746,  0.27199861,  0.05474234,  0.18049645, -0.10380384,\n",
       "          -0.17497478,  0.20552643,  0.18142825, -0.19955967,  0.20607819,\n",
       "           0.20811127, -0.15050533, -0.26588193,  0.1892166 , -0.03064773,\n",
       "           0.21738265, -0.05553181, -0.22946358,  0.17156772, -0.18956828,\n",
       "          -0.22985806, -0.22139187,  0.21235365,  0.21485651,  0.07528257,\n",
       "          -0.18938287, -0.18622102,  0.1535625 , -0.19953054,  0.22602665,\n",
       "           0.21378711, -0.08487163, -0.12350151, -0.14398848,  0.22322515,\n",
       "          -0.20637397,  0.15294942,  0.22731386, -0.03288289, -0.17375939,\n",
       "          -0.15523054, -0.24032408,  0.17906508,  0.05339511,  0.17695731,\n",
       "           0.27914095, -0.17236103, -0.18857314,  0.08936729, -0.17351103,\n",
       "           0.18263191,  0.27429798, -0.16560628,  0.257907  ,  0.03029952,\n",
       "          -0.04450982,  0.13645682, -0.16226049, -0.19358085, -0.12714146,\n",
       "          -0.1700552 , -0.20784609,  0.22432598,  0.19202308,  0.1679139 ,\n",
       "          -0.20227416, -0.18056932,  0.23617561,  0.22482546,  0.20309958,\n",
       "          -0.20929624,  0.16709323,  0.27075669, -0.19923037,  0.20127453,\n",
       "           0.18576433, -0.1701701 , -0.01476158, -0.34299511, -0.08501851,\n",
       "           0.12023987,  0.26403141,  0.16552612,  0.19182278,  0.1028471 ,\n",
       "           0.03280994,  0.19103548,  0.17278974, -0.31641698,  0.17664999,\n",
       "           0.13015136,  0.20329991, -0.00262977,  0.066861  ,  0.21409529,\n",
       "           0.19092566, -0.15809038, -0.11242309,  0.25484669,  0.1638318 ,\n",
       "           0.05822838,  0.20817944, -0.23512308,  0.03028522,  0.17188974,\n",
       "           0.23652972, -0.25676697,  0.16374889,  0.01263216, -0.22224545,\n",
       "          -0.21076635,  0.17545968,  0.20906834, -0.16959871, -0.18192905,\n",
       "          -0.22336549, -0.07842462,  0.25282744, -0.21226139, -0.16017327,\n",
       "           0.20389053, -0.19340305, -0.07636162, -0.18664736,  0.23180288,\n",
       "           0.16052444, -0.18070798,  0.22531641,  0.21566944, -0.13975832,\n",
       "          -0.06724934,  0.19679888, -0.13839233, -0.18751353,  0.16816692,\n",
       "          -0.26639581,  0.21079381, -0.09796593,  0.21474165, -0.25607955,\n",
       "           0.14209905,  0.1568238 ,  0.1557727 ,  0.11674484,  0.02841009,\n",
       "           0.15367344, -0.1835134 ,  0.01725839,  0.27638468, -0.18669793,\n",
       "          -0.20456526, -0.15594956,  0.16700998, -0.0607763 ,  0.19770691,\n",
       "          -0.19674495,  0.17168754, -0.07878339,  0.18107368,  0.15943687,\n",
       "           0.18596092,  0.16918842,  0.19673657, -0.19648631, -0.22045401,\n",
       "           0.01345131, -0.04218023, -0.18262695,  0.11348102,  0.16403994,\n",
       "           0.16059074, -0.23895797, -0.2055327 ,  0.16381893, -0.14633702,\n",
       "           0.22208826,  0.15772699,  0.01694264, -0.31503579, -0.02923959,\n",
       "           0.2283982 , -0.18168725,  0.29633114, -0.2087207 ,  0.1541101 ,\n",
       "          -0.21241663, -0.21079241,  0.26112589, -0.16403854,  0.19673097,\n",
       "          -0.18017045, -0.00276271, -0.17422402, -0.24777029, -0.17079183,\n",
       "           0.23631939, -0.20975989,  0.06621233, -0.16617483, -0.25432441,\n",
       "          -0.17494071,  0.23599946,  0.16951518, -0.23109245, -0.19376637,\n",
       "          -0.27726495, -0.03478853,  0.09690999, -0.02229457, -0.24229386,\n",
       "           0.19256249, -0.18964568,  0.17552742,  0.18012652,  0.17899986,\n",
       "          -0.15941423, -0.03334732,  0.1720601 , -0.08895717,  0.1348204 ,\n",
       "           0.13138844,  0.16353558,  0.16940217, -0.21799763, -0.2686798 ,\n",
       "          -0.07247362,  0.04377358,  0.14268383, -0.11862548,  0.19857959,\n",
       "           0.19802493,  0.19828618, -0.2352576 ,  0.22570477, -0.24582566,\n",
       "           0.2882719 , -0.26691055, -0.16261066, -0.04268806, -0.17161207,\n",
       "          -0.16946687, -0.03147124,  0.16187149, -0.10601924, -0.1759308 ,\n",
       "           0.18809827, -0.15314282, -0.02894108,  0.19561784, -0.2364077 ,\n",
       "           0.20344359,  0.21207274,  0.21780695,  0.10855219,  0.19851094,\n",
       "           0.19957086,  0.17919487,  0.05608141, -0.18667534,  0.19358289,\n",
       "          -0.22518781,  0.18505053,  0.24993372,  0.15735523, -0.06492554,\n",
       "           0.13435416, -0.22941993,  0.25464839, -0.18654524,  0.20483711,\n",
       "          -0.17356744, -0.23315126, -0.22944924,  0.15488942,  0.07784004,\n",
       "          -0.18294688,  0.05272065, -0.06525002,  0.06258687, -0.19214164,\n",
       "           0.18616363, -0.07899448,  0.17097518, -0.211578  ,  0.10278093,\n",
       "          -0.05746089,  0.17669268, -0.17851298, -0.1733527 , -0.0640577 ,\n",
       "           0.16435911, -0.24112746,  0.26335785, -0.07366569, -0.18061376,\n",
       "          -0.19145828, -0.25629762,  0.22475208,  0.22979666,  0.00415492,\n",
       "          -0.09749582, -0.01014159, -0.28478795,  0.18742989,  0.13238861,\n",
       "           0.2001151 ,  0.18755715,  0.19247301, -0.17241825, -0.05215763,\n",
       "           0.07377779,  0.05705302,  0.17636244, -0.23241548,  0.20178695,\n",
       "           0.17675577,  0.03259901, -0.19226828, -0.16821052, -0.15585928,\n",
       "           0.10147808, -0.19710562, -0.02100307,  0.25480479,  0.18884189,\n",
       "           0.0797421 , -0.22675218,  0.03218022, -0.19890381,  0.01850945,\n",
       "          -0.15797299, -0.20260727, -0.20115498,  0.22596069,  0.05602634,\n",
       "           0.1795049 , -0.19313425,  0.05400439,  0.16202669, -0.18101944,\n",
       "           0.18651426, -0.17880224,  0.21423081, -0.10783336, -0.2838062 ,\n",
       "           0.07378948,  0.02703957, -0.18160523,  0.11833178,  0.13954367,\n",
       "          -0.19283687, -0.17519818,  0.21977963, -0.26458597,  0.05631541,\n",
       "          -0.05299584,  0.13926148, -0.20312686,  0.1739828 , -0.18913634,\n",
       "          -0.29647744, -0.1579587 ,  0.22385894,  0.20310088, -0.01438222,\n",
       "           0.14848906, -0.18736774,  0.03496952, -0.03781655,  0.07032859,\n",
       "          -0.05158505, -0.18721811,  0.04796805, -0.17394675, -0.25130385,\n",
       "          -0.19639644,  0.02653438, -0.17610294, -0.13101827, -0.1890018 ,\n",
       "          -0.18199992,  0.18654159, -0.06765002,  0.03677805,  0.27475837,\n",
       "           0.19337343, -0.18109189,  0.23451346,  0.27523246, -0.230387  ,\n",
       "           0.18856393,  0.05266193,  0.17684729, -0.18531211, -0.09040625,\n",
       "          -0.02933723, -0.09740089, -0.08029298,  0.15713066,  0.1773258 ,\n",
       "          -0.16417414,  0.13580182,  0.1916683 ,  0.06994762, -0.21037982,\n",
       "          -0.185525  , -0.17863329, -0.16740291,  0.20147574, -0.21069416,\n",
       "           0.13294199, -0.1674847 , -0.27427831,  0.20588583,  0.19764966,\n",
       "           0.18355832,  0.01063085,  0.19328792,  0.15438783,  0.26510105,\n",
       "          -0.19349165,  0.20017989, -0.24757341, -0.11177664,  0.03765389,\n",
       "           0.11925686, -0.2744284 , -0.06657229, -0.02553431, -0.12369123,\n",
       "           0.1692847 , -0.18999982,  0.27807078, -0.00358407,  0.19538982,\n",
       "          -0.19368775,  0.17855598,  0.17861328,  0.2053241 , -0.21294154,\n",
       "           0.10335653,  0.19620259, -0.16822085,  0.13564368, -0.18221283,\n",
       "           0.10862496,  0.00145425,  0.11596429,  0.04179806,  0.18180692,\n",
       "          -0.23545231, -0.19514945, -0.16011129, -0.04579389, -0.08817169,\n",
       "          -0.16171975, -0.2131395 ,  0.17507356, -0.01691184,  0.0308887 ,\n",
       "           0.20906653,  0.20888126,  0.078414  ,  0.23206373, -0.14089173,\n",
       "           0.05402337, -0.21264996,  0.18013354, -0.12034892,  0.18336822,\n",
       "          -0.1372464 ,  0.21747091, -0.07796677, -0.23305793, -0.20848566,\n",
       "           0.11300547, -0.25744101, -0.1530313 ,  0.02124177, -0.22122341,\n",
       "           0.17829752, -0.02593853, -0.24915442,  0.14593038,  0.07247403,\n",
       "           0.23224759,  0.23540112,  0.19825001,  0.16460133,  0.11099922,\n",
       "           0.19400294,  0.20912836, -0.17904189, -0.23130225, -0.16583587,\n",
       "          -0.2622788 ,  0.1689281 , -0.1835687 ,  0.00799274, -0.18239354,\n",
       "          -0.23411812, -0.04259112, -0.0472306 , -0.1784382 , -0.25222194,\n",
       "           0.04719525,  0.34968135,  0.31847942, -0.24534512, -0.20272094,\n",
       "          -0.2523312 ,  0.15321621, -0.20980531,  0.21078379,  0.17543189,\n",
       "           0.15758568, -0.21161352, -0.04883276,  0.1781117 , -0.21063931,\n",
       "           0.24347849,  0.20044145,  0.20118096,  0.12972285, -0.19678636,\n",
       "          -0.05619133, -0.04813943,  0.18611789, -0.12171629,  0.31484804,\n",
       "          -0.15692452, -0.28757083, -0.19986239, -0.18188003,  0.24039969,\n",
       "           0.23917839,  0.01376889, -0.03695059,  0.17380551,  0.07947004,\n",
       "          -0.22016527, -0.16667888, -0.086236  ,  0.0824286 , -0.12618569,\n",
       "           0.19323355,  0.06084486,  0.1803152 ,  0.14078206, -0.04719853,\n",
       "          -0.19461226,  0.04431627, -0.2022697 ,  0.18483897,  0.24201788,\n",
       "           0.11472532,  0.16580665,  0.18058358, -0.09168897,  0.11119834,\n",
       "          -0.06110214, -0.18176632, -0.10776805, -0.16163941,  0.17619532,\n",
       "           0.20614269, -0.17834596,  0.18055385, -0.1286428 , -0.18355915,\n",
       "          -0.19370191,  0.18439682,  0.18578966, -0.18476351,  0.26377022,\n",
       "          -0.06911348, -0.07781685, -0.04079488, -0.17132694,  0.21345939,\n",
       "           0.21916716,  0.24111634, -0.08951881, -0.18832771, -0.30399239,\n",
       "          -0.01517971, -0.1740707 ,  0.14191806,  0.17781809, -0.24119204,\n",
       "           0.09642176,  0.04563581, -0.19682042, -0.05050367, -0.16913147,\n",
       "          -0.0783883 ,  0.18128918,  0.13311712,  0.13274889, -0.21731931,\n",
       "           0.10959814, -0.2018601 ,  0.18937419, -0.04911468, -0.24900994,\n",
       "          -0.20475538, -0.21476084,  0.04649932, -0.18550767, -0.31956783,\n",
       "           0.07750187, -0.15491341, -0.22390524,  0.18015802,  0.08559907,\n",
       "          -0.11074819,  0.0418014 , -0.19799447,  0.14350747,  0.20176789,\n",
       "           0.18141331, -0.21483967,  0.16906004,  0.22357573,  0.1711081 ,\n",
       "           0.10127572, -0.19547214,  0.17965807, -0.16925086, -0.09975228,\n",
       "          -0.07131015,  0.18280701,  0.16370127, -0.04220612, -0.16997559,\n",
       "          -0.21103935,  0.18060203,  0.0463186 ,  0.01269424, -0.16573794,\n",
       "          -0.1935485 , -0.08312016, -0.2210163 , -0.03348527,  0.24174601,\n",
       "           0.23907177,  0.18851423, -0.28914505,  0.20235337, -0.07708111,\n",
       "          -0.22143893, -0.19767076, -0.34599298,  0.10246403, -0.1688727 ,\n",
       "           0.18043959, -0.17551349, -0.25618294,  0.11159342,  0.13204046,\n",
       "          -0.1467872 ,  0.28688014,  0.3034682 ,  0.16020809, -0.14836101,\n",
       "          -0.01774958,  0.24061921,  0.25192633, -0.19591987, -0.09138473,\n",
       "           0.21041933, -0.17548652, -0.19820756,  0.18468256, -0.15713488,\n",
       "           0.05441267,  0.08947047, -0.06880038, -0.14091958,  0.06892537,\n",
       "           0.01262761,  0.18294117, -0.09814278,  0.16459359,  0.15203835,\n",
       "          -0.04076787, -0.13691628,  0.17516635,  0.03772884,  0.1667164 ,\n",
       "           0.20045263,  0.07954688, -0.01606714, -0.18728153, -0.01677091,\n",
       "           0.13778347, -0.15972012, -0.06353511, -0.21481237,  0.18172693,\n",
       "           0.04630819, -0.20250478, -0.1727286 , -0.17191949, -0.16513385,\n",
       "           0.17224087, -0.07535336, -0.19159175, -0.1826092 ,  0.23081906,\n",
       "           0.18206872, -0.09056383, -0.05054542, -0.19683652, -0.01764802,\n",
       "          -0.20196049,  0.18862168,  0.16310847,  0.02772688,  0.22021264,\n",
       "           0.20948659,  0.23389553, -0.14348638,  0.15093447,  0.18559843,\n",
       "           0.16013332,  0.09857702, -0.06260151,  0.21624196,  0.2053501 ,\n",
       "          -0.21904303, -0.24354535,  0.20819591,  0.20493388, -0.20659307,\n",
       "           0.19332795,  0.14912149,  0.25201508, -0.29904884, -0.1796325 ,\n",
       "          -0.14126815,  0.19885699, -0.07265104,  0.20839147, -0.10690095,\n",
       "          -0.26500416,  0.16902173, -0.19170336, -0.17833641,  0.12383798,\n",
       "          -0.10866701,  0.22249334,  0.17896631,  0.05694589, -0.05583766,\n",
       "          -0.18403961,  0.25526476,  0.02371611,  0.19676864,  0.20448315,\n",
       "          -0.08374275,  0.15195304, -0.05173066, -0.13877706, -0.24008083,\n",
       "          -0.16556738, -0.2002334 , -0.23352529, -0.05563459,  0.0293635 ,\n",
       "          -0.27669621, -0.07155905,  0.24336749, -0.19250762, -0.10047468,\n",
       "           0.21721844, -0.06249525, -0.15842815, -0.18061708,  0.24762541,\n",
       "          -0.16913106,  0.14860021,  0.20199014, -0.16559334,  0.19316594,\n",
       "          -0.23894991, -0.21047688, -0.17507561,  0.19754282, -0.21614406,\n",
       "          -0.11860257, -0.11249015, -0.04574189,  0.15583278, -0.1694774 ,\n",
       "           0.03298503,  0.17879865, -0.1833235 , -0.17806248, -0.07076815,\n",
       "          -0.02800961, -0.22687848,  0.23291725, -0.20708477,  0.1026797 ,\n",
       "           0.05218634, -0.13831553,  0.09176697, -0.16911356,  0.2020558 ,\n",
       "          -0.24739431, -0.01986159, -0.14404869, -0.18772042,  0.17842825,\n",
       "           0.19316764, -0.03363505, -0.19712746, -0.13858725, -0.18698566,\n",
       "          -0.2414199 ,  0.19063435, -0.06125901, -0.15375698,  0.1807159 ,\n",
       "          -0.1965813 , -0.2028321 ,  0.18652025,  0.07573784, -0.13856822,\n",
       "          -0.19356859, -0.22177677,  0.19938706, -0.06763266,  0.06890304,\n",
       "          -0.08308514, -0.20713153,  0.04501959,  0.20416592, -0.35201892,\n",
       "          -0.18087023,  0.31445891,  0.03283826,  0.02971653, -0.20217119,\n",
       "          -0.17865695, -0.17392072, -0.139851  , -0.21959877, -0.16188943,\n",
       "          -0.10965716,  0.23517832, -0.19926746, -0.12493579,  0.09930296,\n",
       "          -0.21592842, -0.20730835,  0.20194733,  0.2404602 ,  0.18814661,\n",
       "          -0.25208312, -0.20739938, -0.17091346,  0.05989225, -0.20555575,\n",
       "          -0.18755442, -0.25658503, -0.31277856, -0.20997545,  0.20462354,\n",
       "          -0.05183058,  0.16504385, -0.20155063, -0.21142536,  0.15015125,\n",
       "          -0.1898168 , -0.28010732, -0.06336509, -0.17562993,  0.06809091,\n",
       "           0.16693695,  0.15294838,  0.14633818, -0.19457318,  0.20198277,\n",
       "          -0.09258062, -0.23064667, -0.15927039, -0.02621587,  0.15187904,\n",
       "          -0.0926891 ,  0.21340516,  0.04346514, -0.18346359,  0.08599128,\n",
       "          -0.17036639,  0.20699033, -0.21104656, -0.20631166,  0.03778637,\n",
       "          -0.23548388, -0.2656503 , -0.15787208, -0.07533687,  0.03205432,\n",
       "           0.11576293,  0.01405843,  0.17994024,  0.12284163, -0.06383342,\n",
       "           0.19122547,  0.17832598, -0.22568601,  0.14528501,  0.21085453,\n",
       "          -0.21111299, -0.15135561, -0.11835128,  0.09312941,  0.18486473,\n",
       "          -0.15735613,  0.18250622,  0.21671386, -0.01442027, -0.19501054,\n",
       "           0.15770715,  0.18026873, -0.1592977 , -0.20567775, -0.19839136,\n",
       "           0.26350722, -0.08578832,  0.19764665, -0.06532522, -0.08442518,\n",
       "          -0.18254688, -0.18191521,  0.19538245, -0.05440373, -0.26450452,\n",
       "           0.0547066 , -0.19817595,  0.13937177,  0.17811938, -0.22008067,\n",
       "           0.09993608,  0.05475646, -0.1904459 , -0.19576049,  0.18539561,\n",
       "           0.15518996, -0.23771693,  0.19908981,  0.03028633, -0.02562238,\n",
       "          -0.05175529,  0.18370071,  0.23596615, -0.16560699,  0.17108817,\n",
       "          -0.17172302, -0.18013676, -0.05884766, -0.15757945, -0.02597872,\n",
       "          -0.15773514, -0.11427493, -0.16554445,  0.1240085 ,  0.16460893,\n",
       "          -0.19709817,  0.17226779,  0.03152421, -0.02229719, -0.22066511,\n",
       "          -0.15417981, -0.27716473,  0.05135192, -0.12001123,  0.16587859,\n",
       "          -0.16790895,  0.2932294 , -0.17369473,  0.17941076,  0.24327995,\n",
       "          -0.14132971,  0.22842579,  0.21676333, -0.11672603, -0.26824942,\n",
       "           0.23757769, -0.1946497 , -0.1540913 ,  0.13134241,  0.1833864 ,\n",
       "          -0.18940222,  0.01694491,  0.2119368 ,  0.1796246 , -0.06065989], dtype=float32),\n",
       "   array([[ 0.01516515, -0.02579973, -0.01234739, ...,  0.01242368,\n",
       "           -0.02503214,  0.03514403],\n",
       "          [ 0.00185499, -0.00842449,  0.01976632, ...,  0.05576935,\n",
       "           -0.00674847,  0.01855051],\n",
       "          [ 0.01468195,  0.05483782, -0.01945426, ...,  0.0105645 ,\n",
       "           -0.03314185, -0.05084606],\n",
       "          ..., \n",
       "          [ 0.03585349, -0.02468087,  0.00763142, ..., -0.04150214,\n",
       "            0.00637957,  0.06349584],\n",
       "          [ 0.04511692, -0.0223011 , -0.01522229, ...,  0.06733442,\n",
       "            0.01135979, -0.01906826],\n",
       "          [-0.03448626,  0.05808153, -0.06219909, ...,  0.00896613,\n",
       "           -0.0632774 ,  0.00661646]], dtype=float32),\n",
       "   array([[-0.04107019,  0.04654973,  0.01726144, ...,  0.0008521 ,\n",
       "           -0.02048482,  0.0176757 ],\n",
       "          [ 0.02307334, -0.01945304, -0.04721496, ...,  0.00268501,\n",
       "            0.00383861,  0.03303381],\n",
       "          [ 0.0098918 , -0.02190272,  0.01813251, ...,  0.03168445,\n",
       "           -0.01883233,  0.05425964],\n",
       "          ..., \n",
       "          [ 0.08495089,  0.01153914,  0.05607764, ..., -0.00774605,\n",
       "           -0.07619871, -0.0173578 ],\n",
       "          [-0.01448375,  0.04209649, -0.00992229, ...,  0.01741991,\n",
       "            0.04102275,  0.00693093],\n",
       "          [ 0.03626059, -0.03269883,  0.03633342, ...,  0.01905767,\n",
       "            0.04638482, -0.01516838]], dtype=float32),\n",
       "   array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32),\n",
       "   array([[ 0.03379557,  0.15716195, -0.18095703, ..., -0.22021902,\n",
       "           -0.12729083, -0.28460076],\n",
       "          [ 0.10778466, -0.04921561,  0.14575091, ..., -0.37763304,\n",
       "            0.38659161, -0.0752696 ],\n",
       "          [ 0.1055944 , -0.04011474, -0.00917711, ..., -0.20388085,\n",
       "            0.06416778,  0.17607647],\n",
       "          ..., \n",
       "          [ 0.26779544,  0.02368596,  0.02526487, ..., -0.24311042,\n",
       "           -0.3820051 ,  0.2747981 ],\n",
       "          [-0.12600024, -0.08101311,  0.25354356, ..., -0.12790781,\n",
       "           -0.28418103, -0.06078205],\n",
       "          [ 0.07874049,  0.00785828,  0.14885736, ...,  0.15604965,\n",
       "           -0.04045479,  0.17863932]], dtype=float32),\n",
       "   array([[ 0.01412528, -0.0102639 , -0.01893821, ..., -0.04403826,\n",
       "            0.08197472, -0.01038972],\n",
       "          [ 0.0289072 ,  0.04140273, -0.06142228, ...,  0.0078589 ,\n",
       "            0.03380815,  0.04523342],\n",
       "          [ 0.00761545, -0.02381059,  0.02938818, ..., -0.08767883,\n",
       "           -0.00486393,  0.0294561 ],\n",
       "          ..., \n",
       "          [ 0.02989209, -0.03220414, -0.00074226, ..., -0.07405414,\n",
       "           -0.01759776, -0.06464975],\n",
       "          [ 0.03328545,  0.02946434,  0.00208879, ...,  0.0400706 ,\n",
       "            0.01083111, -0.00667944],\n",
       "          [-0.02651519,  0.06005763,  0.01523605, ...,  0.00890969,\n",
       "            0.0718189 , -0.01453212]], dtype=float32),\n",
       "   array([ 0.15727563,  0.24601921,  0.39292505,  0.18726602,  0.55056983,\n",
       "           0.14060828,  0.21399145,  0.16404904,  0.18828116,  0.22379941,\n",
       "           0.1749597 ,  0.34974101,  0.23470937,  0.22364475,  0.47115996,\n",
       "           0.17185515,  0.43542895,  0.26451653,  0.27314547,  0.21963392,\n",
       "           0.20041433,  0.18978561,  0.18737571,  0.25365722,  0.38871929,\n",
       "           0.15902452,  0.17214191,  0.12002819,  0.21100233,  0.1723236 ,\n",
       "           0.16389161,  0.43034211,  0.53091019,  0.15074022,  0.18485448,\n",
       "           0.16124782,  0.321253  ,  0.19118617,  0.45323914,  0.21108988,\n",
       "           0.16103962,  0.21723443,  0.17949276,  0.40678987,  0.15224743,\n",
       "           0.24052744,  0.15972023,  0.16885099,  0.43315396,  0.15294613,\n",
       "           0.18516152,  0.16802874,  0.13800745,  0.23183972,  0.31596211,\n",
       "           0.37032935,  0.44129598,  0.30124131,  0.18861318,  0.20584285,\n",
       "           0.21818131,  0.2604112 ,  0.15264437,  0.14068983,  0.16165975,\n",
       "           0.19587329,  0.17957896,  0.21777195,  0.20850362,  0.19627371,\n",
       "           0.2042215 ,  0.26601809,  0.23980567,  0.20983593,  0.19638014,\n",
       "           0.18310198,  0.14634387,  0.27730033,  0.25192738,  0.44330251,\n",
       "           0.47892895,  0.27502108,  0.15507554,  0.26823616,  0.52479613,\n",
       "           0.40280592,  0.15820391,  0.25169015,  0.2326719 ,  0.22213987,\n",
       "           0.51085246,  0.15941562,  0.39087373,  0.39864942,  0.21957853,\n",
       "           0.16313851,  0.39203694,  0.52989322,  0.21985517,  0.16631527,\n",
       "           0.41933304,  0.22939746,  0.37472054,  0.31324467,  0.18613689,\n",
       "           0.22246155,  0.15392046,  0.20426992,  0.42008141,  0.1938998 ,\n",
       "           0.19604683,  0.22723143,  0.1674698 ,  0.21166955,  0.16130871,\n",
       "           0.18127327,  0.44444636,  0.20736098,  0.20327015,  0.15039431,\n",
       "           0.21077578,  0.19328092,  0.56438977,  0.16344361,  0.18305948,\n",
       "           0.22888455,  0.16791245,  0.20647842,  0.19533212,  0.37281927,\n",
       "           0.43160507,  0.18841904,  0.33031988,  0.19966592,  0.20298064,\n",
       "           0.19834507,  0.16529498,  0.58990282,  0.1967402 ,  0.30951884,\n",
       "           0.37332872,  0.13695879,  0.18369967,  0.6026935 ,  0.39577627,\n",
       "           0.29009125,  0.1578164 ,  0.37347072,  0.20075969,  0.1713383 ,\n",
       "           0.21428408,  0.22322263,  0.14012045,  0.41014442,  0.22611837,\n",
       "           0.37536794,  0.19612427,  0.46043888,  0.15964459,  0.23480713,\n",
       "           0.15004951,  0.1816159 ,  0.18305585,  0.19996245,  0.18912552,\n",
       "           0.26812133,  0.31399539,  0.15370657,  0.43357992,  0.23624672,\n",
       "           0.15571372,  0.18917258,  0.20489615,  0.13993673,  0.28352097,\n",
       "           0.18603945,  0.15767674,  0.34990633,  0.26185185,  0.31737694,\n",
       "           0.20316809,  0.16620521,  0.26342699,  0.20812449,  0.25858876,\n",
       "           0.21192622,  0.19530855,  0.25337574,  0.16274557,  0.19576174,\n",
       "           0.19072728,  0.3925747 ,  0.23157482,  0.21251324,  0.14498577,\n",
       "           0.22814526,  0.20207377,  0.33473614,  0.15918207,  0.21560016,\n",
       "           0.15496418,  0.18446156,  0.14399679,  0.20802017,  0.14764242,\n",
       "           0.15894687,  0.35505474,  0.47519976,  0.34785163,  0.17196234,\n",
       "           0.14561184,  0.16970515,  0.21615738,  0.14354596,  0.2057417 ,\n",
       "           0.19267491,  0.41640648,  0.14853065,  0.472552  ,  0.42852354,\n",
       "           0.41874993,  0.13363148,  0.28043467,  0.22132587,  0.22726308,\n",
       "           0.45550066,  0.42849791,  0.47165206,  0.46174118,  0.20280154,\n",
       "           0.15290698,  0.22117212,  0.249799  ,  0.18703459,  0.17067705,\n",
       "           0.48912019,  0.2148716 ,  0.18945552,  0.50572628,  0.28473735,\n",
       "           0.15999542,  0.39206606,  0.15901463,  0.46958116,  0.2149355 ,\n",
       "           0.23485221,  0.18082948,  0.34767321,  0.24698174,  0.18722016,\n",
       "           0.17154278,  0.2221957 ,  0.18485883,  0.39041361,  0.18110295,\n",
       "           0.15886635,  0.23106632,  0.2425362 ,  0.17362382,  0.24242067,\n",
       "           0.20536278,  0.28491893,  0.20221563,  0.63290936,  0.29442099,\n",
       "           0.45627126,  0.19994326,  0.23299892,  0.27627131,  0.17044538,\n",
       "           0.16936025,  0.14458358,  0.20146191,  0.15702477,  0.43407309,\n",
       "           0.15417466,  0.32562837,  0.37014681,  0.40422216,  0.16912608,\n",
       "           0.16153137,  0.3550629 ,  0.16735859,  0.2995716 ,  0.54166412,\n",
       "           0.44034556,  0.20480457,  0.29784718,  0.15759601,  0.6228947 ,\n",
       "           0.15393661,  0.23212619,  0.21011573,  0.32929394,  0.18056576,\n",
       "           0.1619944 ,  0.19866313,  0.17081359,  0.16864768,  0.43124551,\n",
       "           0.51435864,  0.33769384,  0.2636852 ,  0.26623905,  0.34370071,\n",
       "           0.22507632,  0.20644748,  0.15509354,  0.4337469 ,  0.46987247,\n",
       "           0.53621119,  0.44432443,  0.28009397,  0.22537066,  0.23239614,\n",
       "           0.33220226,  0.27905127,  0.15924618,  0.20867604,  0.14780068,\n",
       "           0.5666002 ,  0.16977125,  0.39129776,  0.25007433,  0.16802551,\n",
       "           0.44739306,  0.19329917,  0.43038207,  0.14478679,  0.38481098,\n",
       "           0.21293108,  0.1770408 ,  0.19144459,  0.25215769,  0.33803263,\n",
       "           0.21512288,  0.18261436,  0.35241753,  0.46137357,  0.19293481,\n",
       "           0.1744435 ,  0.15225942,  0.14875606,  0.57412994,  0.20642118,\n",
       "           0.46620476,  0.31017098,  0.16790339,  0.51756692,  0.30146199,\n",
       "           0.13151   ,  0.18456885,  0.20937429,  0.26176441,  0.262398  ,\n",
       "           0.35963839,  0.2626496 ,  0.19930731,  0.29894558,  0.23463064,\n",
       "           0.24805787,  0.14543095,  0.21454944,  0.17719467,  0.26637781,\n",
       "           0.44870713,  0.21230461,  0.40487683,  0.47601986,  0.51067305,\n",
       "           0.35478145,  0.15736826,  0.41038957,  0.14622472,  0.18433326,\n",
       "           0.16416828,  0.30102453,  0.14537998,  0.35278401,  0.16638999,\n",
       "           0.18522996,  0.24593934,  0.38666192,  0.32763577,  0.25896508,\n",
       "           0.15898253,  0.18192717,  0.22850032,  0.22805864,  0.15478097,\n",
       "           0.2226501 ,  0.37680283,  0.20137505,  0.15246078,  0.4348681 ,\n",
       "           0.41055205,  0.38746122,  0.54985046,  0.15899104,  0.35071611,\n",
       "           0.21099462,  0.59472579,  0.26754931,  0.48250398,  0.1696281 ,\n",
       "           0.16020453,  0.24771114,  0.63078302,  0.20999683,  0.17423263,\n",
       "           0.62557292,  0.28346825,  0.21295244,  0.220717  ,  0.19992884,\n",
       "           0.16031846,  0.28516483,  0.20089316,  0.14026178,  0.25902581,\n",
       "           0.15645148,  0.17610352,  0.17882396,  0.56914431,  0.34929046,\n",
       "           0.64077944,  0.1825776 ,  0.49075595,  0.28241813,  0.47784778,\n",
       "           0.21967959,  0.18312135,  0.21339253,  0.48818719,  0.18258265,\n",
       "           0.28916338,  0.20473316,  0.14555021,  0.20743531,  0.19135791,\n",
       "           0.46450689,  0.16508722,  0.16918112,  0.37756032,  0.20008585,\n",
       "           0.50667679,  0.42548686,  0.49799636,  0.35826391,  0.2058437 ,\n",
       "           0.18544573,  0.19298461,  0.25815591,  0.29871947,  0.46376073,\n",
       "           0.44158399,  0.16311695,  0.24571833,  0.4887028 ,  0.28469282,\n",
       "           0.2141467 ,  0.19008251,  0.41835791,  0.20708013,  0.17267886,\n",
       "           0.29671413,  0.2301524 ,  0.24875322,  0.45760313,  0.16738352,\n",
       "           0.42766073,  0.18613471,  0.67530817,  0.21018411,  0.18544702,\n",
       "           0.46219301,  0.21614242,  0.18215139,  0.31917119,  0.32071036,\n",
       "           0.18650135,  0.3122769 ,  0.20627728,  0.32879472,  0.44795004,\n",
       "           0.14793055,  0.17996624,  0.18122789,  0.15010674,  0.32635444,\n",
       "           0.17249554,  0.19510902,  0.22339687,  0.22560966,  0.1667943 ,\n",
       "           0.21827714,  0.43409088,  0.17255963,  0.43712544,  0.25744602,\n",
       "           0.27686906,  0.33674005,  0.3955524 ,  0.15956363,  0.22170191,\n",
       "           0.40703952,  0.26947752,  0.28488249,  0.19320232,  0.19405372,\n",
       "           0.18356986,  0.46028849,  0.18365292,  0.18895715,  0.16947313,\n",
       "           0.1896642 ,  0.21508949,  0.320914  ,  0.25045112,  0.2065509 ,\n",
       "           0.19485259,  0.15968288,  0.17232239,  0.51801378,  0.22262193,\n",
       "           0.4178119 ,  0.45163408,  0.15494296,  0.56128496,  0.31707197,\n",
       "           0.17716762,  0.29269528,  0.18931986,  0.21662416,  0.18466099,\n",
       "           0.21811783,  0.41558725,  0.41253361,  0.13732922,  0.35838816,\n",
       "           0.18318431,  0.15778904,  0.44589508,  0.53744537,  0.538405  ,\n",
       "           0.18823975,  0.42157519,  0.18361177,  0.33303559,  0.45803371,\n",
       "           0.17480008,  0.30077523,  0.16391438,  0.16327177,  0.17420651,\n",
       "           0.53971654,  0.13098435,  0.16002801,  0.36039463,  0.36249134,\n",
       "           0.34873191,  0.17850472,  0.45347309,  0.2584098 ,  0.24413399,\n",
       "           0.19608818,  0.1559761 ,  0.2026532 ,  0.31416574,  0.16945475,\n",
       "           0.22558787,  0.19744344,  0.2490817 ,  0.15591106,  0.20859466,\n",
       "           0.35222617,  0.45558637,  0.38692915,  0.1625324 ,  0.19858426,\n",
       "           0.21267761,  0.48297626,  0.3938981 ,  0.16155604,  0.22411256,\n",
       "           0.36110276,  0.16470689,  0.49029556,  0.17609848,  0.2420873 ,\n",
       "           0.50427389,  0.31652045,  0.17871314,  0.4697977 ,  0.20038638,\n",
       "           0.46220005,  0.24515459,  0.39595887,  0.55877924,  0.19620271,\n",
       "           0.50201309,  0.21446791,  0.16010022,  0.48713571,  0.24159785,\n",
       "           0.22327103,  0.17116551,  0.380364  ,  0.21807066,  0.32661834,\n",
       "           0.27238297,  0.3080807 ,  0.19568467,  0.23607294,  0.47805205,\n",
       "           0.50473595,  0.34474838,  0.18181323,  0.39011219,  0.1776962 ,\n",
       "           0.19393109,  0.34151337,  0.15148494,  0.19705585,  0.14664255,\n",
       "           0.45372921,  0.20793618,  0.17123534,  0.15171865,  0.57091635,\n",
       "           0.45836604,  0.17066887,  0.32540423,  0.40820539,  0.17531708,\n",
       "           0.21880549,  0.24746457,  0.51501667,  0.33814964,  0.17039913,\n",
       "           0.16657807,  0.47435331,  0.19141094,  0.37983945,  0.24005093,\n",
       "           0.17640088,  0.14912632,  0.26594374,  0.20161036,  0.36139017,\n",
       "           0.18263835,  0.1763172 ,  0.25181881,  0.49750444,  0.2228554 ,\n",
       "           0.21376109,  0.2388429 ,  0.23779711,  0.47766763,  0.20990717,\n",
       "           0.24398217,  0.25300992,  0.25745445,  0.19521192,  0.50298274,\n",
       "           0.33575282,  0.22818796,  0.19248477,  0.22444414,  0.5187633 ,\n",
       "           0.21677017,  0.17451119,  0.16511504,  0.17029831,  0.46696758,\n",
       "           0.27321425,  0.48772189,  0.36629698,  0.44703642,  0.45973158,\n",
       "           0.28052908,  0.29969594,  0.51830691,  0.14881618,  0.14895639,\n",
       "           0.37110567,  0.29958728,  0.2693232 ,  0.38432178,  0.1552781 ,\n",
       "           0.18750943,  0.47014368,  0.47045574,  0.26046965,  0.39650741,\n",
       "           0.26122102,  0.17087212,  0.3240563 ,  0.16514894,  0.35774228,\n",
       "           0.50507522,  0.18437368,  0.26865172,  0.15928531,  0.15818383,\n",
       "           0.15513323,  0.44170439,  0.16121767,  0.15335974,  0.19886456,\n",
       "           0.17186396,  0.37898836,  0.34054568,  0.23321149,  0.4728533 ,\n",
       "           0.1828891 ,  0.24228464,  0.15410827,  0.41756448,  0.22236378,\n",
       "           0.16332823,  0.20540702,  0.48642012,  0.26855221,  0.19724776,\n",
       "           0.19237237,  0.50842571,  0.45776093,  0.25323296,  0.19203508,\n",
       "           0.17123158,  0.22921218,  0.20657191,  0.19789618,  0.19998842,\n",
       "           0.18141153,  0.25254023,  0.26621053,  0.25538465,  0.1682774 ,\n",
       "           0.2559185 ,  0.20228793,  0.39604631,  0.24075139,  0.66979337,\n",
       "           0.27021864,  0.16998582,  0.1855296 ,  0.21170224,  0.21334131,\n",
       "           0.49754778,  0.22224312,  0.13900746,  0.38432473,  0.24667142,\n",
       "           0.20138578,  0.20783991,  0.42043296,  0.20410773,  0.18419239,\n",
       "           0.52879918,  0.13808955,  0.30927625,  0.56364685,  0.20181176,\n",
       "           0.18211305,  0.17525154,  0.29019988,  0.37077722,  0.27626729,\n",
       "           0.25808898,  0.38013417,  0.21709488,  0.15479119,  0.45538455,\n",
       "           0.22513705,  0.59248006,  0.1654074 ,  0.15422034,  0.19949795,\n",
       "           0.26127413,  0.42334735,  0.1844629 ,  0.23080558,  0.16802023,\n",
       "           0.22293928,  0.20203096,  0.19212683,  0.22913277,  0.18826626,\n",
       "           0.53448129,  0.41156462,  0.38856125,  0.25049603,  0.20493917,\n",
       "           0.46613213,  0.27867356,  0.19238095,  0.17145468,  0.42507377,\n",
       "           0.26971033,  0.2748439 ,  0.1883318 ,  0.15592687,  0.51586306,\n",
       "           0.34163436,  0.53605521,  0.52010387,  0.17086847,  0.17251235,\n",
       "           0.21471055,  0.38034737,  0.19525301,  0.1538884 ,  0.41768891,\n",
       "           0.24621986,  0.42785433,  0.23608375,  0.26541594,  0.19788653,\n",
       "           0.24433856,  0.28971934,  0.41371149,  0.38213164,  0.17671905,\n",
       "           0.17275681,  0.1837558 ,  0.17750433,  0.40203515,  0.42582616,\n",
       "           0.25492096,  0.23718995,  0.19912192,  0.26767814,  0.34741503,\n",
       "           0.48003027,  0.2302147 ,  0.37352943,  0.14978096,  0.2242603 ,\n",
       "           0.16512252,  0.22508043,  0.38121063,  0.28952616,  0.34033147,\n",
       "           0.16719684,  0.17516544,  0.29261521,  0.16276875,  0.23157014,\n",
       "           0.55445009,  0.2042523 ,  0.19228715,  0.52327919,  0.51002491,\n",
       "           0.19003029,  0.17683525,  0.18611157,  0.2038798 ,  0.14208834,\n",
       "           0.21287093,  0.43650961,  0.23732831,  0.41798085,  0.18559347,\n",
       "           0.22731721,  0.22435531,  0.30653551,  0.1636274 ,  0.23893943,\n",
       "           0.36125693,  0.15690567,  0.17894733,  0.18367431,  0.31573415,\n",
       "           0.16237532,  0.2009218 ,  0.41395265,  0.19305129,  0.39358017,\n",
       "           0.17557059,  0.17370474,  0.21518812,  0.21445511,  0.25336069,\n",
       "           0.61008501,  0.26269168,  0.27932471,  0.33087516,  0.31043136,\n",
       "           0.56529742,  0.21743587,  0.39342195,  0.17318538,  0.49239758,\n",
       "           0.1610626 ,  0.226943  ,  0.14850305,  0.18753318,  0.42190024,\n",
       "           0.17355031,  0.21193829,  0.13519908,  0.4591952 ,  0.5395726 ,\n",
       "           0.51175958,  0.37343416,  0.1714697 ,  0.55853933,  0.41710514,\n",
       "           0.15826447,  0.16032581,  0.17883734,  0.31087488,  0.20563078,\n",
       "           0.20617089,  0.33845511,  0.60349876,  0.57989991,  0.19762231,\n",
       "           0.20050333,  0.18234931,  0.15736341,  0.32695049,  0.17783672,\n",
       "           0.13397361,  0.24211201,  0.14900728,  0.1803745 ,  0.18032201,\n",
       "           0.25106004,  0.53551954,  0.16531059,  0.36031649,  0.47527465,\n",
       "           0.21489041,  0.19562471,  0.21732043,  0.31996265,  0.25610304,\n",
       "           0.46023512,  0.18956454,  0.29356062,  0.15071775,  0.19242834,\n",
       "           0.44621742,  0.36061189,  0.20822875,  0.17471179,  0.17401803,\n",
       "           0.14354602,  0.24148215,  0.20734879,  0.33033195,  0.33470124,\n",
       "           0.31744593,  0.13332361,  0.22044897,  0.15916118,  0.13781539,\n",
       "           0.18286173,  0.17518078,  0.53428549,  0.46163198,  0.39326677,\n",
       "           0.50544274,  0.4672552 ,  0.14193586,  0.50124443,  0.1602443 ,\n",
       "           0.17106253,  0.21060848,  0.3948653 ,  0.44117382,  0.1937446 ,\n",
       "           0.20296703,  0.26281825,  0.48040736,  0.42546663,  0.17324752,\n",
       "           0.15185373,  0.24464156,  0.15681699,  0.27901953,  0.1891834 ,\n",
       "           0.53707772,  0.17753589,  0.21631549,  0.57619435,  0.20545873,\n",
       "           0.20953415,  0.22930549,  0.33897007,  0.40709582,  0.14473371,\n",
       "           0.2549729 ,  0.47115004,  0.17428306,  0.18808128,  0.39273077], dtype=float32),\n",
       "   array([[ 0.25536132,  0.23415436,  0.14083143, ...,  0.23377337,\n",
       "            0.2049593 ,  0.25719517],\n",
       "          [-0.24293412, -0.21401936,  0.01717809, ..., -0.30180371,\n",
       "           -0.21862052, -0.20041391],\n",
       "          [-0.23180814, -0.24309152, -0.28557369, ..., -0.24765432,\n",
       "           -0.22280133, -0.20899244],\n",
       "          ..., \n",
       "          [-0.27926859, -0.2996611 , -0.09094853, ..., -0.25684485,\n",
       "           -0.23710459, -0.27040976],\n",
       "          [-0.26906985, -0.26423046, -0.11735976, ..., -0.30015308,\n",
       "           -0.23241632, -0.24437228],\n",
       "          [ 0.25380003,  0.22556487,  0.2084244 , ...,  0.25820759,\n",
       "            0.18516386,  0.15818481]], dtype=float32),\n",
       "   array([-0.82716823, -0.88739777, -0.1569934 , -0.11924644, -0.09757822,\n",
       "          -0.13945353, -0.12466993, -0.00660037, -0.12857868, -0.1587778 ,\n",
       "          -0.33776057, -0.1346816 , -0.06720071, -0.15434335, -0.85454142,\n",
       "          -0.8844673 , -0.84854496, -0.83814925, -0.86048925, -0.84540552,\n",
       "          -0.86424649, -0.88283151, -0.72188485, -0.8363449 , -0.82252157,\n",
       "          -0.85701424, -0.82478416, -0.87373525, -0.88035083, -0.77203131,\n",
       "          -0.90211344, -0.86731291, -0.4507373 , -0.87226057, -0.1222837 ,\n",
       "          -0.15919134, -0.14724419, -0.21058963, -0.12079176, -0.15714255,\n",
       "          -0.14431863, -0.17680663, -0.18896239, -0.13511311, -0.17585857,\n",
       "          -0.13864028, -0.10839418, -0.19623388, -0.16409799, -0.18198077,\n",
       "          -0.22024933, -0.21015762, -0.12809905, -0.88205159, -0.85156018,\n",
       "          -0.77024734, -0.79597372, -0.82349253, -0.15115914, -0.15887806,\n",
       "          -0.09912878, -0.20441893, -0.21921913, -0.26080608, -0.13923655,\n",
       "          -0.37458873, -0.06842126, -0.1547544 , -0.25680649, -0.13684005,\n",
       "          -0.14115229, -0.15186073, -0.13381943, -0.11111294, -0.11361647,\n",
       "          -0.09991645, -0.26650935, -0.08310857, -0.07864092, -0.13037112,\n",
       "          -0.09827843, -0.11308303, -0.13375951, -0.71863908, -0.06589086,\n",
       "          -0.10081758, -0.08736105, -0.85486633, -0.85907954, -0.88953811,\n",
       "          -0.62486601, -0.08415388, -0.10142734, -0.20217335, -0.07924063,\n",
       "          -0.11960248, -0.12767522, -0.8432467 , -0.15484551,  0.05516737,\n",
       "          -0.10653566, -0.06018904, -0.09063264, -0.11304285, -0.08749906,\n",
       "          -0.13398898, -0.10120806, -0.14831167, -0.80400753, -0.81120229,\n",
       "          -0.80675405, -0.05090191, -0.11711884, -0.20274997, -0.04099168,\n",
       "          -0.13011958, -0.13872041, -0.25829795, -0.50512367, -0.87471938,\n",
       "          -0.80917567, -0.76522994, -0.89112794, -0.90035528, -0.84414041,\n",
       "          -0.87655562, -0.87630832, -0.90779757, -0.86825228, -0.85525388,\n",
       "          -0.82875603, -0.46006602, -0.84441698, -0.08093947, -0.1128578 ,\n",
       "          -0.06444612, -0.09305221, -0.74646091, -0.22415024, -0.09683358,\n",
       "          -0.90533131, -0.18228537, -0.12278333, -0.208873  , -0.13865383,\n",
       "          -0.26701316, -0.10768738, -0.12474228, -0.11072781, -0.18603416,\n",
       "          -0.84793407, -0.78536296, -0.85700089, -0.8448357 , -0.88829517,\n",
       "          -0.79557371, -0.88452739, -0.85821056, -0.72241008, -0.84910595,\n",
       "          -0.78943217, -0.12416691, -0.14239301, -0.11729461, -0.83404791,\n",
       "          -0.91125089, -0.15972605, -0.22305381, -0.78877038, -0.60697073,\n",
       "          -0.88843799, -0.85219449, -0.85602379, -0.8341831 , -0.81939119,\n",
       "          -0.89617693, -0.11945446, -0.1423865 , -0.12325498, -0.14625563,\n",
       "          -0.63312763, -0.29510418, -0.12738952, -0.13379346, -0.38197559,\n",
       "          -0.79036266, -0.64876491, -0.13390887, -0.0892878 , -0.1127216 ,\n",
       "          -0.8702724 , -0.11651938, -0.11212385, -0.11243523, -0.89550102,\n",
       "          -0.23289968, -0.33793908, -0.14770001, -0.10239049, -0.13136984,\n",
       "          -0.12172914, -0.08330208, -0.18011346, -0.12959826, -0.10064096,\n",
       "          -0.12555066, -0.11984438, -0.1580018 , -0.13749932, -0.18775807,\n",
       "          -0.12972762, -0.84674895, -0.12882243, -0.10768294, -0.15084492,\n",
       "          -0.8562181 , -0.12937966, -0.14024702, -0.41701636, -0.21488653,\n",
       "          -0.20757268, -0.54194993, -0.66018593, -0.35149136, -0.28044257,\n",
       "          -0.29950494, -0.16117889, -0.13722478, -0.20981085, -0.1372325 ,\n",
       "          -0.13592428, -0.0769122 , -0.16759992, -0.16198966, -0.16445389,\n",
       "          -0.12733971, -0.12312622, -0.27565527, -0.29795346, -0.13096903,\n",
       "          -0.83161342, -0.08634163, -0.72376031, -0.82681173, -0.86514723,\n",
       "          -0.84945941, -0.87114668, -0.78552777, -0.85341769, -0.29951078,\n",
       "          -0.1986378 , -0.70785117, -0.11060718, -0.8015033 , -0.04290461,\n",
       "          -0.25690815, -0.16726375, -0.11746748, -0.16246539, -0.23371927,\n",
       "          -0.19746672, -0.14779866, -0.16125192, -0.14151977, -0.15911131,\n",
       "          -0.21809754, -0.37154505, -0.15713972, -0.25002405, -0.22647603,\n",
       "          -0.89245486, -0.85180169, -0.87542498, -0.79448855, -0.90089536,\n",
       "          -0.82317293, -0.85290062, -0.10807385, -0.11597162, -0.14209549,\n",
       "          -0.34163719, -0.09965581, -0.12583487, -0.86837649, -0.08918703,\n",
       "          -0.09643728, -0.11786442, -0.38606608, -0.09792413, -0.10042402,\n",
       "          -0.11828969, -0.07235736, -0.12600042, -0.09942591, -0.45477018,\n",
       "          -0.08595043, -0.16244453, -0.19817328, -0.1461207 , -0.19778495,\n",
       "          -0.24215893, -0.31175229, -0.57725543, -0.28130755, -0.18240061,\n",
       "          -0.10038707, -0.31716362, -0.08465975, -0.23742181, -0.12461665,\n",
       "          -0.10635768, -0.23231463, -0.11853158, -0.90694803, -0.0842545 ,\n",
       "          -0.14098658, -0.19296218, -0.129673  , -0.46997684, -0.21192157,\n",
       "          -0.08198435, -0.12140445, -0.16876428, -0.1460706 , -0.11840445,\n",
       "          -0.16511542, -0.07757957, -0.18440884, -0.0818434 , -0.09580852,\n",
       "          -0.09004367, -0.1155793 , -0.13340399, -0.13464774, -0.84515417,\n",
       "          -0.161302  , -0.18403012, -0.09943509, -0.34660518, -0.26472732,\n",
       "          -0.20899774, -0.20736182, -0.21241233, -0.2140393 , -0.17844763,\n",
       "          -0.90043288, -0.0751317 , -0.18253972, -0.15492046, -0.1261421 ,\n",
       "          -0.10811505, -0.75354207, -0.74128306, -0.6749804 , -0.7864939 ,\n",
       "          -0.67517728, -0.58449638, -0.81433481, -0.84202963, -0.81761998,\n",
       "          -0.86109692, -0.08111421, -0.83629924, -0.89781564, -0.91500616,\n",
       "          -0.10911459, -0.11211116, -0.7208547 , -0.86007315, -0.0929597 ,\n",
       "          -0.88378239, -0.28509128, -0.2489861 , -0.21962607, -0.15831301,\n",
       "          -0.50325859, -0.1429345 , -0.32642895, -0.34280297, -0.58331656,\n",
       "          -0.81154609, -0.74513519, -0.83852386, -0.17547241, -0.06576346,\n",
       "           0.0059553 , -0.12379826, -0.22264399, -0.05114887, -0.17284389,\n",
       "          -0.03111565, -0.68769944, -0.9055438 , -0.64063787, -0.73495412,\n",
       "          -0.84173465, -0.14136149, -0.16002484, -0.77709848, -0.04688118,\n",
       "          -0.06136897, -0.25475562, -0.87331384, -0.10567276, -0.06061328,\n",
       "          -0.05654764, -0.12603781, -0.11823709, -0.06116165, -0.3474271 ,\n",
       "          -0.22255221, -0.62419617, -0.12835792, -0.10588928, -0.87638658,\n",
       "          -0.14784661, -0.23620096, -0.79419643, -0.09921643, -0.84753716,\n",
       "          -0.12976612, -0.27357528, -0.10252176, -0.08919286, -0.86743778,\n",
       "          -0.1632344 , -0.19333848, -0.06420326, -0.92086935, -0.83727103,\n",
       "          -0.80515289, -0.26840624, -0.71805489, -0.66536236, -0.35085168,\n",
       "          -0.34014919, -0.89347696, -0.7569319 , -0.11429629,  0.03708313,\n",
       "          -0.88272452, -0.04770581, -0.03609287, -0.40507379, -0.40356934,\n",
       "          -0.44930235, -0.52706444, -0.70414102, -0.85074586, -0.28439847,\n",
       "          -0.88369501, -0.5487749 , -0.34404999, -0.13440156, -0.13814563,\n",
       "          -0.1198701 , -0.83128953, -0.85133386, -0.11386185, -0.1017166 ,\n",
       "          -0.81075323, -0.15256326, -0.91843033, -0.87211037, -0.09398513,\n",
       "          -0.68541574, -0.1465688 , -0.2007733 , -0.12285293, -0.15879883,\n",
       "          -0.13067016, -0.15297641, -0.78469688, -0.11335286, -0.16055328,\n",
       "          -0.80492896, -0.84362763, -0.90816724, -0.80877185, -0.44734007,\n",
       "          -0.29542476, -0.13905334, -0.09638368, -0.20498522, -0.17947856,\n",
       "          -0.11762751, -0.64401317, -0.27064469, -0.26978108, -0.12976025,\n",
       "          -0.46081322, -0.13781646, -0.25894728, -0.78902239, -0.74072069,\n",
       "          -0.11509036, -0.88562024, -0.139395  , -0.17978601, -0.87797326,\n",
       "          -0.2194566 , -0.21138197, -0.85575724, -0.07805898, -0.85625255,\n",
       "          -0.60468036, -0.80374748, -0.2187798 , -0.14699835, -0.21725175,\n",
       "          -0.18834527, -0.71328586, -0.3483648 , -0.26958993, -0.1273347 ,\n",
       "          -0.36300778, -0.10677616, -0.25537801, -0.10728803, -0.43196049,\n",
       "          -0.85737544, -0.8510018 , -0.12119758, -0.10287397, -0.13848621,\n",
       "          -0.14508887, -0.12448134, -0.10946541, -0.62898517, -0.11457898,\n",
       "          -0.118407  , -0.83956444, -0.14297181, -0.11359741, -0.12002909,\n",
       "          -0.15501359, -0.06336346, -0.09000797, -0.10694858, -0.87408632,\n",
       "          -0.10363417, -0.11049688, -0.11669749, -0.09010965, -0.10026541,\n",
       "          -0.11311278, -0.11935044, -0.28176814, -0.11660416, -0.14193101,\n",
       "          -0.87461239, -0.03885187, -0.13635123, -0.17966019, -0.24847457,\n",
       "          -0.90810978, -0.84377819, -0.86019915, -0.13472247, -0.13312855,\n",
       "          -0.07796077, -0.79343152, -0.11012659, -0.09594919, -0.1211416 ,\n",
       "          -0.07918186, -0.852368  , -0.13166305, -0.09418338, -0.07101073,\n",
       "          -0.07877096, -0.12790678, -0.13706246, -0.89921063, -0.11167292,\n",
       "          -0.86546648, -0.09046933, -0.13179795, -0.13364765, -0.10994848,\n",
       "          -0.13147883, -0.07851173, -0.1296721 , -0.32671121, -0.82450795,\n",
       "          -0.12661074, -0.12453207, -0.11689775, -0.18603934, -0.85082185,\n",
       "          -0.52468622, -0.87953991, -0.85112989, -0.12043724, -0.21115327,\n",
       "          -0.20961232, -0.75471973, -0.83244473, -0.11192644, -0.10149295,\n",
       "          -0.0851654 , -0.09899522, -0.13985227, -0.04677678, -0.83248335,\n",
       "          -0.11276116, -0.08049761, -0.09997326, -0.11753599, -0.16431713,\n",
       "          -0.29531723, -0.81004709, -0.40709364, -0.88325822, -0.13873917,\n",
       "          -0.17186278, -0.88230187, -0.75061166, -0.82225156, -0.85177904,\n",
       "          -0.18147272, -0.11068389, -0.86930764, -0.86607343, -0.09802401,\n",
       "          -0.03347012, -0.21860239, -0.14936127, -0.14405856, -0.4143208 ,\n",
       "          -0.88144779, -0.487894  , -0.22161946, -0.16550878, -0.11756553,\n",
       "          -0.14767817, -0.38729277, -0.17324342, -0.22017138, -0.21413532,\n",
       "          -0.20998567, -0.13885981, -0.16684818, -0.13042195, -0.16539332,\n",
       "          -0.09604301, -0.16979595, -0.11138096, -0.12637743, -0.11696793,\n",
       "          -0.85678214, -0.07387387, -0.11387658, -0.08982582, -0.82570928,\n",
       "          -0.15225531, -0.11449233, -0.87171918, -0.12337074, -0.1333046 ,\n",
       "          -0.35194671, -0.34939638, -0.09980698, -0.1228309 , -0.34318891,\n",
       "          -0.84397388, -0.82877964, -0.10752551, -0.11454386, -0.11988618,\n",
       "          -0.20448123, -0.12553076, -0.12546737, -0.19215181, -0.13381736,\n",
       "          -0.16143847, -0.24757184, -0.86578262, -0.71269917, -0.82277316,\n",
       "          -0.47556254, -0.67613208, -0.88302678, -0.88685936, -0.1200862 ,\n",
       "          -0.11980591, -0.21305108, -0.12132823, -0.1329435 , -0.16139708,\n",
       "          -0.09225557, -0.14030091, -0.13077667, -0.13605529, -0.10081934,\n",
       "          -0.12418395, -0.17196466, -0.15988   , -0.07251137, -0.13254812,\n",
       "          -0.88524473, -0.09242103, -0.18315123, -0.07535671, -0.11310701,\n",
       "          -0.76516104, -0.06035364, -0.69344121, -0.8715933 , -0.8290236 ,\n",
       "          -0.77963614, -0.10419305, -0.16488589, -0.20462744, -0.12985764,\n",
       "          -0.04849418, -0.14183912, -0.90671939, -0.85906833, -0.12231231,\n",
       "          -0.17257445, -0.67706829, -0.2024468 , -0.29994991, -0.85875076,\n",
       "          -0.68453133, -0.9161129 , -0.77237499, -0.83793706, -0.50061059,\n",
       "          -0.1247335 , -0.11843009, -0.08989386, -0.14730856, -0.77105528,\n",
       "          -0.79311144, -0.41580692, -0.36670896, -0.48299885, -0.1866101 ,\n",
       "          -0.01592024, -0.18327083, -0.80867362, -0.48158425, -0.05386152,\n",
       "          -0.66417116, -0.18730585, -0.15775965, -0.79274708, -0.8492462 ,\n",
       "          -0.03978931, -0.62272853, -0.10290796, -0.87502581, -0.17140725,\n",
       "          -0.18925111, -0.1539636 , -0.1621969 , -0.19686741, -0.80349529,\n",
       "          -0.838718  , -0.89115292, -0.11678135, -0.15660118, -0.86812323,\n",
       "          -0.44591564, -0.11329979, -0.8317427 , -0.85048079, -0.77323788,\n",
       "          -0.17443725, -0.20834763, -0.49194345, -0.16055468, -0.08365697,\n",
       "          -0.49922922, -0.88462603, -0.75665808, -0.79657817, -0.18347351,\n",
       "          -0.07677644, -0.3350254 , -0.26327091, -0.1080777 , -0.85579139,\n",
       "          -0.15650725, -0.06918447, -0.83416879, -0.86833787, -0.07137109,\n",
       "          -0.04949367, -0.81769145, -0.67031294, -0.8568083 , -0.72383839,\n",
       "          -0.20125294, -0.80126482, -0.8892678 , -0.87376463, -0.80716872,\n",
       "          -0.88527572, -0.85397196, -0.8021422 , -0.47473705, -0.16783234,\n",
       "          -0.39662647, -0.15468737, -0.15957566, -0.35542127, -0.1284506 ,\n",
       "          -0.62139183, -0.88415653, -0.9020983 , -0.90691799, -0.52670866,\n",
       "          -0.77833092, -0.84738296, -0.81767881, -0.82474691, -0.82520097,\n",
       "          -0.82362688, -0.87829673, -0.91623503, -0.8539325 , -0.76514101,\n",
       "          -0.81640303, -0.88196987, -0.88616019, -0.90360636, -0.80590135,\n",
       "          -0.91940421, -0.78764898, -0.82650638, -0.91509801, -0.66029942,\n",
       "          -0.86631751, -0.89431924, -0.16626002, -0.14508885, -0.85240197,\n",
       "          -0.12950514, -0.11686701, -0.11417002, -0.364941  , -0.11192955,\n",
       "          -0.17096448, -0.01004389, -0.04440766, -0.57453787, -0.88367069,\n",
       "          -0.09325098, -0.04075087, -0.05295307, -0.09932844, -0.13339439,\n",
       "          -0.13899603, -0.88418096, -0.12656096, -0.11894287, -0.08076363,\n",
       "          -0.03385443, -0.73682457, -0.06956501, -0.14144202, -0.05787659,\n",
       "          -0.75730526, -0.67506629, -0.13455193, -0.1532077 , -0.13390671,\n",
       "          -0.10792021, -0.13036986, -0.13637373, -0.28577062, -0.10585426,\n",
       "          -0.09240896, -0.11857213, -0.79375339, -0.91824394, -0.75250381,\n",
       "          -0.88213271, -0.06665683, -0.83011919, -0.54766715, -0.76886088,\n",
       "          -0.74327987, -0.14498846, -0.55572426, -0.0944107 , -0.15026832,\n",
       "          -0.02983482, -0.08373155, -0.08537433, -0.92003596, -0.11297698,\n",
       "          -0.12202264, -0.27093974, -0.88383204, -0.04065547, -0.14854695,\n",
       "          -0.52199441, -0.1841107 , -0.14719117, -0.13810378, -0.75245625,\n",
       "          -0.10091823, -0.75287473, -0.81315386, -0.75553823, -0.43934801,\n",
       "          -0.9166081 , -0.87150532, -0.79611832, -0.87369496, -0.87250996,\n",
       "          -0.91517574, -0.90917128, -0.87349981, -0.88507921, -0.88760495,\n",
       "          -0.86376601, -0.88455439, -0.50162911, -0.79218787, -0.71735823,\n",
       "          -0.82204324, -0.87191677, -0.85734081, -0.90355504, -0.54523879,\n",
       "          -0.45712939, -0.83074296, -0.90462798, -0.91217542, -0.88250762,\n",
       "          -0.88069457, -0.87315524, -0.81519604, -0.88466829, -0.791192  ], dtype=float32)],\n",
       "  'duration': 97867.07986807823,\n",
       "  'epochs': 26,\n",
       "  'training_loss': [0.075892228981107826,\n",
       "   0.0070999453925293535,\n",
       "   0.0068098468231826978,\n",
       "   0.0066808552217727689,\n",
       "   0.0066058289906705415,\n",
       "   0.0065552427174750344,\n",
       "   0.006519341675192393,\n",
       "   0.0064915860771469387,\n",
       "   0.0064686015614847285,\n",
       "   0.0064492457102789209,\n",
       "   0.0064331823177996234,\n",
       "   0.0064158823478499168,\n",
       "   0.0064030725759677484,\n",
       "   0.0063909042779057732,\n",
       "   0.0063809967673144966,\n",
       "   0.006369630432197051,\n",
       "   0.0063601769948274638,\n",
       "   0.0063515037360138641,\n",
       "   0.0063437125467212434,\n",
       "   0.0063347625497970333,\n",
       "   0.0063280078511073843,\n",
       "   0.0063211699383277538,\n",
       "   0.00631475152492745,\n",
       "   0.0063083398007621732,\n",
       "   0.0063054618441816509,\n",
       "   0.0062981862635857712],\n",
       "  'validation_loss': [0.0063943661944791978,\n",
       "   0.0051024355327654496,\n",
       "   0.0047191411214055814,\n",
       "   0.0045606944254580097,\n",
       "   0.004452250871424185,\n",
       "   0.0043750744290905847,\n",
       "   0.0044204476717823061,\n",
       "   0.0043597578939986656,\n",
       "   0.0043924579547638129,\n",
       "   0.0042405138176450589,\n",
       "   0.0043881979629782396,\n",
       "   0.0043367232920431056,\n",
       "   0.0043486108305013102,\n",
       "   0.0044110828643257284,\n",
       "   0.0043139210933862632,\n",
       "   0.0043491785002188832,\n",
       "   0.0043671608390246442,\n",
       "   0.004392668659680291,\n",
       "   0.0044895020021298113,\n",
       "   0.0044029265528494682,\n",
       "   0.0044335009452221305,\n",
       "   0.0043555775144043648,\n",
       "   0.0043659771373158966,\n",
       "   0.0043799454766072672,\n",
       "   0.0044749607673511315,\n",
       "   0.0044068520110359588]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = valid_subclasses\n",
    "classifications_type = 'subclasses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_METRICS_FILENAME = '{}_level_{}_lstm_test_metrics.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec_size_200_w_2_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8\n"
     ]
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                            DOC2VEC_WINDOW, \n",
    "                                                            'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                            DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                            DOC2VEC_TRAIN_WORDS,\n",
    "                                                            DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                            str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "\n",
    "epoch = DOC2VEC_EPOCH\n",
    "\n",
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "print GLOBAL_VARS.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARTS_LEVEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_results_path = os.path.join(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                           NN_PARAMETER_SEARCH_PREFIX.format(classifications_type, PARTS_LEVEL, NN_BATCH_SIZE)))\n",
    "param_results_dict = pickle.load(open(param_results_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-16 12:59:14,062 : INFO : Loading Test Data from file\n"
     ]
    }
   ],
   "source": [
    "Xt, yt = get_test_data(classifications_type, PARTS_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "NN_INPUT_NEURONS = Xt.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-16 13:04:29,401 : INFO : ***************************************************************************************\n",
      "2017-04-16 13:04:29,402 : INFO : lstm_optimizer_rmsprop_size_1000_w-drop_0.5_u-drop_0.5_stack_1_conv_None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1000_w-drop_0.5_u-drop_0.5_ (None, 1000)          4804000     lstm_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sigmoid_output (Dense)           (None, 940)           940940      lstm_1000_w-drop_0.5_u-drop_0.5_l\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-16 13:04:35,877 : INFO : Evaluating on Test Data using best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 5744940\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-16 13:13:57,314 : INFO : Generating Test Metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test Metrics: Cov Err: 102.376, Avg Labels: 1.340, \n",
      "\t\t Top 1: 0.074, Top 3: 0.122, Top 5: 0.169, \n",
      "\t\t F1 Micro: 0.014, F1 Macro: 0.000, Total Pos: 76,156\n"
     ]
    }
   ],
   "source": [
    "lstm_output_size = 1000\n",
    "w_dropout_do = 0.5\n",
    "u_dropout_do = 0.5\n",
    "stack_layers = 1\n",
    "conv_size = None\n",
    "conv_filter_length = None\n",
    "conv_max_pooling_length = None\n",
    "\n",
    "GLOBAL_VARS.NN_MODEL_NAME = 'lstm_optimizer_{}_size_{}_w-drop_{}_u-drop_{}_stack_{}_conv_{}'.format(NN_OPTIMIZER,\n",
    "    lstm_output_size,  w_dropout_do, u_dropout_do, stack_layers, str(conv_size)\n",
    ")\n",
    "if conv_size:\n",
    "    GLOBAL_VARS.NN_MODEL_NAME += '_conv-filter-length_{}_max-pooling-size_{}'.format(conv_filter_length, \n",
    "                                                                                     conv_max_pooling_length)\n",
    "                                                                                     \n",
    "if GLOBAL_VARS.NN_MODEL_NAME not in param_results_dict.keys():\n",
    "    print \"Can't find model: {}\".format(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "    raise Exception()\n",
    "\n",
    "info('***************************************************************************************')\n",
    "info(GLOBAL_VARS.NN_MODEL_NAME)\n",
    "\n",
    "# creating the actual keras model\n",
    "model = create_keras_rnn_model(DOC2VEC_SIZE, NN_OUTPUT_NEURONS, \n",
    "                              lstm_output_size, w_dropout_do, u_dropout_do, stack_layers, conv_size, \n",
    "                               conv_filter_length, conv_max_pooling_length)\n",
    "model.summary()\n",
    "\n",
    "# get model best weights\n",
    "# weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['metrics_callback'].best_weights\n",
    "weights = param_results_dict[GLOBAL_VARS.NN_MODEL_NAME]['best_weights']\n",
    "model.set_weights(weights)\n",
    "\n",
    "info('Evaluating on Test Data using best weights')\n",
    "ytp = model.predict(Xt)\n",
    "ytp_binary = get_binary_0_5(ytp)\n",
    "#print yvp\n",
    "info('Generating Test Metrics')\n",
    "test_metrics = get_metrics(yt, ytp, ytp_binary)\n",
    "print \"** Test Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "    test_metrics['coverage_error'], test_metrics['average_num_of_labels'], \n",
    "    test_metrics['top_1'], test_metrics['top_3'], test_metrics['top_5'], \n",
    "    test_metrics['f1_micro'], test_metrics['f1_macro'], test_metrics['total_positive'])\n",
    "\n",
    "ensure_disk_location_exists(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "pickle.dump(test_metrics, open(os.path.join(nn_parameter_search_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                            TEST_METRICS_FILENAME.format(classifications_type, PARTS_LEVEL)), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
