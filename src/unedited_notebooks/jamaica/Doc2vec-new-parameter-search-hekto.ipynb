{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_WORD_COUNT = 20\n",
    "MIN_SIZE = 0\n",
    "NUM_CORES = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATIO = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "METRICS = \"metrics.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_file = \"/home/local/shalaby/docs_output_sample_100.json\"\n",
    "\n",
    "save_parent_location = \"hdfs://deka.cip.ifi.lmu.de/pg-vectors/\"\n",
    "if IS_SAMPLE: \n",
    "    save_parent_location = save_parent_location + \"sample_\" + str(SAMPLE_RATIO) + \"/\"\n",
    "\n",
    "\n",
    "root_location = \"/big/s/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "doc2vec_model_save_location = os.path.join(root_location, \"parameter_search_doc2vec_models_new\", \"sample_\" + str(SAMPLE_RATIO))\n",
    "if not os.path.exists(doc2vec_model_save_location):\n",
    "    os.makedirs(doc2vec_model_save_location)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL)):\n",
    "    os.makedirs(os.path.join(doc2vec_model_save_location, VOCAB_MODEL))\n",
    "\n",
    "#training_file = root_location + \"docs_output.json\"\n",
    "training_file = root_location + 'docs_output_training_validation_documents_' + str(SAMPLE_RATIO)\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_documents_\" + str(SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_documents_\" + str(SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "\n",
    "preprocessed_location = root_location + \"preprocessed_data/\"\n",
    "\n",
    "training_preprocessed_files_prefix = preprocessed_location + \"training_docs_sample_%s_data_preprocessed-\" % str(SAMPLE_RATIO)\n",
    "training_preprocessed_docids_files_prefix = preprocessed_location + \"training_docs_sample_%s_docids_preprocessed-\" % str(SAMPLE_RATIO)\n",
    "validation_preprocessed_files_prefix = preprocessed_location + \"validation_docs_sample_%s_data_preprocessed-\" % str(SAMPLE_RATIO)\n",
    "validation_preprocessed_docids_files_prefix = preprocessed_location + \"validation_docs_sample_%s_docids_preprocessed-\" % str(SAMPLE_RATIO)\n",
    "\n",
    "word2vec_questions_file = result = root_location + 'tensorflow/word2vec/questions-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 s, sys: 2.79 s, total: 31.3 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SMALL_SAMPLE_RATIO = 0.0001\n",
    "\n",
    "validation_small_preprocessed_files_prefix = root_location + \"validation_docs_sample_%s_data_preprocessed-\" % str(SMALL_SAMPLE_RATIO)\n",
    "validation_small_preprocessed_docids_files_prefix = root_location + \"validation_docs_sample_%s_docids_preprocessed-\" % str(SMALL_SAMPLE_RATIO)\n",
    "\n",
    "validation_small_docs_list_file = exports_location + \"validation_documents_\" + str(SMALL_SAMPLE_RATIO) + \"_sample.pkl\"\n",
    "validation_small_docs_list = pickle.load(open(validation_small_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49789"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12412"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            else:\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append(stem)\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_vector(classification, term_list, classifications, number_of_terms):\n",
    "    clss = 1 if classification in classifications else 0\n",
    "    return LabeledPoint(clss, SparseVector(number_of_terms, term_list))\n",
    "\n",
    "def train_level_new(docs_index, classification, doc_classification_map, number_of_terms):\n",
    "    training_vectors = docs_index.map(\n",
    "        lambda (doc_id, postings): get_training_vector(classification, postings,\n",
    "                                                        doc_classification_map[doc_id], number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE, regParam=SVM_REG)\n",
    "    return training_vectors, svm\n",
    "\n",
    "def model_exists(path):\n",
    "    try:\n",
    "        model = SVMModel.load(sc, path)\n",
    "        return True;\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def get_training_vector(classification, dense_vector, classifications):\n",
    "    clss = 1 if classification in classifications else 0\n",
    "    return LabeledPoint(clss, dense_vector)\n",
    "\n",
    "def train_level_doc2vec(classification, doc_classification_map):\n",
    "    doc2vec_model = GLOBAL_VARS.DOC2VEC_MODEL\n",
    "    training_vectors = []\n",
    "    for doc_id in training_docs_list:\n",
    "        # converting from memmap to a normal array as spark is unable to convert memmap to a spark Vector\n",
    "        normal_array = []\n",
    "        normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "        training_vectors.append(get_training_vector(classification, normal_array, \n",
    "                                                    doc_classification_map[doc_id]))\n",
    "    info(\"Finished getting training vectors\")\n",
    "    training_vectors = sc.parallelize(training_vectors)\n",
    "    info(\"Finished parallelization\")\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE, regParam=SVM_REG)\n",
    "    return training_vectors, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ensure_hdfs_location_exists(location):\n",
    "    parent = os.path.dirname(location)\n",
    "    os.system(\"hdfs dfs -mkdir -p \" + location)\n",
    "\n",
    "def ensure_disk_location_exists(location):\n",
    "    if not os.path.exists(location):\n",
    "        os.makedirs(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifications(classifications):\n",
    "    info(\"====== Doing Training\")\n",
    "    i=0\n",
    "    for classification in classifications:\n",
    "        print classification\n",
    "        try:\n",
    "            model_path = get_svm_model_path(GLOBAL_VARS.MODEL_NAME, classification)\n",
    "            if not model_exists(model_path):\n",
    "                training_vectors, svm = train_level_doc2vec(classification, doc_classification_map)\n",
    "                svm.save(sc, model_path)\n",
    "            else:\n",
    "                print \"Model Exists\"\n",
    "        except:\n",
    "            print \"Problem creating: %s: %s\" % (classification, GLOBAL_VARS.MODEL_NAME)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_validation(validation_vectors_matrix, doc_classification_map, classifications, classifications_name):\n",
    "\n",
    "    info(\"====== Doing Validation\")\n",
    "    method = GLOBAL_VARS.MODEL_NAME\n",
    "    subset = classifications_name\n",
    "\n",
    "    doc_count = validation_vectors_matrix.shape[0]\n",
    "    y_score = np.zeros((doc_count, len(classifications)))\n",
    "    y_true = np.zeros((doc_count, len(classifications)))\n",
    "    i=0\n",
    "\n",
    "    for classification in classifications:\n",
    "        print classification\n",
    "\n",
    "        validation_vectors = get_validation_doc2vec_spark_vectors(validation_vectors_matrix, \n",
    "                                                                  classification, doc_classification_map)\n",
    "        #global binarySvm\n",
    "        binarySvm = SVMModel.load(sc, get_svm_model_path(GLOBAL_VARS.MODEL_NAME, classification))\n",
    "        info(\"Loaded the model, Doing the prediction now....\")\n",
    "        binarySvm.clearThreshold()\n",
    "        binarySvmB = sc.broadcast(binarySvm)\n",
    "        # using the broadcasted binarySvm variable, fixes global name 'binarySvm' is not defined as this variable was not\n",
    "        # available in the workers, so we pass it explicitly to the mapper using partial\n",
    "        labels_predictions = validation_vectors.map( \\\n",
    "            partial(lambda svm, p: (p.label, svm.value.predict(p.features)), binarySvmB) \\\n",
    "        ).collect()\n",
    "        #labels = test_labeled_points.map(lambda p: p.labels)\n",
    "        y_true[:,i] = [label_pred[0] for label_pred in labels_predictions]\n",
    "        y_score[:,i] = [label_pred[1] for label_pred in labels_predictions]\n",
    "        i+=1\n",
    "    y_binary_score = get_binary(y_score)\n",
    "    # results[method][\"y_true\"] = y_true\n",
    "    # results[method][\"y_score\"] = y_score\n",
    "    # results[method][\"y_binary_score\"] = y_binary_score\n",
    "    metrics = get_metrics(y_true, y_score, y_binary_score)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference(doc2vec_model, doc_classification_map):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # do inference and store results in dict\n",
    "        i = 0\n",
    "        for (doc_id, doc_contents_array) in ValidationDocumentGenerator(training_file, validation_docs_list):\n",
    "            i += 1\n",
    "            if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "            validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "\n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in validation_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            validation_labels.append([classf for classf in doc_classification_map[validation_doc_id] if classf in sections])\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                           val_docs_list, val_preprocessed_files_prefix, val_preprocessed_docids_files_prefix):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_one_doc(doc_tuple):\n",
    "        #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "        doc_id, doc_tokens = doc_tuple\n",
    "        rep = doc2vec_model.infer_vector(doc_tokens)\n",
    "        return (doc_id, rep)\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_labels = []\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_labels = np.array(validation_labels)\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # Single-threaded inference\n",
    "        # do inference and store results in dict\n",
    "#         i = 0\n",
    "        \n",
    "#         validation_docs_iterator = DocumentBatchGenerator(val_preprocessed_files_prefix, \n",
    "#                                                         val_preprocessed_docids_files_prefix, batch_size=None)\n",
    "#         for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "#             i += 1\n",
    "#             if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "#             validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "        \n",
    "        # Multi-threaded inference\n",
    "        validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                          validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "        generator_func = validation_docs_iterator.__iter__()\n",
    "        pool = ThreadPool(NUM_CORES)\n",
    "        # map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "        validation_documents_reps = {}\n",
    "        mini_batch_size = 1000\n",
    "        while True:\n",
    "            threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "            info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "            if threaded_reps_partial:\n",
    "                #threaded_reps.extend(threaded_reps_partial)\n",
    "                validation_documents_reps.update(threaded_reps_partial)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "                \n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        validation_labels = np.array(validation_labels)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_doc2vec_spark_vectors(validation_vectors_matrix, classification, doc_classification_map):\n",
    "    validation_vectors = []\n",
    "    for (index, doc_id) in enumerate(validation_docs_list):\n",
    "        # converting from memmap to a normal array as spark is unable to convert memmap to a spark Vector\n",
    "        validation_vector = validation_vectors_matrix[index]\n",
    "        validation_vectors.append(get_training_vector(classification, validation_vector, \n",
    "                                                    doc_classification_map[doc_id]))\n",
    "    validation_vectors = sc.parallelize(validation_vectors)\n",
    "    info(\"Finished getting validation vectors\")\n",
    "    return validation_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "\n",
    "def get_training_data(doc2vec_model, classifications):\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for doc_id in training_docs_list:\n",
    "        # converting from memmap to a normal array\n",
    "        normal_array = []\n",
    "        normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "        training_data.append(normal_array)\n",
    "        eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "        training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))\n",
    "    training_labels = np.array(training_labels)\n",
    "    return training_data, training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "                    \n",
    "class DocumentBatchGenerator(object):\n",
    "    def __init__(self, filename_prefix, filename_docids_prefix, batch_size=10000 ):\n",
    "        \"\"\"\n",
    "        batch_size cant be > 10,000 due to a limitation in doc2vec training, \n",
    "        None means no batching (only use for inference)\n",
    "        \"\"\"\n",
    "        assert batch_size <= 10000 or batch_size is None\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.filename_docids_prefix = filename_docids_prefix\n",
    "        self.curr_lines = []\n",
    "        self.curr_docids = []\n",
    "        self.batch_size = batch_size\n",
    "        self.curr_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        self.curr_lines, self.docids = [], []\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_index) )\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    self.curr_lines.append(line.split(\" \"))\n",
    "#                     if i % 1000 == 0:\n",
    "#                         print i\n",
    "            self.curr_docids = pickle.load(open(self.filename_docids_prefix + str(self.curr_index), \"r\"))\n",
    "            self.batch_end = self.curr_index + len(self.curr_lines) -1 \n",
    "            info(\"Finished loading new batch\")\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_index))\n",
    "            raise StopIteration()\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            if self.curr_index > self.batch_end:\n",
    "                self.load_new_batch_in_memory()\n",
    "            for (doc_id, tokens) in zip(self.curr_docids, self.curr_lines):\n",
    "                if self.batch_size is not None:\n",
    "                    curr_batch_iter = 0\n",
    "                    # divide the document to batches according to the batch size\n",
    "                    while curr_batch_iter < len(tokens):\n",
    "                        yield LabeledSentence(words=tokens[curr_batch_iter: curr_batch_iter + self.batch_size], tags=[doc_id])\n",
    "                        curr_batch_iter += self.batch_size\n",
    "                else:\n",
    "                    yield doc_id, tokens\n",
    "                self.curr_index += 1\n",
    "\n",
    "class Word2VecTrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield stemtokenizer(text)\n",
    "                \n",
    "class ValidationDocumentGenerator(object):\n",
    "    def __init__(self, filename, validation_docs_list):\n",
    "        self.filename = filename\n",
    "        self.validation_docs_list = validation_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.validation_docs_list:\n",
    "                    yield doc_id, stemtokenizer(text)\n",
    "                    \n",
    "class StochasticDocumentGenerator(object):\n",
    "    \"\"\"\n",
    "    Randomly shuffle rows while reading them\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, training_docs_list, line_positions):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "        self.line_positions = line_positions\n",
    "        self.lines = set(line_positions.keys())\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            while len(self.lines) > 0:\n",
    "                random_line = random.sample(self.lines,1)[0]\n",
    "                self.lines.remove(random_line)\n",
    "                file_obj.seek(self.line_positions[random_line])\n",
    "                line = file_obj.readline()\n",
    "                if not line.strip(): continue\n",
    "#                 print random_line, self.line_positions[random_line], line[:30]\n",
    "                (doc_id, text) = eval(line)\n",
    "                # print random_line , doc_id\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "#                     yield doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get starting positions in bytes for every line to be able to do random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.62 s, sys: 592 ms, total: 7.22 s\n",
      "Wall time: 7.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "line_positions = dict()\n",
    "with open(training_file) as f:\n",
    "    \n",
    "    i = 0\n",
    "    line_positions[i] = f.tell()\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        i+=1\n",
    "        if not line.strip(): continue\n",
    "        line_positions[i] = f.tell()\n",
    "        line = f.readline()\n",
    "    del line_positions[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 500\n",
    "DOC2VEC_WINDOW = 8\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 20\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 1000 # report the progress every x terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_ITERATIONS = 100\n",
    "SVM_CONVERGENCE = 0.001\n",
    "SVM_REG = 0.01\n",
    "SVM_CLASS_WEIGHTS = 'balanced'\n",
    "GLOBAL_VARS.SVM_MODEL_NAME = 'svm_iter_{}_reg_{}_classweights_{}'.format(SVM_ITERATIONS, SVM_REG, str(SVM_CLASS_WEIGHTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_HIDDEN_NEURONS = 4500\n",
    "NN_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_svm_model_path(method, classification, reg=SVM_REG, iterations=SVM_ITERATIONS):\n",
    "    location = os.path.join(save_parent_location, \"models\", method, \n",
    "                            \"iter_\" + str(iterations) + \"_reg_\" + str(reg),\n",
    "                            classification + \"_model.svm\")\n",
    "    ensure_hdfs_location_exists(location)\n",
    "    return location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_{}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "placeholder_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(size=DOC2VEC_SIZE , window=DOC2VEC_WINDOW, min_count=MIN_WORD_COUNT, \n",
    "                max_vocab_size= DOC2VEC_MAX_VOCAB_SIZE,\n",
    "                sample=DOC2VEC_SAMPLE, seed=DOC2VEC_SEED, workers=NUM_CORES,\n",
    "                # doc2vec algorithm dm=1 => PV-DM, dm=2 => PV-DBOW, PV-DM dictates CBOW for words\n",
    "                dm=DOC2VEC_TYPE,\n",
    "                # hs=0 => negative sampling, hs=1 => hierarchical softmax\n",
    "                hs=DOC2VEC_HIERARCHICAL_SAMPLE, negative=DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                dm_concat=DOC2VEC_CONCAT,\n",
    "                # would train words with skip-gram on top of cbow, we don't need that for now\n",
    "                dbow_words=DOC2VEC_TRAIN_WORDS,\n",
    "                iter=DOC2VEC_EPOCHS)\n",
    "\n",
    "GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 16:17:05,569 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/vocab_model/model\n",
      "2017-01-01 16:17:06,468 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/vocab_model/model.docvecs.* with mmap=None\n",
      "2017-01-01 16:17:06,470 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/vocab_model/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-01 16:17:06,858 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/vocab_model/model.syn1neg.npy with mmap=None\n",
      "2017-01-01 16:17:08,271 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/vocab_model/model.syn0.npy with mmap=None\n",
      "2017-01-01 16:17:08,824 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-01 16:17:08,825 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-01 16:17:09,331 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.4 s, sys: 752 ms, total: 9.15 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_docs_iterator = DocumentBatchGenerator(training_preprocessed_files_prefix, \n",
    "                                                        training_preprocessed_docids_files_prefix, batch_size=10000)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX)):\n",
    "    doc2vec_model.build_vocab(sentences=training_docs_iterator, progress_per=REPORT_VOCAB_PROGRESS)\n",
    "    doc2vec_model.save(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX))\n",
    "else:\n",
    "    doc2vec_model_vocab_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX))\n",
    "    doc2vec_model.reset_from(doc2vec_model_vocab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocab_counts = {k:doc2vec_model.vocab[k].count for k in doc2vec_model.vocab.keys()}\n",
    "# dd = sorted(vocab_counts, key=vocab_counts.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training, validation and Metrics Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_model.min_alpha = 0.025\n",
    "epoch_validation_metrics = []\n",
    "epoch_training_metrics = []\n",
    "epoch_word2vec_metrics = []\n",
    "classifications = sections\n",
    "classifications_type = 'sections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'.format(classifications_type)\n",
    "TRAINING_METRICS_FILENAME = '{}_training_metrics.pkl'.format(classifications_type)\n",
    "METRICS_FIG_PNG_FILENAME = '{}_validation_metrics.png'.format(classifications_type)\n",
    "METRICS_FIG_PDF_FILENAME = '{}_validation_metrics.pdf'.format(classifications_type)\n",
    "WORD2VEC_METRICS_FILENAME = 'word2vec_metrics.pkl'\n",
    "\n",
    "# for epoch in range(DOC2VEC_MAX_EPOCHS):\n",
    "#     GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "# fig_save_location = placeholder_model_name.format('run')\n",
    "# plt.savefig(os.path.join(fig_save_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 16:17:21,847 : INFO : ****************** Epoch 1 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1 *******************\n",
      "2017-01-01 16:17:21,848 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 16:17:21,849 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 16:17:21,860 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 16:17:36,386 : INFO : Finished loading new batch\n",
      "2017-01-01 16:17:36,732 : INFO : PROGRESS: at 0.00% examples, 153 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:17:56,732 : INFO : PROGRESS: at 2.30% examples, 184268 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:18:16,764 : INFO : PROGRESS: at 5.04% examples, 254530 words/s, in_qsize 46, out_qsize 8\n",
      "2017-01-01 16:18:36,771 : INFO : PROGRESS: at 8.03% examples, 297085 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:18:56,781 : INFO : PROGRESS: at 11.24% examples, 326615 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:19:16,787 : INFO : PROGRESS: at 14.47% examples, 345161 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:19:36,789 : INFO : PROGRESS: at 17.85% examples, 361809 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:19:51,625 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 16:20:04,086 : INFO : Finished loading new batch\n",
      "2017-01-01 16:20:04,766 : INFO : PROGRESS: at 20.03% examples, 336794 words/s, in_qsize 21, out_qsize 0\n",
      "2017-01-01 16:20:24,767 : INFO : PROGRESS: at 23.24% examples, 348337 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:20:44,781 : INFO : PROGRESS: at 26.61% examples, 358891 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:21:04,819 : INFO : PROGRESS: at 29.75% examples, 365855 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:21:24,836 : INFO : PROGRESS: at 32.98% examples, 372102 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:21:44,872 : INFO : PROGRESS: at 36.23% examples, 377295 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:22:04,874 : INFO : PROGRESS: at 39.30% examples, 381089 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:22:11,683 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 16:22:24,178 : INFO : Finished loading new batch\n",
      "2017-01-01 16:22:25,316 : INFO : PROGRESS: at 40.13% examples, 363181 words/s, in_qsize 16, out_qsize 0\n",
      "2017-01-01 16:22:45,317 : INFO : PROGRESS: at 43.37% examples, 368567 words/s, in_qsize 46, out_qsize 6\n",
      "2017-01-01 16:23:05,314 : INFO : PROGRESS: at 46.74% examples, 374143 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:23:25,314 : INFO : PROGRESS: at 50.13% examples, 378875 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 16:23:45,327 : INFO : PROGRESS: at 53.53% examples, 383573 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 16:24:05,355 : INFO : PROGRESS: at 56.94% examples, 387567 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:24:26,091 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 16:24:26,114 : INFO : PROGRESS: at 60.14% examples, 388880 words/s, in_qsize 46, out_qsize 10\n",
      "2017-01-01 16:24:38,273 : INFO : Finished loading new batch\n",
      "2017-01-01 16:24:46,109 : INFO : PROGRESS: at 61.32% examples, 378941 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:25:06,122 : INFO : PROGRESS: at 64.63% examples, 382149 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:25:26,135 : INFO : PROGRESS: at 67.76% examples, 384033 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:25:46,151 : INFO : PROGRESS: at 70.87% examples, 385896 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 16:26:06,162 : INFO : PROGRESS: at 74.30% examples, 388759 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:26:26,164 : INFO : PROGRESS: at 77.68% examples, 391410 words/s, in_qsize 45, out_qsize 3\n",
      "2017-01-01 16:26:43,614 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 16:26:54,967 : INFO : Finished loading new batch\n",
      "2017-01-01 16:26:56,480 : INFO : PROGRESS: at 80.36% examples, 383599 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:27:16,486 : INFO : PROGRESS: at 83.74% examples, 386229 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:27:36,499 : INFO : PROGRESS: at 87.15% examples, 388772 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:27:56,502 : INFO : PROGRESS: at 90.51% examples, 391211 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 16:28:16,499 : INFO : PROGRESS: at 93.85% examples, 393178 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 16:28:36,503 : INFO : PROGRESS: at 97.07% examples, 394942 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:28:55,741 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 16:28:55,758 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 16:28:56,228 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 16:28:56,233 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 16:28:56,239 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 16:28:56,244 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 16:28:56,254 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 16:28:56,289 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 16:28:56,293 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 16:28:56,308 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 16:28:56,314 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 16:28:56,324 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 16:28:56,337 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 16:28:56,350 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 16:28:56,355 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 16:28:56,374 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 16:28:56,378 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 16:28:56,388 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 16:28:56,391 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 16:28:56,394 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 16:28:56,395 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 16:28:56,395 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 16:28:56,397 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 16:28:56,401 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 16:28:56,404 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 16:28:56,432 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 16:28:56,433 : INFO : training on 390507860 raw words (274491397 effective words) took 694.6s, 395195 effective words/s\n",
      "2017-01-01 16:28:56,540 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model, separately None\n",
      "2017-01-01 16:28:56,541 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 16:28:58,450 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn1neg.npy\n",
      "2017-01-01 16:29:03,143 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 16:29:03,145 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn0.npy\n",
      "2017-01-01 16:29:07,789 : INFO : not storing attribute cum_table\n",
      "2017-01-01 16:29:11,480 : INFO : precomputing L2-norms of word weight vectors\n",
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/gensim/models/word2vec.py:1616: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if predicted != expected:\n",
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/gensim/models/word2vec.py:1619: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if predicted == expected:\n",
      "2017-01-01 16:29:18,504 : INFO : capital-common-countries: 9.0% (14/156)\n",
      "2017-01-01 16:29:24,911 : INFO : capital-world: 5.9% (9/152)\n",
      "2017-01-01 16:29:26,593 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 16:30:18,691 : INFO : city-in-state: 1.7% (21/1248)\n",
      "2017-01-01 16:30:23,294 : INFO : family: 20.0% (22/110)\n",
      "2017-01-01 16:30:46,264 : INFO : gram1-adjective-to-adverb: 11.2% (62/552)\n",
      "2017-01-01 16:31:00,500 : INFO : gram2-opposite: 18.4% (63/342)\n",
      "2017-01-01 16:31:55,946 : INFO : gram3-comparative: 58.3% (777/1332)\n",
      "2017-01-01 16:32:27,411 : INFO : gram4-superlative: 15.3% (116/756)\n",
      "2017-01-01 16:33:06,099 : INFO : gram5-present-participle: 19.8% (184/930)\n",
      "2017-01-01 16:33:30,420 : INFO : gram6-nationality-adjective: 3.9% (23/584)\n",
      "2017-01-01 16:34:22,867 : INFO : gram7-past-tense: 10.8% (136/1260)\n",
      "2017-01-01 16:35:04,135 : INFO : gram8-plural: 24.6% (244/992)\n",
      "2017-01-01 16:35:33,299 : INFO : gram9-plural-verbs: 44.7% (314/702)\n",
      "2017-01-01 16:35:33,302 : INFO : total: 21.7% (1985/9156)\n",
      "2017-01-01 16:35:41,850 : INFO : Training Classifier\n",
      "2017-01-01 16:37:32,689 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 16:38:05,989 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 16:38:05,994 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 16:38:06,004 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.582, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.543, Top 3: 0.804, Top 5: 0.933, \n",
      "\t\t F1 Micro: 0.576, Total Pos: 119,478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 16:38:17,392 : INFO : Finished loading new batch\n",
      "2017-01-01 16:38:47,744 : INFO : Finished: 999\n",
      "2017-01-01 16:39:17,543 : INFO : Finished: 1999\n",
      "2017-01-01 16:39:46,213 : INFO : Finished: 2999\n",
      "2017-01-01 16:40:14,267 : INFO : Finished: 3999\n",
      "2017-01-01 16:40:43,372 : INFO : Finished: 4999\n",
      "2017-01-01 16:41:12,359 : INFO : Finished: 5999\n",
      "2017-01-01 16:41:39,891 : INFO : Finished: 6999\n",
      "2017-01-01 16:42:07,685 : INFO : Finished: 7999\n",
      "2017-01-01 16:42:36,311 : INFO : Finished: 8999\n",
      "2017-01-01 16:43:04,400 : INFO : Finished: 9999\n",
      "2017-01-01 16:43:06,790 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 16:43:09,653 : INFO : Finished loading new batch\n",
      "2017-01-01 16:43:38,731 : INFO : Finished: 10999\n",
      "2017-01-01 16:44:07,149 : INFO : Finished: 11999\n",
      "2017-01-01 16:44:07,580 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 16:44:07,583 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 16:44:20,323 : INFO : Finished: 12412\n",
      "2017-01-01 16:44:20,326 : INFO : Finished: 12412\n",
      "2017-01-01 16:44:24,785 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 1 1 0]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.418, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.527, Top 3: 0.820, Top 5: 0.946, \n",
      "\t\t F1 Micro: 0.586, Total Pos: 31,474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/matplotlib/axes/_base.py:2787: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=1, right=1\n",
      "  'left=%s, right=%s') % (left, right))\n",
      "2017-01-01 16:44:28,996 : INFO : ****************** Epoch 2 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2 *******************\n",
      "2017-01-01 16:44:29,002 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 16:44:29,004 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 16:44:29,018 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 16:44:38,719 : INFO : Finished loading new batch\n",
      "2017-01-01 16:44:39,328 : INFO : PROGRESS: at 0.00% examples, 646 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:44:59,356 : INFO : PROGRESS: at 2.90% examples, 266853 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:45:19,369 : INFO : PROGRESS: at 6.27% examples, 346450 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:45:39,382 : INFO : PROGRESS: at 9.65% examples, 377534 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:45:59,394 : INFO : PROGRESS: at 12.98% examples, 394723 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:46:19,398 : INFO : PROGRESS: at 16.29% examples, 405068 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 16:46:39,421 : INFO : PROGRESS: at 19.55% examples, 409812 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:46:44,288 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 16:46:55,336 : INFO : Finished loading new batch\n",
      "2017-01-01 16:46:59,451 : INFO : PROGRESS: at 20.47% examples, 373047 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:47:19,501 : INFO : PROGRESS: at 23.87% examples, 383808 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:47:39,528 : INFO : PROGRESS: at 27.21% examples, 390747 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:47:59,552 : INFO : PROGRESS: at 30.44% examples, 396564 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:48:19,599 : INFO : PROGRESS: at 33.73% examples, 401219 words/s, in_qsize 45, out_qsize 1\n",
      "2017-01-01 16:48:39,601 : INFO : PROGRESS: at 37.17% examples, 406301 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:48:59,169 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 16:48:59,602 : INFO : PROGRESS: at 40.04% examples, 406414 words/s, in_qsize 16, out_qsize 0\n",
      "2017-01-01 16:49:10,333 : INFO : Finished loading new batch\n",
      "2017-01-01 16:49:19,608 : INFO : PROGRESS: at 41.41% examples, 391412 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:49:39,621 : INFO : PROGRESS: at 44.63% examples, 395457 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:49:59,622 : INFO : PROGRESS: at 47.99% examples, 398755 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 16:50:19,627 : INFO : PROGRESS: at 51.28% examples, 401979 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:50:39,663 : INFO : PROGRESS: at 54.65% examples, 405300 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:50:59,684 : INFO : PROGRESS: at 58.09% examples, 408346 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:51:13,751 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 16:51:24,394 : INFO : Finished loading new batch\n",
      "2017-01-01 16:51:25,834 : INFO : PROGRESS: at 60.28% examples, 396799 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:51:45,836 : INFO : PROGRESS: at 63.62% examples, 399753 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:52:05,844 : INFO : PROGRESS: at 66.91% examples, 401732 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 16:52:25,847 : INFO : PROGRESS: at 70.14% examples, 403552 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:52:45,848 : INFO : PROGRESS: at 73.30% examples, 404824 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:53:05,877 : INFO : PROGRESS: at 76.56% examples, 406249 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:53:25,892 : INFO : PROGRESS: at 79.78% examples, 407595 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 16:53:31,019 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 16:53:41,548 : INFO : Finished loading new batch\n",
      "2017-01-01 16:53:45,918 : INFO : PROGRESS: at 80.79% examples, 397866 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:54:05,920 : INFO : PROGRESS: at 83.99% examples, 399291 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 16:54:25,945 : INFO : PROGRESS: at 87.29% examples, 400927 words/s, in_qsize 48, out_qsize 4\n",
      "2017-01-01 16:54:45,939 : INFO : PROGRESS: at 90.55% examples, 402651 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:55:05,944 : INFO : PROGRESS: at 93.93% examples, 404459 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 16:55:25,950 : INFO : PROGRESS: at 97.08% examples, 405620 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 16:55:46,246 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 16:55:46,256 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 16:55:46,257 : INFO : PROGRESS: at 99.85% examples, 404750 words/s, in_qsize 36, out_qsize 14\n",
      "2017-01-01 16:55:46,725 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 16:55:46,736 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 16:55:46,754 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 16:55:46,764 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 16:55:46,766 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 16:55:46,791 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 16:55:46,803 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 16:55:46,825 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 16:55:46,848 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 16:55:46,858 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 16:55:46,860 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 16:55:46,888 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 16:55:46,892 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 16:55:46,893 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 16:55:46,914 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 16:55:46,922 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 16:55:46,925 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 16:55:46,926 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 16:55:46,930 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 16:55:46,931 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 16:55:46,940 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 16:55:46,944 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 16:55:46,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 16:55:46,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 16:55:46,947 : INFO : training on 390507860 raw words (274490628 effective words) took 677.9s, 404896 effective words/s\n",
      "2017-01-01 16:55:46,950 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model, separately None\n",
      "2017-01-01 16:55:46,952 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 16:55:48,946 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn1neg.npy\n",
      "2017-01-01 16:55:53,624 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 16:55:53,625 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn0.npy\n",
      "2017-01-01 16:55:58,567 : INFO : not storing attribute cum_table\n",
      "2017-01-01 16:56:02,165 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 16:56:09,242 : INFO : capital-common-countries: 9.0% (14/156)\n",
      "2017-01-01 16:56:15,715 : INFO : capital-world: 6.6% (10/152)\n",
      "2017-01-01 16:56:17,403 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 16:57:08,842 : INFO : city-in-state: 3.0% (38/1248)\n",
      "2017-01-01 16:57:13,359 : INFO : family: 27.3% (30/110)\n",
      "2017-01-01 16:57:35,963 : INFO : gram1-adjective-to-adverb: 9.1% (50/552)\n",
      "2017-01-01 16:57:49,963 : INFO : gram2-opposite: 21.3% (73/342)\n",
      "2017-01-01 16:58:45,451 : INFO : gram3-comparative: 65.5% (873/1332)\n",
      "2017-01-01 16:59:15,926 : INFO : gram4-superlative: 18.1% (137/756)\n",
      "2017-01-01 16:59:53,440 : INFO : gram5-present-participle: 21.5% (200/930)\n",
      "2017-01-01 17:00:17,105 : INFO : gram6-nationality-adjective: 3.3% (19/584)\n",
      "2017-01-01 17:01:07,933 : INFO : gram7-past-tense: 14.2% (179/1260)\n",
      "2017-01-01 17:01:47,954 : INFO : gram8-plural: 35.7% (354/992)\n",
      "2017-01-01 17:02:16,278 : INFO : gram9-plural-verbs: 48.6% (341/702)\n",
      "2017-01-01 17:02:16,281 : INFO : total: 25.3% (2318/9156)\n",
      "2017-01-01 17:02:25,322 : INFO : Training Classifier\n",
      "2017-01-01 17:04:19,681 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:04:53,402 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 17:04:53,406 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 17:04:53,422 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.342, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.580, Top 3: 0.852, Top 5: 0.946, \n",
      "\t\t F1 Micro: 0.613, Total Pos: 112,862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:05:03,479 : INFO : Finished loading new batch\n",
      "2017-01-01 17:05:33,826 : INFO : Finished: 999\n",
      "2017-01-01 17:06:03,730 : INFO : Finished: 1999\n",
      "2017-01-01 17:06:32,630 : INFO : Finished: 2999\n",
      "2017-01-01 17:07:01,110 : INFO : Finished: 3999\n",
      "2017-01-01 17:07:30,491 : INFO : Finished: 4999\n",
      "2017-01-01 17:07:59,843 : INFO : Finished: 5999\n",
      "2017-01-01 17:08:28,146 : INFO : Finished: 6999\n",
      "2017-01-01 17:08:56,334 : INFO : Finished: 7999\n",
      "2017-01-01 17:09:25,317 : INFO : Finished: 8999\n",
      "2017-01-01 17:09:53,757 : INFO : Finished: 9999\n",
      "2017-01-01 17:09:56,246 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 17:09:58,509 : INFO : Finished loading new batch\n",
      "2017-01-01 17:10:27,818 : INFO : Finished: 10999\n",
      "2017-01-01 17:10:56,613 : INFO : Finished: 11999\n",
      "2017-01-01 17:10:57,031 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 17:10:57,034 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 17:11:09,779 : INFO : Finished: 12412\n",
      "2017-01-01 17:11:09,785 : INFO : Finished: 12412\n",
      "2017-01-01 17:11:14,429 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 1 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.384, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.552, Top 3: 0.839, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.597, Total Pos: 30,436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:11:18,601 : INFO : ****************** Epoch 3 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3 *******************\n",
      "2017-01-01 17:11:18,607 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 17:11:18,609 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 17:11:18,622 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 17:11:28,898 : INFO : Finished loading new batch\n",
      "2017-01-01 17:11:29,112 : INFO : PROGRESS: at 0.00% examples, 641 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:11:49,156 : INFO : PROGRESS: at 3.25% examples, 293481 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:12:09,178 : INFO : PROGRESS: at 6.43% examples, 353888 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 17:12:29,170 : INFO : PROGRESS: at 9.73% examples, 379511 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-01 17:12:49,176 : INFO : PROGRESS: at 13.03% examples, 395258 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:13:09,196 : INFO : PROGRESS: at 16.44% examples, 407791 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:13:29,218 : INFO : PROGRESS: at 19.72% examples, 413048 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 17:13:32,911 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 17:13:45,208 : INFO : Finished loading new batch\n",
      "2017-01-01 17:13:49,238 : INFO : PROGRESS: at 20.54% examples, 374217 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:14:09,245 : INFO : PROGRESS: at 23.83% examples, 382827 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:14:29,278 : INFO : PROGRESS: at 27.28% examples, 391405 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:14:49,274 : INFO : PROGRESS: at 30.61% examples, 398475 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:15:09,278 : INFO : PROGRESS: at 34.01% examples, 404416 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:15:29,279 : INFO : PROGRESS: at 37.47% examples, 409645 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:15:47,002 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 17:15:58,049 : INFO : Finished loading new batch\n",
      "2017-01-01 17:15:58,475 : INFO : PROGRESS: at 40.13% examples, 393785 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:16:18,518 : INFO : PROGRESS: at 43.46% examples, 398369 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 17:16:38,509 : INFO : PROGRESS: at 46.87% examples, 402785 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:16:58,517 : INFO : PROGRESS: at 50.34% examples, 406888 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:17:18,519 : INFO : PROGRESS: at 53.75% examples, 410367 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:17:38,540 : INFO : PROGRESS: at 57.11% examples, 412746 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 17:17:58,758 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 17:17:58,779 : INFO : PROGRESS: at 60.14% examples, 412270 words/s, in_qsize 28, out_qsize 20\n",
      "2017-01-01 17:18:09,402 : INFO : Finished loading new batch\n",
      "2017-01-01 17:18:18,785 : INFO : PROGRESS: at 61.68% examples, 403017 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:18:38,784 : INFO : PROGRESS: at 65.08% examples, 405899 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 17:18:58,794 : INFO : PROGRESS: at 68.50% examples, 408615 words/s, in_qsize 46, out_qsize 0\n",
      "2017-01-01 17:19:18,804 : INFO : PROGRESS: at 71.82% examples, 410763 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:19:38,814 : INFO : PROGRESS: at 75.23% examples, 412384 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 17:19:58,814 : INFO : PROGRESS: at 78.46% examples, 413700 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:20:11,794 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 17:20:21,951 : INFO : Finished loading new batch\n",
      "2017-01-01 17:20:22,685 : INFO : PROGRESS: at 80.36% examples, 405129 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:20:42,686 : INFO : PROGRESS: at 83.72% examples, 407031 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:21:02,715 : INFO : PROGRESS: at 87.09% examples, 408756 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:21:22,720 : INFO : PROGRESS: at 90.35% examples, 410211 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:21:42,731 : INFO : PROGRESS: at 93.62% examples, 411388 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-01 17:22:02,756 : INFO : PROGRESS: at 96.82% examples, 412610 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:22:24,128 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 17:22:24,150 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 17:22:24,152 : INFO : PROGRESS: at 99.85% examples, 411860 words/s, in_qsize 40, out_qsize 16\n",
      "2017-01-01 17:22:24,643 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 17:22:24,650 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 17:22:24,664 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 17:22:24,670 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 17:22:24,680 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 17:22:24,694 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 17:22:24,707 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 17:22:24,711 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 17:22:24,722 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 17:22:24,724 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 17:22:24,727 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 17:22:24,740 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 17:22:24,773 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 17:22:24,783 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 17:22:24,785 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 17:22:24,787 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 17:22:24,788 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 17:22:24,794 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 17:22:24,795 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 17:22:24,797 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 17:22:24,805 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 17:22:24,805 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 17:22:24,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 17:22:24,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 17:22:24,818 : INFO : training on 390507860 raw words (274488090 effective words) took 666.2s, 412023 effective words/s\n",
      "2017-01-01 17:22:24,821 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model, separately None\n",
      "2017-01-01 17:22:24,822 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 17:22:26,275 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn1neg.npy\n",
      "2017-01-01 17:22:30,731 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 17:22:30,732 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn0.npy\n",
      "2017-01-01 17:22:35,219 : INFO : not storing attribute cum_table\n",
      "2017-01-01 17:22:38,969 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 17:22:45,857 : INFO : capital-common-countries: 10.3% (16/156)\n",
      "2017-01-01 17:22:52,198 : INFO : capital-world: 7.9% (12/152)\n",
      "2017-01-01 17:22:53,831 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 17:23:44,247 : INFO : city-in-state: 4.4% (55/1248)\n",
      "2017-01-01 17:23:48,673 : INFO : family: 24.5% (27/110)\n",
      "2017-01-01 17:24:10,834 : INFO : gram1-adjective-to-adverb: 10.9% (60/552)\n",
      "2017-01-01 17:24:24,564 : INFO : gram2-opposite: 27.5% (94/342)\n",
      "2017-01-01 17:25:18,043 : INFO : gram3-comparative: 62.7% (835/1332)\n",
      "2017-01-01 17:25:48,388 : INFO : gram4-superlative: 20.6% (156/756)\n",
      "2017-01-01 17:26:25,720 : INFO : gram5-present-participle: 23.4% (218/930)\n",
      "2017-01-01 17:26:49,177 : INFO : gram6-nationality-adjective: 2.4% (14/584)\n",
      "2017-01-01 17:27:39,915 : INFO : gram7-past-tense: 12.1% (153/1260)\n",
      "2017-01-01 17:28:20,676 : INFO : gram8-plural: 38.2% (379/992)\n",
      "2017-01-01 17:28:48,833 : INFO : gram9-plural-verbs: 52.1% (366/702)\n",
      "2017-01-01 17:28:48,836 : INFO : total: 26.0% (2385/9156)\n",
      "2017-01-01 17:28:57,444 : INFO : Training Classifier\n",
      "2017-01-01 17:30:48,525 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:31:22,928 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 17:31:22,933 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 17:31:22,943 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.236, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.596, Top 3: 0.868, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.628, Total Pos: 110,566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:31:34,369 : INFO : Finished loading new batch\n",
      "2017-01-01 17:32:03,477 : INFO : Finished: 999\n",
      "2017-01-01 17:32:33,201 : INFO : Finished: 1999\n",
      "2017-01-01 17:33:02,118 : INFO : Finished: 2999\n",
      "2017-01-01 17:33:30,437 : INFO : Finished: 3999\n",
      "2017-01-01 17:33:59,373 : INFO : Finished: 4999\n",
      "2017-01-01 17:34:28,549 : INFO : Finished: 5999\n",
      "2017-01-01 17:34:56,514 : INFO : Finished: 6999\n",
      "2017-01-01 17:35:24,829 : INFO : Finished: 7999\n",
      "2017-01-01 17:35:53,947 : INFO : Finished: 8999\n",
      "2017-01-01 17:36:22,325 : INFO : Finished: 9999\n",
      "2017-01-01 17:36:24,718 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 17:36:26,818 : INFO : Finished loading new batch\n",
      "2017-01-01 17:36:55,909 : INFO : Finished: 10999\n",
      "2017-01-01 17:37:24,437 : INFO : Finished: 11999\n",
      "2017-01-01 17:37:24,865 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 17:37:24,868 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 17:37:37,597 : INFO : Finished: 12412\n",
      "2017-01-01 17:37:37,599 : INFO : Finished: 12412\n",
      "2017-01-01 17:37:42,017 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 1 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.370, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.548, Top 3: 0.839, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.597, Total Pos: 30,692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:37:46,060 : INFO : ****************** Epoch 4 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4 *******************\n",
      "2017-01-01 17:37:46,064 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 17:37:46,065 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 17:37:46,091 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 17:37:55,632 : INFO : Finished loading new batch\n",
      "2017-01-01 17:37:56,303 : INFO : PROGRESS: at 0.00% examples, 658 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:38:16,327 : INFO : PROGRESS: at 3.35% examples, 305757 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:38:36,330 : INFO : PROGRESS: at 6.74% examples, 371179 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:38:56,354 : INFO : PROGRESS: at 10.17% examples, 398600 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:39:16,386 : INFO : PROGRESS: at 13.63% examples, 413890 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:39:36,387 : INFO : PROGRESS: at 16.97% examples, 421427 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:39:56,374 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 17:39:56,395 : INFO : PROGRESS: at 19.89% examples, 417903 words/s, in_qsize 30, out_qsize 17\n",
      "2017-01-01 17:40:06,210 : INFO : Finished loading new batch\n",
      "2017-01-01 17:40:16,415 : INFO : PROGRESS: at 21.52% examples, 393861 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:40:36,418 : INFO : PROGRESS: at 25.11% examples, 403987 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 17:40:56,456 : INFO : PROGRESS: at 28.56% examples, 410836 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:41:16,467 : INFO : PROGRESS: at 31.89% examples, 415699 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:41:36,490 : INFO : PROGRESS: at 35.31% examples, 419975 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:41:56,485 : INFO : PROGRESS: at 38.62% examples, 423072 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:42:07,408 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 17:42:17,512 : INFO : Finished loading new batch\n",
      "2017-01-01 17:42:18,668 : INFO : PROGRESS: at 40.13% examples, 404315 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:42:38,674 : INFO : PROGRESS: at 43.13% examples, 405090 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:42:58,682 : INFO : PROGRESS: at 46.36% examples, 407810 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:43:18,695 : INFO : PROGRESS: at 49.83% examples, 411534 words/s, in_qsize 47, out_qsize 5\n",
      "2017-01-01 17:43:38,706 : INFO : PROGRESS: at 53.18% examples, 414459 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:43:58,714 : INFO : PROGRESS: at 56.52% examples, 416483 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 17:44:18,740 : INFO : PROGRESS: at 59.76% examples, 417603 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:44:23,422 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 17:44:33,721 : INFO : Finished loading new batch\n",
      "2017-01-01 17:44:38,742 : INFO : PROGRESS: at 60.85% examples, 404762 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:44:58,768 : INFO : PROGRESS: at 64.19% examples, 407246 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:45:18,774 : INFO : PROGRESS: at 67.52% examples, 409242 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:45:38,787 : INFO : PROGRESS: at 70.66% examples, 410365 words/s, in_qsize 45, out_qsize 3\n",
      "2017-01-01 17:45:58,788 : INFO : PROGRESS: at 73.99% examples, 412022 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 17:46:18,793 : INFO : PROGRESS: at 77.37% examples, 413934 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:46:38,120 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 17:46:38,799 : INFO : PROGRESS: at 80.33% examples, 413591 words/s, in_qsize 0, out_qsize 0\n",
      "2017-01-01 17:46:47,442 : INFO : Finished loading new batch\n",
      "2017-01-01 17:46:58,818 : INFO : PROGRESS: at 82.03% examples, 407199 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:47:18,827 : INFO : PROGRESS: at 85.49% examples, 409300 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 17:47:38,826 : INFO : PROGRESS: at 88.87% examples, 411119 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 17:47:58,829 : INFO : PROGRESS: at 92.21% examples, 412762 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:48:18,833 : INFO : PROGRESS: at 95.40% examples, 413781 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 17:48:38,834 : INFO : PROGRESS: at 98.62% examples, 414812 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 17:48:48,898 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 17:48:48,917 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 17:48:49,389 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 17:48:49,404 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 17:48:49,407 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 17:48:49,422 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 17:48:49,431 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 17:48:49,461 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 17:48:49,466 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 17:48:49,493 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 17:48:49,514 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 17:48:49,517 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 17:48:49,518 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 17:48:49,527 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 17:48:49,554 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 17:48:49,556 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 17:48:49,560 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 17:48:49,562 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 17:48:49,568 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 17:48:49,572 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 17:48:49,574 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 17:48:49,576 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 17:48:49,578 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 17:48:49,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 17:48:49,582 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 17:48:49,587 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 17:48:49,587 : INFO : training on 390507860 raw words (274493265 effective words) took 663.5s, 413707 effective words/s\n",
      "2017-01-01 17:48:49,591 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model, separately None\n",
      "2017-01-01 17:48:49,593 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 17:48:51,584 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn1neg.npy\n",
      "2017-01-01 17:48:56,084 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 17:48:56,086 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn0.npy\n",
      "2017-01-01 17:49:00,349 : INFO : not storing attribute cum_table\n",
      "2017-01-01 17:49:03,939 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 17:49:10,930 : INFO : capital-common-countries: 12.8% (20/156)\n",
      "2017-01-01 17:49:17,323 : INFO : capital-world: 9.9% (15/152)\n",
      "2017-01-01 17:49:19,006 : INFO : currency: 2.5% (1/40)\n",
      "2017-01-01 17:50:09,991 : INFO : city-in-state: 4.5% (56/1248)\n",
      "2017-01-01 17:50:14,433 : INFO : family: 23.6% (26/110)\n",
      "2017-01-01 17:50:36,725 : INFO : gram1-adjective-to-adverb: 11.4% (63/552)\n",
      "2017-01-01 17:50:50,494 : INFO : gram2-opposite: 23.7% (81/342)\n",
      "2017-01-01 17:51:44,421 : INFO : gram3-comparative: 65.8% (877/1332)\n",
      "2017-01-01 17:52:14,951 : INFO : gram4-superlative: 24.6% (186/756)\n",
      "2017-01-01 17:52:52,461 : INFO : gram5-present-participle: 20.9% (194/930)\n",
      "2017-01-01 17:53:16,090 : INFO : gram6-nationality-adjective: 3.3% (19/584)\n",
      "2017-01-01 17:54:06,994 : INFO : gram7-past-tense: 11.2% (141/1260)\n",
      "2017-01-01 17:54:46,930 : INFO : gram8-plural: 36.4% (361/992)\n",
      "2017-01-01 17:55:15,325 : INFO : gram9-plural-verbs: 51.1% (359/702)\n",
      "2017-01-01 17:55:15,328 : INFO : total: 26.2% (2399/9156)\n",
      "2017-01-01 17:55:23,440 : INFO : Training Classifier\n",
      "2017-01-01 17:57:12,239 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:57:45,249 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 17:57:45,255 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 17:57:45,266 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.201, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.602, Top 3: 0.873, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.633, Total Pos: 109,817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 17:57:55,079 : INFO : Finished loading new batch\n",
      "2017-01-01 17:58:25,021 : INFO : Finished: 999\n",
      "2017-01-01 17:58:54,513 : INFO : Finished: 1999\n",
      "2017-01-01 17:59:22,994 : INFO : Finished: 2999\n",
      "2017-01-01 17:59:51,084 : INFO : Finished: 3999\n",
      "2017-01-01 18:00:20,199 : INFO : Finished: 4999\n",
      "2017-01-01 18:00:49,278 : INFO : Finished: 5999\n",
      "2017-01-01 18:01:17,315 : INFO : Finished: 6999\n",
      "2017-01-01 18:01:45,476 : INFO : Finished: 7999\n",
      "2017-01-01 18:02:14,631 : INFO : Finished: 8999\n",
      "2017-01-01 18:02:43,069 : INFO : Finished: 9999\n",
      "2017-01-01 18:02:45,440 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 18:02:47,460 : INFO : Finished loading new batch\n",
      "2017-01-01 18:03:16,407 : INFO : Finished: 10999\n",
      "2017-01-01 18:03:44,957 : INFO : Finished: 11999\n",
      "2017-01-01 18:03:45,364 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 18:03:45,367 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 18:03:58,171 : INFO : Finished: 12412\n",
      "2017-01-01 18:03:58,173 : INFO : Finished: 12412\n",
      "2017-01-01 18:04:02,783 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.279, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.570, Top 3: 0.856, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.612, Total Pos: 29,623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 18:04:06,900 : INFO : ****************** Epoch 5 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5 *******************\n",
      "2017-01-01 18:04:06,945 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 18:04:06,947 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 18:04:06,979 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 18:04:16,206 : INFO : Finished loading new batch\n",
      "2017-01-01 18:04:17,641 : INFO : PROGRESS: at 0.00% examples, 627 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:04:37,646 : INFO : PROGRESS: at 2.71% examples, 246048 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:04:57,648 : INFO : PROGRESS: at 5.72% examples, 314076 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:05:17,664 : INFO : PROGRESS: at 8.97% examples, 350942 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:05:37,674 : INFO : PROGRESS: at 12.35% examples, 374524 words/s, in_qsize 47, out_qsize 3\n",
      "2017-01-01 18:05:57,705 : INFO : PROGRESS: at 15.73% examples, 389567 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:06:17,708 : INFO : PROGRESS: at 19.11% examples, 399418 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:06:25,015 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 18:06:36,279 : INFO : Finished loading new batch\n",
      "2017-01-01 18:06:37,728 : INFO : PROGRESS: at 20.16% examples, 366895 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:06:57,753 : INFO : PROGRESS: at 23.51% examples, 377239 words/s, in_qsize 48, out_qsize 3\n",
      "2017-01-01 18:07:17,772 : INFO : PROGRESS: at 26.94% examples, 386605 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:07:37,784 : INFO : PROGRESS: at 30.30% examples, 394226 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:07:57,813 : INFO : PROGRESS: at 33.71% examples, 400503 words/s, in_qsize 48, out_qsize 3\n",
      "2017-01-01 18:08:17,829 : INFO : PROGRESS: at 37.05% examples, 404587 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:08:38,838 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 18:08:38,859 : INFO : PROGRESS: at 39.98% examples, 403821 words/s, in_qsize 38, out_qsize 14\n",
      "2017-01-01 18:08:50,340 : INFO : Finished loading new batch\n",
      "2017-01-01 18:08:58,869 : INFO : PROGRESS: at 41.41% examples, 389670 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-01 18:09:18,886 : INFO : PROGRESS: at 44.66% examples, 394045 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 18:09:38,887 : INFO : PROGRESS: at 48.20% examples, 398774 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:09:58,904 : INFO : PROGRESS: at 51.57% examples, 402913 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:10:18,908 : INFO : PROGRESS: at 54.78% examples, 404872 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:10:38,921 : INFO : PROGRESS: at 57.97% examples, 406190 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:10:54,265 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 18:11:04,991 : INFO : Finished loading new batch\n",
      "2017-01-01 18:11:05,509 : INFO : PROGRESS: at 60.28% examples, 395160 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:11:25,530 : INFO : PROGRESS: at 63.52% examples, 397480 words/s, in_qsize 46, out_qsize 3\n",
      "2017-01-01 18:11:45,527 : INFO : PROGRESS: at 66.69% examples, 398904 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:12:05,574 : INFO : PROGRESS: at 69.72% examples, 399758 words/s, in_qsize 48, out_qsize 4\n",
      "2017-01-01 18:12:25,601 : INFO : PROGRESS: at 72.79% examples, 400774 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:12:45,596 : INFO : PROGRESS: at 76.13% examples, 402618 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:13:05,599 : INFO : PROGRESS: at 79.57% examples, 405180 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:13:11,765 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 18:13:21,870 : INFO : Finished loading new batch\n",
      "2017-01-01 18:13:25,628 : INFO : PROGRESS: at 80.88% examples, 397087 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:13:45,633 : INFO : PROGRESS: at 84.34% examples, 399659 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:14:05,636 : INFO : PROGRESS: at 87.79% examples, 402171 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 18:14:25,639 : INFO : PROGRESS: at 91.16% examples, 404223 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:14:45,673 : INFO : PROGRESS: at 94.50% examples, 405910 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 18:15:05,683 : INFO : PROGRESS: at 97.77% examples, 407452 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:15:20,549 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 18:15:20,576 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 18:15:21,077 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 18:15:21,090 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 18:15:21,105 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 18:15:21,110 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 18:15:21,113 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 18:15:21,124 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 18:15:21,126 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 18:15:21,149 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 18:15:21,155 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 18:15:21,174 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 18:15:21,183 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 18:15:21,187 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 18:15:21,197 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 18:15:21,210 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 18:15:21,213 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 18:15:21,215 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 18:15:21,218 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 18:15:21,221 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 18:15:21,235 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 18:15:21,239 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 18:15:21,241 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 18:15:21,242 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 18:15:21,254 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 18:15:21,261 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 18:15:21,261 : INFO : training on 390507860 raw words (274482849 effective words) took 674.3s, 407074 effective words/s\n",
      "2017-01-01 18:15:21,265 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model, separately None\n",
      "2017-01-01 18:15:21,266 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 18:15:23,326 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn1neg.npy\n",
      "2017-01-01 18:15:28,109 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 18:15:28,111 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn0.npy\n",
      "2017-01-01 18:15:32,686 : INFO : not storing attribute cum_table\n",
      "2017-01-01 18:15:39,458 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 18:15:46,444 : INFO : capital-common-countries: 14.1% (22/156)\n",
      "2017-01-01 18:15:52,654 : INFO : capital-world: 12.5% (19/152)\n",
      "2017-01-01 18:15:54,285 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 18:16:44,340 : INFO : city-in-state: 4.3% (54/1248)\n",
      "2017-01-01 18:16:48,705 : INFO : family: 18.2% (20/110)\n",
      "2017-01-01 18:17:10,466 : INFO : gram1-adjective-to-adverb: 8.9% (49/552)\n",
      "2017-01-01 18:17:23,912 : INFO : gram2-opposite: 24.9% (85/342)\n",
      "2017-01-01 18:18:17,632 : INFO : gram3-comparative: 67.0% (892/1332)\n",
      "2017-01-01 18:18:47,767 : INFO : gram4-superlative: 22.6% (171/756)\n",
      "2017-01-01 18:19:24,686 : INFO : gram5-present-participle: 24.0% (223/930)\n",
      "2017-01-01 18:19:47,956 : INFO : gram6-nationality-adjective: 2.2% (13/584)\n",
      "2017-01-01 18:20:38,089 : INFO : gram7-past-tense: 12.0% (151/1260)\n",
      "2017-01-01 18:21:17,630 : INFO : gram8-plural: 34.3% (340/992)\n",
      "2017-01-01 18:21:45,544 : INFO : gram9-plural-verbs: 50.1% (352/702)\n",
      "2017-01-01 18:21:45,547 : INFO : total: 26.1% (2391/9156)\n",
      "2017-01-01 18:21:50,508 : INFO : Training Classifier\n",
      "2017-01-01 18:23:32,113 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 18:24:04,008 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 18:24:04,011 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 18:24:04,025 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.185, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.604, Top 3: 0.876, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.635, Total Pos: 109,795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 18:24:14,714 : INFO : Finished loading new batch\n",
      "2017-01-01 18:24:43,508 : INFO : Finished: 999\n",
      "2017-01-01 18:25:12,883 : INFO : Finished: 1999\n",
      "2017-01-01 18:25:41,832 : INFO : Finished: 2999\n",
      "2017-01-01 18:26:09,927 : INFO : Finished: 3999\n",
      "2017-01-01 18:26:38,634 : INFO : Finished: 4999\n",
      "2017-01-01 18:27:07,680 : INFO : Finished: 5999\n",
      "2017-01-01 18:27:35,570 : INFO : Finished: 6999\n",
      "2017-01-01 18:28:03,588 : INFO : Finished: 7999\n",
      "2017-01-01 18:28:32,714 : INFO : Finished: 8999\n",
      "2017-01-01 18:29:00,544 : INFO : Finished: 9999\n",
      "2017-01-01 18:29:02,825 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 18:29:04,946 : INFO : Finished loading new batch\n",
      "2017-01-01 18:29:33,848 : INFO : Finished: 10999\n",
      "2017-01-01 18:30:02,278 : INFO : Finished: 11999\n",
      "2017-01-01 18:30:02,681 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 18:30:02,684 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 18:30:15,340 : INFO : Finished: 12412\n",
      "2017-01-01 18:30:15,343 : INFO : Finished: 12412\n",
      "2017-01-01 18:30:19,845 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.274, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.569, Top 3: 0.858, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.617, Total Pos: 28,923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 18:30:24,014 : INFO : ****************** Epoch 6 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6 *******************\n",
      "2017-01-01 18:30:24,030 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 18:30:24,032 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 18:30:24,046 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 18:30:34,020 : INFO : Finished loading new batch\n",
      "2017-01-01 18:30:34,270 : INFO : PROGRESS: at 0.00% examples, 659 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:30:54,287 : INFO : PROGRESS: at 2.86% examples, 263134 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:31:14,290 : INFO : PROGRESS: at 6.04% examples, 334191 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 18:31:34,298 : INFO : PROGRESS: at 9.46% examples, 370847 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:31:54,308 : INFO : PROGRESS: at 12.91% examples, 393130 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:32:14,322 : INFO : PROGRESS: at 16.27% examples, 404912 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:32:34,327 : INFO : PROGRESS: at 19.48% examples, 408945 words/s, in_qsize 46, out_qsize 4\n",
      "2017-01-01 18:32:39,500 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 18:32:51,467 : INFO : Finished loading new batch\n",
      "2017-01-01 18:32:54,338 : INFO : PROGRESS: at 20.34% examples, 371030 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:33:14,351 : INFO : PROGRESS: at 23.53% examples, 378531 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 18:33:34,353 : INFO : PROGRESS: at 26.89% examples, 386740 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:33:54,354 : INFO : PROGRESS: at 30.22% examples, 394242 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:34:14,367 : INFO : PROGRESS: at 33.65% examples, 400646 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:34:34,373 : INFO : PROGRESS: at 37.07% examples, 405564 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:34:55,027 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 18:34:55,051 : INFO : PROGRESS: at 39.98% examples, 405158 words/s, in_qsize 35, out_qsize 13\n",
      "2017-01-01 18:35:06,729 : INFO : Finished loading new batch\n",
      "2017-01-01 18:35:15,055 : INFO : PROGRESS: at 41.36% examples, 390409 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:35:35,058 : INFO : PROGRESS: at 44.68% examples, 395364 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 18:35:55,068 : INFO : PROGRESS: at 48.28% examples, 400514 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 18:36:15,082 : INFO : PROGRESS: at 51.69% examples, 404803 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 18:36:35,086 : INFO : PROGRESS: at 55.14% examples, 408746 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:36:55,094 : INFO : PROGRESS: at 58.63% examples, 411627 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:37:05,983 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 18:37:16,781 : INFO : Finished loading new batch\n",
      "2017-01-01 18:37:17,504 : INFO : PROGRESS: at 60.28% examples, 400014 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:37:37,512 : INFO : PROGRESS: at 63.68% examples, 403235 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:37:57,538 : INFO : PROGRESS: at 67.21% examples, 406715 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 18:38:17,543 : INFO : PROGRESS: at 70.61% examples, 409378 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:38:37,550 : INFO : PROGRESS: at 74.16% examples, 412206 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:38:57,570 : INFO : PROGRESS: at 77.65% examples, 414730 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 18:39:14,728 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 18:39:24,375 : INFO : Finished loading new batch\n",
      "2017-01-01 18:39:25,243 : INFO : PROGRESS: at 80.36% examples, 407289 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:39:45,237 : INFO : PROGRESS: at 83.88% examples, 409864 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:40:05,246 : INFO : PROGRESS: at 87.34% examples, 412044 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:40:25,257 : INFO : PROGRESS: at 90.72% examples, 413953 words/s, in_qsize 45, out_qsize 1\n",
      "2017-01-01 18:40:45,268 : INFO : PROGRESS: at 94.16% examples, 415725 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:41:05,277 : INFO : PROGRESS: at 97.49% examples, 417341 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:41:21,299 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 18:41:21,319 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 18:41:21,765 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 18:41:21,782 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 18:41:21,790 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 18:41:21,797 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 18:41:21,823 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 18:41:21,831 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 18:41:21,843 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 18:41:21,853 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 18:41:21,864 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 18:41:21,873 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 18:41:21,880 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 18:41:21,893 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 18:41:21,912 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 18:41:21,921 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 18:41:21,923 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 18:41:21,929 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 18:41:21,934 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 18:41:21,939 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 18:41:21,940 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 18:41:21,942 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 18:41:21,946 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 18:41:21,947 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 18:41:21,952 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 18:41:21,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 18:41:21,972 : INFO : training on 390507860 raw words (274485433 effective words) took 657.9s, 417199 effective words/s\n",
      "2017-01-01 18:41:21,975 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model, separately None\n",
      "2017-01-01 18:41:21,976 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 18:41:23,663 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy\n",
      "2017-01-01 18:41:28,617 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 18:41:28,618 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy\n",
      "2017-01-01 18:41:32,881 : INFO : not storing attribute cum_table\n",
      "2017-01-01 18:41:39,691 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 18:41:46,608 : INFO : capital-common-countries: 13.5% (21/156)\n",
      "2017-01-01 18:41:52,805 : INFO : capital-world: 13.8% (21/152)\n",
      "2017-01-01 18:41:54,436 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 18:42:44,863 : INFO : city-in-state: 4.0% (50/1248)\n",
      "2017-01-01 18:42:49,310 : INFO : family: 21.8% (24/110)\n",
      "2017-01-01 18:43:11,605 : INFO : gram1-adjective-to-adverb: 9.2% (51/552)\n",
      "2017-01-01 18:43:25,396 : INFO : gram2-opposite: 25.4% (87/342)\n",
      "2017-01-01 18:44:19,089 : INFO : gram3-comparative: 64.3% (856/1332)\n",
      "2017-01-01 18:44:49,549 : INFO : gram4-superlative: 22.2% (168/756)\n",
      "2017-01-01 18:45:27,095 : INFO : gram5-present-participle: 23.5% (219/930)\n",
      "2017-01-01 18:45:50,609 : INFO : gram6-nationality-adjective: 3.3% (19/584)\n",
      "2017-01-01 18:46:41,359 : INFO : gram7-past-tense: 11.0% (138/1260)\n",
      "2017-01-01 18:47:21,263 : INFO : gram8-plural: 35.4% (351/992)\n",
      "2017-01-01 18:47:49,491 : INFO : gram9-plural-verbs: 50.9% (357/702)\n",
      "2017-01-01 18:47:49,494 : INFO : total: 25.8% (2362/9156)\n",
      "2017-01-01 18:47:54,077 : INFO : Training Classifier\n",
      "2017-01-01 18:49:34,491 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 18:50:06,482 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 18:50:06,485 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 18:50:06,497 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.179, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.604, Top 3: 0.877, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.636, Total Pos: 109,750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 18:50:15,678 : INFO : Finished loading new batch\n",
      "2017-01-01 18:50:44,428 : INFO : Finished: 999\n",
      "2017-01-01 18:51:13,682 : INFO : Finished: 1999\n",
      "2017-01-01 18:51:42,242 : INFO : Finished: 2999\n",
      "2017-01-01 18:52:10,196 : INFO : Finished: 3999\n",
      "2017-01-01 18:52:38,831 : INFO : Finished: 4999\n",
      "2017-01-01 18:53:07,629 : INFO : Finished: 5999\n",
      "2017-01-01 18:53:35,136 : INFO : Finished: 6999\n",
      "2017-01-01 18:54:02,776 : INFO : Finished: 7999\n",
      "2017-01-01 18:54:31,498 : INFO : Finished: 8999\n",
      "2017-01-01 18:54:59,471 : INFO : Finished: 9999\n",
      "2017-01-01 18:55:01,744 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 18:55:03,950 : INFO : Finished loading new batch\n",
      "2017-01-01 18:55:32,618 : INFO : Finished: 10999\n",
      "2017-01-01 18:56:00,961 : INFO : Finished: 11999\n",
      "2017-01-01 18:56:01,355 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 18:56:01,358 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 18:56:14,001 : INFO : Finished: 12412\n",
      "2017-01-01 18:56:14,004 : INFO : Finished: 12412\n",
      "2017-01-01 18:56:18,535 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.257, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.574, Top 3: 0.859, Top 5: 0.950, \n",
      "\t\t F1 Micro: 0.619, Total Pos: 29,037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 18:56:22,649 : INFO : ****************** Epoch 7 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7 *******************\n",
      "2017-01-01 18:56:22,673 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 18:56:22,674 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 18:56:22,699 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 18:56:32,571 : INFO : Finished loading new batch\n",
      "2017-01-01 18:56:33,108 : INFO : PROGRESS: at 0.00% examples, 650 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:56:53,102 : INFO : PROGRESS: at 3.18% examples, 288563 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:57:13,103 : INFO : PROGRESS: at 6.31% examples, 348543 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:57:33,104 : INFO : PROGRESS: at 9.55% examples, 373271 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:57:53,115 : INFO : PROGRESS: at 12.63% examples, 384317 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 18:58:13,110 : INFO : PROGRESS: at 15.66% examples, 389005 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:58:33,142 : INFO : PROGRESS: at 18.59% examples, 389507 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 18:58:44,722 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 18:58:54,838 : INFO : Finished loading new batch\n",
      "2017-01-01 18:58:55,627 : INFO : PROGRESS: at 20.03% examples, 358782 words/s, in_qsize 0, out_qsize 0\n",
      "2017-01-01 18:59:15,659 : INFO : PROGRESS: at 23.05% examples, 365645 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:59:35,664 : INFO : PROGRESS: at 26.27% examples, 373077 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 18:59:55,668 : INFO : PROGRESS: at 29.39% examples, 377859 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:00:15,684 : INFO : PROGRESS: at 32.40% examples, 381380 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:00:35,701 : INFO : PROGRESS: at 35.52% examples, 384513 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:00:55,710 : INFO : PROGRESS: at 38.46% examples, 386483 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 19:01:08,602 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 19:01:18,896 : INFO : Finished loading new batch\n",
      "2017-01-01 19:01:19,664 : INFO : PROGRESS: at 40.13% examples, 371108 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:01:39,696 : INFO : PROGRESS: at 43.03% examples, 373076 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:01:59,703 : INFO : PROGRESS: at 45.87% examples, 374484 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 19:02:19,727 : INFO : PROGRESS: at 48.83% examples, 375566 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:02:39,744 : INFO : PROGRESS: at 51.60% examples, 376304 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:02:59,752 : INFO : PROGRESS: at 54.46% examples, 376986 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:03:19,758 : INFO : PROGRESS: at 57.33% examples, 377397 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:03:39,796 : INFO : PROGRESS: at 60.08% examples, 377068 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:03:42,562 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 19:03:52,636 : INFO : Finished loading new batch\n",
      "2017-01-01 19:03:59,812 : INFO : PROGRESS: at 61.19% examples, 367432 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:04:19,820 : INFO : PROGRESS: at 64.40% examples, 370547 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:04:39,825 : INFO : PROGRESS: at 67.77% examples, 374189 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-01 19:04:59,834 : INFO : PROGRESS: at 71.12% examples, 377648 words/s, in_qsize 46, out_qsize 4\n",
      "2017-01-01 19:05:19,835 : INFO : PROGRESS: at 74.54% examples, 380709 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 19:05:39,846 : INFO : PROGRESS: at 77.80% examples, 382976 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:05:57,206 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 19:06:06,610 : INFO : Finished loading new batch\n",
      "2017-01-01 19:06:07,603 : INFO : PROGRESS: at 80.36% examples, 376857 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:06:27,622 : INFO : PROGRESS: at 83.69% examples, 379423 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:06:47,641 : INFO : PROGRESS: at 87.19% examples, 382529 words/s, in_qsize 46, out_qsize 3\n",
      "2017-01-01 19:07:07,642 : INFO : PROGRESS: at 90.60% examples, 385348 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:07:27,646 : INFO : PROGRESS: at 94.01% examples, 387769 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:07:47,650 : INFO : PROGRESS: at 97.30% examples, 389959 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:08:05,012 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 19:08:05,029 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 19:08:05,482 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 19:08:05,495 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 19:08:05,498 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 19:08:05,512 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 19:08:05,519 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 19:08:05,535 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 19:08:05,559 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 19:08:05,562 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 19:08:05,570 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 19:08:05,577 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 19:08:05,584 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 19:08:05,588 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 19:08:05,602 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 19:08:05,607 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 19:08:05,610 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 19:08:05,619 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 19:08:05,626 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 19:08:05,628 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 19:08:05,632 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 19:08:05,646 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 19:08:05,653 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 19:08:05,658 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 19:08:05,666 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 19:08:05,667 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 19:08:05,674 : INFO : training on 390507860 raw words (274494372 effective words) took 703.0s, 390475 effective words/s\n",
      "2017-01-01 19:08:05,678 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model, separately None\n",
      "2017-01-01 19:08:05,679 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 19:08:07,586 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn1neg.npy\n",
      "2017-01-01 19:08:12,152 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 19:08:12,154 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn0.npy\n",
      "2017-01-01 19:08:16,460 : INFO : not storing attribute cum_table\n",
      "2017-01-01 19:08:23,326 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 19:08:30,237 : INFO : capital-common-countries: 12.2% (19/156)\n",
      "2017-01-01 19:08:36,559 : INFO : capital-world: 12.5% (19/152)\n",
      "2017-01-01 19:08:38,220 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 19:09:29,056 : INFO : city-in-state: 3.7% (46/1248)\n",
      "2017-01-01 19:09:33,522 : INFO : family: 23.6% (26/110)\n",
      "2017-01-01 19:09:55,896 : INFO : gram1-adjective-to-adverb: 8.3% (46/552)\n",
      "2017-01-01 19:10:09,883 : INFO : gram2-opposite: 21.9% (75/342)\n",
      "2017-01-01 19:11:04,352 : INFO : gram3-comparative: 67.0% (893/1332)\n",
      "2017-01-01 19:11:35,011 : INFO : gram4-superlative: 22.6% (171/756)\n",
      "2017-01-01 19:12:12,765 : INFO : gram5-present-participle: 22.4% (208/930)\n",
      "2017-01-01 19:12:36,438 : INFO : gram6-nationality-adjective: 4.3% (25/584)\n",
      "2017-01-01 19:13:27,467 : INFO : gram7-past-tense: 12.1% (153/1260)\n",
      "2017-01-01 19:14:07,647 : INFO : gram8-plural: 37.8% (375/992)\n",
      "2017-01-01 19:14:36,119 : INFO : gram9-plural-verbs: 49.1% (345/702)\n",
      "2017-01-01 19:14:36,122 : INFO : total: 26.2% (2401/9156)\n",
      "2017-01-01 19:14:40,623 : INFO : Training Classifier\n",
      "2017-01-01 19:16:20,484 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 19:16:51,894 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 19:16:51,897 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 19:16:51,913 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.171, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.607, Top 3: 0.878, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 19:17:01,017 : INFO : Finished loading new batch\n",
      "2017-01-01 19:17:30,159 : INFO : Finished: 999\n",
      "2017-01-01 19:17:59,466 : INFO : Finished: 1999\n",
      "2017-01-01 19:18:28,113 : INFO : Finished: 2999\n",
      "2017-01-01 19:18:56,235 : INFO : Finished: 3999\n",
      "2017-01-01 19:19:25,442 : INFO : Finished: 4999\n",
      "2017-01-01 19:19:54,252 : INFO : Finished: 5999\n",
      "2017-01-01 19:20:21,997 : INFO : Finished: 6999\n",
      "2017-01-01 19:20:49,892 : INFO : Finished: 7999\n",
      "2017-01-01 19:21:18,611 : INFO : Finished: 8999\n",
      "2017-01-01 19:21:46,611 : INFO : Finished: 9999\n",
      "2017-01-01 19:21:48,917 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 19:21:51,007 : INFO : Finished loading new batch\n",
      "2017-01-01 19:22:19,799 : INFO : Finished: 10999\n",
      "2017-01-01 19:22:48,053 : INFO : Finished: 11999\n",
      "2017-01-01 19:22:48,463 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 19:22:48,466 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 19:23:00,964 : INFO : Finished: 12412\n",
      "2017-01-01 19:23:00,966 : INFO : Finished: 12412\n",
      "2017-01-01 19:23:05,270 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.262, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.575, Top 3: 0.863, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.619, Total Pos: 28,863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 19:23:09,376 : INFO : ****************** Epoch 8 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8 *******************\n",
      "2017-01-01 19:23:09,401 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 19:23:09,403 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 19:23:09,425 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 19:23:19,057 : INFO : Finished loading new batch\n",
      "2017-01-01 19:23:19,840 : INFO : PROGRESS: at 0.00% examples, 650 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:23:39,843 : INFO : PROGRESS: at 3.25% examples, 295036 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:23:59,846 : INFO : PROGRESS: at 6.29% examples, 347064 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:24:19,851 : INFO : PROGRESS: at 9.47% examples, 370502 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:24:39,862 : INFO : PROGRESS: at 12.78% examples, 388735 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:24:59,862 : INFO : PROGRESS: at 16.20% examples, 402321 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:25:19,886 : INFO : PROGRESS: at 19.75% examples, 414004 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:25:23,299 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 19:25:33,842 : INFO : Finished loading new batch\n",
      "2017-01-01 19:25:39,909 : INFO : PROGRESS: at 20.80% examples, 379342 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:25:59,936 : INFO : PROGRESS: at 24.28% examples, 390045 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 19:26:19,931 : INFO : PROGRESS: at 27.69% examples, 397922 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:26:39,945 : INFO : PROGRESS: at 30.96% examples, 403213 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:26:59,959 : INFO : PROGRESS: at 34.33% examples, 408720 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-01 19:27:19,973 : INFO : PROGRESS: at 37.81% examples, 413836 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:27:35,241 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 19:27:46,062 : INFO : Finished loading new batch\n",
      "2017-01-01 19:27:47,454 : INFO : PROGRESS: at 40.13% examples, 396388 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:28:07,458 : INFO : PROGRESS: at 43.52% examples, 401432 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:28:27,462 : INFO : PROGRESS: at 46.94% examples, 405616 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:28:47,475 : INFO : PROGRESS: at 50.47% examples, 410174 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:29:07,467 : INFO : PROGRESS: at 53.95% examples, 414044 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:29:27,473 : INFO : PROGRESS: at 57.43% examples, 417079 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:29:45,210 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 19:29:55,401 : INFO : Finished loading new batch\n",
      "2017-01-01 19:29:56,951 : INFO : PROGRESS: at 60.28% examples, 405846 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-01 19:30:16,954 : INFO : PROGRESS: at 63.74% examples, 409174 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:30:36,965 : INFO : PROGRESS: at 67.24% examples, 412292 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:30:57,004 : INFO : PROGRESS: at 70.55% examples, 414173 words/s, in_qsize 48, out_qsize 5\n",
      "2017-01-01 19:31:16,998 : INFO : PROGRESS: at 73.66% examples, 414459 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:31:37,012 : INFO : PROGRESS: at 76.73% examples, 414542 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:31:57,027 : INFO : PROGRESS: at 79.89% examples, 415400 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 19:32:01,450 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 19:32:13,496 : INFO : Finished loading new batch\n",
      "2017-01-01 19:32:17,029 : INFO : PROGRESS: at 80.86% examples, 405034 words/s, in_qsize 47, out_qsize 4\n",
      "2017-01-01 19:32:37,036 : INFO : PROGRESS: at 83.77% examples, 404736 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:32:57,045 : INFO : PROGRESS: at 86.65% examples, 404167 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:33:17,045 : INFO : PROGRESS: at 89.54% examples, 403941 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 19:33:37,066 : INFO : PROGRESS: at 92.31% examples, 403399 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:33:57,067 : INFO : PROGRESS: at 95.09% examples, 402867 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:34:17,084 : INFO : PROGRESS: at 97.94% examples, 402698 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:34:31,992 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 19:34:32,007 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 19:34:32,488 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 19:34:32,512 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 19:34:32,516 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 19:34:32,536 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 19:34:32,549 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 19:34:32,564 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 19:34:32,579 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 19:34:32,583 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 19:34:32,586 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 19:34:32,609 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 19:34:32,611 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 19:34:32,612 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 19:34:32,628 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 19:34:32,645 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 19:34:32,654 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 19:34:32,664 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 19:34:32,666 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 19:34:32,674 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 19:34:32,680 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 19:34:32,692 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 19:34:32,693 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 19:34:32,694 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 19:34:32,695 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 19:34:32,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 19:34:32,699 : INFO : training on 390507860 raw words (274495926 effective words) took 683.3s, 401736 effective words/s\n",
      "2017-01-01 19:34:32,703 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model, separately None\n",
      "2017-01-01 19:34:32,705 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 19:34:34,587 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn1neg.npy\n",
      "2017-01-01 19:34:39,448 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 19:34:39,449 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn0.npy\n",
      "2017-01-01 19:34:44,470 : INFO : not storing attribute cum_table\n",
      "2017-01-01 19:34:51,333 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 19:34:58,271 : INFO : capital-common-countries: 10.9% (17/156)\n",
      "2017-01-01 19:35:04,562 : INFO : capital-world: 11.8% (18/152)\n",
      "2017-01-01 19:35:06,186 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 19:35:56,121 : INFO : city-in-state: 3.1% (39/1248)\n",
      "2017-01-01 19:36:00,565 : INFO : family: 21.8% (24/110)\n",
      "2017-01-01 19:36:22,563 : INFO : gram1-adjective-to-adverb: 8.5% (47/552)\n",
      "2017-01-01 19:36:36,205 : INFO : gram2-opposite: 25.7% (88/342)\n",
      "2017-01-01 19:37:29,446 : INFO : gram3-comparative: 64.3% (856/1332)\n",
      "2017-01-01 19:37:59,610 : INFO : gram4-superlative: 23.0% (174/756)\n",
      "2017-01-01 19:38:37,630 : INFO : gram5-present-participle: 23.1% (215/930)\n",
      "2017-01-01 19:39:00,972 : INFO : gram6-nationality-adjective: 3.9% (23/584)\n",
      "2017-01-01 19:39:51,230 : INFO : gram7-past-tense: 10.7% (135/1260)\n",
      "2017-01-01 19:40:31,347 : INFO : gram8-plural: 37.0% (367/992)\n",
      "2017-01-01 19:41:00,747 : INFO : gram9-plural-verbs: 51.0% (358/702)\n",
      "2017-01-01 19:41:00,750 : INFO : total: 25.8% (2361/9156)\n",
      "2017-01-01 19:41:05,313 : INFO : Training Classifier\n",
      "2017-01-01 19:42:45,311 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 19:43:17,350 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 19:43:17,353 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 19:43:17,369 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.178, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.605, Top 3: 0.878, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.637, Total Pos: 109,544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 19:43:26,233 : INFO : Finished loading new batch\n",
      "2017-01-01 19:43:54,971 : INFO : Finished: 999\n",
      "2017-01-01 19:44:23,546 : INFO : Finished: 1999\n",
      "2017-01-01 19:44:51,585 : INFO : Finished: 2999\n",
      "2017-01-01 19:45:19,055 : INFO : Finished: 3999\n",
      "2017-01-01 19:45:47,314 : INFO : Finished: 4999\n",
      "2017-01-01 19:46:15,615 : INFO : Finished: 5999\n",
      "2017-01-01 19:46:42,679 : INFO : Finished: 6999\n",
      "2017-01-01 19:47:09,803 : INFO : Finished: 7999\n",
      "2017-01-01 19:47:37,943 : INFO : Finished: 8999\n",
      "2017-01-01 19:48:05,437 : INFO : Finished: 9999\n",
      "2017-01-01 19:48:07,781 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 19:48:09,706 : INFO : Finished loading new batch\n",
      "2017-01-01 19:48:37,779 : INFO : Finished: 10999\n",
      "2017-01-01 19:49:05,767 : INFO : Finished: 11999\n",
      "2017-01-01 19:49:06,157 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 19:49:06,160 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 19:49:18,718 : INFO : Finished: 12412\n",
      "2017-01-01 19:49:18,720 : INFO : Finished: 12412\n",
      "2017-01-01 19:49:23,260 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.268, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.574, Top 3: 0.860, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.618, Total Pos: 29,043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 19:49:27,473 : INFO : ****************** Epoch 9 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9 *******************\n",
      "2017-01-01 19:49:27,518 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 19:49:27,521 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 19:49:27,539 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 19:49:36,733 : INFO : Finished loading new batch\n",
      "2017-01-01 19:49:37,805 : INFO : PROGRESS: at 0.00% examples, 656 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:49:57,814 : INFO : PROGRESS: at 3.19% examples, 290876 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:50:17,829 : INFO : PROGRESS: at 6.34% examples, 351229 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:50:37,836 : INFO : PROGRESS: at 9.66% examples, 378197 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:50:57,864 : INFO : PROGRESS: at 13.02% examples, 396097 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 19:51:17,870 : INFO : PROGRESS: at 16.46% examples, 409289 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:51:39,661 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 19:51:39,676 : INFO : PROGRESS: at 19.89% examples, 412087 words/s, in_qsize 44, out_qsize 15\n",
      "2017-01-01 19:51:49,799 : INFO : Finished loading new batch\n",
      "2017-01-01 19:51:59,683 : INFO : PROGRESS: at 21.37% examples, 386242 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:52:19,690 : INFO : PROGRESS: at 24.91% examples, 396374 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:52:39,701 : INFO : PROGRESS: at 28.08% examples, 400119 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:52:59,694 : INFO : PROGRESS: at 31.15% examples, 402484 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:53:19,702 : INFO : PROGRESS: at 34.21% examples, 404189 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:53:39,718 : INFO : PROGRESS: at 37.37% examples, 406028 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:53:59,210 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 19:53:59,735 : INFO : PROGRESS: at 40.05% examples, 404085 words/s, in_qsize 10, out_qsize 1\n",
      "2017-01-01 19:54:10,959 : INFO : Finished loading new batch\n",
      "2017-01-01 19:54:19,743 : INFO : PROGRESS: at 41.41% examples, 389311 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:54:39,746 : INFO : PROGRESS: at 44.60% examples, 393169 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-01 19:54:59,747 : INFO : PROGRESS: at 47.96% examples, 396562 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 19:55:19,765 : INFO : PROGRESS: at 51.42% examples, 401358 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:55:39,770 : INFO : PROGRESS: at 54.91% examples, 405560 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:55:59,781 : INFO : PROGRESS: at 58.45% examples, 409032 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:56:11,665 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 19:56:24,050 : INFO : Finished loading new batch\n",
      "2017-01-01 19:56:24,476 : INFO : PROGRESS: at 60.28% examples, 396662 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:56:44,490 : INFO : PROGRESS: at 63.73% examples, 400237 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:57:04,506 : INFO : PROGRESS: at 67.26% examples, 403823 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:57:24,509 : INFO : PROGRESS: at 70.71% examples, 407034 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 19:57:44,517 : INFO : PROGRESS: at 74.26% examples, 409884 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 19:58:04,527 : INFO : PROGRESS: at 77.67% examples, 412046 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:58:22,824 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 19:58:34,390 : INFO : Finished loading new batch\n",
      "2017-01-01 19:58:35,052 : INFO : PROGRESS: at 80.36% examples, 402568 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:58:55,057 : INFO : PROGRESS: at 83.70% examples, 404488 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 19:59:15,091 : INFO : PROGRESS: at 87.15% examples, 406653 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:59:35,096 : INFO : PROGRESS: at 90.55% examples, 408805 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 19:59:55,095 : INFO : PROGRESS: at 94.07% examples, 411114 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:00:15,099 : INFO : PROGRESS: at 97.48% examples, 413179 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:00:31,038 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 20:00:31,060 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 20:00:31,498 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 20:00:31,512 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 20:00:31,526 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 20:00:31,530 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 20:00:31,533 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 20:00:31,557 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 20:00:31,575 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 20:00:31,578 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 20:00:31,585 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 20:00:31,588 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 20:00:31,590 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 20:00:31,605 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 20:00:31,624 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 20:00:31,638 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 20:00:31,640 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 20:00:31,658 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 20:00:31,660 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 20:00:31,662 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 20:00:31,669 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 20:00:31,672 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 20:00:31,673 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 20:00:31,674 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 20:00:31,680 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 20:00:31,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 20:00:31,681 : INFO : training on 390507860 raw words (274481687 effective words) took 664.1s, 413288 effective words/s\n",
      "2017-01-01 20:00:31,685 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model, separately None\n",
      "2017-01-01 20:00:31,686 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 20:00:33,821 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.syn1neg.npy\n",
      "2017-01-01 20:00:38,382 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 20:00:38,384 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.syn0.npy\n",
      "2017-01-01 20:00:42,626 : INFO : not storing attribute cum_table\n",
      "2017-01-01 20:00:49,401 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 20:00:56,312 : INFO : capital-common-countries: 12.2% (19/156)\n",
      "2017-01-01 20:01:02,576 : INFO : capital-world: 13.2% (20/152)\n",
      "2017-01-01 20:01:04,207 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 20:01:54,698 : INFO : city-in-state: 3.8% (47/1248)\n",
      "2017-01-01 20:01:59,153 : INFO : family: 21.8% (24/110)\n",
      "2017-01-01 20:02:21,477 : INFO : gram1-adjective-to-adverb: 8.2% (45/552)\n",
      "2017-01-01 20:02:35,260 : INFO : gram2-opposite: 23.4% (80/342)\n",
      "2017-01-01 20:03:28,908 : INFO : gram3-comparative: 64.1% (854/1332)\n",
      "2017-01-01 20:03:59,409 : INFO : gram4-superlative: 21.7% (164/756)\n",
      "2017-01-01 20:04:36,878 : INFO : gram5-present-participle: 23.0% (214/930)\n",
      "2017-01-01 20:05:00,468 : INFO : gram6-nationality-adjective: 4.8% (28/584)\n",
      "2017-01-01 20:05:51,283 : INFO : gram7-past-tense: 11.5% (145/1260)\n",
      "2017-01-01 20:06:31,254 : INFO : gram8-plural: 39.4% (391/992)\n",
      "2017-01-01 20:06:59,523 : INFO : gram9-plural-verbs: 47.6% (334/702)\n",
      "2017-01-01 20:06:59,526 : INFO : total: 25.8% (2365/9156)\n",
      "2017-01-01 20:07:04,151 : INFO : Training Classifier\n",
      "2017-01-01 20:08:43,527 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 20:09:14,963 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 20:09:14,966 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 20:09:14,981 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.180, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.605, Top 3: 0.878, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.637, Total Pos: 109,351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 20:09:24,456 : INFO : Finished loading new batch\n",
      "2017-01-01 20:09:53,080 : INFO : Finished: 999\n",
      "2017-01-01 20:10:22,230 : INFO : Finished: 1999\n",
      "2017-01-01 20:10:50,655 : INFO : Finished: 2999\n",
      "2017-01-01 20:11:18,701 : INFO : Finished: 3999\n",
      "2017-01-01 20:11:47,600 : INFO : Finished: 4999\n",
      "2017-01-01 20:12:16,395 : INFO : Finished: 5999\n",
      "2017-01-01 20:12:44,067 : INFO : Finished: 6999\n",
      "2017-01-01 20:13:11,928 : INFO : Finished: 7999\n",
      "2017-01-01 20:13:40,671 : INFO : Finished: 8999\n",
      "2017-01-01 20:14:08,679 : INFO : Finished: 9999\n",
      "2017-01-01 20:14:10,878 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 20:14:13,039 : INFO : Finished loading new batch\n",
      "2017-01-01 20:14:41,859 : INFO : Finished: 10999\n",
      "2017-01-01 20:15:09,935 : INFO : Finished: 11999\n",
      "2017-01-01 20:15:10,374 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 20:15:10,377 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 20:15:22,918 : INFO : Finished: 12412\n",
      "2017-01-01 20:15:22,920 : INFO : Finished: 12412\n",
      "2017-01-01 20:15:27,511 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.197, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.588, Top 3: 0.873, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.633, Total Pos: 27,875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 20:15:31,734 : INFO : ****************** Epoch 10 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10 *******************\n",
      "2017-01-01 20:15:31,738 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 20:15:31,739 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 20:15:31,759 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 20:15:42,075 : INFO : Finished loading new batch\n",
      "2017-01-01 20:15:42,292 : INFO : PROGRESS: at 0.00% examples, 636 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:16:02,302 : INFO : PROGRESS: at 3.43% examples, 310151 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:16:22,311 : INFO : PROGRESS: at 6.87% examples, 376641 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 20:16:42,310 : INFO : PROGRESS: at 10.43% examples, 407142 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:17:02,356 : INFO : PROGRESS: at 14.03% examples, 424475 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:17:22,358 : INFO : PROGRESS: at 17.58% examples, 435344 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:17:37,894 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 20:17:48,851 : INFO : Finished loading new batch\n",
      "2017-01-01 20:17:49,192 : INFO : PROGRESS: at 20.03% examples, 399232 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:18:09,229 : INFO : PROGRESS: at 23.50% examples, 408841 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:18:29,248 : INFO : PROGRESS: at 27.03% examples, 416698 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:18:49,248 : INFO : PROGRESS: at 30.42% examples, 422338 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:19:09,253 : INFO : PROGRESS: at 33.90% examples, 427612 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:19:29,277 : INFO : PROGRESS: at 37.36% examples, 431038 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:19:47,860 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 20:20:00,014 : INFO : Finished loading new batch\n",
      "2017-01-01 20:20:00,667 : INFO : PROGRESS: at 40.13% examples, 409850 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:20:20,665 : INFO : PROGRESS: at 43.35% examples, 412456 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:20:40,682 : INFO : PROGRESS: at 46.65% examples, 415178 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:21:00,706 : INFO : PROGRESS: at 50.17% examples, 418912 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:21:20,718 : INFO : PROGRESS: at 53.61% examples, 422157 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:21:40,717 : INFO : PROGRESS: at 57.08% examples, 424791 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:22:00,559 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 20:22:00,729 : INFO : PROGRESS: at 60.20% examples, 424546 words/s, in_qsize 21, out_qsize 0\n",
      "2017-01-01 20:22:12,298 : INFO : Finished loading new batch\n",
      "2017-01-01 20:22:20,734 : INFO : PROGRESS: at 61.57% examples, 413381 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:22:40,756 : INFO : PROGRESS: at 65.10% examples, 416576 words/s, in_qsize 46, out_qsize 5\n",
      "2017-01-01 20:23:00,741 : INFO : PROGRESS: at 68.53% examples, 418987 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:23:20,752 : INFO : PROGRESS: at 71.94% examples, 421221 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:23:40,762 : INFO : PROGRESS: at 75.57% examples, 423826 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:24:00,768 : INFO : PROGRESS: at 79.06% examples, 426077 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:24:09,764 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 20:24:21,096 : INFO : Finished loading new batch\n",
      "2017-01-01 20:24:22,226 : INFO : PROGRESS: at 80.36% examples, 415512 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:24:42,245 : INFO : PROGRESS: at 83.86% examples, 417738 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:25:02,246 : INFO : PROGRESS: at 87.37% examples, 419953 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:25:22,261 : INFO : PROGRESS: at 90.82% examples, 421938 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:25:42,279 : INFO : PROGRESS: at 94.35% examples, 423909 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 20:26:02,283 : INFO : PROGRESS: at 97.81% examples, 425866 words/s, in_qsize 43, out_qsize 0\n",
      "2017-01-01 20:26:16,150 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 20:26:16,166 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 20:26:16,638 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 20:26:16,643 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 20:26:16,648 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 20:26:16,663 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 20:26:16,668 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 20:26:16,696 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 20:26:16,710 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 20:26:16,714 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 20:26:16,725 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 20:26:16,736 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 20:26:16,738 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 20:26:16,752 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 20:26:16,762 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 20:26:16,780 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 20:26:16,784 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 20:26:16,785 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 20:26:16,788 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 20:26:16,791 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 20:26:16,793 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 20:26:16,794 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 20:26:16,795 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 20:26:16,796 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 20:26:16,797 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 20:26:16,815 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 20:26:16,816 : INFO : training on 390507860 raw words (274489192 effective words) took 645.1s, 425528 effective words/s\n",
      "2017-01-01 20:26:16,827 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model, separately None\n",
      "2017-01-01 20:26:16,828 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 20:26:18,803 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.syn1neg.npy\n",
      "2017-01-01 20:26:23,435 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 20:26:23,437 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.syn0.npy\n",
      "2017-01-01 20:26:27,910 : INFO : not storing attribute cum_table\n",
      "2017-01-01 20:26:35,010 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 20:26:42,024 : INFO : capital-common-countries: 10.9% (17/156)\n",
      "2017-01-01 20:26:48,413 : INFO : capital-world: 11.8% (18/152)\n",
      "2017-01-01 20:26:50,091 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 20:27:40,970 : INFO : city-in-state: 4.0% (50/1248)\n",
      "2017-01-01 20:27:45,384 : INFO : family: 20.9% (23/110)\n",
      "2017-01-01 20:28:07,802 : INFO : gram1-adjective-to-adverb: 7.8% (43/552)\n",
      "2017-01-01 20:28:22,564 : INFO : gram2-opposite: 24.0% (82/342)\n",
      "2017-01-01 20:29:15,914 : INFO : gram3-comparative: 65.2% (868/1332)\n",
      "2017-01-01 20:29:46,025 : INFO : gram4-superlative: 25.1% (190/756)\n",
      "2017-01-01 20:30:23,224 : INFO : gram5-present-participle: 23.2% (216/930)\n",
      "2017-01-01 20:30:46,506 : INFO : gram6-nationality-adjective: 4.6% (27/584)\n",
      "2017-01-01 20:31:36,532 : INFO : gram7-past-tense: 11.1% (140/1260)\n",
      "2017-01-01 20:32:15,685 : INFO : gram8-plural: 39.4% (391/992)\n",
      "2017-01-01 20:32:43,393 : INFO : gram9-plural-verbs: 49.6% (348/702)\n",
      "2017-01-01 20:32:43,397 : INFO : total: 26.4% (2413/9156)\n",
      "2017-01-01 20:32:47,904 : INFO : Training Classifier\n",
      "2017-01-01 20:34:27,895 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 20:34:59,320 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 20:34:59,323 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 20:34:59,334 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.171, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.607, Top 3: 0.879, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 20:35:09,013 : INFO : Finished loading new batch\n",
      "2017-01-01 20:35:37,260 : INFO : Finished: 999\n",
      "2017-01-01 20:36:05,862 : INFO : Finished: 1999\n",
      "2017-01-01 20:36:33,974 : INFO : Finished: 2999\n",
      "2017-01-01 20:37:01,592 : INFO : Finished: 3999\n",
      "2017-01-01 20:37:30,142 : INFO : Finished: 4999\n",
      "2017-01-01 20:37:58,781 : INFO : Finished: 5999\n",
      "2017-01-01 20:38:26,726 : INFO : Finished: 6999\n",
      "2017-01-01 20:38:54,530 : INFO : Finished: 7999\n",
      "2017-01-01 20:39:23,055 : INFO : Finished: 8999\n",
      "2017-01-01 20:39:50,983 : INFO : Finished: 9999\n",
      "2017-01-01 20:39:53,264 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 20:39:55,612 : INFO : Finished loading new batch\n",
      "2017-01-01 20:40:24,244 : INFO : Finished: 10999\n",
      "2017-01-01 20:40:52,829 : INFO : Finished: 11999\n",
      "2017-01-01 20:40:53,204 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 20:40:53,207 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 20:41:05,938 : INFO : Finished: 12412\n",
      "2017-01-01 20:41:05,941 : INFO : Finished: 12412\n",
      "2017-01-01 20:41:10,634 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 1 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.202, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.583, Top 3: 0.870, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.630, Total Pos: 28,343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 20:41:14,729 : INFO : ****************** Epoch 11 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11 *******************\n",
      "2017-01-01 20:41:14,733 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 20:41:14,735 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 20:41:14,755 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 20:41:24,954 : INFO : Finished loading new batch\n",
      "2017-01-01 20:41:25,467 : INFO : PROGRESS: at 0.00% examples, 624 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:41:45,481 : INFO : PROGRESS: at 3.07% examples, 277227 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:42:05,480 : INFO : PROGRESS: at 6.34% examples, 347913 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:42:25,492 : INFO : PROGRESS: at 9.73% examples, 378321 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:42:45,494 : INFO : PROGRESS: at 13.05% examples, 395446 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:43:05,509 : INFO : PROGRESS: at 16.27% examples, 403283 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:43:25,526 : INFO : PROGRESS: at 19.49% examples, 407463 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:43:30,595 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 20:43:41,175 : INFO : Finished loading new batch\n",
      "2017-01-01 20:43:45,528 : INFO : PROGRESS: at 20.54% examples, 373741 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:44:05,547 : INFO : PROGRESS: at 23.77% examples, 381678 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:44:25,567 : INFO : PROGRESS: at 27.13% examples, 389165 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 20:44:45,570 : INFO : PROGRESS: at 30.44% examples, 395942 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:45:05,574 : INFO : PROGRESS: at 33.80% examples, 401735 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 20:45:25,572 : INFO : PROGRESS: at 37.15% examples, 405790 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:45:46,025 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 20:45:46,048 : INFO : PROGRESS: at 39.98% examples, 404722 words/s, in_qsize 38, out_qsize 13\n",
      "2017-01-01 20:45:55,955 : INFO : Finished loading new batch\n",
      "2017-01-01 20:46:06,046 : INFO : PROGRESS: at 41.66% examples, 393040 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:46:26,071 : INFO : PROGRESS: at 44.98% examples, 397877 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:46:46,086 : INFO : PROGRESS: at 48.39% examples, 401068 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:47:06,094 : INFO : PROGRESS: at 51.45% examples, 402630 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:47:26,107 : INFO : PROGRESS: at 54.49% examples, 403324 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 20:47:46,115 : INFO : PROGRESS: at 57.49% examples, 403258 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:48:06,490 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 20:48:06,516 : INFO : PROGRESS: at 60.14% examples, 400671 words/s, in_qsize 28, out_qsize 19\n",
      "2017-01-01 20:48:16,191 : INFO : Finished loading new batch\n",
      "2017-01-01 20:48:26,512 : INFO : PROGRESS: at 61.53% examples, 391341 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:48:46,517 : INFO : PROGRESS: at 64.61% examples, 392621 words/s, in_qsize 46, out_qsize 0\n",
      "2017-01-01 20:49:06,519 : INFO : PROGRESS: at 67.82% examples, 394641 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:49:26,520 : INFO : PROGRESS: at 70.95% examples, 396205 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:49:46,532 : INFO : PROGRESS: at 74.10% examples, 397180 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 20:50:06,558 : INFO : PROGRESS: at 77.20% examples, 398120 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:50:28,655 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 20:50:28,670 : INFO : PROGRESS: at 80.22% examples, 397258 words/s, in_qsize 43, out_qsize 16\n",
      "2017-01-01 20:50:37,831 : INFO : Finished loading new batch\n",
      "2017-01-01 20:50:48,700 : INFO : PROGRESS: at 81.78% examples, 390995 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:51:08,727 : INFO : PROGRESS: at 85.11% examples, 392895 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 20:51:28,739 : INFO : PROGRESS: at 88.54% examples, 395424 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:51:48,753 : INFO : PROGRESS: at 91.96% examples, 397779 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:52:08,766 : INFO : PROGRESS: at 95.35% examples, 400133 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 20:52:28,788 : INFO : PROGRESS: at 98.71% examples, 402022 words/s, in_qsize 46, out_qsize 3\n",
      "2017-01-01 20:52:37,981 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 20:52:38,002 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 20:52:38,473 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 20:52:38,476 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 20:52:38,495 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 20:52:38,519 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 20:52:38,523 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 20:52:38,531 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 20:52:38,534 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 20:52:38,544 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 20:52:38,552 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 20:52:38,554 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 20:52:38,570 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 20:52:38,572 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 20:52:38,589 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 20:52:38,601 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 20:52:38,617 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 20:52:38,621 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 20:52:38,623 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 20:52:38,625 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 20:52:38,628 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 20:52:38,631 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 20:52:38,632 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 20:52:38,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 20:52:38,638 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 20:52:38,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 20:52:38,656 : INFO : training on 390507860 raw words (274496113 effective words) took 683.9s, 401368 effective words/s\n",
      "2017-01-01 20:52:38,659 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model, separately None\n",
      "2017-01-01 20:52:38,660 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 20:52:40,593 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.syn1neg.npy\n",
      "2017-01-01 20:52:45,496 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 20:52:45,498 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.syn0.npy\n",
      "2017-01-01 20:52:49,923 : INFO : not storing attribute cum_table\n",
      "2017-01-01 20:52:57,184 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 20:53:04,192 : INFO : capital-common-countries: 10.9% (17/156)\n",
      "2017-01-01 20:53:10,494 : INFO : capital-world: 12.5% (19/152)\n",
      "2017-01-01 20:53:12,140 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 20:54:01,405 : INFO : city-in-state: 3.4% (43/1248)\n",
      "2017-01-01 20:54:05,658 : INFO : family: 23.6% (26/110)\n",
      "2017-01-01 20:54:27,199 : INFO : gram1-adjective-to-adverb: 8.5% (47/552)\n",
      "2017-01-01 20:54:40,496 : INFO : gram2-opposite: 24.0% (82/342)\n",
      "2017-01-01 20:55:32,055 : INFO : gram3-comparative: 63.6% (847/1332)\n",
      "2017-01-01 20:56:01,371 : INFO : gram4-superlative: 21.3% (161/756)\n",
      "2017-01-01 20:56:37,178 : INFO : gram5-present-participle: 22.7% (211/930)\n",
      "2017-01-01 20:56:59,713 : INFO : gram6-nationality-adjective: 4.6% (27/584)\n",
      "2017-01-01 20:57:48,472 : INFO : gram7-past-tense: 10.3% (130/1260)\n",
      "2017-01-01 20:58:27,297 : INFO : gram8-plural: 39.7% (394/992)\n",
      "2017-01-01 20:58:54,137 : INFO : gram9-plural-verbs: 50.3% (353/702)\n",
      "2017-01-01 20:58:54,140 : INFO : total: 25.7% (2357/9156)\n",
      "2017-01-01 20:58:58,756 : INFO : Training Classifier\n",
      "2017-01-01 21:00:37,811 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:01:09,605 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 21:01:09,608 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 21:01:09,619 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.178, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.606, Top 3: 0.878, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.637, Total Pos: 109,238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:01:20,598 : INFO : Finished loading new batch\n",
      "2017-01-01 21:01:50,006 : INFO : Finished: 999\n",
      "2017-01-01 21:02:19,564 : INFO : Finished: 1999\n",
      "2017-01-01 21:02:48,243 : INFO : Finished: 2999\n",
      "2017-01-01 21:03:16,325 : INFO : Finished: 3999\n",
      "2017-01-01 21:03:45,155 : INFO : Finished: 4999\n",
      "2017-01-01 21:04:14,275 : INFO : Finished: 5999\n",
      "2017-01-01 21:04:42,048 : INFO : Finished: 6999\n",
      "2017-01-01 21:05:10,102 : INFO : Finished: 7999\n",
      "2017-01-01 21:05:39,157 : INFO : Finished: 8999\n",
      "2017-01-01 21:06:07,481 : INFO : Finished: 9999\n",
      "2017-01-01 21:06:09,787 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 21:06:11,848 : INFO : Finished loading new batch\n",
      "2017-01-01 21:06:40,568 : INFO : Finished: 10999\n",
      "2017-01-01 21:07:08,912 : INFO : Finished: 11999\n",
      "2017-01-01 21:07:09,390 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 21:07:09,393 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 21:07:22,107 : INFO : Finished: 12412\n",
      "2017-01-01 21:07:22,109 : INFO : Finished: 12412\n",
      "2017-01-01 21:07:27,058 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.218, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.590, Top 3: 0.868, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.628, Total Pos: 28,194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:07:31,402 : INFO : ****************** Epoch 12 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12 *******************\n",
      "2017-01-01 21:07:31,405 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 21:07:31,407 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 21:07:31,433 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 21:07:41,050 : INFO : Finished loading new batch\n",
      "2017-01-01 21:07:41,950 : INFO : PROGRESS: at 0.00% examples, 634 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:08:01,965 : INFO : PROGRESS: at 3.20% examples, 289784 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:08:21,968 : INFO : PROGRESS: at 6.41% examples, 352806 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:08:41,979 : INFO : PROGRESS: at 9.63% examples, 375941 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:09:01,990 : INFO : PROGRESS: at 12.77% examples, 387626 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:09:22,005 : INFO : PROGRESS: at 15.97% examples, 396192 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:09:42,002 : INFO : PROGRESS: at 19.16% examples, 401170 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:09:49,316 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 21:09:59,149 : INFO : Finished loading new batch\n",
      "2017-01-01 21:10:02,049 : INFO : PROGRESS: at 20.25% examples, 368588 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:10:22,075 : INFO : PROGRESS: at 23.34% examples, 374902 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:10:42,081 : INFO : PROGRESS: at 26.64% examples, 382369 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:11:02,103 : INFO : PROGRESS: at 29.81% examples, 388026 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:11:22,107 : INFO : PROGRESS: at 33.05% examples, 392756 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:11:42,116 : INFO : PROGRESS: at 36.31% examples, 396725 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:12:02,148 : INFO : PROGRESS: at 39.30% examples, 398364 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:12:09,083 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 21:12:18,576 : INFO : Finished loading new batch\n",
      "2017-01-01 21:12:22,164 : INFO : PROGRESS: at 40.49% examples, 382364 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:12:42,225 : INFO : PROGRESS: at 43.63% examples, 385918 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:13:02,227 : INFO : PROGRESS: at 46.91% examples, 389758 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:13:22,245 : INFO : PROGRESS: at 50.14% examples, 392640 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:13:42,258 : INFO : PROGRESS: at 53.16% examples, 393999 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:14:02,274 : INFO : PROGRESS: at 56.22% examples, 395240 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 21:14:22,276 : INFO : PROGRESS: at 59.20% examples, 395645 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:14:30,538 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 21:14:40,819 : INFO : Finished loading new batch\n",
      "2017-01-01 21:14:42,375 : INFO : PROGRESS: at 60.28% examples, 383804 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:15:02,399 : INFO : PROGRESS: at 63.31% examples, 385218 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 21:15:22,401 : INFO : PROGRESS: at 66.47% examples, 387153 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 21:15:42,409 : INFO : PROGRESS: at 69.81% examples, 390207 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 21:16:02,444 : INFO : PROGRESS: at 73.14% examples, 392787 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:16:22,456 : INFO : PROGRESS: at 76.43% examples, 394707 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:16:42,480 : INFO : PROGRESS: at 79.66% examples, 396535 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:16:48,200 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 21:16:58,771 : INFO : Finished loading new batch\n",
      "2017-01-01 21:17:02,485 : INFO : PROGRESS: at 80.92% examples, 388721 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:17:22,526 : INFO : PROGRESS: at 83.99% examples, 389700 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 21:17:42,547 : INFO : PROGRESS: at 87.01% examples, 390347 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:18:02,555 : INFO : PROGRESS: at 89.91% examples, 390768 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:18:22,561 : INFO : PROGRESS: at 93.00% examples, 391682 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:18:42,565 : INFO : PROGRESS: at 96.03% examples, 392702 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:19:02,582 : INFO : PROGRESS: at 99.13% examples, 393833 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:19:09,315 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 21:19:09,322 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 21:19:09,785 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 21:19:09,790 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 21:19:09,833 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 21:19:09,856 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 21:19:09,860 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 21:19:09,868 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 21:19:09,875 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 21:19:09,879 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 21:19:09,880 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 21:19:09,881 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 21:19:09,893 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 21:19:09,899 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 21:19:09,914 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 21:19:09,921 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 21:19:09,931 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 21:19:09,936 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 21:19:09,939 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 21:19:09,945 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 21:19:09,948 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 21:19:09,952 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 21:19:09,967 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 21:19:09,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 21:19:09,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 21:19:09,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 21:19:09,971 : INFO : training on 390507860 raw words (274494156 effective words) took 698.5s, 392956 effective words/s\n",
      "2017-01-01 21:19:09,974 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model, separately None\n",
      "2017-01-01 21:19:09,975 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 21:19:11,974 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn1neg.npy\n",
      "2017-01-01 21:19:16,628 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 21:19:16,630 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn0.npy\n",
      "2017-01-01 21:19:21,410 : INFO : not storing attribute cum_table\n",
      "2017-01-01 21:19:28,171 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 21:19:34,772 : INFO : capital-common-countries: 10.9% (17/156)\n",
      "2017-01-01 21:19:40,713 : INFO : capital-world: 11.2% (17/152)\n",
      "2017-01-01 21:19:42,271 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 21:20:30,012 : INFO : city-in-state: 3.1% (39/1248)\n",
      "2017-01-01 21:20:34,202 : INFO : family: 20.0% (22/110)\n",
      "2017-01-01 21:20:55,164 : INFO : gram1-adjective-to-adverb: 8.2% (45/552)\n",
      "2017-01-01 21:21:08,174 : INFO : gram2-opposite: 23.4% (80/342)\n",
      "2017-01-01 21:21:58,782 : INFO : gram3-comparative: 62.2% (829/1332)\n",
      "2017-01-01 21:22:27,437 : INFO : gram4-superlative: 22.0% (166/756)\n",
      "2017-01-01 21:23:02,627 : INFO : gram5-present-participle: 23.7% (220/930)\n",
      "2017-01-01 21:23:24,802 : INFO : gram6-nationality-adjective: 5.1% (30/584)\n",
      "2017-01-01 21:24:12,629 : INFO : gram7-past-tense: 10.9% (137/1260)\n",
      "2017-01-01 21:24:50,276 : INFO : gram8-plural: 40.0% (397/992)\n",
      "2017-01-01 21:25:17,071 : INFO : gram9-plural-verbs: 47.6% (334/702)\n",
      "2017-01-01 21:25:17,073 : INFO : total: 25.5% (2333/9156)\n",
      "2017-01-01 21:25:21,569 : INFO : Training Classifier\n",
      "2017-01-01 21:27:01,191 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:27:33,357 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 21:27:33,360 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 21:27:33,374 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.174, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.606, Top 3: 0.879, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.637, Total Pos: 109,383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:27:44,034 : INFO : Finished loading new batch\n",
      "2017-01-01 21:28:14,136 : INFO : Finished: 999\n",
      "2017-01-01 21:28:43,991 : INFO : Finished: 1999\n",
      "2017-01-01 21:29:12,635 : INFO : Finished: 2999\n",
      "2017-01-01 21:29:40,708 : INFO : Finished: 3999\n",
      "2017-01-01 21:30:09,583 : INFO : Finished: 4999\n",
      "2017-01-01 21:30:38,642 : INFO : Finished: 5999\n",
      "2017-01-01 21:31:06,413 : INFO : Finished: 6999\n",
      "2017-01-01 21:31:34,450 : INFO : Finished: 7999\n",
      "2017-01-01 21:32:03,470 : INFO : Finished: 8999\n",
      "2017-01-01 21:32:31,553 : INFO : Finished: 9999\n",
      "2017-01-01 21:32:33,925 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 21:32:36,061 : INFO : Finished loading new batch\n",
      "2017-01-01 21:33:04,779 : INFO : Finished: 10999\n",
      "2017-01-01 21:33:33,323 : INFO : Finished: 11999\n",
      "2017-01-01 21:33:33,711 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 21:33:33,715 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 21:33:46,406 : INFO : Finished: 12412\n",
      "2017-01-01 21:33:46,409 : INFO : Finished: 12412\n",
      "2017-01-01 21:33:50,850 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.264, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.584, Top 3: 0.864, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.621, Total Pos: 28,579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:33:54,905 : INFO : ****************** Epoch 13 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13 *******************\n",
      "2017-01-01 21:33:54,932 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 21:33:54,933 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 21:33:54,950 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 21:34:04,202 : INFO : Finished loading new batch\n",
      "2017-01-01 21:34:05,455 : INFO : PROGRESS: at 0.00% examples, 638 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:34:25,479 : INFO : PROGRESS: at 2.61% examples, 236787 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:34:45,533 : INFO : PROGRESS: at 5.56% examples, 305512 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:35:05,547 : INFO : PROGRESS: at 8.62% examples, 338197 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:35:25,560 : INFO : PROGRESS: at 11.69% examples, 355581 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:35:45,583 : INFO : PROGRESS: at 14.81% examples, 366987 words/s, in_qsize 46, out_qsize 4\n",
      "2017-01-01 21:36:05,597 : INFO : PROGRESS: at 18.04% examples, 377565 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:36:19,958 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 21:36:29,542 : INFO : Finished loading new batch\n",
      "2017-01-01 21:36:31,076 : INFO : PROGRESS: at 20.03% examples, 351414 words/s, in_qsize 35, out_qsize 0\n",
      "2017-01-01 21:36:51,097 : INFO : PROGRESS: at 23.38% examples, 363756 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:37:11,118 : INFO : PROGRESS: at 26.89% examples, 375157 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:37:31,128 : INFO : PROGRESS: at 30.33% examples, 384825 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:37:51,148 : INFO : PROGRESS: at 33.82% examples, 392734 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:38:11,161 : INFO : PROGRESS: at 37.29% examples, 398803 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 21:38:30,021 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 21:38:39,628 : INFO : Finished loading new batch\n",
      "2017-01-01 21:38:40,916 : INFO : PROGRESS: at 40.13% examples, 385358 words/s, in_qsize 29, out_qsize 0\n",
      "2017-01-01 21:39:00,920 : INFO : PROGRESS: at 43.42% examples, 390035 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:39:20,934 : INFO : PROGRESS: at 46.82% examples, 394875 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 21:39:40,937 : INFO : PROGRESS: at 50.34% examples, 399763 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:40:00,957 : INFO : PROGRESS: at 53.79% examples, 403880 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:40:20,960 : INFO : PROGRESS: at 57.17% examples, 406629 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:40:41,332 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 21:40:41,353 : INFO : PROGRESS: at 60.14% examples, 405969 words/s, in_qsize 30, out_qsize 18\n",
      "2017-01-01 21:40:51,837 : INFO : Finished loading new batch\n",
      "2017-01-01 21:41:01,370 : INFO : PROGRESS: at 61.74% examples, 397489 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:41:21,380 : INFO : PROGRESS: at 65.10% examples, 400238 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 21:41:41,385 : INFO : PROGRESS: at 68.56% examples, 403520 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:42:01,395 : INFO : PROGRESS: at 71.97% examples, 406266 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:42:21,406 : INFO : PROGRESS: at 75.40% examples, 408299 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:42:41,448 : INFO : PROGRESS: at 78.16% examples, 407216 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:42:58,137 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 21:43:08,647 : INFO : Finished loading new batch\n",
      "2017-01-01 21:43:09,181 : INFO : PROGRESS: at 80.36% examples, 397683 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:43:29,198 : INFO : PROGRESS: at 83.23% examples, 397469 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:43:49,206 : INFO : PROGRESS: at 86.12% examples, 397274 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:44:09,240 : INFO : PROGRESS: at 88.90% examples, 396776 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:44:29,242 : INFO : PROGRESS: at 91.73% examples, 396579 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 21:44:49,245 : INFO : PROGRESS: at 94.66% examples, 396851 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:45:09,259 : INFO : PROGRESS: at 97.52% examples, 396951 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 21:45:27,569 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 21:45:27,590 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 21:45:28,165 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 21:45:28,175 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 21:45:28,194 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 21:45:28,196 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 21:45:28,214 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 21:45:28,219 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 21:45:28,232 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 21:45:28,237 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 21:45:28,258 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 21:45:28,287 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 21:45:28,305 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 21:45:28,308 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 21:45:28,314 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 21:45:28,316 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 21:45:28,323 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 21:45:28,325 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 21:45:28,337 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 21:45:28,342 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 21:45:28,343 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 21:45:28,347 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 21:45:28,348 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 21:45:28,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 21:45:28,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 21:45:28,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 21:45:28,360 : INFO : training on 390507860 raw words (274484508 effective words) took 693.4s, 395847 effective words/s\n",
      "2017-01-01 21:45:28,365 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model, separately None\n",
      "2017-01-01 21:45:28,366 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 21:45:29,892 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.syn1neg.npy\n",
      "2017-01-01 21:45:34,048 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 21:45:34,050 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.syn0.npy\n",
      "2017-01-01 21:45:38,292 : INFO : not storing attribute cum_table\n",
      "2017-01-01 21:45:45,301 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 21:45:52,362 : INFO : capital-common-countries: 10.9% (17/156)\n",
      "2017-01-01 21:45:58,660 : INFO : capital-world: 11.8% (18/152)\n",
      "2017-01-01 21:46:00,259 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 21:46:49,521 : INFO : city-in-state: 3.7% (46/1248)\n",
      "2017-01-01 21:46:53,705 : INFO : family: 20.9% (23/110)\n",
      "2017-01-01 21:47:14,491 : INFO : gram1-adjective-to-adverb: 7.4% (41/552)\n",
      "2017-01-01 21:47:27,349 : INFO : gram2-opposite: 24.0% (82/342)\n",
      "2017-01-01 21:48:18,726 : INFO : gram3-comparative: 62.7% (835/1332)\n",
      "2017-01-01 21:48:46,913 : INFO : gram4-superlative: 24.1% (182/756)\n",
      "2017-01-01 21:49:21,328 : INFO : gram5-present-participle: 24.2% (225/930)\n",
      "2017-01-01 21:49:42,901 : INFO : gram6-nationality-adjective: 5.1% (30/584)\n",
      "2017-01-01 21:50:29,589 : INFO : gram7-past-tense: 10.4% (131/1260)\n",
      "2017-01-01 21:51:06,285 : INFO : gram8-plural: 40.4% (401/992)\n",
      "2017-01-01 21:51:32,259 : INFO : gram9-plural-verbs: 47.6% (334/702)\n",
      "2017-01-01 21:51:32,263 : INFO : total: 25.8% (2365/9156)\n",
      "2017-01-01 21:51:36,939 : INFO : Training Classifier\n",
      "2017-01-01 21:53:17,500 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:53:49,141 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 21:53:49,144 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 21:53:49,156 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.177, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.605, Top 3: 0.879, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.637, Total Pos: 109,339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 21:53:59,050 : INFO : Finished loading new batch\n",
      "2017-01-01 21:54:27,134 : INFO : Finished: 999\n",
      "2017-01-01 21:54:55,650 : INFO : Finished: 1999\n",
      "2017-01-01 21:55:23,563 : INFO : Finished: 2999\n",
      "2017-01-01 21:55:51,022 : INFO : Finished: 3999\n",
      "2017-01-01 21:56:19,319 : INFO : Finished: 4999\n",
      "2017-01-01 21:56:47,684 : INFO : Finished: 5999\n",
      "2017-01-01 21:57:14,740 : INFO : Finished: 6999\n",
      "2017-01-01 21:57:41,997 : INFO : Finished: 7999\n",
      "2017-01-01 21:58:10,565 : INFO : Finished: 8999\n",
      "2017-01-01 21:58:38,304 : INFO : Finished: 9999\n",
      "2017-01-01 21:58:40,457 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 21:58:42,676 : INFO : Finished loading new batch\n",
      "2017-01-01 21:59:11,094 : INFO : Finished: 10999\n",
      "2017-01-01 21:59:39,126 : INFO : Finished: 11999\n",
      "2017-01-01 21:59:39,537 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 21:59:39,541 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 21:59:52,069 : INFO : Finished: 12412\n",
      "2017-01-01 21:59:52,071 : INFO : Finished: 12412\n",
      "2017-01-01 21:59:56,563 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 1 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.235, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.580, Top 3: 0.868, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.628, Total Pos: 27,983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 22:00:00,723 : INFO : ****************** Epoch 14 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14 *******************\n",
      "2017-01-01 22:00:00,728 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 22:00:00,729 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 22:00:00,759 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 22:00:10,013 : INFO : Finished loading new batch\n",
      "2017-01-01 22:00:11,322 : INFO : PROGRESS: at 0.00% examples, 638 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:00:31,361 : INFO : PROGRESS: at 3.13% examples, 282847 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:00:51,364 : INFO : PROGRESS: at 6.18% examples, 339125 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:01:11,370 : INFO : PROGRESS: at 9.46% examples, 368810 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:01:31,376 : INFO : PROGRESS: at 12.94% examples, 392549 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:01:51,389 : INFO : PROGRESS: at 16.46% examples, 408308 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:02:12,996 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 22:02:13,013 : INFO : PROGRESS: at 19.89% examples, 411745 words/s, in_qsize 43, out_qsize 20\n",
      "2017-01-01 22:02:24,121 : INFO : Finished loading new batch\n",
      "2017-01-01 22:02:33,020 : INFO : PROGRESS: at 21.40% examples, 386416 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:02:53,023 : INFO : PROGRESS: at 24.68% examples, 392397 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:03:13,037 : INFO : PROGRESS: at 27.78% examples, 395626 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:03:33,056 : INFO : PROGRESS: at 30.90% examples, 398988 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 22:03:53,064 : INFO : PROGRESS: at 34.16% examples, 403496 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:04:13,078 : INFO : PROGRESS: at 37.52% examples, 407667 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 22:04:30,633 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 22:04:41,710 : INFO : Finished loading new batch\n",
      "2017-01-01 22:04:42,280 : INFO : PROGRESS: at 40.13% examples, 391468 words/s, in_qsize 17, out_qsize 0\n",
      "2017-01-01 22:05:02,269 : INFO : PROGRESS: at 43.44% examples, 395953 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 22:05:22,297 : INFO : PROGRESS: at 46.90% examples, 400895 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:05:42,306 : INFO : PROGRESS: at 50.41% examples, 405484 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:06:02,309 : INFO : PROGRESS: at 53.79% examples, 408880 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:06:22,335 : INFO : PROGRESS: at 57.20% examples, 411570 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:06:42,556 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 22:06:42,622 : INFO : PROGRESS: at 60.14% examples, 410565 words/s, in_qsize 33, out_qsize 18\n",
      "2017-01-01 22:06:54,473 : INFO : Finished loading new batch\n",
      "2017-01-01 22:07:02,605 : INFO : PROGRESS: at 61.45% examples, 399994 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:07:22,631 : INFO : PROGRESS: at 64.88% examples, 403075 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 22:07:42,650 : INFO : PROGRESS: at 68.36% examples, 406195 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:08:02,661 : INFO : PROGRESS: at 71.83% examples, 409346 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:08:22,672 : INFO : PROGRESS: at 75.32% examples, 411589 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:08:42,685 : INFO : PROGRESS: at 78.59% examples, 412976 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:08:55,225 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 22:09:06,410 : INFO : Finished loading new batch\n",
      "2017-01-01 22:09:07,236 : INFO : PROGRESS: at 80.36% examples, 403345 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:09:27,265 : INFO : PROGRESS: at 83.56% examples, 404494 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:09:47,274 : INFO : PROGRESS: at 87.02% examples, 406744 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:10:07,276 : INFO : PROGRESS: at 90.39% examples, 408783 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:10:27,282 : INFO : PROGRESS: at 93.84% examples, 410750 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:10:47,294 : INFO : PROGRESS: at 97.01% examples, 411892 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:11:07,119 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 22:11:07,137 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 22:11:07,317 : INFO : PROGRESS: at 99.90% examples, 411435 words/s, in_qsize 45, out_qsize 0\n",
      "2017-01-01 22:11:07,614 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 22:11:07,637 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 22:11:07,646 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 22:11:07,655 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 22:11:07,662 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 22:11:07,664 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 22:11:07,681 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 22:11:07,698 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 22:11:07,712 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 22:11:07,720 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 22:11:07,722 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 22:11:07,725 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 22:11:07,742 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 22:11:07,745 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 22:11:07,745 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 22:11:07,759 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 22:11:07,768 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 22:11:07,786 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 22:11:07,787 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 22:11:07,788 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 22:11:07,789 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 22:11:07,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 22:11:07,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 22:11:07,791 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 22:11:07,792 : INFO : training on 390507860 raw words (274486360 effective words) took 667.0s, 411503 effective words/s\n",
      "2017-01-01 22:11:07,796 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model, separately None\n",
      "2017-01-01 22:11:07,797 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 22:11:09,376 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.syn1neg.npy\n",
      "2017-01-01 22:11:13,608 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 22:11:13,610 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.syn0.npy\n",
      "2017-01-01 22:11:17,845 : INFO : not storing attribute cum_table\n",
      "2017-01-01 22:11:24,714 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 22:11:32,013 : INFO : capital-common-countries: 11.5% (18/156)\n",
      "2017-01-01 22:11:38,285 : INFO : capital-world: 13.2% (20/152)\n",
      "2017-01-01 22:11:39,912 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 22:12:30,103 : INFO : city-in-state: 3.7% (46/1248)\n",
      "2017-01-01 22:12:34,488 : INFO : family: 23.6% (26/110)\n",
      "2017-01-01 22:12:56,460 : INFO : gram1-adjective-to-adverb: 8.9% (49/552)\n",
      "2017-01-01 22:13:10,099 : INFO : gram2-opposite: 23.1% (79/342)\n",
      "2017-01-01 22:14:02,963 : INFO : gram3-comparative: 61.7% (822/1332)\n",
      "2017-01-01 22:14:32,955 : INFO : gram4-superlative: 20.5% (155/756)\n",
      "2017-01-01 22:15:10,033 : INFO : gram5-present-participle: 24.1% (224/930)\n",
      "2017-01-01 22:15:33,273 : INFO : gram6-nationality-adjective: 5.0% (29/584)\n",
      "2017-01-01 22:16:23,410 : INFO : gram7-past-tense: 11.0% (138/1260)\n",
      "2017-01-01 22:17:03,030 : INFO : gram8-plural: 40.0% (397/992)\n",
      "2017-01-01 22:17:31,033 : INFO : gram9-plural-verbs: 45.7% (321/702)\n",
      "2017-01-01 22:17:31,037 : INFO : total: 25.4% (2324/9156)\n",
      "2017-01-01 22:17:35,600 : INFO : Training Classifier\n",
      "2017-01-01 22:19:15,464 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 22:19:48,441 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 22:19:48,445 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 22:19:48,457 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.176, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.606, Top 3: 0.879, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.637, Total Pos: 109,379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 22:19:58,049 : INFO : Finished loading new batch\n",
      "2017-01-01 22:20:27,154 : INFO : Finished: 999\n",
      "2017-01-01 22:20:56,389 : INFO : Finished: 1999\n",
      "2017-01-01 22:21:24,897 : INFO : Finished: 2999\n",
      "2017-01-01 22:21:52,931 : INFO : Finished: 3999\n",
      "2017-01-01 22:22:21,618 : INFO : Finished: 4999\n",
      "2017-01-01 22:22:50,628 : INFO : Finished: 5999\n",
      "2017-01-01 22:23:18,378 : INFO : Finished: 6999\n",
      "2017-01-01 22:23:46,314 : INFO : Finished: 7999\n",
      "2017-01-01 22:24:15,166 : INFO : Finished: 8999\n",
      "2017-01-01 22:24:43,080 : INFO : Finished: 9999\n",
      "2017-01-01 22:24:45,352 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 22:24:47,674 : INFO : Finished loading new batch\n",
      "2017-01-01 22:25:16,477 : INFO : Finished: 10999\n",
      "2017-01-01 22:25:45,006 : INFO : Finished: 11999\n",
      "2017-01-01 22:25:45,390 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 22:25:45,394 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 22:25:58,082 : INFO : Finished: 12412\n",
      "2017-01-01 22:25:58,086 : INFO : Finished: 12412\n",
      "2017-01-01 22:26:02,764 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.216, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.588, Top 3: 0.873, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.635, Total Pos: 27,393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 22:26:06,915 : INFO : ****************** Epoch 15 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15 *******************\n",
      "2017-01-01 22:26:06,918 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 22:26:06,920 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 22:26:06,936 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 22:26:16,589 : INFO : Finished loading new batch\n",
      "2017-01-01 22:26:17,027 : INFO : PROGRESS: at 0.00% examples, 667 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:26:37,066 : INFO : PROGRESS: at 2.64% examples, 242829 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:26:57,072 : INFO : PROGRESS: at 5.78% examples, 320482 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:27:17,084 : INFO : PROGRESS: at 9.09% examples, 358284 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:27:37,089 : INFO : PROGRESS: at 12.37% examples, 377384 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:27:57,091 : INFO : PROGRESS: at 15.62% examples, 389210 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:28:17,136 : INFO : PROGRESS: at 18.86% examples, 396030 words/s, in_qsize 47, out_qsize 3\n",
      "2017-01-01 22:28:26,219 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 22:28:37,240 : INFO : Finished loading new batch\n",
      "2017-01-01 22:28:37,810 : INFO : PROGRESS: at 20.03% examples, 363679 words/s, in_qsize 1, out_qsize 0\n",
      "2017-01-01 22:28:57,799 : INFO : PROGRESS: at 23.19% examples, 372163 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:29:17,845 : INFO : PROGRESS: at 26.14% examples, 375523 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:29:37,850 : INFO : PROGRESS: at 28.95% examples, 375834 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:29:57,889 : INFO : PROGRESS: at 31.65% examples, 375731 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:30:17,890 : INFO : PROGRESS: at 34.36% examples, 375648 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:30:37,935 : INFO : PROGRESS: at 37.15% examples, 375524 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:30:57,965 : INFO : PROGRESS: at 39.75% examples, 374840 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:31:02,305 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 22:31:12,434 : INFO : Finished loading new batch\n",
      "2017-01-01 22:31:17,988 : INFO : PROGRESS: at 40.72% examples, 359437 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:31:38,012 : INFO : PROGRESS: at 43.39% examples, 360176 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:31:58,025 : INFO : PROGRESS: at 46.13% examples, 361396 words/s, in_qsize 48, out_qsize 3\n",
      "2017-01-01 22:32:18,029 : INFO : PROGRESS: at 48.98% examples, 362526 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:32:38,051 : INFO : PROGRESS: at 51.69% examples, 363309 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:32:58,056 : INFO : PROGRESS: at 54.45% examples, 364001 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:33:18,076 : INFO : PROGRESS: at 57.25% examples, 364520 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:33:38,079 : INFO : PROGRESS: at 60.03% examples, 364980 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:33:41,351 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 22:33:51,597 : INFO : Finished loading new batch\n",
      "2017-01-01 22:33:58,100 : INFO : PROGRESS: at 60.99% examples, 355266 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:34:18,123 : INFO : PROGRESS: at 63.73% examples, 356078 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 22:34:38,125 : INFO : PROGRESS: at 66.49% examples, 356801 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:34:58,133 : INFO : PROGRESS: at 69.17% examples, 357434 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:35:18,194 : INFO : PROGRESS: at 71.94% examples, 358325 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:35:38,228 : INFO : PROGRESS: at 74.79% examples, 359104 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:35:58,228 : INFO : PROGRESS: at 77.53% examples, 359608 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:36:20,390 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 22:36:20,412 : INFO : PROGRESS: at 80.22% examples, 358652 words/s, in_qsize 29, out_qsize 19\n",
      "2017-01-01 22:36:30,302 : INFO : Finished loading new batch\n",
      "2017-01-01 22:36:40,423 : INFO : PROGRESS: at 81.54% examples, 353184 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:37:00,426 : INFO : PROGRESS: at 84.46% examples, 354327 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:37:20,428 : INFO : PROGRESS: at 87.28% examples, 355291 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:37:40,429 : INFO : PROGRESS: at 90.00% examples, 356000 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:38:00,431 : INFO : PROGRESS: at 92.79% examples, 356597 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:38:20,455 : INFO : PROGRESS: at 95.44% examples, 357075 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:38:40,475 : INFO : PROGRESS: at 98.13% examples, 357503 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 22:38:55,487 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 22:38:55,498 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 22:38:56,021 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 22:38:56,052 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 22:38:56,065 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 22:38:56,122 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 22:38:56,128 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 22:38:56,136 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 22:38:56,149 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 22:38:56,163 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 22:38:56,173 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 22:38:56,178 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 22:38:56,187 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 22:38:56,200 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 22:38:56,237 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 22:38:56,247 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 22:38:56,249 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 22:38:56,250 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 22:38:56,251 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 22:38:56,252 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 22:38:56,253 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 22:38:56,254 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 22:38:56,254 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 22:38:56,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 22:38:56,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 22:38:56,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 22:38:56,270 : INFO : training on 390507860 raw words (274486964 effective words) took 769.3s, 356786 effective words/s\n",
      "2017-01-01 22:38:56,273 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model, separately None\n",
      "2017-01-01 22:38:56,274 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 22:38:57,987 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model.syn1neg.npy\n",
      "2017-01-01 22:39:02,192 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 22:39:02,194 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15/model.syn0.npy\n",
      "2017-01-01 22:39:06,538 : INFO : not storing attribute cum_table\n",
      "2017-01-01 22:39:13,413 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 22:39:20,359 : INFO : capital-common-countries: 12.2% (19/156)\n",
      "2017-01-01 22:39:26,642 : INFO : capital-world: 13.2% (20/152)\n",
      "2017-01-01 22:39:28,223 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 22:40:17,079 : INFO : city-in-state: 3.8% (48/1248)\n",
      "2017-01-01 22:40:21,364 : INFO : family: 21.8% (24/110)\n",
      "2017-01-01 22:40:43,200 : INFO : gram1-adjective-to-adverb: 9.1% (50/552)\n",
      "2017-01-01 22:40:57,374 : INFO : gram2-opposite: 22.8% (78/342)\n",
      "2017-01-01 22:41:49,943 : INFO : gram3-comparative: 62.8% (837/1332)\n",
      "2017-01-01 22:42:19,023 : INFO : gram4-superlative: 20.9% (158/756)\n",
      "2017-01-01 22:42:54,738 : INFO : gram5-present-participle: 23.2% (216/930)\n",
      "2017-01-01 22:43:17,139 : INFO : gram6-nationality-adjective: 5.5% (32/584)\n",
      "2017-01-01 22:44:05,490 : INFO : gram7-past-tense: 10.2% (129/1260)\n",
      "2017-01-01 22:44:43,582 : INFO : gram8-plural: 38.7% (384/992)\n",
      "2017-01-01 22:45:10,612 : INFO : gram9-plural-verbs: 44.2% (310/702)\n",
      "2017-01-01 22:45:10,616 : INFO : total: 25.2% (2305/9156)\n",
      "2017-01-01 22:45:15,515 : INFO : Training Classifier\n",
      "2017-01-01 22:46:55,641 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 22:47:29,509 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 22:47:29,513 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 22:47:29,526 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.176, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.607, Top 3: 0.879, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 22:47:38,994 : INFO : Finished loading new batch\n",
      "2017-01-01 22:48:08,372 : INFO : Finished: 999\n",
      "2017-01-01 22:48:37,826 : INFO : Finished: 1999\n",
      "2017-01-01 22:49:06,419 : INFO : Finished: 2999\n",
      "2017-01-01 22:49:34,287 : INFO : Finished: 3999\n",
      "2017-01-01 22:50:02,951 : INFO : Finished: 4999\n",
      "2017-01-01 22:50:31,964 : INFO : Finished: 5999\n",
      "2017-01-01 22:50:59,765 : INFO : Finished: 6999\n",
      "2017-01-01 22:51:27,530 : INFO : Finished: 7999\n",
      "2017-01-01 22:51:56,466 : INFO : Finished: 8999\n",
      "2017-01-01 22:52:24,433 : INFO : Finished: 9999\n",
      "2017-01-01 22:52:26,709 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 22:52:28,923 : INFO : Finished loading new batch\n",
      "2017-01-01 22:52:57,733 : INFO : Finished: 10999\n",
      "2017-01-01 22:53:26,284 : INFO : Finished: 11999\n",
      "2017-01-01 22:53:26,736 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 22:53:26,741 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 22:53:39,453 : INFO : Finished: 12412\n",
      "2017-01-01 22:53:39,455 : INFO : Finished: 12412\n",
      "2017-01-01 22:53:43,687 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.197, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.585, Top 3: 0.875, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.633, Total Pos: 27,859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 22:53:47,835 : INFO : ****************** Epoch 16 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16 *******************\n",
      "2017-01-01 22:53:47,838 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 22:53:47,839 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 22:53:47,856 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 22:53:57,241 : INFO : Finished loading new batch\n",
      "2017-01-01 22:53:58,001 : INFO : PROGRESS: at 0.00% examples, 669 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:54:18,033 : INFO : PROGRESS: at 2.57% examples, 236683 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 22:54:38,033 : INFO : PROGRESS: at 5.25% examples, 290156 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:54:58,049 : INFO : PROGRESS: at 7.90% examples, 312259 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:55:18,050 : INFO : PROGRESS: at 10.64% examples, 324767 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:55:38,079 : INFO : PROGRESS: at 13.37% examples, 332950 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:55:58,085 : INFO : PROGRESS: at 16.09% examples, 338766 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:56:18,090 : INFO : PROGRESS: at 18.84% examples, 342517 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:56:28,593 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 22:56:39,218 : INFO : Finished loading new batch\n",
      "2017-01-01 22:56:40,168 : INFO : PROGRESS: at 20.03% examples, 318381 words/s, in_qsize 2, out_qsize 0\n",
      "2017-01-01 22:57:00,182 : INFO : PROGRESS: at 22.65% examples, 323538 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:57:20,189 : INFO : PROGRESS: at 25.47% examples, 328675 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:57:40,196 : INFO : PROGRESS: at 28.25% examples, 332911 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 22:58:00,233 : INFO : PROGRESS: at 30.98% examples, 336471 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 22:58:20,304 : INFO : PROGRESS: at 33.69% examples, 339059 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:58:40,321 : INFO : PROGRESS: at 36.39% examples, 340717 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:59:00,339 : INFO : PROGRESS: at 38.94% examples, 341922 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 22:59:11,124 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 22:59:22,495 : INFO : Finished loading new batch\n",
      "2017-01-01 22:59:24,048 : INFO : PROGRESS: at 40.13% examples, 327782 words/s, in_qsize 0, out_qsize 0\n",
      "2017-01-01 22:59:44,048 : INFO : PROGRESS: at 42.65% examples, 329209 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:00:04,060 : INFO : PROGRESS: at 45.17% examples, 330504 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:00:24,076 : INFO : PROGRESS: at 47.88% examples, 331901 words/s, in_qsize 46, out_qsize 4\n",
      "2017-01-01 23:00:44,071 : INFO : PROGRESS: at 50.53% examples, 333527 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:01:04,096 : INFO : PROGRESS: at 53.21% examples, 335249 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:01:24,100 : INFO : PROGRESS: at 55.91% examples, 336746 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 23:01:44,106 : INFO : PROGRESS: at 58.58% examples, 337748 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:01:57,842 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 23:02:08,391 : INFO : Finished loading new batch\n",
      "2017-01-01 23:02:10,036 : INFO : PROGRESS: at 60.28% examples, 329341 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:02:30,038 : INFO : PROGRESS: at 62.89% examples, 330444 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:02:50,047 : INFO : PROGRESS: at 65.48% examples, 331559 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-01 23:03:10,068 : INFO : PROGRESS: at 68.11% examples, 332487 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:03:30,077 : INFO : PROGRESS: at 70.68% examples, 333263 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:03:50,093 : INFO : PROGRESS: at 73.26% examples, 333809 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 23:04:10,093 : INFO : PROGRESS: at 75.85% examples, 334177 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:04:30,127 : INFO : PROGRESS: at 78.32% examples, 334444 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 23:04:47,632 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 23:04:58,915 : INFO : Finished loading new batch\n",
      "2017-01-01 23:04:59,115 : INFO : PROGRESS: at 80.36% examples, 328361 words/s, in_qsize 14, out_qsize 0\n",
      "2017-01-01 23:05:19,119 : INFO : PROGRESS: at 83.17% examples, 330012 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:05:39,147 : INFO : PROGRESS: at 86.07% examples, 331667 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:05:59,155 : INFO : PROGRESS: at 88.86% examples, 333178 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:06:19,189 : INFO : PROGRESS: at 91.54% examples, 334148 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:06:39,247 : INFO : PROGRESS: at 94.24% examples, 335048 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:06:59,246 : INFO : PROGRESS: at 96.84% examples, 335908 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:07:19,250 : INFO : PROGRESS: at 99.49% examples, 336663 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:07:24,082 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 23:07:24,097 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 23:07:24,674 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 23:07:24,681 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 23:07:24,709 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 23:07:24,734 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 23:07:24,737 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 23:07:24,767 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 23:07:24,796 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 23:07:24,799 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 23:07:24,802 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 23:07:24,813 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 23:07:24,819 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 23:07:24,844 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 23:07:24,850 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 23:07:24,853 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 23:07:24,854 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 23:07:24,857 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 23:07:24,859 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 23:07:24,860 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 23:07:24,865 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 23:07:24,885 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 23:07:24,889 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 23:07:24,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 23:07:24,902 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 23:07:24,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 23:07:24,903 : INFO : training on 390507860 raw words (274484772 effective words) took 817.0s, 335947 effective words/s\n",
      "2017-01-01 23:07:24,907 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model, separately None\n",
      "2017-01-01 23:07:24,908 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 23:07:26,525 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model.syn1neg.npy\n",
      "2017-01-01 23:07:30,705 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 23:07:30,707 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_16/model.syn0.npy\n",
      "2017-01-01 23:07:35,112 : INFO : not storing attribute cum_table\n",
      "2017-01-01 23:07:42,052 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 23:07:49,025 : INFO : capital-common-countries: 14.1% (22/156)\n",
      "2017-01-01 23:07:55,318 : INFO : capital-world: 14.5% (22/152)\n",
      "2017-01-01 23:07:56,939 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 23:08:46,263 : INFO : city-in-state: 3.8% (48/1248)\n",
      "2017-01-01 23:08:50,433 : INFO : family: 21.8% (24/110)\n",
      "2017-01-01 23:09:11,202 : INFO : gram1-adjective-to-adverb: 7.4% (41/552)\n",
      "2017-01-01 23:09:23,984 : INFO : gram2-opposite: 24.3% (83/342)\n",
      "2017-01-01 23:10:13,921 : INFO : gram3-comparative: 60.8% (810/1332)\n",
      "2017-01-01 23:10:42,112 : INFO : gram4-superlative: 19.0% (144/756)\n",
      "2017-01-01 23:11:16,748 : INFO : gram5-present-participle: 22.9% (213/930)\n",
      "2017-01-01 23:11:38,596 : INFO : gram6-nationality-adjective: 5.5% (32/584)\n",
      "2017-01-01 23:12:26,063 : INFO : gram7-past-tense: 10.5% (132/1260)\n",
      "2017-01-01 23:13:03,059 : INFO : gram8-plural: 39.6% (393/992)\n",
      "2017-01-01 23:13:29,200 : INFO : gram9-plural-verbs: 43.4% (305/702)\n",
      "2017-01-01 23:13:29,205 : INFO : total: 24.8% (2269/9156)\n",
      "2017-01-01 23:13:33,984 : INFO : Training Classifier\n",
      "2017-01-01 23:15:14,621 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 23:15:46,824 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 23:15:46,826 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 23:15:46,852 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.178, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.607, Top 3: 0.878, Top 5: 0.954, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 23:15:57,438 : INFO : Finished loading new batch\n",
      "2017-01-01 23:16:27,277 : INFO : Finished: 999\n",
      "2017-01-01 23:16:56,695 : INFO : Finished: 1999\n",
      "2017-01-01 23:17:25,431 : INFO : Finished: 2999\n",
      "2017-01-01 23:17:53,513 : INFO : Finished: 3999\n",
      "2017-01-01 23:18:22,738 : INFO : Finished: 4999\n",
      "2017-01-01 23:18:51,713 : INFO : Finished: 5999\n",
      "2017-01-01 23:19:19,791 : INFO : Finished: 6999\n",
      "2017-01-01 23:19:47,752 : INFO : Finished: 7999\n",
      "2017-01-01 23:20:16,895 : INFO : Finished: 8999\n",
      "2017-01-01 23:20:44,848 : INFO : Finished: 9999\n",
      "2017-01-01 23:20:47,182 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 23:20:49,262 : INFO : Finished loading new batch\n",
      "2017-01-01 23:21:17,787 : INFO : Finished: 10999\n",
      "2017-01-01 23:21:46,490 : INFO : Finished: 11999\n",
      "2017-01-01 23:21:46,879 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 23:21:46,883 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 23:21:59,774 : INFO : Finished: 12412\n",
      "2017-01-01 23:21:59,776 : INFO : Finished: 12412\n",
      "2017-01-01 23:22:04,058 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.255, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.583, Top 3: 0.867, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.623, Total Pos: 28,364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 23:22:08,089 : INFO : ****************** Epoch 17 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_17 *******************\n",
      "2017-01-01 23:22:08,093 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 23:22:08,094 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 23:22:08,110 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 23:22:17,506 : INFO : Finished loading new batch\n",
      "2017-01-01 23:22:18,810 : INFO : PROGRESS: at 0.00% examples, 631 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:22:38,816 : INFO : PROGRESS: at 2.50% examples, 226439 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:22:58,811 : INFO : PROGRESS: at 5.08% examples, 277737 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 23:23:18,802 : INFO : PROGRESS: at 7.62% examples, 299212 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:23:38,813 : INFO : PROGRESS: at 10.26% examples, 311267 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 23:23:58,864 : INFO : PROGRESS: at 12.82% examples, 318166 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:24:18,866 : INFO : PROGRESS: at 15.42% examples, 323472 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:24:38,888 : INFO : PROGRESS: at 18.05% examples, 327394 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:24:55,887 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 23:25:06,491 : INFO : Finished loading new batch\n",
      "2017-01-01 23:25:07,790 : INFO : PROGRESS: at 20.03% examples, 305317 words/s, in_qsize 23, out_qsize 0\n",
      "2017-01-01 23:25:27,794 : INFO : PROGRESS: at 22.55% examples, 310216 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:25:47,807 : INFO : PROGRESS: at 25.30% examples, 315494 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:26:07,822 : INFO : PROGRESS: at 28.07% examples, 320520 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:26:27,824 : INFO : PROGRESS: at 30.80% examples, 324977 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:26:47,828 : INFO : PROGRESS: at 33.56% examples, 329125 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:27:07,836 : INFO : PROGRESS: at 36.43% examples, 332907 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 23:27:27,838 : INFO : PROGRESS: at 39.16% examples, 336083 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:27:36,349 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 23:27:47,236 : INFO : Finished loading new batch\n",
      "2017-01-01 23:27:48,679 : INFO : PROGRESS: at 40.13% examples, 323575 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-01 23:28:08,683 : INFO : PROGRESS: at 42.85% examples, 326652 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:28:28,702 : INFO : PROGRESS: at 45.52% examples, 329257 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:28:48,710 : INFO : PROGRESS: at 48.47% examples, 332190 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:29:08,721 : INFO : PROGRESS: at 51.25% examples, 334874 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 23:29:28,732 : INFO : PROGRESS: at 54.09% examples, 337280 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:29:48,743 : INFO : PROGRESS: at 56.91% examples, 339304 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 23:30:08,738 : INFO : PROGRESS: at 59.77% examples, 341201 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:30:13,664 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 23:30:25,521 : INFO : Finished loading new batch\n",
      "2017-01-01 23:30:28,749 : INFO : PROGRESS: at 60.67% examples, 332469 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:30:48,758 : INFO : PROGRESS: at 63.46% examples, 334446 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:31:08,783 : INFO : PROGRESS: at 66.24% examples, 336231 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:31:28,782 : INFO : PROGRESS: at 69.06% examples, 338050 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:31:48,807 : INFO : PROGRESS: at 71.87% examples, 339859 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:32:08,815 : INFO : PROGRESS: at 74.76% examples, 341370 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:32:28,863 : INFO : PROGRESS: at 77.55% examples, 342606 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:32:49,957 : INFO : Loading new batch for index: 40000\n",
      "2017-01-01 23:32:49,974 : INFO : PROGRESS: at 80.22% examples, 342782 words/s, in_qsize 34, out_qsize 15\n",
      "2017-01-01 23:33:00,825 : INFO : Finished loading new batch\n",
      "2017-01-01 23:33:09,983 : INFO : PROGRESS: at 81.55% examples, 338079 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:33:29,986 : INFO : PROGRESS: at 84.46% examples, 339571 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:33:50,058 : INFO : PROGRESS: at 87.19% examples, 340544 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:34:10,081 : INFO : PROGRESS: at 89.91% examples, 341566 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-01 23:34:30,081 : INFO : PROGRESS: at 92.76% examples, 342775 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:34:50,107 : INFO : PROGRESS: at 95.45% examples, 343774 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:35:10,111 : INFO : PROGRESS: at 98.21% examples, 344780 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:35:24,195 : INFO : Loading new batch for index: 49789\n",
      "2017-01-01 23:35:24,216 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-01 23:35:24,723 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-01 23:35:24,742 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-01 23:35:24,752 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-01 23:35:24,771 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-01 23:35:24,774 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-01 23:35:24,779 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-01 23:35:24,805 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-01 23:35:24,818 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-01 23:35:24,837 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-01 23:35:24,844 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-01 23:35:24,854 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-01 23:35:24,859 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-01 23:35:24,887 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-01 23:35:24,892 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-01 23:35:24,898 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-01 23:35:24,899 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-01 23:35:24,905 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-01 23:35:24,915 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-01 23:35:24,918 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-01 23:35:24,926 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-01 23:35:24,927 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-01 23:35:24,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-01 23:35:24,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-01 23:35:24,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-01 23:35:24,948 : INFO : training on 390507860 raw words (274486445 effective words) took 796.8s, 344470 effective words/s\n",
      "2017-01-01 23:35:24,974 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_17/model, separately None\n",
      "2017-01-01 23:35:24,976 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_17/model.docvecs.doctag_syn0.npy\n",
      "2017-01-01 23:35:26,618 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_17/model.syn1neg.npy\n",
      "2017-01-01 23:35:30,869 : INFO : not storing attribute syn0norm\n",
      "2017-01-01 23:35:30,871 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_17/model.syn0.npy\n",
      "2017-01-01 23:35:35,448 : INFO : not storing attribute cum_table\n",
      "2017-01-01 23:35:42,695 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-01 23:35:49,572 : INFO : capital-common-countries: 13.5% (21/156)\n",
      "2017-01-01 23:35:55,913 : INFO : capital-world: 13.2% (20/152)\n",
      "2017-01-01 23:35:57,571 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-01 23:36:48,174 : INFO : city-in-state: 3.9% (49/1248)\n",
      "2017-01-01 23:36:52,565 : INFO : family: 22.7% (25/110)\n",
      "2017-01-01 23:37:14,604 : INFO : gram1-adjective-to-adverb: 7.1% (39/552)\n",
      "2017-01-01 23:37:28,247 : INFO : gram2-opposite: 22.8% (78/342)\n",
      "2017-01-01 23:38:22,858 : INFO : gram3-comparative: 60.3% (803/1332)\n",
      "2017-01-01 23:38:53,070 : INFO : gram4-superlative: 20.4% (154/756)\n",
      "2017-01-01 23:39:30,066 : INFO : gram5-present-participle: 22.3% (207/930)\n",
      "2017-01-01 23:39:53,316 : INFO : gram6-nationality-adjective: 5.7% (33/584)\n",
      "2017-01-01 23:40:43,980 : INFO : gram7-past-tense: 10.6% (133/1260)\n",
      "2017-01-01 23:41:24,157 : INFO : gram8-plural: 40.5% (402/992)\n",
      "2017-01-01 23:41:51,841 : INFO : gram9-plural-verbs: 44.9% (315/702)\n",
      "2017-01-01 23:41:51,845 : INFO : total: 24.9% (2279/9156)\n",
      "2017-01-01 23:41:56,612 : INFO : Training Classifier\n",
      "2017-01-01 23:43:36,435 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 23:44:09,158 : INFO : Getting Validation Embeddings\n",
      "2017-01-01 23:44:09,161 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-01 23:44:09,174 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.175, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.607, Top 3: 0.879, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 23:44:21,169 : INFO : Finished loading new batch\n",
      "2017-01-01 23:44:49,956 : INFO : Finished: 999\n",
      "2017-01-01 23:45:19,155 : INFO : Finished: 1999\n",
      "2017-01-01 23:45:47,771 : INFO : Finished: 2999\n",
      "2017-01-01 23:46:16,031 : INFO : Finished: 3999\n",
      "2017-01-01 23:46:44,909 : INFO : Finished: 4999\n",
      "2017-01-01 23:47:13,701 : INFO : Finished: 5999\n",
      "2017-01-01 23:47:41,301 : INFO : Finished: 6999\n",
      "2017-01-01 23:48:09,141 : INFO : Finished: 7999\n",
      "2017-01-01 23:48:37,940 : INFO : Finished: 8999\n",
      "2017-01-01 23:49:06,048 : INFO : Finished: 9999\n",
      "2017-01-01 23:49:08,359 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 23:49:10,475 : INFO : Finished loading new batch\n",
      "2017-01-01 23:49:39,435 : INFO : Finished: 10999\n",
      "2017-01-01 23:50:07,877 : INFO : Finished: 11999\n",
      "2017-01-01 23:50:08,277 : INFO : Loading new batch for index: 12412\n",
      "2017-01-01 23:50:08,281 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-01 23:50:20,890 : INFO : Finished: 12412\n",
      "2017-01-01 23:50:20,892 : INFO : Finished: 12412\n",
      "2017-01-01 23:50:25,337 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.221, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.590, Top 3: 0.872, Top 5: 0.953, \n",
      "\t\t F1 Micro: 0.631, Total Pos: 27,826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-01 23:50:29,476 : INFO : ****************** Epoch 18 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_18 *******************\n",
      "2017-01-01 23:50:29,480 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-01 23:50:29,482 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-01 23:50:29,513 : INFO : Loading new batch for index: 0\n",
      "2017-01-01 23:50:39,777 : INFO : Finished loading new batch\n",
      "2017-01-01 23:50:41,302 : INFO : PROGRESS: at 0.00% examples, 570 words/s, in_qsize 0, out_qsize 0\n",
      "2017-01-01 23:51:01,323 : INFO : PROGRESS: at 3.26% examples, 282640 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 23:51:21,350 : INFO : PROGRESS: at 6.42% examples, 344149 words/s, in_qsize 46, out_qsize 2\n",
      "2017-01-01 23:51:41,345 : INFO : PROGRESS: at 9.69% examples, 371438 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:52:01,334 : INFO : PROGRESS: at 12.92% examples, 386589 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:52:21,356 : INFO : PROGRESS: at 16.18% examples, 396697 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:52:41,379 : INFO : PROGRESS: at 19.57% examples, 405805 words/s, in_qsize 45, out_qsize 3\n",
      "2017-01-01 23:52:45,819 : INFO : Loading new batch for index: 10000\n",
      "2017-01-01 23:52:56,660 : INFO : Finished loading new batch\n",
      "2017-01-01 23:53:01,375 : INFO : PROGRESS: at 20.67% examples, 373573 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:53:21,392 : INFO : PROGRESS: at 24.07% examples, 383753 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 23:53:41,390 : INFO : PROGRESS: at 27.48% examples, 392061 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:54:01,394 : INFO : PROGRESS: at 30.82% examples, 398768 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:54:21,423 : INFO : PROGRESS: at 34.20% examples, 404546 words/s, in_qsize 47, out_qsize 2\n",
      "2017-01-01 23:54:41,424 : INFO : PROGRESS: at 37.60% examples, 409211 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:54:58,786 : INFO : Loading new batch for index: 20000\n",
      "2017-01-01 23:55:10,673 : INFO : Finished loading new batch\n",
      "2017-01-01 23:55:11,002 : INFO : PROGRESS: at 40.13% examples, 391519 words/s, in_qsize 23, out_qsize 0\n",
      "2017-01-01 23:55:31,029 : INFO : PROGRESS: at 43.31% examples, 394840 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:55:51,038 : INFO : PROGRESS: at 46.12% examples, 394578 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:56:11,045 : INFO : PROGRESS: at 49.05% examples, 394504 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:56:31,093 : INFO : PROGRESS: at 51.82% examples, 393938 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:56:51,127 : INFO : PROGRESS: at 54.61% examples, 393329 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-01 23:57:11,137 : INFO : PROGRESS: at 57.46% examples, 392768 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:57:31,978 : INFO : Loading new batch for index: 30000\n",
      "2017-01-01 23:57:31,998 : INFO : PROGRESS: at 60.14% examples, 390528 words/s, in_qsize 46, out_qsize 15\n",
      "2017-01-01 23:57:42,528 : INFO : Finished loading new batch\n",
      "2017-01-01 23:57:51,990 : INFO : PROGRESS: at 61.51% examples, 381729 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:58:11,991 : INFO : PROGRESS: at 64.35% examples, 381993 words/s, in_qsize 48, out_qsize 6\n",
      "2017-01-01 23:58:32,002 : INFO : PROGRESS: at 67.22% examples, 382278 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:58:52,012 : INFO : PROGRESS: at 70.04% examples, 382434 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-01 23:59:12,068 : INFO : PROGRESS: at 72.83% examples, 382617 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:59:32,075 : INFO : PROGRESS: at 75.75% examples, 382776 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-01 23:59:52,082 : INFO : PROGRESS: at 78.51% examples, 382753 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:00:06,859 : INFO : Loading new batch for index: 40000\n",
      "2017-01-02 00:00:17,755 : INFO : Finished loading new batch\n",
      "2017-01-02 00:00:18,391 : INFO : PROGRESS: at 80.36% examples, 374313 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:00:38,399 : INFO : PROGRESS: at 83.08% examples, 374278 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:00:58,406 : INFO : PROGRESS: at 85.89% examples, 374394 words/s, in_qsize 48, out_qsize 4\n",
      "2017-01-02 00:01:18,425 : INFO : PROGRESS: at 88.61% examples, 374435 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:01:38,428 : INFO : PROGRESS: at 91.29% examples, 374422 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:01:58,450 : INFO : PROGRESS: at 94.10% examples, 374589 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:02:18,458 : INFO : PROGRESS: at 96.77% examples, 374687 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:02:38,463 : INFO : PROGRESS: at 99.51% examples, 374848 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:02:43,042 : INFO : Loading new batch for index: 49789\n",
      "2017-01-02 00:02:43,065 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-02 00:02:43,592 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-02 00:02:43,596 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-02 00:02:43,640 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-02 00:02:43,648 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-02 00:02:43,651 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-02 00:02:43,660 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-02 00:02:43,663 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-02 00:02:43,679 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-02 00:02:43,698 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-02 00:02:43,702 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-02 00:02:43,716 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-02 00:02:43,737 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-02 00:02:43,771 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-02 00:02:43,781 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-02 00:02:43,784 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-02 00:02:43,787 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-02 00:02:43,788 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-02 00:02:43,791 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-02 00:02:43,792 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-02 00:02:43,793 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-02 00:02:43,793 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-02 00:02:43,794 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-02 00:02:43,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-02 00:02:43,812 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-02 00:02:43,813 : INFO : training on 390507860 raw words (274490161 effective words) took 734.3s, 373812 effective words/s\n",
      "2017-01-02 00:02:43,847 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_18/model, separately None\n",
      "2017-01-02 00:02:43,848 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_18/model.docvecs.doctag_syn0.npy\n",
      "2017-01-02 00:02:45,490 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_18/model.syn1neg.npy\n",
      "2017-01-02 00:02:49,825 : INFO : not storing attribute syn0norm\n",
      "2017-01-02 00:02:49,827 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_18/model.syn0.npy\n",
      "2017-01-02 00:02:54,136 : INFO : not storing attribute cum_table\n",
      "2017-01-02 00:03:01,408 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-02 00:03:08,505 : INFO : capital-common-countries: 14.1% (22/156)\n",
      "2017-01-02 00:03:14,918 : INFO : capital-world: 13.8% (21/152)\n",
      "2017-01-02 00:03:16,567 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-02 00:04:07,428 : INFO : city-in-state: 3.6% (45/1248)\n",
      "2017-01-02 00:04:11,893 : INFO : family: 24.5% (27/110)\n",
      "2017-01-02 00:04:34,277 : INFO : gram1-adjective-to-adverb: 8.0% (44/552)\n",
      "2017-01-02 00:04:48,155 : INFO : gram2-opposite: 22.2% (76/342)\n",
      "2017-01-02 00:05:42,149 : INFO : gram3-comparative: 60.0% (799/1332)\n",
      "2017-01-02 00:06:12,819 : INFO : gram4-superlative: 20.4% (154/756)\n",
      "2017-01-02 00:06:50,560 : INFO : gram5-present-participle: 24.0% (223/930)\n",
      "2017-01-02 00:07:14,252 : INFO : gram6-nationality-adjective: 5.8% (34/584)\n",
      "2017-01-02 00:08:05,231 : INFO : gram7-past-tense: 9.8% (124/1260)\n",
      "2017-01-02 00:08:46,540 : INFO : gram8-plural: 37.3% (370/992)\n",
      "2017-01-02 00:09:14,945 : INFO : gram9-plural-verbs: 43.9% (308/702)\n",
      "2017-01-02 00:09:14,949 : INFO : total: 24.5% (2247/9156)\n",
      "2017-01-02 00:09:19,765 : INFO : Training Classifier\n",
      "2017-01-02 00:10:59,920 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 00:11:32,608 : INFO : Getting Validation Embeddings\n",
      "2017-01-02 00:11:32,611 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-02 00:11:32,666 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.177, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.607, Top 3: 0.879, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 00:11:43,301 : INFO : Finished loading new batch\n",
      "2017-01-02 00:12:12,370 : INFO : Finished: 999\n",
      "2017-01-02 00:12:42,154 : INFO : Finished: 1999\n",
      "2017-01-02 00:13:10,786 : INFO : Finished: 2999\n",
      "2017-01-02 00:13:39,025 : INFO : Finished: 3999\n",
      "2017-01-02 00:14:07,889 : INFO : Finished: 4999\n",
      "2017-01-02 00:14:36,819 : INFO : Finished: 5999\n",
      "2017-01-02 00:15:04,524 : INFO : Finished: 6999\n",
      "2017-01-02 00:15:32,469 : INFO : Finished: 7999\n",
      "2017-01-02 00:16:01,199 : INFO : Finished: 8999\n",
      "2017-01-02 00:16:29,241 : INFO : Finished: 9999\n",
      "2017-01-02 00:16:31,495 : INFO : Loading new batch for index: 10000\n",
      "2017-01-02 00:16:34,160 : INFO : Finished loading new batch\n",
      "2017-01-02 00:17:03,298 : INFO : Finished: 10999\n",
      "2017-01-02 00:17:31,855 : INFO : Finished: 11999\n",
      "2017-01-02 00:17:32,240 : INFO : Loading new batch for index: 12412\n",
      "2017-01-02 00:17:32,244 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-02 00:17:45,019 : INFO : Finished: 12412\n",
      "2017-01-02 00:17:45,023 : INFO : Finished: 12412\n",
      "2017-01-02 00:17:49,440 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.243, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.588, Top 3: 0.869, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.629, Total Pos: 27,697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 00:17:53,535 : INFO : ****************** Epoch 19 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_19 *******************\n",
      "2017-01-02 00:17:53,539 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-02 00:17:53,541 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-02 00:17:53,557 : INFO : Loading new batch for index: 0\n",
      "2017-01-02 00:18:04,040 : INFO : Finished loading new batch\n",
      "2017-01-02 00:18:04,334 : INFO : PROGRESS: at 0.00% examples, 626 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:18:24,370 : INFO : PROGRESS: at 2.52% examples, 227306 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:18:44,376 : INFO : PROGRESS: at 5.10% examples, 278147 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:19:04,408 : INFO : PROGRESS: at 7.76% examples, 304051 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:19:24,411 : INFO : PROGRESS: at 10.59% examples, 321185 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:19:44,418 : INFO : PROGRESS: at 13.47% examples, 333291 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:20:04,445 : INFO : PROGRESS: at 16.32% examples, 342085 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:20:24,523 : INFO : PROGRESS: at 19.23% examples, 348101 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:20:31,809 : INFO : Loading new batch for index: 10000\n",
      "2017-01-02 00:20:43,357 : INFO : Finished loading new batch\n",
      "2017-01-02 00:20:44,524 : INFO : PROGRESS: at 20.07% examples, 321818 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-02 00:21:04,531 : INFO : PROGRESS: at 22.82% examples, 328134 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-02 00:21:24,581 : INFO : PROGRESS: at 25.61% examples, 332641 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:21:44,594 : INFO : PROGRESS: at 28.37% examples, 336227 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:22:04,623 : INFO : PROGRESS: at 31.18% examples, 340412 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:22:24,621 : INFO : PROGRESS: at 34.00% examples, 344044 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:22:44,629 : INFO : PROGRESS: at 36.90% examples, 347285 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:23:04,643 : INFO : PROGRESS: at 39.62% examples, 349613 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:23:09,702 : INFO : Loading new batch for index: 20000\n",
      "2017-01-02 00:23:20,837 : INFO : Finished loading new batch\n",
      "2017-01-02 00:23:24,659 : INFO : PROGRESS: at 40.56% examples, 336303 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:23:44,668 : INFO : PROGRESS: at 43.34% examples, 339347 words/s, in_qsize 45, out_qsize 1\n",
      "2017-01-02 00:24:04,682 : INFO : PROGRESS: at 46.11% examples, 341773 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:24:24,699 : INFO : PROGRESS: at 49.03% examples, 344277 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:24:44,713 : INFO : PROGRESS: at 51.79% examples, 346251 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:25:04,741 : INFO : PROGRESS: at 54.60% examples, 348044 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:25:24,742 : INFO : PROGRESS: at 57.38% examples, 349194 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:25:47,105 : INFO : Loading new batch for index: 30000\n",
      "2017-01-02 00:25:47,124 : INFO : PROGRESS: at 60.14% examples, 348399 words/s, in_qsize 37, out_qsize 18\n",
      "2017-01-02 00:25:59,003 : INFO : Finished loading new batch\n",
      "2017-01-02 00:26:07,127 : INFO : PROGRESS: at 61.24% examples, 340541 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:26:27,160 : INFO : PROGRESS: at 63.98% examples, 341968 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:26:47,175 : INFO : PROGRESS: at 66.83% examples, 343499 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:27:07,178 : INFO : PROGRESS: at 69.56% examples, 344915 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:27:27,189 : INFO : PROGRESS: at 72.34% examples, 346359 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:27:47,197 : INFO : PROGRESS: at 75.27% examples, 347690 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:28:07,199 : INFO : PROGRESS: at 78.06% examples, 348916 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:28:24,640 : INFO : Loading new batch for index: 40000\n",
      "2017-01-02 00:28:35,398 : INFO : Finished loading new batch\n",
      "2017-01-02 00:28:36,107 : INFO : PROGRESS: at 80.36% examples, 343044 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:28:56,126 : INFO : PROGRESS: at 83.18% examples, 344327 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:29:16,133 : INFO : PROGRESS: at 86.07% examples, 345651 words/s, in_qsize 45, out_qsize 1\n",
      "2017-01-02 00:29:36,134 : INFO : PROGRESS: at 88.87% examples, 346830 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:29:56,147 : INFO : PROGRESS: at 91.64% examples, 347775 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:30:16,189 : INFO : PROGRESS: at 94.43% examples, 348811 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:30:36,229 : INFO : PROGRESS: at 97.17% examples, 349715 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:30:58,137 : INFO : Loading new batch for index: 49789\n",
      "2017-01-02 00:30:58,150 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-02 00:30:58,154 : INFO : PROGRESS: at 99.85% examples, 349372 words/s, in_qsize 32, out_qsize 13\n",
      "2017-01-02 00:30:58,732 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-02 00:30:58,745 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-02 00:30:58,751 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-02 00:30:58,755 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-02 00:30:58,771 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-02 00:30:58,777 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-02 00:30:58,784 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-02 00:30:58,787 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-02 00:30:58,796 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-02 00:30:58,815 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-02 00:30:58,843 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-02 00:30:58,845 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-02 00:30:58,859 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-02 00:30:58,864 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-02 00:30:58,869 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-02 00:30:58,878 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-02 00:30:58,879 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-02 00:30:58,880 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-02 00:30:58,893 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-02 00:30:58,894 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-02 00:30:58,897 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-02 00:30:58,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-02 00:30:58,910 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-02 00:30:58,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-02 00:30:58,914 : INFO : training on 390507860 raw words (274492312 effective words) took 785.4s, 349513 effective words/s\n",
      "2017-01-02 00:30:58,917 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_19/model, separately None\n",
      "2017-01-02 00:30:58,918 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_19/model.docvecs.doctag_syn0.npy\n",
      "2017-01-02 00:31:00,446 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_19/model.syn1neg.npy\n",
      "2017-01-02 00:31:04,806 : INFO : not storing attribute syn0norm\n",
      "2017-01-02 00:31:04,807 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_19/model.syn0.npy\n",
      "2017-01-02 00:31:09,012 : INFO : not storing attribute cum_table\n",
      "2017-01-02 00:31:16,026 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-02 00:31:23,034 : INFO : capital-common-countries: 13.5% (21/156)\n",
      "2017-01-02 00:31:29,392 : INFO : capital-world: 13.2% (20/152)\n",
      "2017-01-02 00:31:31,020 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-02 00:32:20,888 : INFO : city-in-state: 3.5% (44/1248)\n",
      "2017-01-02 00:32:25,251 : INFO : family: 23.6% (26/110)\n",
      "2017-01-02 00:32:47,175 : INFO : gram1-adjective-to-adverb: 7.6% (42/552)\n",
      "2017-01-02 00:33:00,771 : INFO : gram2-opposite: 24.3% (83/342)\n",
      "2017-01-02 00:33:53,632 : INFO : gram3-comparative: 57.1% (761/1332)\n",
      "2017-01-02 00:34:23,671 : INFO : gram4-superlative: 20.9% (158/756)\n",
      "2017-01-02 00:35:00,663 : INFO : gram5-present-participle: 22.9% (213/930)\n",
      "2017-01-02 00:35:24,042 : INFO : gram6-nationality-adjective: 6.0% (35/584)\n",
      "2017-01-02 00:36:14,196 : INFO : gram7-past-tense: 10.2% (129/1260)\n",
      "2017-01-02 00:36:53,696 : INFO : gram8-plural: 37.4% (371/992)\n",
      "2017-01-02 00:37:21,655 : INFO : gram9-plural-verbs: 42.6% (299/702)\n",
      "2017-01-02 00:37:21,658 : INFO : total: 24.0% (2202/9156)\n",
      "2017-01-02 00:37:26,373 : INFO : Training Classifier\n",
      "2017-01-02 00:39:07,594 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 00:39:40,497 : INFO : Getting Validation Embeddings\n",
      "2017-01-02 00:39:40,500 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-02 00:39:40,512 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.175, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.608, Top 3: 0.879, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 00:39:51,268 : INFO : Finished loading new batch\n",
      "2017-01-02 00:40:20,508 : INFO : Finished: 999\n",
      "2017-01-02 00:40:50,191 : INFO : Finished: 1999\n",
      "2017-01-02 00:41:18,969 : INFO : Finished: 2999\n",
      "2017-01-02 00:41:47,299 : INFO : Finished: 3999\n",
      "2017-01-02 00:42:16,303 : INFO : Finished: 4999\n",
      "2017-01-02 00:42:45,423 : INFO : Finished: 5999\n",
      "2017-01-02 00:43:13,278 : INFO : Finished: 6999\n",
      "2017-01-02 00:43:41,136 : INFO : Finished: 7999\n",
      "2017-01-02 00:44:09,948 : INFO : Finished: 8999\n",
      "2017-01-02 00:44:38,026 : INFO : Finished: 9999\n",
      "2017-01-02 00:44:40,318 : INFO : Loading new batch for index: 10000\n",
      "2017-01-02 00:44:42,721 : INFO : Finished loading new batch\n",
      "2017-01-02 00:45:12,067 : INFO : Finished: 10999\n",
      "2017-01-02 00:45:40,671 : INFO : Finished: 11999\n",
      "2017-01-02 00:45:41,097 : INFO : Loading new batch for index: 12412\n",
      "2017-01-02 00:45:41,101 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-02 00:45:54,001 : INFO : Finished: 12412\n",
      "2017-01-02 00:45:54,005 : INFO : Finished: 12412\n",
      "2017-01-02 00:45:58,466 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 1 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.210, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.589, Top 3: 0.869, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.630, Total Pos: 28,163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 00:46:02,686 : INFO : ****************** Epoch 20 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_20 *******************\n",
      "2017-01-02 00:46:02,690 : INFO : training model with 24 workers on 146034 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-02 00:46:02,691 : INFO : expecting 65535 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-02 00:46:02,711 : INFO : Loading new batch for index: 0\n",
      "2017-01-02 00:46:13,105 : INFO : Finished loading new batch\n",
      "2017-01-02 00:46:13,466 : INFO : PROGRESS: at 0.00% examples, 632 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:46:33,473 : INFO : PROGRESS: at 2.53% examples, 228978 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:46:53,518 : INFO : PROGRESS: at 5.13% examples, 280322 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-02 00:47:13,539 : INFO : PROGRESS: at 7.77% examples, 304540 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:47:33,576 : INFO : PROGRESS: at 10.54% examples, 319626 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:47:53,587 : INFO : PROGRESS: at 13.25% examples, 328713 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:48:13,622 : INFO : PROGRESS: at 15.95% examples, 334262 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:48:33,627 : INFO : PROGRESS: at 18.69% examples, 338594 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:48:45,325 : INFO : Loading new batch for index: 10000\n",
      "2017-01-02 00:48:55,793 : INFO : Finished loading new batch\n",
      "2017-01-02 00:48:56,270 : INFO : PROGRESS: at 20.03% examples, 316142 words/s, in_qsize 0, out_qsize 0\n",
      "2017-01-02 00:49:16,279 : INFO : PROGRESS: at 22.52% examples, 319650 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:49:36,286 : INFO : PROGRESS: at 25.31% examples, 324830 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-02 00:49:56,293 : INFO : PROGRESS: at 28.11% examples, 329556 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-02 00:50:16,305 : INFO : PROGRESS: at 30.85% examples, 333508 words/s, in_qsize 48, out_qsize 2\n",
      "2017-01-02 00:50:36,321 : INFO : PROGRESS: at 33.65% examples, 337229 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:50:56,342 : INFO : PROGRESS: at 36.49% examples, 340352 words/s, in_qsize 48, out_qsize 1\n",
      "2017-01-02 00:51:16,353 : INFO : PROGRESS: at 39.18% examples, 342777 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:51:24,970 : INFO : Loading new batch for index: 20000\n",
      "2017-01-02 00:51:36,578 : INFO : Finished loading new batch\n",
      "2017-01-02 00:51:37,252 : INFO : PROGRESS: at 40.13% examples, 329431 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:51:57,271 : INFO : PROGRESS: at 42.73% examples, 331401 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:52:17,317 : INFO : PROGRESS: at 45.42% examples, 333781 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:52:37,322 : INFO : PROGRESS: at 48.37% examples, 336593 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:52:57,327 : INFO : PROGRESS: at 51.08% examples, 338513 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:53:17,348 : INFO : PROGRESS: at 53.73% examples, 339748 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:53:37,353 : INFO : PROGRESS: at 56.53% examples, 341406 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:53:57,355 : INFO : PROGRESS: at 59.29% examples, 342938 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:54:05,763 : INFO : Loading new batch for index: 30000\n",
      "2017-01-02 00:54:16,506 : INFO : Finished loading new batch\n",
      "2017-01-02 00:54:17,430 : INFO : PROGRESS: at 60.28% examples, 334320 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:54:37,465 : INFO : PROGRESS: at 63.06% examples, 336204 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:54:57,472 : INFO : PROGRESS: at 65.87% examples, 338075 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:55:17,476 : INFO : PROGRESS: at 68.64% examples, 339658 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:55:37,540 : INFO : PROGRESS: at 71.38% examples, 340996 words/s, in_qsize 47, out_qsize 1\n",
      "2017-01-02 00:55:57,546 : INFO : PROGRESS: at 74.21% examples, 342207 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:56:17,559 : INFO : PROGRESS: at 76.94% examples, 343152 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:56:37,593 : INFO : PROGRESS: at 79.63% examples, 344037 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:56:44,311 : INFO : Loading new batch for index: 40000\n",
      "2017-01-02 00:56:54,351 : INFO : Finished loading new batch\n",
      "2017-01-02 00:56:57,609 : INFO : PROGRESS: at 80.65% examples, 337768 words/s, in_qsize 46, out_qsize 1\n",
      "2017-01-02 00:57:17,641 : INFO : PROGRESS: at 83.13% examples, 337854 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:57:37,687 : INFO : PROGRESS: at 85.80% examples, 338413 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:57:57,711 : INFO : PROGRESS: at 88.41% examples, 339096 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:58:17,723 : INFO : PROGRESS: at 91.03% examples, 339782 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:58:37,730 : INFO : PROGRESS: at 93.78% examples, 340664 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:58:57,747 : INFO : PROGRESS: at 96.38% examples, 341323 words/s, in_qsize 48, out_qsize 0\n",
      "2017-01-02 00:59:17,790 : INFO : PROGRESS: at 98.96% examples, 341707 words/s, in_qsize 47, out_qsize 0\n",
      "2017-01-02 00:59:27,140 : INFO : Loading new batch for index: 49789\n",
      "2017-01-02 00:59:27,149 : INFO : No more batches to load, exiting at index: 49789\n",
      "2017-01-02 00:59:27,728 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-01-02 00:59:27,731 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-01-02 00:59:27,737 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-01-02 00:59:27,748 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-01-02 00:59:27,778 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-01-02 00:59:27,788 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-01-02 00:59:27,795 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-01-02 00:59:27,798 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-01-02 00:59:27,816 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-01-02 00:59:27,828 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-01-02 00:59:27,843 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-01-02 00:59:27,858 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-01-02 00:59:27,862 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-01-02 00:59:27,864 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-01-02 00:59:27,868 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-01-02 00:59:27,871 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-01-02 00:59:27,874 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-02 00:59:27,878 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-02 00:59:27,904 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-02 00:59:27,906 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-02 00:59:27,912 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-02 00:59:27,924 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-02 00:59:27,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-02 00:59:27,940 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-02 00:59:27,941 : INFO : training on 390507860 raw words (274489882 effective words) took 805.2s, 340884 effective words/s\n",
      "2017-01-02 00:59:27,947 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_20/model, separately None\n",
      "2017-01-02 00:59:27,949 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_20/model.docvecs.doctag_syn0.npy\n",
      "2017-01-02 00:59:29,497 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_20/model.syn1neg.npy\n",
      "2017-01-02 00:59:33,772 : INFO : not storing attribute syn0norm\n",
      "2017-01-02 00:59:33,774 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/sample_0.01/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_20/model.syn0.npy\n",
      "2017-01-02 00:59:38,373 : INFO : not storing attribute cum_table\n",
      "2017-01-02 00:59:45,325 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-02 00:59:52,105 : INFO : capital-common-countries: 13.5% (21/156)\n",
      "2017-01-02 00:59:58,229 : INFO : capital-world: 12.5% (19/152)\n",
      "2017-01-02 00:59:59,834 : INFO : currency: 0.0% (0/40)\n",
      "2017-01-02 01:00:49,435 : INFO : city-in-state: 3.4% (43/1248)\n",
      "2017-01-02 01:00:53,791 : INFO : family: 23.6% (26/110)\n",
      "2017-01-02 01:01:15,675 : INFO : gram1-adjective-to-adverb: 8.3% (46/552)\n",
      "2017-01-02 01:01:29,208 : INFO : gram2-opposite: 23.1% (79/342)\n",
      "2017-01-02 01:02:21,946 : INFO : gram3-comparative: 57.1% (761/1332)\n",
      "2017-01-02 01:02:51,945 : INFO : gram4-superlative: 19.8% (150/756)\n",
      "2017-01-02 01:03:28,793 : INFO : gram5-present-participle: 23.8% (221/930)\n",
      "2017-01-02 01:03:51,945 : INFO : gram6-nationality-adjective: 6.2% (36/584)\n",
      "2017-01-02 01:04:41,896 : INFO : gram7-past-tense: 10.1% (127/1260)\n",
      "2017-01-02 01:05:21,254 : INFO : gram8-plural: 37.0% (367/992)\n",
      "2017-01-02 01:05:49,011 : INFO : gram9-plural-verbs: 41.2% (289/702)\n",
      "2017-01-02 01:05:49,014 : INFO : total: 23.9% (2185/9156)\n",
      "2017-01-02 01:05:53,716 : INFO : Training Classifier\n",
      "2017-01-02 01:07:33,010 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 01:08:04,711 : INFO : Getting Validation Embeddings\n",
      "2017-01-02 01:08:04,714 : INFO : ===== Getting validation vectors with inference\n",
      "2017-01-02 01:08:04,727 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.175, Avg Labels: 1.290, \n",
      "\t\t Top 1: 0.608, Top 3: 0.879, Top 5: 0.955, \n",
      "\t\t F1 Micro: 0.638, Total Pos: 109,159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-02 01:08:14,769 : INFO : Finished loading new batch\n",
      "2017-01-02 01:08:43,739 : INFO : Finished: 999\n",
      "2017-01-02 01:09:13,448 : INFO : Finished: 1999\n",
      "2017-01-02 01:09:42,314 : INFO : Finished: 2999\n",
      "2017-01-02 01:10:10,699 : INFO : Finished: 3999\n",
      "2017-01-02 01:10:39,714 : INFO : Finished: 4999\n",
      "2017-01-02 01:11:08,766 : INFO : Finished: 5999\n",
      "2017-01-02 01:11:36,454 : INFO : Finished: 6999\n",
      "2017-01-02 01:12:04,381 : INFO : Finished: 7999\n",
      "2017-01-02 01:12:33,224 : INFO : Finished: 8999\n",
      "2017-01-02 01:13:01,682 : INFO : Finished: 9999\n",
      "2017-01-02 01:13:03,957 : INFO : Loading new batch for index: 10000\n",
      "2017-01-02 01:13:06,457 : INFO : Finished loading new batch\n",
      "2017-01-02 01:13:35,536 : INFO : Finished: 10999\n",
      "2017-01-02 01:14:04,018 : INFO : Finished: 11999\n",
      "2017-01-02 01:14:04,402 : INFO : Loading new batch for index: 12412\n",
      "2017-01-02 01:14:04,406 : INFO : No more batches to load, exiting at index: 12412\n",
      "2017-01-02 01:14:17,043 : INFO : Finished: 12412\n",
      "2017-01-02 01:14:17,045 : INFO : Finished: 12412\n",
      "2017-01-02 01:14:21,531 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.261, Avg Labels: 1.300, \n",
      "\t\t Top 1: 0.591, Top 3: 0.868, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.628, Total Pos: 27,757\n",
      "CPU times: user 5d 5h 54min 47s, sys: 23h 51min 59s, total: 6d 5h 46min 47s\n",
      "Wall time: 8h 57min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph(len(classifications) +2)\n",
    "# when resuming, resume from an epoch with a previously created doc2vec model to get the learning rate right\n",
    "start_from = 1\n",
    "for epoch in range(start_from, DOC2VEC_MAX_EPOCHS+1):\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    info(\"****************** Epoch {} --- Working on {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "    # if we have the model, just load it, otherwise train the previous model\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "        doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "    else:\n",
    "        # train the doc2vec model\n",
    "        training_docs_iterator = DocumentBatchGenerator(training_preprocessed_files_prefix, \n",
    "                                                        training_preprocessed_docids_files_prefix, batch_size=10000)\n",
    "        doc2vec_model.train(sentences=training_docs_iterator, report_delay=REPORT_DELAY)\n",
    "        doc2vec_model.alpha -= 0.001  # decrease the learning rate\n",
    "        doc2vec_model.min_alpha = doc2vec_model.alpha  # fix the learning rate, no decay\n",
    "        ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME))\n",
    "        doc2vec_model.save(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "        \n",
    "        # get the word2vec analogy accuracy score\n",
    "        word2vec_result = doc2vec_model.accuracy(word2vec_questions_file, restrict_vocab=None)\n",
    "        epoch_word2vec_metrics.append(word2vec_result)\n",
    "        pickle.dump(word2vec_result, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME,\n",
    "                                                       WORD2VEC_METRICS_FILENAME), 'w'))\n",
    "\n",
    "    X, y = get_training_data(doc2vec_model, classifications)\n",
    "    \n",
    "    # try class weights\n",
    "    # try warm start and evaluate after every iter\n",
    "    \n",
    "    info('Training Classifier')\n",
    "    clf = OneVsRestClassifier(linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                         #alpha is the 1/C parameter\n",
    "                                                         alpha=SVM_REG, fit_intercept=True, n_iter=SVM_ITERATIONS,\n",
    "                                                         #n_jobs=-1 means use all cpus\n",
    "                                                         shuffle=True, verbose=0, n_jobs=1,\n",
    "                                                         #eta0 is the learning rate when we use constant configuration\n",
    "                                                         random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                         class_weight=SVM_CLASS_WEIGHTS, warm_start=False), n_jobs=1)\n",
    "    \n",
    "    \n",
    "    # Training Metrics\n",
    "    clf.fit(X,y)\n",
    "    info('Evaluating on Training Data')\n",
    "    yp = clf.predict(X)\n",
    "    print yp\n",
    "    training_metrics = get_metrics(y, yp, yp)\n",
    "    print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "        training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "        training_metrics['f1_micro'], training_metrics['total_positive'])\n",
    "    \n",
    "    epoch_training_metrics.append(training_metrics)\n",
    "    \n",
    "    \n",
    "    # Validation Metrics\n",
    "    info('Getting Validation Embeddings')\n",
    "    Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                    validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                    validation_preprocessed_docids_files_prefix)\n",
    "    info('Evaluating on Validation Data')\n",
    "    yvp = clf.predict(Xv)\n",
    "    print yvp\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp)\n",
    "    print \"** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "        validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['total_positive'])\n",
    "    \n",
    "    graph.add_metrics_to_graph(validation_metrics, epoch)\n",
    "    \n",
    "    epoch_validation_metrics.append(validation_metrics)\n",
    "    \n",
    "    \n",
    "    # Saving the metrics\n",
    "    \n",
    "    ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "    pickle.dump(training_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, TRAINING_METRICS_FILENAME), 'w'))\n",
    "    pickle.dump(validation_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, VALIDATION_METRICS_FILENAME), 'w'))\n",
    "\n",
    "\n",
    "\n",
    "# graph.fig.savefig(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.DOC2VEC_MODEL_NAME, \n",
    "#                                             METRICS_FIG_PNG_FILENAME))\n",
    "# graph.fig.savefig(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.DOC2VEC_MODEL_NAME, \n",
    "#                                             METRICS_FIG_PDF_FILENAME))\n",
    "\n",
    "\n",
    "#     # Training and validation of SVMs using those docvecs\n",
    "#     train_classifications(sections)\n",
    "#     validation_vectors_matrix = get_validation_docs_with_inference(doc2vec_model, doc_classification_map)\n",
    "#     metrics = do_validation(validation_vectors_matrix, doc_classification_map, sections, \"sections\")\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "#     print \"Coverage Error: {}, Average No of Labels: {}, Top 1: {}, Top 3: {}, Top 5: {}, F1 Micro: {}, Total Positive: {}\".format(\n",
    "#         metrics['coverage_error'], metrics['average_num_of_labels'], metrics['top_1'], metrics['top_3'], metrics['top_5'], \n",
    "#         metrics['f1_micro'], metrics['total_positive'])\n",
    "                                                                                     \n",
    "#     epoch_metrics.append(metrics)\n",
    "#     graph.add_metrics_to_graph(metrics, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import thesis.utils.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 22:22:21,536 : INFO : Loading new batch\n",
      "2016-12-28 22:22:27,109 : INFO : Finished loading new batch\n"
     ]
    }
   ],
   "source": [
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "i=0\n",
    "doc_contents = []\n",
    "for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "    i += 1\n",
    "    doc_contents.append((doc_id, doc_contents_array))\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def infer_one_doc(doc):\n",
    "    #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "    rep = doc2vec_model.infer_vector(doc[1])\n",
    "    return (doc[0], rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threaded Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 620 ms, total: 1min 41s\n",
      "Wall time: 9.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = ThreadPool(16)\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "threaded_reps = pool.map(infer_one_doc, doc_contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Threaded Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 44 ms, total: 14.1 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reps = []\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "for doc in doc_contents:\n",
    "    reps.append((doc[0], doc2vec_model.infer_vector(doc[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'08825480',\n",
       " u'08774433',\n",
       " u'08791071',\n",
       " u'08912011',\n",
       " u'08678092',\n",
       " u'08859194',\n",
       " u'08635554',\n",
       " u'08914715',\n",
       " u'08740442',\n",
       " u'08740792',\n",
       " u'08741891',\n",
       " u'08889791',\n",
       " u'08845058',\n",
       " u'08675352',\n",
       " u'08910298',\n",
       " u'08908470',\n",
       " u'07336611',\n",
       " u'07370801',\n",
       " u'08923495',\n",
       " u'08730828']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[0] for d in threaded_reps][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'08825480',\n",
       " u'08774433',\n",
       " u'08791071',\n",
       " u'08912011',\n",
       " u'08678092',\n",
       " u'08859194',\n",
       " u'08635554',\n",
       " u'08914715',\n",
       " u'08740442',\n",
       " u'08740792',\n",
       " u'08741891',\n",
       " u'08889791',\n",
       " u'08845058',\n",
       " u'08675352',\n",
       " u'08910298',\n",
       " u'08908470',\n",
       " u'07336611',\n",
       " u'07370801',\n",
       " u'08923495',\n",
       " u'08730828']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[0] for d in reps][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal([d[0] for d in reps], [d[0] for d in threaded_reps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30695215,  0.62732637, -0.16665867,  0.21510798, -0.31053102,\n",
       "        0.24912256,  0.27854046, -0.18195362, -0.2556676 , -0.5964365 ,\n",
       "        0.21105912, -0.23973639, -0.03185667, -0.07150706,  0.34752986,\n",
       "       -0.10195051, -0.21096784, -0.16357803, -0.36328176,  0.69572109,\n",
       "        0.56532162, -0.2350243 ,  0.29052514,  0.08191228,  0.35617095,\n",
       "       -0.04608935, -0.22245102, -0.2092436 ,  0.03193387,  0.20119652,\n",
       "        0.41143674, -0.00198068,  0.2738685 ,  0.53701001, -0.1117554 ,\n",
       "       -0.03540101, -0.34937236, -0.79319656, -0.24756837,  0.25518459,\n",
       "       -0.13143119, -0.28934225,  0.40138   , -0.98963302,  0.13317154,\n",
       "       -0.78089136,  0.02822817,  0.09919885,  0.06839398,  1.14812255,\n",
       "       -0.35712692,  0.03212974,  0.31967002,  0.01885306,  0.32403627,\n",
       "        0.06881366, -0.36663699, -0.06164655, -0.50977266,  0.13202219,\n",
       "        0.34584206, -0.23481339, -0.26995379, -0.05701207,  0.09176121,\n",
       "        0.05095135, -0.33242008,  0.24291369,  0.01117826,  0.10993928,\n",
       "       -0.1800983 ,  0.49444726,  0.26564318,  0.7361095 , -0.06239768,\n",
       "       -0.21320428, -0.20742436, -0.03807143, -0.12843417, -0.48612225,\n",
       "        0.14675111,  0.1267944 , -0.44746301, -0.68673682, -0.54249072,\n",
       "       -0.07855206, -0.43142584,  0.35044146,  0.15806454, -0.81718534,\n",
       "       -0.24564786, -0.41462311,  0.05346218,  0.13060793, -0.52602261,\n",
       "       -0.68961495, -0.35983112, -0.10904109, -0.70629472, -0.74079585], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44398868,  0.72295773, -0.1431679 ,  0.12140259, -0.35566956,\n",
       "        0.25285348,  0.25987589, -0.25635543, -0.27375746, -0.68261814,\n",
       "        0.2418227 , -0.31993562, -0.04068605, -0.19011304,  0.25827357,\n",
       "       -0.23827454, -0.14665996, -0.24676035, -0.31205919,  0.7144047 ,\n",
       "        0.51341397, -0.27819353,  0.2297533 ,  0.21143083,  0.21526954,\n",
       "       -0.12819654, -0.23137507, -0.18031113, -0.0302615 ,  0.25606248,\n",
       "        0.46331209,  0.03231328,  0.29240945,  0.55419838, -0.08406049,\n",
       "       -0.02534914, -0.30697635, -0.89490503, -0.25361407, -0.0620365 ,\n",
       "       -0.10279118, -0.24122375,  0.2858358 , -0.89883715,  0.2349384 ,\n",
       "       -0.77614403,  0.07704009,  0.00219567,  0.05001302,  1.00935435,\n",
       "       -0.43593982,  0.03736721,  0.49705869, -0.04218138,  0.37695912,\n",
       "        0.0875724 , -0.41761422,  0.01351045, -0.63688326,  0.19897321,\n",
       "        0.29641187, -0.23571339, -0.14795278, -0.12061672,  0.1306804 ,\n",
       "        0.2521036 , -0.36068025,  0.26970887, -0.00897445,  0.17607778,\n",
       "       -0.101063  ,  0.44033691,  0.19987908,  0.65593952, -0.2147298 ,\n",
       "       -0.10094108, -0.20588517, -0.08825132, -0.08381121, -0.44989595,\n",
       "        0.17535064,  0.10233553, -0.57504725, -0.80179036, -0.56347519,\n",
       "       -0.09048223, -0.4018501 ,  0.54773515,  0.20243937, -0.86586028,\n",
       "       -0.30235139, -0.51399952,  0.10769948, -0.03541334, -0.45822388,\n",
       "       -0.72284496, -0.29005697, -0.11217777, -0.75840199, -0.75367755], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threaded_reps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple threading, but problem is that pool.map exhausts the whole iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 23:52:07,981 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 12 ms, total: 36 ms\n",
      "Wall time: 26.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 23:52:14,764 : INFO : Finished loading new batch\n",
      "2016-12-28 23:52:16,320 : INFO : Loading new batch for index: 10000\n",
      "2016-12-28 23:52:36,742 : INFO : Finished loading new batch\n",
      "2016-12-28 23:52:37,438 : INFO : Loading new batch for index: 12412\n",
      "2016-12-28 23:52:37,487 : INFO : No more batches to load, exiting at index: 12412\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "pool = ThreadPool(16)\n",
    "threaded_reps = pool.map(infer_one_doc, validation_docs_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nothing_func(doc):\n",
    "    1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-29 02:08:42,347 : INFO : Loading new batch for index: 0\n",
      "2016-12-29 02:08:49,943 : INFO : Finished loading new batch\n",
      "2016-12-29 02:09:13,387 : INFO : Finished: 1000\n",
      "2016-12-29 02:09:36,895 : INFO : Finished: 2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-20d2bff78aed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'validation_docs_iterator = DocumentBatchGenerator2(validation_preprocessed_files_prefix, \\n                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\\ngenerator_func = validation_docs_iterator.__iter__()\\npool = ThreadPool(16)\\n# map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\\nthreaded_reps = {}\\nmini_batch_size = 1000\\nwhile True:\\n    threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\\n    info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\\n    if threaded_reps_partial:\\n        #threaded_reps.extend(threaded_reps_partial)\\n        threaded_reps.update(threaded_reps_partial)\\n    else:\\n        break'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    249\u001b[0m         '''\n\u001b[0;32m    250\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_docs_iterator = DocumentBatchGenerator2(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "generator_func = validation_docs_iterator.__iter__()\n",
    "pool = ThreadPool(16)\n",
    "# map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "threaded_reps = {}\n",
    "mini_batch_size = 1000\n",
    "while True:\n",
    "    threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "    info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "    if threaded_reps_partial:\n",
    "        #threaded_reps.extend(threaded_reps_partial)\n",
    "        threaded_reps.update(threaded_reps_partial)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocumentBatchGenerator2(object):\n",
    "    def __init__(self, filename_prefix, filename_docids_prefix, batch_size=10000 ):\n",
    "        \"\"\"\n",
    "        batch_size cant be > 10,000 due to a limitation in doc2vec training, \n",
    "        None means no batching (only use for inference)\n",
    "        \"\"\"\n",
    "        assert batch_size <= 10000 or batch_size is None\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.filename_docids_prefix = filename_docids_prefix\n",
    "        self.curr_lines = []\n",
    "        self.curr_docids = []\n",
    "        self.batch_size = batch_size\n",
    "        self.curr_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        self.curr_lines, self.docids = [], []\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_index) )\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    self.curr_lines.append(line.split(\" \"))\n",
    "#                     if i % 1000 == 0:\n",
    "#                         print i\n",
    "            self.curr_docids = pickle.load(open(self.filename_docids_prefix + str(self.curr_index), \"r\"))\n",
    "            self.batch_end = self.curr_index + len(self.curr_lines) -1 \n",
    "            info(\"Finished loading new batch\")\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_index))\n",
    "            raise StopIteration()\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            if self.curr_index > self.batch_end:\n",
    "                self.load_new_batch_in_memory()\n",
    "            for (doc_id, tokens) in zip(self.curr_docids, self.curr_lines):\n",
    "                if self.batch_size is not None:\n",
    "                    curr_batch_iter = 0\n",
    "                    # divide the document to batches according to the batch size\n",
    "                    while curr_batch_iter < len(tokens):\n",
    "                        self.curr_index += 1\n",
    "                        yield LabeledSentence(words=tokens[curr_batch_iter: curr_batch_iter + self.batch_size], tags=[doc_id])\n",
    "                        curr_batch_iter += self.batch_size\n",
    "                else:\n",
    "                    self.curr_index += 1\n",
    "                    yield doc_id, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12412"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threaded_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "pool = ThreadPool(20)\n",
    "# map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "threaded_reps = []\n",
    "mini_batch_size = 1000\n",
    "while True:\n",
    "    threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(validation_docs_iterator, mini_batch_size))\n",
    "    info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "    if threaded_reps_partial:\n",
    "        threaded_reps.extend(threaded_reps_partial)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def g():\n",
    "    for el in xrange(50):\n",
    "        yield el\n",
    "\n",
    "go = g()\n",
    "result = []\n",
    "N = 10\n",
    "for i in itertools.islice(go, N):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 18:35:17,009 : INFO : Loading new batch\n",
      "2016-12-28 18:35:21,915 : INFO : Finished loading new batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 848 ms, sys: 8 ms, total: 856 ms\n",
      "Wall time: 852 ms\n",
      "CPU times: user 448 ms, sys: 12 ms, total: 460 ms\n",
      "Wall time: 457 ms\n",
      "CPU times: user 248 ms, sys: 4 ms, total: 252 ms\n",
      "Wall time: 250 ms\n",
      "{u'08774433': array([-0.24957576, -0.44971526, -0.56399536,  0.26340374, -0.72280848,\n",
      "        0.07701001,  0.53518784,  0.47400331,  0.00103833, -0.21523826,\n",
      "        0.5090881 , -0.66132861, -0.54403561,  0.44076878,  0.00470332,\n",
      "       -0.60674977,  0.25171441,  0.01955804, -0.42058256,  0.12502177,\n",
      "       -0.16908602, -0.77621526,  0.66039973,  0.22638585, -0.14937432,\n",
      "        0.18073724, -0.22520301, -0.01612019, -0.94866085, -0.56705993,\n",
      "       -0.31372947, -0.61444628,  0.36096638,  0.05321291,  0.31520829,\n",
      "       -0.78794104, -0.02634728,  0.27075273, -0.69757801, -0.11887208,\n",
      "        0.24548931, -0.37358913,  0.30241317, -0.02301121, -0.16444607,\n",
      "        0.32210201, -0.49894542,  0.47786587, -0.7696104 ,  0.57316011,\n",
      "        0.75851572, -0.29875955, -0.39299953,  0.29592195,  0.01002928,\n",
      "       -0.00714504, -0.45345017, -0.45329556, -0.15423954,  0.0956117 ,\n",
      "       -0.17815629,  0.00485223, -0.47434196,  0.8352198 ,  0.29984775,\n",
      "       -0.75325739, -0.2932708 ,  0.22751437, -0.72489858, -0.23059492,\n",
      "       -0.62555069,  1.02729392, -0.00715734, -0.35845065, -0.04130894,\n",
      "       -0.63375956,  0.13670547, -0.35168752, -0.120276  ,  0.06363766,\n",
      "       -0.14529508, -0.73692763, -0.10244129,  0.24102579, -0.39304346,\n",
      "       -0.44905126, -0.02963378,  0.40327483,  0.09173202, -0.20075732,\n",
      "        0.25192481, -0.40484259,  0.03583284,  0.08575827, -0.71413624,\n",
      "       -0.12856877,  0.00697137,  0.17350946, -0.09800411, -0.2387124 ], dtype=float32), u'08825480': array([ 0.43869719,  0.69493228, -0.15423374,  0.18415831, -0.27953076,\n",
      "        0.32741979,  0.25916466, -0.2263912 , -0.30463687, -0.68594444,\n",
      "        0.23562942, -0.26695064, -0.03071095, -0.19515269,  0.16481824,\n",
      "       -0.26835197, -0.1237495 , -0.21595523, -0.31863457,  0.67200935,\n",
      "        0.54566181, -0.3022787 ,  0.21178976,  0.16891097,  0.25907236,\n",
      "       -0.13429914, -0.29047617, -0.19215892, -0.03019565,  0.23971696,\n",
      "        0.4794547 , -0.0125326 ,  0.27816984,  0.5431518 , -0.08415657,\n",
      "       -0.06213364, -0.31795123, -0.95289969, -0.25565225, -0.03096373,\n",
      "       -0.0847759 , -0.239768  ,  0.34742916, -0.92078727,  0.13093236,\n",
      "       -0.80080444,  0.06648453, -0.03016538,  0.06161455,  1.04044044,\n",
      "       -0.43327764,  0.07086919,  0.35355189,  0.01039008,  0.4170292 ,\n",
      "        0.08228578, -0.45204273, -0.00495607, -0.65024465,  0.18624543,\n",
      "        0.29581559, -0.26705703, -0.08137546, -0.06691577,  0.14972705,\n",
      "        0.151612  , -0.31241465,  0.24215488,  0.00248444,  0.1801302 ,\n",
      "       -0.09848733,  0.43015948,  0.1988074 ,  0.64442545, -0.18052702,\n",
      "       -0.18566328, -0.22178149, -0.0649749 , -0.09142254, -0.46278423,\n",
      "        0.15451705,  0.1908915 , -0.52935004, -0.82046568, -0.49538887,\n",
      "       -0.10716466, -0.36556813,  0.5163148 ,  0.19676271, -0.84946609,\n",
      "       -0.29985458, -0.52276957,  0.03275018,  0.06643863, -0.43565878,\n",
      "       -0.76278096, -0.28564611, -0.09855174, -0.72650057, -0.71671903], dtype=float32), u'08791071': array([-0.23259643,  0.41450036,  0.51434827,  0.00787312, -0.2284483 ,\n",
      "       -0.52937728, -0.19830056,  0.03082488,  1.05058038,  0.17992359,\n",
      "        0.31625026, -0.21843682, -0.37463692, -0.30913776,  0.3170667 ,\n",
      "       -0.36334237, -0.70675725,  0.52395636, -0.26112491,  1.05543351,\n",
      "       -1.10443592, -0.21194471, -0.54147512,  0.09155747, -0.32934853,\n",
      "        0.01652185,  0.04093302,  0.08362015,  0.54133213,  0.03441263,\n",
      "       -0.88398618, -0.10849927,  0.56919503, -0.60503298,  0.12571461,\n",
      "        0.18873298,  0.17914939,  0.04950287, -0.28671712, -0.10798603,\n",
      "       -0.744412  ,  0.31562504, -0.27431366,  0.28065825,  0.23825864,\n",
      "       -0.1323806 ,  0.06025767, -0.22927827, -0.44928807,  0.21095365,\n",
      "        0.57495964, -0.1029187 , -0.00365091,  0.61913794, -0.88101172,\n",
      "        0.60874623, -0.38232478,  0.47158134, -0.05255252,  0.4324486 ,\n",
      "        0.3947401 ,  1.06982732,  0.19763152, -0.52621794,  0.30451465,\n",
      "       -0.41999158, -0.23451024,  0.31681204,  0.28471184, -0.22745852,\n",
      "       -0.60245752, -0.37300718, -0.06770302,  0.0346529 ,  0.36362028,\n",
      "       -0.08779243, -0.16030943, -0.11415948, -0.3266314 ,  0.30446157,\n",
      "        0.11385298, -0.21830294,  0.14570464, -0.71273166, -0.22124635,\n",
      "        0.22901915, -0.69352126, -0.81168574,  0.120683  ,  0.68962598,\n",
      "        0.1142956 ,  0.08250535, -0.01027837,  0.10909576,  0.22610265,\n",
      "        0.06197856, -0.4596194 ,  0.27084136,  0.23881529,  0.26482731], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "i = 0\n",
    "val_docs_reps = {}\n",
    "for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "    i += 1\n",
    "    %time val_docs_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array, steps=15)\n",
    "    if i > 2:\n",
    "        break\n",
    "    \n",
    "print val_docs_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_training_data(doc2vec_model, classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yc = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49789, 8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(estimator=linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                         #alpha is the 1/C parameter\n",
    "                                                         alpha=0.001, fit_intercept=True, n_iter=10,\n",
    "                                                         #n_jobs=-1 means use all cpus\n",
    "                                                         shuffle=True, verbose=1, epsilon=0.1, n_jobs=-1,\n",
    "                                                         #eta0 is the learning rate when we use constant configuration\n",
    "                                                         random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                         class_weight=None, warm_start=False), n_jobs=1)\n",
    "\n",
    "# clf = OneVsRestClassifier(estimator=SVC(kernel='linear'), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "yp = clf.predict(X)\n",
    "\n",
    "print yp\n",
    "\n",
    "training_metrics = get_metrics(np.array(y), yp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "Y = np.array(['a', 'a', 'b', 'b'])\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict([[-0.8, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_svm_epoch = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-11-26 18:25:14,192 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model\n",
      "2016-11-26 18:25:14,584 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.docvecs.* with mmap=None\n",
      "2016-11-26 18:25:14,585 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2016-11-26 18:25:14,814 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.syn1neg.npy with mmap=None\n",
      "2016-11-26 18:26:37,586 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.syn0.npy with mmap=None\n",
      "2016-11-26 18:26:41,876 : INFO : setting ignored attribute syn0norm to None\n",
      "2016-11-26 18:26:41,877 : INFO : setting ignored attribute cum_table to None\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(best_svm_epoch)\n",
    "doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 520 ms, total: 2.13 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifications = sections\n",
    "\n",
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "one_hot_encoder = OneHotEncoder(classifications)\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for doc_id in training_docs_list:\n",
    "    # converting from memmap to a normal array\n",
    "    normal_array = []\n",
    "    normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "    training_data.append(normal_array)\n",
    "    eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "    training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1969, 3000)\n",
      "CPU times: user 2.58 s, sys: 360 ms, total: 2.94 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "validation_labels = []\n",
    "validation_data = pickle.load(open(\n",
    "        os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)\n",
    "))\n",
    "print validation_data.shape\n",
    "\n",
    "for validation_doc_id in validation_docs_list:\n",
    "    eligible_classifications = [clssf for clssf in doc_classification_map[validation_doc_id] if clssf in classifications]\n",
    "    validation_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 500)           0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_64[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     dropout_65[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     dropout_66[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)             (None, 500)           0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_67[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)             (None, 500)           0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_68[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     dropout_69[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     dropout_70[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)             (None, 500)           0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_71[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)             (None, 500)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_72[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     dropout_73[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     dropout_74[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)             (None, 500)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_75[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)             (None, 500)           0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_76[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     dropout_77[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     dropout_78[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)             (None, 500)           0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_79[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)             (None, 500)           0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_80[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     dropout_81[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     dropout_82[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)             (None, 500)           0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_83[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)             (None, 1500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_84[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     dropout_85[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     dropout_86[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)             (None, 1500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_87[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)             (None, 1500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_88[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     dropout_89[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     dropout_90[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)             (None, 1500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_91[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)             (None, 1500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_92[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     dropout_93[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     dropout_94[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)             (None, 1500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_95[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)             (None, 1500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_96[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     dropout_97[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     dropout_98[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)             (None, 1500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_99[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)            (None, 1500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_100[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     dropout_101[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     dropout_102[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)            (None, 1500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_103[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)            (None, 3000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_104[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     dropout_105[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     dropout_106[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)            (None, 3000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_107[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)            (None, 3000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_108[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     dropout_109[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     dropout_110[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)            (None, 3000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_111[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)            (None, 3000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_112[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     dropout_113[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     dropout_114[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)            (None, 3000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_115[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)            (None, 3000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_116[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     dropout_117[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     dropout_118[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)            (None, 3000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_119[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)            (None, 3000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_120[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     dropout_121[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     dropout_122[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)            (None, 3000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_123[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)            (None, 4500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_124[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    dropout_125[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    dropout_126[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)            (None, 4500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_127[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)            (None, 4500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_128[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    dropout_129[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    dropout_130[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)            (None, 4500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_131[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)            (None, 4500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_132[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    dropout_133[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    dropout_134[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)            (None, 4500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_135[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)            (None, 4500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_136[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    dropout_137[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    dropout_138[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)            (None, 4500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_139[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)            (None, 4500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_140[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    dropout_141[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    dropout_142[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)            (None, 4500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_143[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)            (None, 6000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_144[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    dropout_145[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    dropout_146[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)            (None, 6000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_147[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)            (None, 6000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_148[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    dropout_149[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    dropout_150[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)            (None, 6000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_151[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)            (None, 6000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_152[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    dropout_153[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    dropout_154[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)            (None, 6000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_155[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)            (None, 6000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_156[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    dropout_157[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    dropout_158[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)            (None, 6000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_159[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)            (None, 6000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_160[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    dropout_161[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    dropout_162[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)            (None, 6000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_163[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "CPU times: user 1h 52min 19s, sys: 2h 41min 12s, total: 4h 33min 31s\n",
      "Wall time: 4h 34min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_list = []\n",
    "hidden_layer_sizes = [500,1500,3000,4500,6000]\n",
    "activations = ['relu','sigmoid', 'tanh', 'linear', 'softmax']\n",
    "input_dropout_options = [False, True]\n",
    "hidden_dropout_options = [False, True]\n",
    "\n",
    "params = list(itertools.product(hidden_layer_sizes, activations, input_dropout_options, hidden_dropout_options))\n",
    "for layer_size, activation_func, input_dropout_do, hidden_dropout_do in params:\n",
    "    print \"===================================================================================\\n\" + \\\n",
    "          \"========== Layer Size: {}, Activation: {}, Input Dropout: {}, Hidden Dropout: {} ==========================\"\"\".format(layer_size, activation_func, input_dropout_do, hidden_dropout_do)\n",
    "    doc_input = Input(shape=(DOC2VEC_SIZE,), name='doc_input')\n",
    "    if input_dropout_do:\n",
    "        hidden = Dropout(0.7)(doc_input)\n",
    "    hidden = Dense(layer_size, activation=activation_func, name='hidden_layer_{}'.format(activation_func))(doc_input if not input_dropout_do else hidden)\n",
    "    if hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    softmax_output = Dense(NN_OUTPUT_NEURONS, activation='sigmoid', name='softmax_output')(hidden)\n",
    "    model = Model(input=doc_input, output=softmax_output)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', 'fbeta_score', theano_coverage_error])\n",
    "    model.summary()\n",
    "    history = model.fit(x=training_data, y=training_labels, \n",
    "          validation_data=(validation_data, validation_labels), \n",
    "          nb_epoch=NN_EPOCHS, verbose=0)\n",
    "    history_list.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(history_list, open('/mnt/data2/shalaby/history_list_sample_0.0001.pickle','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.66835957339\n",
      "2.51193499238\n",
      "2.40680548502\n",
      "2.281361097\n",
      "2.76536312849\n",
      "2.42001015744\n",
      "2.3844591163\n",
      "2.3092940579\n",
      "3.03910614525\n",
      "2.50482478415\n",
      "2.52412392077\n",
      "2.38547486034\n",
      "2.89588623667\n",
      "2.85017775521\n",
      "2.46267140681\n",
      "2.45962417471\n",
      "2.91010665312\n",
      "2.81513458608\n",
      "3.01218892839\n",
      "3.13052310818\n",
      "2.61097003555\n",
      "2.64144235653\n",
      "2.39918740477\n",
      "2.29456576943\n",
      "2.89893346877\n",
      "2.5876079228\n",
      "2.49212798375\n",
      "2.42153377349\n",
      "3.01422041646\n",
      "2.63484002031\n",
      "2.50837988827\n",
      "2.39969527679\n",
      "2.87455561199\n",
      "2.94261046216\n",
      "2.50431691214\n",
      "2.52615540884\n",
      "2.71203656679\n",
      "2.96901980701\n",
      "2.96597257491\n",
      "3.17013712544\n",
      "2.81665820213\n",
      "2.87760284408\n",
      "2.39918740477\n",
      "2.3001523616\n",
      "3.03098019299\n",
      "2.67394616557\n",
      "2.64347384459\n",
      "2.6719146775\n",
      "2.95226003047\n",
      "2.68359573388\n",
      "2.50279329609\n",
      "2.49771457593\n",
      "2.89233113255\n",
      "2.9939055358\n",
      "2.54647028949\n",
      "2.63941086846\n",
      "2.93143727781\n",
      "2.97206703911\n",
      "3.06094464195\n",
      "3.22346368715\n",
      "2.93905535805\n",
      "3.12341289995\n",
      "2.39969527679\n",
      "2.32453021838\n",
      "3.03859827324\n",
      "2.76231589639\n",
      "2.66124936516\n",
      "2.64550533266\n",
      "2.96800406298\n",
      "2.75825292026\n",
      "2.5281868969\n",
      "2.60589131539\n",
      "2.92432706958\n",
      "2.97257491112\n",
      "2.59878110716\n",
      "2.71051295074\n",
      "2.7374301676\n",
      "3.09192483494\n",
      "2.88725241239\n",
      "3.50380904012\n",
      "3.09446419502\n",
      "3.2092432707\n",
      "2.43219908583\n",
      "2.34890807517\n",
      "3.05688166582\n",
      "2.80700863382\n",
      "2.84255967496\n",
      "2.86084306755\n",
      "2.92737430168\n",
      "2.84560690706\n",
      "2.55510411376\n",
      "2.64093448451\n",
      "2.8938547486\n",
      "3.13610970036\n",
      "2.63026917217\n",
      "2.81056373794\n",
      "2.83646521077\n",
      "3.1188420518\n",
      "3.19857795835\n",
      "3.59268664297\n"
     ]
    }
   ],
   "source": [
    "for history in history_list:\n",
    "    hist = history.history\n",
    "    max_val_fbeta = max(hist['val_coverage error'])\n",
    "    print max_val_fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_input = Input(shape=(DOC2VEC_SIZE,), name='doc_input')\n",
    "hidden = Dense(NN_HIDDEN_NEURONS, activation='relu', name='hidden_layer')(doc_input)\n",
    "softmax_output = Dense(NN_OUTPUT_NEURONS, activation='sigmoid', name='softmax_output')(hidden)\n",
    "model = Model(input=doc_input, output=softmax_output)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', 'fbeta_score', theano_coverage_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer (Dense)             (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8979 samples, validate on 1969 samples\n",
      "Epoch 1/1\n",
      "8979/8979 [==============================] - 4s - loss: 0.0427 - acc: 0.9835 - fbeta_score: 0.9504 - coverage error: 1.4936 - val_loss: 2.1309 - val_acc: 0.8531 - val_fbeta_score: 0.4738 - val_coverage error: 3.4474\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=training_data, y=training_labels, \n",
    "          validation_data=(validation_data, validation_labels), \n",
    "          nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_prediction = model.predict(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.70263344e-01,   3.49998474e-02,   3.13610617e-05,\n",
       "          1.08150870e-03,   3.11665332e-07,   7.09001958e-01,\n",
       "          4.97711152e-02,   2.63609409e-01],\n",
       "       [  1.70166213e-02,   5.36046147e-01,   2.61311390e-04,\n",
       "          4.87348643e-06,   1.27638310e-01,   9.57404263e-03,\n",
       "          3.39831635e-02,   2.13784515e-03]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = T.matrix('y_true')\n",
    "y_score = T.matrix('y_score')\n",
    "\n",
    "y_score_true = y_true * y_score # mark the scores of actually true labels\n",
    "zero_true_elem = T.eq(y_true, 0).nonzero()\n",
    "y_score_masked = T.set_subtensor(y_score_true[zero_true_elem], 100)\n",
    "#zero_elements = T.eq(true_scores,0)\n",
    "min_true_scores = T.min(y_score_masked, axis=1, keepdims=True) # we do keepdims in order to keep the broadcastable columns\n",
    "coverage_per_row = (y_score >= min_true_scores).sum(axis=1)\n",
    "coverage = T.mean(coverage_per_row)\n",
    "theano_coverage_err_func = function(inputs=[y_true, y_score], outputs=coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uu = np.array([[1,0,1],[0,0,1]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yc = T.set_subtensor(y_true[T.eq(y_true,0).nonzero()], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,  100.,    1.],\n",
       "       [ 100.,  100.,    1.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yc.eval({y_true: uu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T.set_subtensor(y_true[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1, 1]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.08178342e-08,   1.02713175e-05,   4.41441728e-28,\n",
       "          1.19779872e-36,   0.00000000e+00,   1.00000000e+00,\n",
       "          2.75591228e-05,   2.31643662e-06]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 8.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(2.5129507364144237)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "theano_coverage_err_func(validation_labels, val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.08178342e-08,   1.02713175e-05,   4.41441728e-28,\n",
       "          1.19779872e-36,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000028e+02,   1.00000002e+02]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(validation_labels[:1] , 100) + val_prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000231643662"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction[0,7] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-99.99999768])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.multiply(validation_labels[:1] , -100) + val_prediction[:1]).min(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 5.51 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5129507364144237"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "coverage_error(validation_labels, val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.43536258e-08,   2.79983366e-03,   1.15342544e-08,\n",
       "          7.79373941e-17,   5.66347130e-03,   9.99988794e-01,\n",
       "          6.53333089e-04,   5.85054120e-20],\n",
       "       [  2.85919495e-02,   4.81873751e-02,   1.16070651e-05,\n",
       "          2.11304723e-04,   9.95886266e-01,   7.23218254e-05,\n",
       "          2.44005350e-03,   9.50191250e-08],\n",
       "       [  1.57324195e-01,   4.55876261e-01,   1.18607618e-01,\n",
       "          1.59025192e-02,   5.29134236e-02,   3.10803294e-01,\n",
       "          7.60788023e-02,   4.09732945e-02],\n",
       "       [  8.80629957e-01,   8.06344330e-01,   8.66507888e-01,\n",
       "          8.60296586e-06,   8.48201476e-03,   3.66728357e-03,\n",
       "          4.01142472e-03,   6.63176891e-09],\n",
       "       [  3.67009136e-07,   2.43742179e-04,   4.91571154e-05,\n",
       "          3.91778943e-16,   2.10585220e-08,   9.19317733e-03,\n",
       "          2.35959844e-04,   9.99994278e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(training_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.07762730e-06,   4.37068702e-05,   8.50037267e-16,\n",
       "          3.26617112e-20,   5.99386426e-25,   9.99954700e-01,\n",
       "          4.03022398e-08,   5.06598099e-07],\n",
       "       [  7.84522370e-02,   7.51568982e-03,   3.02292941e-10,\n",
       "          1.27776785e-27,   8.58146071e-01,   5.19246235e-02,\n",
       "          3.96136660e-03,   9.01197339e-09],\n",
       "       [  8.13455582e-01,   3.37661535e-04,   1.86206713e-01,\n",
       "          2.93652289e-25,   1.42611062e-11,   8.11548398e-11,\n",
       "          1.56509191e-13,   3.87454735e-10],\n",
       "       [  9.48790824e-10,   4.76847440e-02,   2.83465356e-01,\n",
       "          2.84471139e-27,   8.79647612e-15,   5.65862817e-15,\n",
       "          4.19551939e-01,   2.49298021e-01],\n",
       "       [  1.14569569e-10,   1.01953819e-12,   1.14190914e-01,\n",
       "          4.46660243e-30,   3.54068044e-18,   8.85809124e-01,\n",
       "          1.19672533e-14,   2.22166152e-09]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(validation_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='529ae006-9318-4a66-885e-c1acfd8626d5'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-11-27 12:06:37,744 : INFO : ****************** Epoch 1 --- Working on doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1 *******************\n",
      "2016-11-27 12:06:37,755 : INFO : training model with 12 workers on 243681 vocabulary and 51000 features, using sg=0 hs=0 sample=1e-05 negative=10\n",
      "2016-11-27 12:06:37,756 : INFO : expecting 49789 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-11-27 12:07:05,285 : INFO : PROGRESS: at 0.00% examples, 40 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:08:05,390 : INFO : PROGRESS: at 0.18% examples, 1894 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:09:05,994 : INFO : PROGRESS: at 0.37% examples, 2579 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:10:06,043 : INFO : PROGRESS: at 0.61% examples, 2862 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:11:06,643 : INFO : PROGRESS: at 0.83% examples, 2995 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:12:07,595 : INFO : PROGRESS: at 1.07% examples, 3100 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:13:08,002 : INFO : PROGRESS: at 1.29% examples, 3203 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:14:09,096 : INFO : PROGRESS: at 1.50% examples, 3232 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:15:09,907 : INFO : PROGRESS: at 1.71% examples, 3282 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:16:09,978 : INFO : PROGRESS: at 1.90% examples, 3288 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:17:10,530 : INFO : PROGRESS: at 2.13% examples, 3349 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:18:14,161 : INFO : PROGRESS: at 2.34% examples, 3345 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:19:14,616 : INFO : PROGRESS: at 2.61% examples, 3389 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:20:15,627 : INFO : PROGRESS: at 2.84% examples, 3394 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:21:15,663 : INFO : PROGRESS: at 3.08% examples, 3417 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:22:15,936 : INFO : PROGRESS: at 3.30% examples, 3423 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:23:16,886 : INFO : PROGRESS: at 3.57% examples, 3448 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:24:17,161 : INFO : PROGRESS: at 3.80% examples, 3465 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:25:17,872 : INFO : PROGRESS: at 4.04% examples, 3477 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:26:19,350 : INFO : PROGRESS: at 4.23% examples, 3478 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:27:19,567 : INFO : PROGRESS: at 4.46% examples, 3486 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:28:19,671 : INFO : PROGRESS: at 4.66% examples, 3494 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:29:20,065 : INFO : PROGRESS: at 4.91% examples, 3506 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:30:20,207 : INFO : PROGRESS: at 5.13% examples, 3509 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:31:20,227 : INFO : PROGRESS: at 5.37% examples, 3519 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:32:21,132 : INFO : PROGRESS: at 5.60% examples, 3519 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:33:21,471 : INFO : PROGRESS: at 5.83% examples, 3531 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:34:22,513 : INFO : PROGRESS: at 6.10% examples, 3534 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:35:23,635 : INFO : PROGRESS: at 6.32% examples, 3539 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:36:23,744 : INFO : PROGRESS: at 6.57% examples, 3544 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:37:25,751 : INFO : PROGRESS: at 6.81% examples, 3540 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:38:25,994 : INFO : PROGRESS: at 7.05% examples, 3554 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:39:26,711 : INFO : PROGRESS: at 7.26% examples, 3550 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:40:27,694 : INFO : PROGRESS: at 7.49% examples, 3556 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:41:27,976 : INFO : PROGRESS: at 7.73% examples, 3560 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:42:27,996 : INFO : PROGRESS: at 7.97% examples, 3568 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:43:28,208 : INFO : PROGRESS: at 8.21% examples, 3572 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:44:28,550 : INFO : PROGRESS: at 8.44% examples, 3575 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:45:28,867 : INFO : PROGRESS: at 8.65% examples, 3578 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:46:29,758 : INFO : PROGRESS: at 8.88% examples, 3582 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:47:30,399 : INFO : PROGRESS: at 9.11% examples, 3584 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:48:32,137 : INFO : PROGRESS: at 9.34% examples, 3589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:49:32,723 : INFO : PROGRESS: at 9.58% examples, 3588 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:50:34,411 : INFO : PROGRESS: at 9.79% examples, 3587 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:51:36,420 : INFO : PROGRESS: at 9.99% examples, 3589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:52:37,124 : INFO : PROGRESS: at 10.19% examples, 3599 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:53:37,138 : INFO : PROGRESS: at 10.40% examples, 3602 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:54:37,311 : INFO : PROGRESS: at 10.63% examples, 3607 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:55:39,995 : INFO : PROGRESS: at 10.87% examples, 3607 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:56:40,373 : INFO : PROGRESS: at 11.09% examples, 3611 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:57:41,091 : INFO : PROGRESS: at 11.33% examples, 3614 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:58:41,147 : INFO : PROGRESS: at 11.55% examples, 3616 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:59:42,045 : INFO : PROGRESS: at 11.79% examples, 3618 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:00:42,422 : INFO : PROGRESS: at 12.05% examples, 3619 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:01:42,940 : INFO : PROGRESS: at 12.28% examples, 3620 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:02:43,099 : INFO : PROGRESS: at 12.51% examples, 3626 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:03:43,389 : INFO : PROGRESS: at 12.76% examples, 3626 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:04:43,883 : INFO : PROGRESS: at 13.00% examples, 3629 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:05:44,325 : INFO : PROGRESS: at 13.24% examples, 3631 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:06:44,716 : INFO : PROGRESS: at 13.49% examples, 3634 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:07:45,235 : INFO : PROGRESS: at 13.71% examples, 3639 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:08:45,909 : INFO : PROGRESS: at 13.94% examples, 3642 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:09:45,937 : INFO : PROGRESS: at 14.17% examples, 3642 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:10:46,236 : INFO : PROGRESS: at 14.41% examples, 3645 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:11:46,816 : INFO : PROGRESS: at 14.64% examples, 3652 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:12:47,090 : INFO : PROGRESS: at 14.86% examples, 3652 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:13:48,900 : INFO : PROGRESS: at 15.11% examples, 3654 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:14:49,108 : INFO : PROGRESS: at 15.35% examples, 3655 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:15:50,781 : INFO : PROGRESS: at 15.57% examples, 3658 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:16:51,094 : INFO : PROGRESS: at 15.79% examples, 3662 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:17:51,147 : INFO : PROGRESS: at 15.98% examples, 3664 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:18:52,657 : INFO : PROGRESS: at 16.17% examples, 3663 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:19:53,850 : INFO : PROGRESS: at 16.41% examples, 3670 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:20:54,106 : INFO : PROGRESS: at 16.65% examples, 3670 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:21:54,118 : INFO : PROGRESS: at 16.88% examples, 3673 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:22:54,360 : INFO : PROGRESS: at 17.12% examples, 3672 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:23:55,945 : INFO : PROGRESS: at 17.33% examples, 3680 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:24:55,966 : INFO : PROGRESS: at 17.57% examples, 3678 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:25:56,032 : INFO : PROGRESS: at 17.81% examples, 3684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:26:57,736 : INFO : PROGRESS: at 18.10% examples, 3683 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:27:58,649 : INFO : PROGRESS: at 18.37% examples, 3687 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:29:00,395 : INFO : PROGRESS: at 18.61% examples, 3686 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:30:00,548 : INFO : PROGRESS: at 18.84% examples, 3690 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:31:01,628 : INFO : PROGRESS: at 19.08% examples, 3692 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:32:02,692 : INFO : PROGRESS: at 19.34% examples, 3695 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:33:03,441 : INFO : PROGRESS: at 19.57% examples, 3696 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:34:03,603 : INFO : PROGRESS: at 19.81% examples, 3696 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:35:04,129 : INFO : PROGRESS: at 20.05% examples, 3698 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:36:04,342 : INFO : PROGRESS: at 20.30% examples, 3701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:37:04,515 : INFO : PROGRESS: at 20.55% examples, 3705 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:38:04,606 : INFO : PROGRESS: at 20.77% examples, 3705 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:39:07,558 : INFO : PROGRESS: at 21.01% examples, 3707 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:40:07,760 : INFO : PROGRESS: at 21.25% examples, 3709 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:41:08,162 : INFO : PROGRESS: at 21.51% examples, 3711 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:42:08,511 : INFO : PROGRESS: at 21.74% examples, 3715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:43:09,995 : INFO : PROGRESS: at 21.98% examples, 3715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:44:12,443 : INFO : PROGRESS: at 22.22% examples, 3716 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:45:12,783 : INFO : PROGRESS: at 22.50% examples, 3719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:46:12,856 : INFO : PROGRESS: at 22.72% examples, 3720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:47:12,912 : INFO : PROGRESS: at 22.92% examples, 3721 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:48:13,354 : INFO : PROGRESS: at 23.15% examples, 3724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:49:14,160 : INFO : PROGRESS: at 23.37% examples, 3726 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:50:14,577 : INFO : PROGRESS: at 23.61% examples, 3729 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:51:15,438 : INFO : PROGRESS: at 23.90% examples, 3729 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:52:15,861 : INFO : PROGRESS: at 24.15% examples, 3732 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:53:16,073 : INFO : PROGRESS: at 24.37% examples, 3733 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:54:16,314 : INFO : PROGRESS: at 24.61% examples, 3734 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:55:16,996 : INFO : PROGRESS: at 24.89% examples, 3735 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:56:17,309 : INFO : PROGRESS: at 25.11% examples, 3737 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:57:18,897 : INFO : PROGRESS: at 25.35% examples, 3738 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:58:19,271 : INFO : PROGRESS: at 25.59% examples, 3740 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:59:20,328 : INFO : PROGRESS: at 25.84% examples, 3742 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:00:20,444 : INFO : PROGRESS: at 26.08% examples, 3742 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:01:21,553 : INFO : PROGRESS: at 26.33% examples, 3743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:02:21,901 : INFO : PROGRESS: at 26.55% examples, 3749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:03:22,303 : INFO : PROGRESS: at 26.79% examples, 3749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:04:22,445 : INFO : PROGRESS: at 27.06% examples, 3750 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:05:22,795 : INFO : PROGRESS: at 27.31% examples, 3750 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:06:23,435 : INFO : PROGRESS: at 27.56% examples, 3752 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:07:23,547 : INFO : PROGRESS: at 27.80% examples, 3752 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:08:23,668 : INFO : PROGRESS: at 28.07% examples, 3754 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:09:24,668 : INFO : PROGRESS: at 28.32% examples, 3754 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:10:25,781 : INFO : PROGRESS: at 28.54% examples, 3756 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:11:26,837 : INFO : PROGRESS: at 28.78% examples, 3758 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:12:28,205 : INFO : PROGRESS: at 28.99% examples, 3759 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:13:29,199 : INFO : PROGRESS: at 29.25% examples, 3760 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:14:30,036 : INFO : PROGRESS: at 29.49% examples, 3761 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:15:31,272 : INFO : PROGRESS: at 29.71% examples, 3762 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:16:32,173 : INFO : PROGRESS: at 29.92% examples, 3764 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:17:32,589 : INFO : PROGRESS: at 30.16% examples, 3761 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:18:32,648 : INFO : PROGRESS: at 30.44% examples, 3766 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:19:33,214 : INFO : PROGRESS: at 30.66% examples, 3765 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:20:33,301 : INFO : PROGRESS: at 30.88% examples, 3766 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:21:33,306 : INFO : PROGRESS: at 31.12% examples, 3769 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:22:33,772 : INFO : PROGRESS: at 31.36% examples, 3769 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:23:33,884 : INFO : PROGRESS: at 31.60% examples, 3771 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:24:33,907 : INFO : PROGRESS: at 31.83% examples, 3772 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:25:34,438 : INFO : PROGRESS: at 32.08% examples, 3770 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:26:35,310 : INFO : PROGRESS: at 32.30% examples, 3771 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:27:36,287 : INFO : PROGRESS: at 32.55% examples, 3776 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:28:36,659 : INFO : PROGRESS: at 32.81% examples, 3776 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:29:38,235 : INFO : PROGRESS: at 33.05% examples, 3778 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:30:39,040 : INFO : PROGRESS: at 33.29% examples, 3777 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:31:39,149 : INFO : PROGRESS: at 33.53% examples, 3778 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:32:39,746 : INFO : PROGRESS: at 33.73% examples, 3780 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:33:40,393 : INFO : PROGRESS: at 33.97% examples, 3781 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:34:41,110 : INFO : PROGRESS: at 34.20% examples, 3782 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:35:41,428 : INFO : PROGRESS: at 34.46% examples, 3784 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:36:41,802 : INFO : PROGRESS: at 34.72% examples, 3785 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:37:41,945 : INFO : PROGRESS: at 34.97% examples, 3787 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:38:42,424 : INFO : PROGRESS: at 35.21% examples, 3788 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:39:42,632 : INFO : PROGRESS: at 35.44% examples, 3789 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:40:42,650 : INFO : PROGRESS: at 35.67% examples, 3788 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:41:42,729 : INFO : PROGRESS: at 35.90% examples, 3792 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:42:43,062 : INFO : PROGRESS: at 36.11% examples, 3792 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:43:44,539 : INFO : PROGRESS: at 36.36% examples, 3793 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:44:45,034 : INFO : PROGRESS: at 36.61% examples, 3795 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:45:45,860 : INFO : PROGRESS: at 36.85% examples, 3794 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:46:46,532 : INFO : PROGRESS: at 37.07% examples, 3795 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:47:47,010 : INFO : PROGRESS: at 37.32% examples, 3798 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:48:47,158 : INFO : PROGRESS: at 37.57% examples, 3799 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:49:47,192 : INFO : PROGRESS: at 37.81% examples, 3798 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:50:47,381 : INFO : PROGRESS: at 38.04% examples, 3799 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:51:47,770 : INFO : PROGRESS: at 38.25% examples, 3802 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:52:48,094 : INFO : PROGRESS: at 38.48% examples, 3803 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:53:48,834 : INFO : PROGRESS: at 38.73% examples, 3803 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:54:49,413 : INFO : PROGRESS: at 38.96% examples, 3804 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:55:49,470 : INFO : PROGRESS: at 39.22% examples, 3805 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:56:49,600 : INFO : PROGRESS: at 39.44% examples, 3806 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:57:50,476 : INFO : PROGRESS: at 39.71% examples, 3807 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:58:50,657 : INFO : PROGRESS: at 39.94% examples, 3807 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:59:51,537 : INFO : PROGRESS: at 40.19% examples, 3809 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:00:52,562 : INFO : PROGRESS: at 40.42% examples, 3808 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:01:53,476 : INFO : PROGRESS: at 40.64% examples, 3810 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:02:55,361 : INFO : PROGRESS: at 40.90% examples, 3809 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:03:55,573 : INFO : PROGRESS: at 41.15% examples, 3811 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:04:56,214 : INFO : PROGRESS: at 41.39% examples, 3811 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:05:57,202 : INFO : PROGRESS: at 41.65% examples, 3813 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:06:58,459 : INFO : PROGRESS: at 41.89% examples, 3812 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:07:59,897 : INFO : PROGRESS: at 42.13% examples, 3812 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:09:00,216 : INFO : PROGRESS: at 42.38% examples, 3815 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:10:01,291 : INFO : PROGRESS: at 42.60% examples, 3814 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:11:01,798 : INFO : PROGRESS: at 42.84% examples, 3816 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:12:02,237 : INFO : PROGRESS: at 43.10% examples, 3815 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:13:02,729 : INFO : PROGRESS: at 43.38% examples, 3817 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:14:02,965 : INFO : PROGRESS: at 43.61% examples, 3817 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:15:03,094 : INFO : PROGRESS: at 43.81% examples, 3818 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:16:04,555 : INFO : PROGRESS: at 44.07% examples, 3819 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:17:05,176 : INFO : PROGRESS: at 44.31% examples, 3820 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:18:05,499 : INFO : PROGRESS: at 44.57% examples, 3820 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:19:05,809 : INFO : PROGRESS: at 44.80% examples, 3822 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:20:06,080 : INFO : PROGRESS: at 45.02% examples, 3822 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:21:07,820 : INFO : PROGRESS: at 45.25% examples, 3822 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:22:08,802 : INFO : PROGRESS: at 45.46% examples, 3823 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:23:09,905 : INFO : PROGRESS: at 45.72% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:24:11,410 : INFO : PROGRESS: at 45.93% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:25:12,732 : INFO : PROGRESS: at 46.17% examples, 3826 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:26:13,796 : INFO : PROGRESS: at 46.41% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:27:14,710 : INFO : PROGRESS: at 46.65% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:28:15,152 : INFO : PROGRESS: at 46.89% examples, 3826 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:29:15,300 : INFO : PROGRESS: at 47.15% examples, 3827 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:30:15,568 : INFO : PROGRESS: at 47.39% examples, 3827 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:31:15,937 : INFO : PROGRESS: at 47.61% examples, 3828 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:32:15,997 : INFO : PROGRESS: at 47.84% examples, 3829 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 15:33:16,769 : INFO : PROGRESS: at 48.08% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:34:17,608 : INFO : PROGRESS: at 48.32% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:35:17,871 : INFO : PROGRESS: at 48.52% examples, 3832 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:36:18,551 : INFO : PROGRESS: at 48.78% examples, 3833 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:37:19,257 : INFO : PROGRESS: at 49.06% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:38:19,846 : INFO : PROGRESS: at 49.31% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:39:19,872 : INFO : PROGRESS: at 49.56% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:40:20,518 : INFO : PROGRESS: at 49.81% examples, 3835 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:41:21,740 : INFO : PROGRESS: at 50.05% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:42:21,806 : INFO : PROGRESS: at 50.27% examples, 3835 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:43:21,861 : INFO : PROGRESS: at 50.51% examples, 3836 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:44:21,950 : INFO : PROGRESS: at 50.75% examples, 3837 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:45:22,252 : INFO : PROGRESS: at 51.00% examples, 3838 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:46:22,377 : INFO : PROGRESS: at 51.22% examples, 3839 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:47:22,727 : INFO : PROGRESS: at 51.46% examples, 3840 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:48:22,741 : INFO : PROGRESS: at 51.67% examples, 3841 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:49:23,232 : INFO : PROGRESS: at 51.91% examples, 3840 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:50:23,718 : INFO : PROGRESS: at 52.15% examples, 3841 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:51:23,847 : INFO : PROGRESS: at 52.40% examples, 3840 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:52:24,316 : INFO : PROGRESS: at 52.68% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:53:24,843 : INFO : PROGRESS: at 52.90% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:54:25,804 : INFO : PROGRESS: at 53.14% examples, 3843 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:55:26,238 : INFO : PROGRESS: at 53.34% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:56:26,612 : INFO : PROGRESS: at 53.61% examples, 3843 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:57:26,654 : INFO : PROGRESS: at 53.85% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:58:27,203 : INFO : PROGRESS: at 54.10% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:59:27,465 : INFO : PROGRESS: at 54.34% examples, 3845 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:00:27,535 : INFO : PROGRESS: at 54.58% examples, 3846 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:01:27,717 : INFO : PROGRESS: at 54.80% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:02:28,146 : INFO : PROGRESS: at 55.04% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:03:28,536 : INFO : PROGRESS: at 55.28% examples, 3847 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:04:28,978 : INFO : PROGRESS: at 55.56% examples, 3847 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:05:29,040 : INFO : PROGRESS: at 55.77% examples, 3848 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:06:29,192 : INFO : PROGRESS: at 56.01% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:07:29,843 : INFO : PROGRESS: at 56.24% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:08:30,027 : INFO : PROGRESS: at 56.50% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:09:30,213 : INFO : PROGRESS: at 56.75% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:10:31,597 : INFO : PROGRESS: at 57.01% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:11:31,816 : INFO : PROGRESS: at 57.29% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:12:31,941 : INFO : PROGRESS: at 57.55% examples, 3851 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:13:32,174 : INFO : PROGRESS: at 57.77% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:14:32,200 : INFO : PROGRESS: at 58.00% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:15:32,302 : INFO : PROGRESS: at 58.22% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:16:32,923 : INFO : PROGRESS: at 58.46% examples, 3852 words/s, in_qsize 20, out_qsize 0\n",
      "2016-11-27 16:17:33,586 : INFO : PROGRESS: at 58.71% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:18:34,611 : INFO : PROGRESS: at 58.97% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:19:35,200 : INFO : PROGRESS: at 59.21% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:20:35,371 : INFO : PROGRESS: at 59.41% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:21:35,707 : INFO : PROGRESS: at 59.66% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:22:35,715 : INFO : PROGRESS: at 59.93% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:23:35,949 : INFO : PROGRESS: at 60.15% examples, 3853 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:24:36,451 : INFO : PROGRESS: at 60.38% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:25:36,661 : INFO : PROGRESS: at 60.65% examples, 3853 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:26:37,261 : INFO : PROGRESS: at 60.87% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:27:37,316 : INFO : PROGRESS: at 61.10% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:28:37,458 : INFO : PROGRESS: at 61.36% examples, 3855 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:29:38,067 : INFO : PROGRESS: at 61.60% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:30:39,788 : INFO : PROGRESS: at 61.86% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:31:41,442 : INFO : PROGRESS: at 62.08% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:32:41,788 : INFO : PROGRESS: at 62.29% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:33:41,878 : INFO : PROGRESS: at 62.53% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:34:42,541 : INFO : PROGRESS: at 62.78% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:35:42,541 : INFO : PROGRESS: at 63.02% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:36:43,306 : INFO : PROGRESS: at 63.27% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:37:43,331 : INFO : PROGRESS: at 63.50% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:38:43,466 : INFO : PROGRESS: at 63.73% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:39:44,227 : INFO : PROGRESS: at 63.95% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:40:44,430 : INFO : PROGRESS: at 64.18% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:41:47,124 : INFO : PROGRESS: at 64.43% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:42:47,589 : INFO : PROGRESS: at 64.67% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:43:47,628 : INFO : PROGRESS: at 64.94% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:44:47,669 : INFO : PROGRESS: at 65.17% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:45:47,680 : INFO : PROGRESS: at 65.41% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:46:47,687 : INFO : PROGRESS: at 65.62% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:47:49,221 : INFO : PROGRESS: at 65.85% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:48:49,277 : INFO : PROGRESS: at 66.08% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:49:50,278 : INFO : PROGRESS: at 66.34% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:50:51,221 : INFO : PROGRESS: at 66.58% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:51:52,038 : INFO : PROGRESS: at 66.81% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:52:52,907 : INFO : PROGRESS: at 67.06% examples, 3858 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:53:53,344 : INFO : PROGRESS: at 67.31% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:54:54,263 : INFO : PROGRESS: at 67.55% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:55:54,376 : INFO : PROGRESS: at 67.80% examples, 3858 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:56:55,078 : INFO : PROGRESS: at 68.01% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:57:55,290 : INFO : PROGRESS: at 68.25% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:58:55,506 : INFO : PROGRESS: at 68.50% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:59:55,739 : INFO : PROGRESS: at 68.73% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:00:56,353 : INFO : PROGRESS: at 68.97% examples, 3859 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:01:57,413 : INFO : PROGRESS: at 69.21% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:02:59,446 : INFO : PROGRESS: at 69.45% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:04:00,869 : INFO : PROGRESS: at 69.68% examples, 3859 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:05:01,259 : INFO : PROGRESS: at 69.93% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:06:03,301 : INFO : PROGRESS: at 70.18% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:07:05,741 : INFO : PROGRESS: at 70.43% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:08:06,579 : INFO : PROGRESS: at 70.70% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:09:07,149 : INFO : PROGRESS: at 70.96% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:10:07,340 : INFO : PROGRESS: at 71.19% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:11:08,053 : INFO : PROGRESS: at 71.44% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:12:08,346 : INFO : PROGRESS: at 71.65% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:13:08,403 : INFO : PROGRESS: at 71.88% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:14:08,715 : INFO : PROGRESS: at 72.11% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:15:09,343 : INFO : PROGRESS: at 72.35% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:16:09,701 : INFO : PROGRESS: at 72.58% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:17:09,770 : INFO : PROGRESS: at 72.83% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:18:09,948 : INFO : PROGRESS: at 73.07% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:19:10,260 : INFO : PROGRESS: at 73.27% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:20:10,457 : INFO : PROGRESS: at 73.51% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:21:12,006 : INFO : PROGRESS: at 73.75% examples, 3857 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:22:12,423 : INFO : PROGRESS: at 74.02% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:23:12,864 : INFO : PROGRESS: at 74.28% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:24:13,619 : INFO : PROGRESS: at 74.50% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:25:13,633 : INFO : PROGRESS: at 74.74% examples, 3856 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:26:13,792 : INFO : PROGRESS: at 74.93% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:27:15,185 : INFO : PROGRESS: at 75.16% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:28:16,374 : INFO : PROGRESS: at 75.38% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:29:17,040 : INFO : PROGRESS: at 75.61% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:30:18,028 : INFO : PROGRESS: at 75.83% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:31:18,620 : INFO : PROGRESS: at 76.07% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:32:19,137 : INFO : PROGRESS: at 76.31% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:33:19,177 : INFO : PROGRESS: at 76.56% examples, 3857 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:34:20,893 : INFO : PROGRESS: at 76.81% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:35:21,113 : INFO : PROGRESS: at 77.04% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:36:21,423 : INFO : PROGRESS: at 77.29% examples, 3856 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 17:37:23,028 : INFO : PROGRESS: at 77.53% examples, 3856 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:38:23,085 : INFO : PROGRESS: at 77.76% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:39:23,474 : INFO : PROGRESS: at 78.02% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:40:24,945 : INFO : PROGRESS: at 78.22% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:41:25,386 : INFO : PROGRESS: at 78.47% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:42:25,656 : INFO : PROGRESS: at 78.72% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:43:25,679 : INFO : PROGRESS: at 78.97% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:44:25,724 : INFO : PROGRESS: at 79.17% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:45:26,503 : INFO : PROGRESS: at 79.39% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:46:26,751 : INFO : PROGRESS: at 79.63% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:47:27,402 : INFO : PROGRESS: at 79.87% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:48:27,790 : INFO : PROGRESS: at 80.12% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:49:27,908 : INFO : PROGRESS: at 80.33% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:50:30,324 : INFO : PROGRESS: at 80.54% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:51:30,580 : INFO : PROGRESS: at 80.80% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:52:30,974 : INFO : PROGRESS: at 80.99% examples, 3855 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:53:31,603 : INFO : PROGRESS: at 81.21% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:54:31,727 : INFO : PROGRESS: at 81.46% examples, 3855 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:55:31,852 : INFO : PROGRESS: at 81.68% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:56:33,918 : INFO : PROGRESS: at 81.94% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:57:35,239 : INFO : PROGRESS: at 82.18% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:58:35,671 : INFO : PROGRESS: at 82.41% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:59:36,050 : INFO : PROGRESS: at 82.65% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:00:36,300 : INFO : PROGRESS: at 82.89% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:01:38,453 : INFO : PROGRESS: at 83.13% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:02:39,104 : INFO : PROGRESS: at 83.38% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:03:39,910 : INFO : PROGRESS: at 83.59% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:04:41,486 : INFO : PROGRESS: at 83.82% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:05:41,765 : INFO : PROGRESS: at 84.03% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:06:42,376 : INFO : PROGRESS: at 84.29% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:07:42,776 : INFO : PROGRESS: at 84.52% examples, 3853 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:08:42,903 : INFO : PROGRESS: at 84.79% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:09:44,183 : INFO : PROGRESS: at 85.01% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:10:44,538 : INFO : PROGRESS: at 85.25% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:11:45,248 : INFO : PROGRESS: at 85.51% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:12:45,373 : INFO : PROGRESS: at 85.74% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:13:46,019 : INFO : PROGRESS: at 85.96% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:14:46,761 : INFO : PROGRESS: at 86.20% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:15:46,898 : INFO : PROGRESS: at 86.42% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:16:46,987 : INFO : PROGRESS: at 86.65% examples, 3851 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:17:47,811 : INFO : PROGRESS: at 86.86% examples, 3851 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:18:47,842 : INFO : PROGRESS: at 87.10% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:19:47,897 : INFO : PROGRESS: at 87.33% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:20:48,647 : INFO : PROGRESS: at 87.56% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:21:48,829 : INFO : PROGRESS: at 87.80% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:22:48,845 : INFO : PROGRESS: at 88.03% examples, 3850 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 18:23:50,486 : INFO : PROGRESS: at 88.25% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:24:50,848 : INFO : PROGRESS: at 88.46% examples, 3850 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:25:50,931 : INFO : PROGRESS: at 88.69% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:26:51,107 : INFO : PROGRESS: at 88.91% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:27:51,168 : INFO : PROGRESS: at 89.13% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:28:51,448 : INFO : PROGRESS: at 89.38% examples, 3848 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:29:51,753 : INFO : PROGRESS: at 89.58% examples, 3848 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:30:52,853 : INFO : PROGRESS: at 89.83% examples, 3847 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:31:52,974 : INFO : PROGRESS: at 90.07% examples, 3847 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:32:54,092 : INFO : PROGRESS: at 90.28% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:33:54,281 : INFO : PROGRESS: at 90.51% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:34:55,199 : INFO : PROGRESS: at 90.72% examples, 3846 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:35:56,721 : INFO : PROGRESS: at 90.91% examples, 3845 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:36:57,442 : INFO : PROGRESS: at 91.12% examples, 3845 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:37:59,098 : INFO : PROGRESS: at 91.34% examples, 3845 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:38:59,783 : INFO : PROGRESS: at 91.56% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:39:59,822 : INFO : PROGRESS: at 91.80% examples, 3844 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:40:59,917 : INFO : PROGRESS: at 92.01% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:42:01,200 : INFO : PROGRESS: at 92.23% examples, 3843 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:43:02,262 : INFO : PROGRESS: at 92.44% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:44:02,292 : INFO : PROGRESS: at 92.64% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:45:02,311 : INFO : PROGRESS: at 92.91% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:46:02,583 : INFO : PROGRESS: at 93.14% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:47:02,596 : INFO : PROGRESS: at 93.39% examples, 3841 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:48:03,333 : INFO : PROGRESS: at 93.61% examples, 3841 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:49:03,370 : INFO : PROGRESS: at 93.86% examples, 3840 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:50:05,308 : INFO : PROGRESS: at 94.11% examples, 3840 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:51:05,472 : INFO : PROGRESS: at 94.34% examples, 3839 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:52:05,722 : INFO : PROGRESS: at 94.57% examples, 3839 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:53:05,875 : INFO : PROGRESS: at 94.77% examples, 3839 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:54:06,951 : INFO : PROGRESS: at 94.99% examples, 3838 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:55:07,928 : INFO : PROGRESS: at 95.22% examples, 3838 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:56:08,759 : INFO : PROGRESS: at 95.41% examples, 3837 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:57:08,926 : INFO : PROGRESS: at 95.64% examples, 3837 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:58:09,117 : INFO : PROGRESS: at 95.84% examples, 3836 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:59:10,087 : INFO : PROGRESS: at 96.07% examples, 3836 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:00:10,102 : INFO : PROGRESS: at 96.29% examples, 3835 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:01:10,634 : INFO : PROGRESS: at 96.48% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:02:11,459 : INFO : PROGRESS: at 96.72% examples, 3835 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:03:11,719 : INFO : PROGRESS: at 96.94% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:04:11,985 : INFO : PROGRESS: at 97.17% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:05:12,982 : INFO : PROGRESS: at 97.39% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:06:13,099 : INFO : PROGRESS: at 97.66% examples, 3833 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:07:13,105 : INFO : PROGRESS: at 97.86% examples, 3832 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:08:13,454 : INFO : PROGRESS: at 98.11% examples, 3832 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:09:13,568 : INFO : PROGRESS: at 98.32% examples, 3832 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:10:13,978 : INFO : PROGRESS: at 98.53% examples, 3831 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:11:14,467 : INFO : PROGRESS: at 98.75% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:12:14,471 : INFO : PROGRESS: at 98.99% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:13:15,543 : INFO : PROGRESS: at 99.21% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:14:15,651 : INFO : PROGRESS: at 99.42% examples, 3829 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:15:15,673 : INFO : PROGRESS: at 99.66% examples, 3829 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:16:16,457 : INFO : PROGRESS: at 99.87% examples, 3828 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:16:44,065 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2016-11-27 19:16:44,870 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2016-11-27 19:16:45,467 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2016-11-27 19:16:46,775 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2016-11-27 19:16:46,851 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2016-11-27 19:16:46,951 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2016-11-27 19:16:47,279 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2016-11-27 19:16:47,761 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2016-11-27 19:16:48,298 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-11-27 19:16:48,667 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-11-27 19:16:48,896 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-11-27 19:16:49,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-11-27 19:16:49,651 : INFO : training on 390507860 raw words (98830815 effective words) took 25811.9s, 3829 effective words/s\n",
      "2016-11-27 19:16:49,652 : INFO : saving Doc2Vec object under /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model, separately None\n",
      "2016-11-27 19:16:49,654 : INFO : storing numpy array 'doctag_syn0' to /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model.docvecs.doctag_syn0.npy\n",
      "2016-11-27 19:16:50,043 : INFO : storing numpy array 'syn1neg' to /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model.syn1neg.npy\n",
      "2016-11-27 19:18:13,911 : INFO : not storing attribute syn0norm\n",
      "2016-11-27 19:18:13,912 : INFO : storing numpy array 'syn0' to /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model.syn0.npy\n",
      "2016-11-27 19:18:19,424 : INFO : not storing attribute cum_table\n",
      "2016-11-27 19:18:27,517 : INFO : ****************** Epoch 2 --- Working on doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_2 *******************\n",
      "2016-11-27 19:18:27,526 : INFO : training model with 12 workers on 243681 vocabulary and 51000 features, using sg=0 hs=0 sample=1e-05 negative=10\n",
      "2016-11-27 19:18:27,527 : INFO : expecting 49789 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-11-27 19:18:30,758 : INFO : PROGRESS: at 0.00% examples, 670 words/s, in_qsize 2, out_qsize 0\n",
      "2016-11-27 19:19:31,559 : INFO : PROGRESS: at 0.27% examples, 3909 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:20:31,739 : INFO : PROGRESS: at 0.52% examples, 4063 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:21:31,795 : INFO : PROGRESS: at 0.78% examples, 4211 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:22:32,265 : INFO : PROGRESS: at 1.05% examples, 4206 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:23:32,379 : INFO : PROGRESS: at 1.30% examples, 4237 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:24:32,547 : INFO : PROGRESS: at 1.55% examples, 4284 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:25:32,624 : INFO : PROGRESS: at 1.85% examples, 4297 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:26:33,040 : INFO : PROGRESS: at 2.11% examples, 4291 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:27:34,585 : INFO : PROGRESS: at 2.40% examples, 4330 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:28:34,900 : INFO : PROGRESS: at 2.66% examples, 4342 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:29:35,379 : INFO : PROGRESS: at 2.93% examples, 4355 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:30:35,647 : INFO : PROGRESS: at 3.19% examples, 4338 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:31:36,400 : INFO : PROGRESS: at 3.44% examples, 4364 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:32:36,517 : INFO : PROGRESS: at 3.75% examples, 4390 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:33:36,765 : INFO : PROGRESS: at 4.07% examples, 4401 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:34:36,920 : INFO : PROGRESS: at 4.37% examples, 4399 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:35:37,033 : INFO : PROGRESS: at 4.65% examples, 4414 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:36:37,544 : INFO : PROGRESS: at 4.92% examples, 4413 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:37:39,340 : INFO : PROGRESS: at 5.21% examples, 4442 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:38:39,396 : INFO : PROGRESS: at 5.46% examples, 4445 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:39:39,440 : INFO : PROGRESS: at 5.77% examples, 4469 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:40:39,934 : INFO : PROGRESS: at 6.07% examples, 4472 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:41:40,065 : INFO : PROGRESS: at 6.35% examples, 4486 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:42:41,252 : INFO : PROGRESS: at 6.66% examples, 4485 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:43:41,969 : INFO : PROGRESS: at 6.94% examples, 4499 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:44:42,204 : INFO : PROGRESS: at 7.20% examples, 4513 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:45:42,909 : INFO : PROGRESS: at 7.46% examples, 4518 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:46:43,340 : INFO : PROGRESS: at 7.77% examples, 4527 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:47:45,937 : INFO : PROGRESS: at 8.04% examples, 4530 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:48:46,229 : INFO : PROGRESS: at 8.30% examples, 4538 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:49:46,284 : INFO : PROGRESS: at 8.57% examples, 4551 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:50:48,122 : INFO : PROGRESS: at 8.90% examples, 4554 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:51:48,272 : INFO : PROGRESS: at 9.19% examples, 4562 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:52:48,459 : INFO : PROGRESS: at 9.47% examples, 4566 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:53:48,875 : INFO : PROGRESS: at 9.78% examples, 4583 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:54:49,025 : INFO : PROGRESS: at 10.06% examples, 4589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:55:49,470 : INFO : PROGRESS: at 10.35% examples, 4593 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:56:50,296 : INFO : PROGRESS: at 10.65% examples, 4601 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:57:51,032 : INFO : PROGRESS: at 10.94% examples, 4605 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:58:51,285 : INFO : PROGRESS: at 11.25% examples, 4614 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:59:51,754 : INFO : PROGRESS: at 11.56% examples, 4620 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:00:51,874 : INFO : PROGRESS: at 11.86% examples, 4631 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:01:52,014 : INFO : PROGRESS: at 12.18% examples, 4640 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:02:52,564 : INFO : PROGRESS: at 12.47% examples, 4639 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:03:52,904 : INFO : PROGRESS: at 12.79% examples, 4650 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:04:53,246 : INFO : PROGRESS: at 13.10% examples, 4654 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:05:53,455 : INFO : PROGRESS: at 13.39% examples, 4664 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:06:53,934 : INFO : PROGRESS: at 13.68% examples, 4666 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:07:54,607 : INFO : PROGRESS: at 13.96% examples, 4673 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:08:55,063 : INFO : PROGRESS: at 14.27% examples, 4675 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:09:55,757 : INFO : PROGRESS: at 14.58% examples, 4684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:10:57,225 : INFO : PROGRESS: at 14.87% examples, 4684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:11:57,498 : INFO : PROGRESS: at 15.20% examples, 4693 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:12:57,937 : INFO : PROGRESS: at 15.53% examples, 4699 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:13:58,220 : INFO : PROGRESS: at 15.84% examples, 4705 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:14:58,854 : INFO : PROGRESS: at 16.15% examples, 4711 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:15:59,174 : INFO : PROGRESS: at 16.45% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:16:59,188 : INFO : PROGRESS: at 16.78% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:17:59,987 : INFO : PROGRESS: at 17.08% examples, 4730 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:19:00,127 : INFO : PROGRESS: at 17.36% examples, 4733 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:20:00,206 : INFO : PROGRESS: at 17.66% examples, 4743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:21:00,225 : INFO : PROGRESS: at 18.00% examples, 4744 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:22:00,645 : INFO : PROGRESS: at 18.26% examples, 4748 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:23:01,336 : INFO : PROGRESS: at 18.58% examples, 4757 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:24:01,439 : INFO : PROGRESS: at 18.89% examples, 4763 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:25:01,622 : INFO : PROGRESS: at 19.21% examples, 4769 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:26:02,045 : INFO : PROGRESS: at 19.52% examples, 4775 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:27:02,147 : INFO : PROGRESS: at 19.89% examples, 4779 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:28:02,507 : INFO : PROGRESS: at 20.20% examples, 4785 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:29:04,324 : INFO : PROGRESS: at 20.53% examples, 4786 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:30:05,600 : INFO : PROGRESS: at 20.83% examples, 4794 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:31:06,919 : INFO : PROGRESS: at 21.10% examples, 4794 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:32:06,982 : INFO : PROGRESS: at 21.39% examples, 4792 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:33:07,113 : INFO : PROGRESS: at 21.66% examples, 4789 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:34:08,404 : INFO : PROGRESS: at 21.95% examples, 4784 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:35:09,226 : INFO : PROGRESS: at 22.24% examples, 4780 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:36:09,463 : INFO : PROGRESS: at 22.52% examples, 4779 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:37:09,529 : INFO : PROGRESS: at 22.81% examples, 4776 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:38:10,189 : INFO : PROGRESS: at 23.08% examples, 4772 words/s, in_qsize 18, out_qsize 0\n",
      "2016-11-27 20:39:10,764 : INFO : PROGRESS: at 23.33% examples, 4771 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:40:11,025 : INFO : PROGRESS: at 23.64% examples, 4770 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:41:11,805 : INFO : PROGRESS: at 23.90% examples, 4767 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:42:11,900 : INFO : PROGRESS: at 24.17% examples, 4761 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:43:11,985 : INFO : PROGRESS: at 24.46% examples, 4758 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:44:12,403 : INFO : PROGRESS: at 24.77% examples, 4757 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:45:12,859 : INFO : PROGRESS: at 25.06% examples, 4752 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:46:14,003 : INFO : PROGRESS: at 25.34% examples, 4750 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:47:14,018 : INFO : PROGRESS: at 25.63% examples, 4751 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:48:14,653 : INFO : PROGRESS: at 25.95% examples, 4749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:49:14,977 : INFO : PROGRESS: at 26.22% examples, 4750 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:50:14,993 : INFO : PROGRESS: at 26.50% examples, 4749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:51:15,068 : INFO : PROGRESS: at 26.78% examples, 4747 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:52:16,106 : INFO : PROGRESS: at 27.06% examples, 4743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:53:16,485 : INFO : PROGRESS: at 27.35% examples, 4743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:54:17,102 : INFO : PROGRESS: at 27.65% examples, 4741 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:55:17,623 : INFO : PROGRESS: at 27.92% examples, 4740 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:56:17,686 : INFO : PROGRESS: at 28.18% examples, 4739 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:57:18,534 : INFO : PROGRESS: at 28.47% examples, 4736 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:58:18,743 : INFO : PROGRESS: at 28.74% examples, 4735 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 20:59:19,727 : INFO : PROGRESS: at 29.02% examples, 4733 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:00:20,022 : INFO : PROGRESS: at 29.28% examples, 4731 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:01:20,325 : INFO : PROGRESS: at 29.59% examples, 4730 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:02:20,680 : INFO : PROGRESS: at 29.91% examples, 4729 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:03:21,121 : INFO : PROGRESS: at 30.17% examples, 4728 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:04:21,494 : INFO : PROGRESS: at 30.47% examples, 4727 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:05:21,973 : INFO : PROGRESS: at 30.73% examples, 4727 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:06:22,037 : INFO : PROGRESS: at 31.00% examples, 4727 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:07:22,133 : INFO : PROGRESS: at 31.29% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:08:22,518 : INFO : PROGRESS: at 31.60% examples, 4727 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:09:22,534 : INFO : PROGRESS: at 31.88% examples, 4726 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:10:23,429 : INFO : PROGRESS: at 32.13% examples, 4726 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:11:23,597 : INFO : PROGRESS: at 32.38% examples, 4727 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:12:23,773 : INFO : PROGRESS: at 32.66% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:13:23,783 : INFO : PROGRESS: at 32.96% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:14:23,802 : INFO : PROGRESS: at 33.24% examples, 4724 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:15:24,876 : INFO : PROGRESS: at 33.52% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:16:25,391 : INFO : PROGRESS: at 33.83% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:17:25,601 : INFO : PROGRESS: at 34.10% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:18:25,870 : INFO : PROGRESS: at 34.38% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:19:26,112 : INFO : PROGRESS: at 34.70% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:20:27,197 : INFO : PROGRESS: at 35.01% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:21:27,908 : INFO : PROGRESS: at 35.31% examples, 4725 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:22:28,027 : INFO : PROGRESS: at 35.60% examples, 4723 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:23:29,967 : INFO : PROGRESS: at 35.90% examples, 4723 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:24:30,506 : INFO : PROGRESS: at 36.18% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:25:30,658 : INFO : PROGRESS: at 36.47% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:26:30,912 : INFO : PROGRESS: at 36.77% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:27:31,019 : INFO : PROGRESS: at 37.06% examples, 4723 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:28:31,104 : INFO : PROGRESS: at 37.34% examples, 4722 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:29:31,580 : INFO : PROGRESS: at 37.62% examples, 4722 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:30:32,006 : INFO : PROGRESS: at 37.91% examples, 4721 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:31:33,500 : INFO : PROGRESS: at 38.24% examples, 4721 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:32:34,504 : INFO : PROGRESS: at 38.50% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:33:34,538 : INFO : PROGRESS: at 38.80% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:34:34,665 : INFO : PROGRESS: at 39.10% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:35:34,718 : INFO : PROGRESS: at 39.38% examples, 4719 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:36:34,961 : INFO : PROGRESS: at 39.66% examples, 4719 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:37:35,048 : INFO : PROGRESS: at 39.93% examples, 4720 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:38:35,167 : INFO : PROGRESS: at 40.22% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:39:35,211 : INFO : PROGRESS: at 40.52% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:40:35,360 : INFO : PROGRESS: at 40.77% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:41:35,499 : INFO : PROGRESS: at 41.04% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:42:35,690 : INFO : PROGRESS: at 41.31% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:43:35,826 : INFO : PROGRESS: at 41.61% examples, 4717 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:44:35,968 : INFO : PROGRESS: at 41.89% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:45:36,533 : INFO : PROGRESS: at 42.22% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:46:37,165 : INFO : PROGRESS: at 42.53% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:47:37,643 : INFO : PROGRESS: at 42.79% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:48:38,053 : INFO : PROGRESS: at 43.09% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:49:38,221 : INFO : PROGRESS: at 43.40% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:50:39,593 : INFO : PROGRESS: at 43.70% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:51:39,788 : INFO : PROGRESS: at 43.99% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:52:40,092 : INFO : PROGRESS: at 44.28% examples, 4717 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:53:40,167 : INFO : PROGRESS: at 44.56% examples, 4717 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:54:40,971 : INFO : PROGRESS: at 44.83% examples, 4715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:55:41,156 : INFO : PROGRESS: at 45.12% examples, 4715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:56:41,412 : INFO : PROGRESS: at 45.42% examples, 4713 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:57:42,417 : INFO : PROGRESS: at 45.75% examples, 4716 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:58:43,073 : INFO : PROGRESS: at 46.03% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:59:43,356 : INFO : PROGRESS: at 46.32% examples, 4714 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:00:43,663 : INFO : PROGRESS: at 46.57% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:01:43,853 : INFO : PROGRESS: at 46.88% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:02:44,194 : INFO : PROGRESS: at 47.14% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:03:44,299 : INFO : PROGRESS: at 47.45% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:04:44,875 : INFO : PROGRESS: at 47.72% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:05:44,961 : INFO : PROGRESS: at 48.01% examples, 4714 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:06:45,093 : INFO : PROGRESS: at 48.30% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:07:45,348 : INFO : PROGRESS: at 48.59% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:08:45,438 : INFO : PROGRESS: at 48.83% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:09:47,994 : INFO : PROGRESS: at 49.17% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:10:48,784 : INFO : PROGRESS: at 49.49% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:11:49,496 : INFO : PROGRESS: at 49.80% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:12:50,118 : INFO : PROGRESS: at 50.11% examples, 4712 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:13:50,173 : INFO : PROGRESS: at 50.39% examples, 4711 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:14:51,105 : INFO : PROGRESS: at 50.66% examples, 4711 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:15:51,136 : INFO : PROGRESS: at 50.93% examples, 4710 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:16:51,475 : INFO : PROGRESS: at 51.22% examples, 4710 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:17:51,722 : INFO : PROGRESS: at 51.49% examples, 4709 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:18:52,008 : INFO : PROGRESS: at 51.77% examples, 4710 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:19:52,071 : INFO : PROGRESS: at 52.02% examples, 4709 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:20:52,342 : INFO : PROGRESS: at 52.30% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:21:52,478 : INFO : PROGRESS: at 52.57% examples, 4708 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:22:52,970 : INFO : PROGRESS: at 52.83% examples, 4708 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:23:53,625 : INFO : PROGRESS: at 53.11% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:24:53,883 : INFO : PROGRESS: at 53.37% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:25:54,299 : INFO : PROGRESS: at 53.65% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:26:55,831 : INFO : PROGRESS: at 53.96% examples, 4708 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:27:56,645 : INFO : PROGRESS: at 54.27% examples, 4707 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:28:58,077 : INFO : PROGRESS: at 54.57% examples, 4706 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:29:58,372 : INFO : PROGRESS: at 54.86% examples, 4706 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:31:00,043 : INFO : PROGRESS: at 55.14% examples, 4704 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:32:00,755 : INFO : PROGRESS: at 55.38% examples, 4706 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:33:01,966 : INFO : PROGRESS: at 55.64% examples, 4704 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:34:02,174 : INFO : PROGRESS: at 55.95% examples, 4705 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:35:02,625 : INFO : PROGRESS: at 56.21% examples, 4705 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:36:02,636 : INFO : PROGRESS: at 56.51% examples, 4704 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:37:03,274 : INFO : PROGRESS: at 56.78% examples, 4703 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:38:03,533 : INFO : PROGRESS: at 57.06% examples, 4703 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:39:04,418 : INFO : PROGRESS: at 57.35% examples, 4703 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:40:05,753 : INFO : PROGRESS: at 57.64% examples, 4702 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:41:05,795 : INFO : PROGRESS: at 57.91% examples, 4702 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:42:05,875 : INFO : PROGRESS: at 58.20% examples, 4701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:43:06,336 : INFO : PROGRESS: at 58.49% examples, 4701 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:44:07,305 : INFO : PROGRESS: at 58.82% examples, 4701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:45:07,710 : INFO : PROGRESS: at 59.09% examples, 4700 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:46:08,059 : INFO : PROGRESS: at 59.37% examples, 4700 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:47:08,806 : INFO : PROGRESS: at 59.66% examples, 4700 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:48:09,041 : INFO : PROGRESS: at 59.96% examples, 4699 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:49:09,517 : INFO : PROGRESS: at 60.23% examples, 4701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:50:09,651 : INFO : PROGRESS: at 60.48% examples, 4700 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:51:09,847 : INFO : PROGRESS: at 60.78% examples, 4699 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:52:10,024 : INFO : PROGRESS: at 61.07% examples, 4699 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:53:10,180 : INFO : PROGRESS: at 61.32% examples, 4698 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:54:10,673 : INFO : PROGRESS: at 61.56% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:55:11,157 : INFO : PROGRESS: at 61.86% examples, 4698 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:56:11,199 : INFO : PROGRESS: at 62.15% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:57:11,654 : INFO : PROGRESS: at 62.43% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:58:12,037 : INFO : PROGRESS: at 62.67% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:59:13,390 : INFO : PROGRESS: at 62.93% examples, 4696 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:00:14,699 : INFO : PROGRESS: at 63.23% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:01:15,084 : INFO : PROGRESS: at 63.49% examples, 4696 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:02:16,581 : INFO : PROGRESS: at 63.74% examples, 4696 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:03:19,138 : INFO : PROGRESS: at 64.03% examples, 4695 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:04:19,434 : INFO : PROGRESS: at 64.33% examples, 4695 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:05:19,548 : INFO : PROGRESS: at 64.61% examples, 4694 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:06:20,611 : INFO : PROGRESS: at 64.92% examples, 4693 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:07:20,979 : INFO : PROGRESS: at 65.20% examples, 4692 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:08:21,523 : INFO : PROGRESS: at 65.45% examples, 4691 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:09:22,349 : INFO : PROGRESS: at 65.75% examples, 4691 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:10:22,645 : INFO : PROGRESS: at 66.01% examples, 4690 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:11:23,033 : INFO : PROGRESS: at 66.29% examples, 4689 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:12:23,629 : INFO : PROGRESS: at 66.56% examples, 4689 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:13:23,654 : INFO : PROGRESS: at 66.82% examples, 4688 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:14:23,911 : INFO : PROGRESS: at 67.08% examples, 4687 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:15:24,602 : INFO : PROGRESS: at 67.36% examples, 4686 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:16:25,216 : INFO : PROGRESS: at 67.64% examples, 4685 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:17:26,234 : INFO : PROGRESS: at 67.89% examples, 4685 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:18:26,255 : INFO : PROGRESS: at 68.15% examples, 4684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:19:26,691 : INFO : PROGRESS: at 68.44% examples, 4682 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:20:26,768 : INFO : PROGRESS: at 68.71% examples, 4682 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:21:27,115 : INFO : PROGRESS: at 68.99% examples, 4682 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:22:28,086 : INFO : PROGRESS: at 69.26% examples, 4680 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:23:28,183 : INFO : PROGRESS: at 69.50% examples, 4680 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:24:28,480 : INFO : PROGRESS: at 69.75% examples, 4679 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:25:28,664 : INFO : PROGRESS: at 70.02% examples, 4679 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:26:28,958 : INFO : PROGRESS: at 70.30% examples, 4678 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:27:29,611 : INFO : PROGRESS: at 70.57% examples, 4677 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:28:31,935 : INFO : PROGRESS: at 70.84% examples, 4675 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:29:34,809 : INFO : PROGRESS: at 71.09% examples, 4674 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:30:35,029 : INFO : PROGRESS: at 71.39% examples, 4674 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:31:35,325 : INFO : PROGRESS: at 71.66% examples, 4673 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:32:36,165 : INFO : PROGRESS: at 71.93% examples, 4672 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:33:38,164 : INFO : PROGRESS: at 72.22% examples, 4672 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:34:39,251 : INFO : PROGRESS: at 72.51% examples, 4671 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:35:39,274 : INFO : PROGRESS: at 72.75% examples, 4671 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:36:39,917 : INFO : PROGRESS: at 73.02% examples, 4669 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:37:40,285 : INFO : PROGRESS: at 73.26% examples, 4669 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:38:40,463 : INFO : PROGRESS: at 73.55% examples, 4668 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:39:40,811 : INFO : PROGRESS: at 73.82% examples, 4667 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:40:41,118 : INFO : PROGRESS: at 74.09% examples, 4665 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:41:41,332 : INFO : PROGRESS: at 74.35% examples, 4665 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:42:41,451 : INFO : PROGRESS: at 74.61% examples, 4664 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:43:41,680 : INFO : PROGRESS: at 74.88% examples, 4662 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:44:42,720 : INFO : PROGRESS: at 75.18% examples, 4660 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:45:43,101 : INFO : PROGRESS: at 75.44% examples, 4660 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:46:43,541 : INFO : PROGRESS: at 75.69% examples, 4658 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:47:44,124 : INFO : PROGRESS: at 75.93% examples, 4657 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:48:44,422 : INFO : PROGRESS: at 76.18% examples, 4656 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:49:44,538 : INFO : PROGRESS: at 76.44% examples, 4654 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:50:44,570 : INFO : PROGRESS: at 76.75% examples, 4653 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:51:44,733 : INFO : PROGRESS: at 77.04% examples, 4651 words/s, in_qsize 12, out_qsize 0\n",
      "2016-11-27 23:52:45,977 : INFO : PROGRESS: at 77.25% examples, 4649 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:53:46,560 : INFO : PROGRESS: at 77.47% examples, 4648 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:54:47,410 : INFO : PROGRESS: at 77.73% examples, 4647 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:55:47,740 : INFO : PROGRESS: at 77.98% examples, 4645 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:56:48,972 : INFO : PROGRESS: at 78.24% examples, 4644 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:57:49,252 : INFO : PROGRESS: at 78.49% examples, 4642 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:58:49,286 : INFO : PROGRESS: at 78.76% examples, 4641 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:59:49,727 : INFO : PROGRESS: at 79.02% examples, 4640 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:00:49,764 : INFO : PROGRESS: at 79.28% examples, 4639 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:01:50,123 : INFO : PROGRESS: at 79.54% examples, 4637 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:02:50,442 : INFO : PROGRESS: at 79.77% examples, 4636 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:03:50,471 : INFO : PROGRESS: at 80.04% examples, 4635 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:04:50,724 : INFO : PROGRESS: at 80.28% examples, 4634 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:05:51,023 : INFO : PROGRESS: at 80.57% examples, 4633 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:06:51,695 : INFO : PROGRESS: at 80.85% examples, 4632 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:07:53,317 : INFO : PROGRESS: at 81.11% examples, 4630 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:08:53,494 : INFO : PROGRESS: at 81.33% examples, 4628 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:09:54,678 : INFO : PROGRESS: at 81.58% examples, 4627 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:10:54,852 : INFO : PROGRESS: at 81.82% examples, 4627 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:11:55,022 : INFO : PROGRESS: at 82.10% examples, 4626 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:12:55,274 : INFO : PROGRESS: at 82.35% examples, 4624 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:13:57,220 : INFO : PROGRESS: at 82.64% examples, 4622 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:14:57,887 : INFO : PROGRESS: at 82.92% examples, 4621 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:15:58,365 : INFO : PROGRESS: at 83.17% examples, 4619 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:16:59,359 : INFO : PROGRESS: at 83.43% examples, 4618 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:18:00,202 : INFO : PROGRESS: at 83.69% examples, 4616 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:19:00,897 : INFO : PROGRESS: at 83.96% examples, 4616 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:20:01,400 : INFO : PROGRESS: at 84.20% examples, 4614 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:21:01,697 : INFO : PROGRESS: at 84.46% examples, 4613 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:22:01,858 : INFO : PROGRESS: at 84.74% examples, 4612 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:23:02,181 : INFO : PROGRESS: at 84.98% examples, 4610 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:24:03,004 : INFO : PROGRESS: at 85.23% examples, 4608 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:25:03,645 : INFO : PROGRESS: at 85.52% examples, 4607 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:26:04,022 : INFO : PROGRESS: at 85.78% examples, 4606 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:27:04,109 : INFO : PROGRESS: at 86.05% examples, 4604 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:28:04,494 : INFO : PROGRESS: at 86.28% examples, 4603 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:29:04,600 : INFO : PROGRESS: at 86.51% examples, 4602 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:30:04,630 : INFO : PROGRESS: at 86.78% examples, 4600 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:31:04,808 : INFO : PROGRESS: at 87.03% examples, 4598 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:32:04,857 : INFO : PROGRESS: at 87.28% examples, 4595 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:33:04,979 : INFO : PROGRESS: at 87.51% examples, 4595 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:34:05,662 : INFO : PROGRESS: at 87.77% examples, 4593 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:35:05,721 : INFO : PROGRESS: at 88.04% examples, 4591 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:36:06,006 : INFO : PROGRESS: at 88.27% examples, 4589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:37:06,056 : INFO : PROGRESS: at 88.55% examples, 4587 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:38:06,189 : INFO : PROGRESS: at 88.78% examples, 4586 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:39:06,876 : INFO : PROGRESS: at 89.04% examples, 4584 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:40:07,140 : INFO : PROGRESS: at 89.28% examples, 4582 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:41:08,709 : INFO : PROGRESS: at 89.53% examples, 4581 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:42:08,871 : INFO : PROGRESS: at 89.81% examples, 4580 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:43:08,912 : INFO : PROGRESS: at 90.04% examples, 4578 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:44:09,131 : INFO : PROGRESS: at 90.28% examples, 4577 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:45:10,040 : INFO : PROGRESS: at 90.52% examples, 4576 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:46:10,043 : INFO : PROGRESS: at 90.76% examples, 4575 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:47:10,374 : INFO : PROGRESS: at 91.02% examples, 4574 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:48:10,832 : INFO : PROGRESS: at 91.29% examples, 4572 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:49:11,616 : INFO : PROGRESS: at 91.56% examples, 4571 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:50:11,860 : INFO : PROGRESS: at 91.83% examples, 4569 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:51:12,301 : INFO : PROGRESS: at 92.09% examples, 4567 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:52:12,671 : INFO : PROGRESS: at 92.33% examples, 4566 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:53:13,345 : INFO : PROGRESS: at 92.59% examples, 4565 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:54:15,373 : INFO : PROGRESS: at 92.87% examples, 4563 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:55:17,078 : INFO : PROGRESS: at 93.12% examples, 4561 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:56:17,317 : INFO : PROGRESS: at 93.37% examples, 4559 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:57:17,437 : INFO : PROGRESS: at 93.65% examples, 4558 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:58:18,082 : INFO : PROGRESS: at 93.90% examples, 4556 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:59:18,770 : INFO : PROGRESS: at 94.20% examples, 4555 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:00:18,773 : INFO : PROGRESS: at 94.44% examples, 4553 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:01:19,927 : INFO : PROGRESS: at 94.68% examples, 4551 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:02:20,352 : INFO : PROGRESS: at 94.93% examples, 4550 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:03:20,692 : INFO : PROGRESS: at 95.18% examples, 4549 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:04:20,693 : INFO : PROGRESS: at 95.43% examples, 4547 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 01:05:21,223 : INFO : PROGRESS: at 95.71% examples, 4546 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:06:22,718 : INFO : PROGRESS: at 95.96% examples, 4544 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:07:22,827 : INFO : PROGRESS: at 96.20% examples, 4543 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:08:23,342 : INFO : PROGRESS: at 96.41% examples, 4541 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:09:23,551 : INFO : PROGRESS: at 96.68% examples, 4540 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:10:24,202 : INFO : PROGRESS: at 96.93% examples, 4538 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:11:24,292 : INFO : PROGRESS: at 97.19% examples, 4537 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:12:24,502 : INFO : PROGRESS: at 97.42% examples, 4536 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:13:24,973 : INFO : PROGRESS: at 97.66% examples, 4534 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 01:14:25,121 : INFO : PROGRESS: at 97.89% examples, 4533 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:15:26,315 : INFO : PROGRESS: at 98.16% examples, 4531 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:16:26,937 : INFO : PROGRESS: at 98.40% examples, 4530 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:17:28,062 : INFO : PROGRESS: at 98.64% examples, 4529 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:18:28,187 : INFO : PROGRESS: at 98.89% examples, 4528 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:19:28,267 : INFO : PROGRESS: at 99.15% examples, 4527 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:20:28,419 : INFO : PROGRESS: at 99.41% examples, 4525 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 01:21:28,625 : INFO : PROGRESS: at 99.71% examples, 4524 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:22:28,777 : INFO : PROGRESS: at 99.96% examples, 4523 words/s, in_qsize 17, out_qsize 0\n",
      "2016-11-28 01:22:31,614 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2016-11-28 01:22:32,235 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2016-11-28 01:22:32,657 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2016-11-28 01:22:32,724 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2016-11-28 01:22:33,007 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2016-11-28 01:22:35,805 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2016-11-28 01:22:35,809 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph()\n",
    "# when resuming, resume from an epoch with a previously created doc2vec model to get the learning rate right\n",
    "start_from = 1\n",
    "for epoch in range(start_from,DOC2VEC_MAX_EPOCHS+1):\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    info(\"****************** Epoch {} --- Working on {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "    # if we have the model, just load it, otherwise train the previous model\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "        doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "    else:\n",
    "        # train the doc2vec model\n",
    "        doc2vec_model.train(sentences=StochasticDocumentGenerator(training_file, training_docs_list, line_positions), \n",
    "                            report_delay=REPORT_DELAY)\n",
    "        #doc2vec_model.alpha -= 0.001  # decrease the learning rate\n",
    "        #doc2vec_model.min_alpha = doc2vec_model.alpha  # fix the learning rate, no decay\n",
    "        ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME))\n",
    "        doc2vec_model.save(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "\n",
    "#     # Training and validation of SVMs using those docvecs\n",
    "#     train_classifications(sections)\n",
    "#     validation_vectors_matrix = get_validation_docs_with_inference(doc2vec_model, doc_classification_map)\n",
    "#     metrics = do_validation(validation_vectors_matrix, doc_classification_map, sections, \"sections\")\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "#     print \"Coverage Error: {}, Average No of Labels: {}, Top 1: {}, Top 3: {}, Top 5: {}, F1 Micro: {}, Total Positive: {}\".format(\n",
    "#         metrics['coverage_error'], metrics['average_num_of_labels'], metrics['top_1'], metrics['top_3'], metrics['top_5'], \n",
    "#         metrics['f1_micro'], metrics['total_positive'])\n",
    "                                                                                     \n",
    "#     epoch_metrics.append(metrics)\n",
    "#     graph.add_metrics_to_graph(metrics, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loaded metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/local/shalaby/parameter_search_doc2vec_models/sample_0.0001'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model_save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_{}_iter_1000_reg_0.001\n",
      "Epoch 01: Coverage Error -> 6.56\n",
      "Epoch 02: Coverage Error -> 6.51\n",
      "Epoch 03: Coverage Error -> 6.56\n",
      "Epoch 04: Coverage Error -> 6.45\n",
      "Epoch 05: Coverage Error -> 6.49\n",
      "Epoch 06: Coverage Error -> 6.39\n",
      "Epoch 07: Coverage Error -> 6.48\n",
      "Epoch 08: Coverage Error -> 6.55\n",
      "Epoch 09: Coverage Error -> 6.51\n",
      "Epoch 10: Coverage Error -> 6.54\n",
      "Epoch 11: Coverage Error -> 6.59\n",
      "Epoch 12: Coverage Error -> 6.50\n",
      "Epoch 13: Coverage Error -> 4.30\n",
      "Epoch 14: Coverage Error -> 4.44\n",
      "Epoch 15: Coverage Error -> 4.58\n",
      "Epoch 16: Coverage Error -> 4.75\n",
      "Epoch 17: Coverage Error -> 4.79\n",
      "Epoch 18: Coverage Error -> 4.75\n",
      "Epoch 19: Coverage Error -> 4.68\n",
      "Epoch 20: Coverage Error -> 4.69\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph()\n",
    "print placeholder_model_name + \"_\" + GLOBAL_VARS.SVM_MODEL_NAME\n",
    "\n",
    "for epoch in range(1,DOC2VEC_MAX_EPOCHS+1):\n",
    "    try:\n",
    "        model_name = placeholder_model_name.format(epoch)\n",
    "        metrics = pickle.load(open(os.path.join(doc2vec_model_save_location, model_name, GLOBAL_VARS.SVM_MODEL_NAME, METRICS)))\n",
    "        print \"Epoch {:02d}: Coverage Error -> {:.2f}\".format(epoch, metrics['coverage_error'])\n",
    "        graph.add_metrics_to_graph(metrics, epoch)\n",
    "    except IOError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0518029456576938,\n",
       " 4.3138649060436771,\n",
       " 3.7851701371254443,\n",
       " 1.4565769426104622,\n",
       " 1.3819197562214323]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[metric['coverage_error'] for metric in epoch_metrics]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
