{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "\n",
    "import logging\n",
    "from logging import info\n",
    "from functools import partial\n",
    "\n",
    "from thesis.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234\n",
    "DOC2VEC_SEED = 1234\n",
    "WORD2VEC_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_WORD_COUNT = 100\n",
    "MIN_SIZE = 0\n",
    "NUM_CORES = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', \n",
    "                                         'SVM_MODEL_NAME', 'NN_MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_MODEL = \"vocab_model\"\n",
    "MODEL_PREFIX = \"model\"\n",
    "VALIDATION_MATRIX = \"validation_matrix.pkl\"\n",
    "METRICS = \"metrics.pkl\"\n",
    "CLASSIFIER = \"classifier.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_file = \"/home/local/shalaby/docs_output_sample_100.json\"\n",
    "\n",
    "root_location = \"/big/s/shalaby/\"\n",
    "exports_location = root_location + \"exported_data/\"\n",
    "\n",
    "doc2vec_model_save_location = os.path.join(root_location, \"parameter_search_doc2vec_models_new\", \"full\")\n",
    "if not os.path.exists(doc2vec_model_save_location):\n",
    "    os.makedirs(doc2vec_model_save_location)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL)):\n",
    "    os.makedirs(os.path.join(doc2vec_model_save_location, VOCAB_MODEL))\n",
    "\n",
    "training_file = root_location + \"docs_output.json\"\n",
    "\n",
    "doc_classifications_map_file = exports_location + \"doc_classification_map.pkl\"\n",
    "sections_file = exports_location + \"sections.pkl\"\n",
    "classes_file = exports_location + \"classes.pkl\"\n",
    "subclasses_file = exports_location + \"subclasses.pkl\"\n",
    "classifications_output = exports_location + \"classifications.pkl\"\n",
    "training_docs_list_file = exports_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_file = exports_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_file = exports_location + \"test_docs_list.pkl\"\n",
    "\n",
    "preprocessed_location = root_location + \"preprocessed_data/\"\n",
    "\n",
    "training_preprocessed_files_prefix = preprocessed_location + \"training_docs_merged_data_preprocessed-\"\n",
    "training_preprocessed_docids_files_prefix = preprocessed_location + \"training_docs_merged_docids_preprocessed-\"\n",
    "validation_preprocessed_files_prefix = preprocessed_location + \"validation_docs_merged_data_preprocessed-\"\n",
    "validation_preprocessed_docids_files_prefix = preprocessed_location + \"validation_docs_merged_docids_preprocessed-\"\n",
    "\n",
    "word2vec_questions_file = result = root_location + 'tensorflow/word2vec/questions-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 1.45 s, total: 31.8 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_classification_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "classes = pickle.load(open(classes_file))\n",
    "subclasses = pickle.load(open(subclasses_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "#test_docs_list = pickle.load(open(test_docs_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321473"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            else:\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append(stem)\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ensure_hdfs_location_exists(location):\n",
    "    parent = os.path.dirname(location)\n",
    "    os.system(\"hdfs dfs -mkdir -p \" + location)\n",
    "\n",
    "def ensure_disk_location_exists(location):\n",
    "    if not os.path.exists(location):\n",
    "        os.makedirs(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference(doc2vec_model, doc_classification_map):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # do inference and store results in dict\n",
    "        i = 0\n",
    "        for (doc_id, doc_contents_array) in ValidationDocumentGenerator(training_file, validation_docs_list):\n",
    "            i += 1\n",
    "            if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "            validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "\n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in validation_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            validation_labels.append([classf for classf in doc_classification_map[validation_doc_id] if classf in sections])\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                           val_docs_list, val_preprocessed_files_prefix, val_preprocessed_docids_files_prefix):\n",
    "    \"\"\"\n",
    "    Use the trained doc2vec model to get the paragraph vector representations of the validation documents\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_one_doc(doc_tuple):\n",
    "        #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "        doc_id, doc_tokens = doc_tuple\n",
    "        rep = doc2vec_model.infer_vector(doc_tokens)\n",
    "        return (doc_id, rep)\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)):\n",
    "        info(\"===== Loading validation vectors\")\n",
    "        validation_labels = []\n",
    "        validation_vectors_matrix = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)))\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_labels = np.array(validation_labels)\n",
    "    else:\n",
    "        validation_documents_reps = {}\n",
    "        validation_vectors = []\n",
    "        validation_labels = []\n",
    "        info(\"===== Getting validation vectors with inference\")\n",
    "\n",
    "        # Single-threaded inference\n",
    "        # do inference and store results in dict\n",
    "#         i = 0\n",
    "        \n",
    "#         validation_docs_iterator = DocumentBatchGenerator(val_preprocessed_files_prefix, \n",
    "#                                                         val_preprocessed_docids_files_prefix, batch_size=None)\n",
    "#         for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "#             i += 1\n",
    "#             if i % 1000 == 0: info(\"Finished: {}\".format(str(i)))\n",
    "#             validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)\n",
    "        \n",
    "        # Multi-threaded inference\n",
    "        validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                          validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "        generator_func = validation_docs_iterator.__iter__()\n",
    "        pool = ThreadPool(NUM_CORES)\n",
    "        # map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "        validation_documents_reps = {}\n",
    "        mini_batch_size = 1000\n",
    "        while True:\n",
    "            threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "            info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "            if threaded_reps_partial:\n",
    "                #threaded_reps.extend(threaded_reps_partial)\n",
    "                validation_documents_reps.update(threaded_reps_partial)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "                \n",
    "        # create matrix for the validation vectors\n",
    "        for validation_doc_id in val_docs_list:\n",
    "            validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "            val_labels = [classf for classf in doc_classification_map[validation_doc_id] if classf in classifications]\n",
    "            validation_labels.append(one_hot_encoder.get_label_vector(val_labels))\n",
    "        validation_vectors_matrix = np.array(validation_vectors)\n",
    "        validation_labels = np.array(validation_labels)\n",
    "        pickle.dump(validation_vectors_matrix, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX), 'w'))\n",
    "    \n",
    "    return validation_vectors_matrix, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_doc2vec_spark_vectors(validation_vectors_matrix, classification, doc_classification_map):\n",
    "    validation_vectors = []\n",
    "    for (index, doc_id) in enumerate(validation_docs_list):\n",
    "        # converting from memmap to a normal array as spark is unable to convert memmap to a spark Vector\n",
    "        validation_vector = validation_vectors_matrix[index]\n",
    "        validation_vectors.append(get_training_vector(classification, validation_vector, \n",
    "                                                    doc_classification_map[doc_id]))\n",
    "    validation_vectors = sc.parallelize(validation_vectors)\n",
    "    info(\"Finished getting validation vectors\")\n",
    "    return validation_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    \n",
    "    def __init__(self, classifications):\n",
    "        self.classifications = classifications\n",
    "        self.one_hot_indices = {}\n",
    "\n",
    "        # convert character classifications to bit vectors\n",
    "        for i, clssf in enumerate(classifications):\n",
    "            bits = [0] * len(classifications)\n",
    "            bits[i] = 1\n",
    "            self.one_hot_indices[clssf] = i\n",
    "    \n",
    "    def get_label_vector(self, labels):\n",
    "        \"\"\"\n",
    "        classes: array of string with the classes assigned to the instance\n",
    "        \"\"\"\n",
    "        output_vector = [0] * len(self.classifications)\n",
    "        for label in labels:\n",
    "            index = self.one_hot_indices[label]\n",
    "            output_vector[index] = 1\n",
    "            \n",
    "        return output_vector\n",
    "\n",
    "def get_training_data(doc2vec_model, classifications):\n",
    "    one_hot_encoder = OneHotEncoder(classifications)\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for doc_id in training_docs_list:\n",
    "        # converting from memmap to a normal array\n",
    "        normal_array = []\n",
    "        normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "        training_data.append(normal_array)\n",
    "        eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "        training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))\n",
    "    training_labels = np.array(training_labels)\n",
    "    return training_data, training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "                    \n",
    "class DocumentBatchGenerator(object):\n",
    "    def __init__(self, filename_prefix, filename_docids_prefix, batch_size=10000 ):\n",
    "        \"\"\"\n",
    "        batch_size cant be > 10,000 due to a limitation in doc2vec training, \n",
    "        None means no batching (only use for inference)\n",
    "        \"\"\"\n",
    "        assert batch_size <= 10000 or batch_size is None\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.filename_docids_prefix = filename_docids_prefix\n",
    "        self.curr_lines = []\n",
    "        self.curr_docids = []\n",
    "        self.batch_size = batch_size\n",
    "        self.curr_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        self.curr_lines, self.docids = [], []\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_index) )\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    self.curr_lines.append(line.split(\" \"))\n",
    "#                     if i % 1000 == 0:\n",
    "#                         print i\n",
    "            self.curr_docids = pickle.load(open(self.filename_docids_prefix + str(self.curr_index), \"r\"))\n",
    "            self.batch_end = self.curr_index + len(self.curr_lines) -1 \n",
    "            info(\"Finished loading new batch\")\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_index))\n",
    "            raise StopIteration()\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            if self.curr_index > self.batch_end:\n",
    "                self.load_new_batch_in_memory()\n",
    "            for (doc_id, tokens) in zip(self.curr_docids, self.curr_lines):\n",
    "                if self.batch_size is not None:\n",
    "                    curr_batch_iter = 0\n",
    "                    # divide the document to batches according to the batch size\n",
    "                    while curr_batch_iter < len(tokens):\n",
    "                        yield LabeledSentence(words=tokens[curr_batch_iter: curr_batch_iter + self.batch_size], tags=[doc_id])\n",
    "                        curr_batch_iter += self.batch_size\n",
    "                else:\n",
    "                    yield doc_id, tokens\n",
    "                self.curr_index += 1\n",
    "\n",
    "class Word2VecTrainingDocumentGenerator(object):\n",
    "    def __init__(self, filename, training_docs_list):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield stemtokenizer(text)\n",
    "                \n",
    "class ValidationDocumentGenerator(object):\n",
    "    def __init__(self, filename, validation_docs_list):\n",
    "        self.filename = filename\n",
    "        self.validation_docs_list = validation_docs_list\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            for line in file_obj:\n",
    "                if not line.strip(): continue\n",
    "                (doc_id, text) = eval(line)\n",
    "                if doc_id in self.validation_docs_list:\n",
    "                    yield doc_id, stemtokenizer(text)\n",
    "                    \n",
    "class StochasticDocumentGenerator(object):\n",
    "    \"\"\"\n",
    "    Randomly shuffle rows while reading them\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, training_docs_list, line_positions):\n",
    "        self.filename = filename\n",
    "        self.training_docs_list = training_docs_list\n",
    "        self.line_positions = line_positions\n",
    "        self.lines = set(line_positions.keys())\n",
    "    def __iter__(self):\n",
    "        with open(self.filename) as file_obj:\n",
    "            while len(self.lines) > 0:\n",
    "                random_line = random.sample(self.lines,1)[0]\n",
    "                self.lines.remove(random_line)\n",
    "                file_obj.seek(self.line_positions[random_line])\n",
    "                line = file_obj.readline()\n",
    "                if not line.strip(): continue\n",
    "#                 print random_line, self.line_positions[random_line], line[:30]\n",
    "                (doc_id, text) = eval(line)\n",
    "                # print random_line , doc_id\n",
    "                if doc_id in self.training_docs_list:\n",
    "                    yield LabeledSentence(words=stemtokenizer(text), tags=[doc_id])\n",
    "#                     yield doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 200\n",
    "DOC2VEC_WINDOW = 8\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-3\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 1\n",
    "DOC2VEC_TRAIN_WORDS = 0\n",
    "DOC2VEC_EPOCHS = 1 # we do our training manually one epoch at a time\n",
    "DOC2VEC_MAX_EPOCHS = 20\n",
    "REPORT_DELAY = 20 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 10000 # report vocab progress every x documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVM_ITERATIONS = 10\n",
    "SVM_CONVERGENCE = 0.001\n",
    "SVM_REG = 0.001\n",
    "SVM_CLASS_WEIGHTS = 'balanced'\n",
    "GLOBAL_VARS.SVM_MODEL_NAME = 'svm_iter_{}_reg_{}_classweights_{}'.format(SVM_ITERATIONS, SVM_REG, str(SVM_CLASS_WEIGHTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_svm_model_path(method, classification, reg=SVM_REG, iterations=SVM_ITERATIONS):\n",
    "    location = os.path.join(save_parent_location, \"models\", method, \n",
    "                            \"iter_\" + str(iterations) + \"_reg_\" + str(reg),\n",
    "                            classification + \"_model.svm\")\n",
    "    ensure_hdfs_location_exists(location)\n",
    "    return location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_{}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placeholder_model_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_trainwords_{}_hs_{}_neg_{}_vocabsize_{}'.format(DOC2VEC_SIZE, \n",
    "                                                                DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_TRAIN_WORDS,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL_NAME = placeholder_model_name\n",
    "placeholder_model_name = os.path.join(placeholder_model_name, \"epoch_{}\")\n",
    "placeholder_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(size=DOC2VEC_SIZE , window=DOC2VEC_WINDOW, min_count=MIN_WORD_COUNT, \n",
    "                max_vocab_size= DOC2VEC_MAX_VOCAB_SIZE,\n",
    "                sample=DOC2VEC_SAMPLE, seed=DOC2VEC_SEED, workers=NUM_CORES,\n",
    "                # doc2vec algorithm dm=1 => PV-DM, dm=2 => PV-DBOW, PV-DM dictates CBOW for words\n",
    "                dm=DOC2VEC_TYPE,\n",
    "                # hs=0 => negative sampling, hs=1 => hierarchical softmax\n",
    "                hs=DOC2VEC_HIERARCHICAL_SAMPLE, negative=DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                dm_concat=DOC2VEC_CONCAT,\n",
    "                # would train words with skip-gram on top of cbow, we don't need that for now\n",
    "                dbow_words=DOC2VEC_TRAIN_WORDS,\n",
    "                iter=DOC2VEC_EPOCHS)\n",
    "\n",
    "GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:00:10,101 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model\n",
      "2017-01-14 21:00:19,425 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.docvecs.* with mmap=None\n",
      "2017-01-14 21:00:19,427 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 21:00:26,369 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 21:01:03,709 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/vocab_model/model.syn0.npy with mmap=None\n",
      "2017-01-14 21:01:05,710 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 21:01:05,711 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 21:01:07,092 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 4.18 s, total: 1min 7s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_docs_iterator = DocumentBatchGenerator(training_preprocessed_files_prefix, \n",
    "                                                        training_preprocessed_docids_files_prefix, batch_size=10000)\n",
    "if not os.path.exists(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX)):\n",
    "    doc2vec_model.build_vocab(sentences=training_docs_iterator, progress_per=REPORT_VOCAB_PROGRESS)\n",
    "    doc2vec_model.save(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX))\n",
    "else:\n",
    "    doc2vec_model_vocab_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, VOCAB_MODEL, MODEL_PREFIX))\n",
    "    doc2vec_model.reset_from(doc2vec_model_vocab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocab_counts = {k:doc2vec_model.vocab[k].count for k in doc2vec_model.vocab.keys()}\n",
    "# dd = sorted(vocab_counts, key=vocab_counts.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training, validation and Metrics Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_model.min_alpha = 0.025\n",
    "epoch_validation_metrics = []\n",
    "epoch_training_metrics = []\n",
    "epoch_word2vec_metrics = []\n",
    "classifications = sections\n",
    "classifications_type = 'sections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_METRICS_FILENAME= '{}_validation_metrics.pkl'.format(classifications_type)\n",
    "TRAINING_METRICS_FILENAME = '{}_training_metrics.pkl'.format(classifications_type)\n",
    "METRICS_FIG_PNG_FILENAME = '{}_validation_metrics.png'.format(classifications_type)\n",
    "METRICS_FIG_PDF_FILENAME = '{}_validation_metrics.pdf'.format(classifications_type)\n",
    "WORD2VEC_METRICS_FILENAME = 'word2vec_metrics.pkl'\n",
    "\n",
    "# for epoch in range(DOC2VEC_MAX_EPOCHS):\n",
    "#     GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "# fig_save_location = placeholder_model_name.format('run')\n",
    "# plt.savefig(os.path.join(fig_save_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:02:37,874 : INFO : ****************** Epoch 1 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1 *******************\n",
      "2017-01-14 21:02:37,877 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model\n",
      "2017-01-14 21:02:50,590 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.* with mmap=None\n",
      "2017-01-14 21:02:50,592 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 21:03:07,054 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 21:03:12,430 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_1/model.syn0.npy with mmap=None\n",
      "2017-01-14 21:03:17,567 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 21:03:17,568 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 21:03:18,924 : INFO : Getting training Data\n",
      "2017-01-14 21:04:32,164 : INFO : Training Classifier\n",
      "2017-01-14 21:12:57,469 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:20:20,335 : INFO : Getting Validation Embeddings\n",
      "2017-01-14 21:20:20,339 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.316, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.557, Top 3: 0.865, Top 5: 0.946, \n",
      "\t\t F1 Micro: 0.580, F1 Macro: 0.489, Total Pos: 2,684,026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:21:08,420 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 1 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 1 1 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.622, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.486, Top 3: 0.815, Top 5: 0.932, \n",
      "\t\t F1 Micro: 0.510, F1 Macro: 0.429, Total Pos: 839,445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/matplotlib/axes/_base.py:2787: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=1, right=1\n",
      "  'left=%s, right=%s') % (left, right))\n",
      "2017-01-14 21:21:42,256 : INFO : ****************** Epoch 2 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2 *******************\n",
      "2017-01-14 21:21:42,258 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model\n",
      "2017-01-14 21:22:00,507 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.* with mmap=None\n",
      "2017-01-14 21:22:00,508 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 21:22:15,383 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 21:22:21,428 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_2/model.syn0.npy with mmap=None\n",
      "2017-01-14 21:22:26,809 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 21:22:26,810 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 21:22:29,047 : INFO : Getting training Data\n",
      "2017-01-14 21:23:45,741 : INFO : Training Classifier\n",
      "2017-01-14 21:32:04,944 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:39:02,729 : INFO : Getting Validation Embeddings\n",
      "2017-01-14 21:39:02,732 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.114, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.584, Top 3: 0.889, Top 5: 0.956, \n",
      "\t\t F1 Micro: 0.608, F1 Macro: 0.512, Total Pos: 2,604,615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:39:59,603 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 1 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 1 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.262, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.535, Top 3: 0.858, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.558, F1 Macro: 0.477, Total Pos: 776,220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:40:30,448 : INFO : ****************** Epoch 3 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3 *******************\n",
      "2017-01-14 21:40:30,450 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model\n",
      "2017-01-14 21:40:50,599 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.* with mmap=None\n",
      "2017-01-14 21:40:50,600 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 21:41:22,651 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 21:41:31,673 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_3/model.syn0.npy with mmap=None\n",
      "2017-01-14 21:41:42,793 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 21:41:42,794 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 21:41:45,123 : INFO : Getting training Data\n",
      "2017-01-14 21:42:58,757 : INFO : Training Classifier\n",
      "2017-01-14 21:51:18,678 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:58:13,596 : INFO : Getting Validation Embeddings\n",
      "2017-01-14 21:58:13,600 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.066, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.591, Top 3: 0.894, Top 5: 0.958, \n",
      "\t\t F1 Micro: 0.615, F1 Macro: 0.518, Total Pos: 2,583,134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:58:50,956 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 1 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.182, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.540, Top 3: 0.866, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.571, F1 Macro: 0.489, Total Pos: 754,750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 21:59:21,209 : INFO : ****************** Epoch 4 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4 *******************\n",
      "2017-01-14 21:59:21,212 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model\n",
      "2017-01-14 21:59:37,861 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.* with mmap=None\n",
      "2017-01-14 21:59:37,862 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 21:59:47,532 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 21:59:50,603 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_4/model.syn0.npy with mmap=None\n",
      "2017-01-14 21:59:53,692 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 21:59:53,693 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 21:59:55,862 : INFO : Getting training Data\n",
      "2017-01-14 22:01:19,535 : INFO : Training Classifier\n",
      "2017-01-14 22:09:23,434 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.049, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.593, Top 3: 0.896, Top 5: 0.959, \n",
      "\t\t F1 Micro: 0.617, F1 Macro: 0.520, Total Pos: 2,578,399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 22:17:02,495 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 1 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.066, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.544, Top 3: 0.880, Top 5: 0.949, \n",
      "\t\t F1 Micro: 0.592, F1 Macro: 0.504, Total Pos: 716,595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 22:17:33,501 : INFO : ****************** Epoch 5 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5 *******************\n",
      "2017-01-14 22:17:33,503 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model\n",
      "2017-01-14 22:17:40,682 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.* with mmap=None\n",
      "2017-01-14 22:17:40,683 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 22:17:56,104 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 22:18:00,330 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_5/model.syn0.npy with mmap=None\n",
      "2017-01-14 22:18:04,867 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 22:18:04,868 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 22:18:07,233 : INFO : Getting training Data\n",
      "2017-01-14 22:19:27,533 : INFO : Training Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.045, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.593, Top 3: 0.896, Top 5: 0.959, \n",
      "\t\t F1 Micro: 0.617, F1 Macro: 0.520, Total Pos: 2,577,150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 22:35:09,888 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 1 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.049, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.553, Top 3: 0.880, Top 5: 0.948, \n",
      "\t\t F1 Micro: 0.597, F1 Macro: 0.507, Total Pos: 706,128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 22:35:39,783 : INFO : ****************** Epoch 6 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6 *******************\n",
      "2017-01-14 22:35:39,785 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model\n",
      "2017-01-14 22:35:56,622 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.* with mmap=None\n",
      "2017-01-14 22:35:56,623 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 22:36:15,582 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 22:36:21,446 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy with mmap=None\n",
      "2017-01-14 22:36:27,556 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 22:36:27,557 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 22:36:29,791 : INFO : Getting training Data\n",
      "2017-01-14 22:37:41,561 : INFO : Training Classifier\n",
      "2017-01-14 22:45:46,650 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 22:52:38,082 : INFO : Getting Validation Embeddings\n",
      "2017-01-14 22:52:38,085 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.034, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.595, Top 3: 0.898, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.619, F1 Macro: 0.522, Total Pos: 2,569,917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 22:53:22,008 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.016, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.575, Top 3: 0.889, Top 5: 0.950, \n",
      "\t\t F1 Micro: 0.607, F1 Macro: 0.513, Total Pos: 685,229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 22:53:51,873 : INFO : ****************** Epoch 7 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7 *******************\n",
      "2017-01-14 22:53:51,875 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model\n",
      "2017-01-14 22:54:09,323 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.* with mmap=None\n",
      "2017-01-14 22:54:09,324 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 22:54:25,883 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 22:54:32,045 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_7/model.syn0.npy with mmap=None\n",
      "2017-01-14 22:54:36,834 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 22:54:36,836 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 22:54:39,765 : INFO : Getting training Data\n",
      "2017-01-14 22:56:03,496 : INFO : Training Classifier\n",
      "2017-01-14 23:04:09,047 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:11:38,199 : INFO : Getting Validation Embeddings\n",
      "2017-01-14 23:11:38,202 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.042, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.593, Top 3: 0.897, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.617, F1 Macro: 0.520, Total Pos: 2,583,032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:12:22,982 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.005, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.562, Top 3: 0.888, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.605, F1 Macro: 0.512, Total Pos: 696,311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:12:55,562 : INFO : ****************** Epoch 8 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8 *******************\n",
      "2017-01-14 23:12:55,564 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model\n",
      "2017-01-14 23:13:02,987 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.* with mmap=None\n",
      "2017-01-14 23:13:02,989 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 23:13:21,151 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 23:13:26,922 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_8/model.syn0.npy with mmap=None\n",
      "2017-01-14 23:13:32,127 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 23:13:32,128 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 23:13:34,450 : INFO : Getting training Data\n",
      "2017-01-14 23:14:56,679 : INFO : Training Classifier\n",
      "2017-01-14 23:24:00,948 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:32:22,323 : INFO : Getting Validation Embeddings\n",
      "2017-01-14 23:32:22,329 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.042, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.593, Top 3: 0.897, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.618, F1 Macro: 0.520, Total Pos: 2,579,273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:33:09,167 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 0]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 2.980, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.568, Top 3: 0.890, Top 5: 0.947, \n",
      "\t\t F1 Micro: 0.612, F1 Macro: 0.517, Total Pos: 678,429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:33:39,677 : INFO : ****************** Epoch 9 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9 *******************\n",
      "2017-01-14 23:33:39,717 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model\n",
      "2017-01-14 23:33:57,140 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.docvecs.* with mmap=None\n",
      "2017-01-14 23:33:57,142 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 23:34:14,016 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 23:34:19,037 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_9/model.syn0.npy with mmap=None\n",
      "2017-01-14 23:34:24,190 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 23:34:24,191 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 23:34:26,451 : INFO : Getting training Data\n",
      "2017-01-14 23:35:36,770 : INFO : Training Classifier\n",
      "2017-01-14 23:43:34,035 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:50:20,382 : INFO : Getting Validation Embeddings\n",
      "2017-01-14 23:50:20,385 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.040, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.594, Top 3: 0.897, Top 5: 0.959, \n",
      "\t\t F1 Micro: 0.618, F1 Macro: 0.521, Total Pos: 2,573,212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:51:04,714 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 1]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.016, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.564, Top 3: 0.885, Top 5: 0.948, \n",
      "\t\t F1 Micro: 0.604, F1 Macro: 0.511, Total Pos: 693,973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-14 23:51:34,151 : INFO : ****************** Epoch 10 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10 *******************\n",
      "2017-01-14 23:51:34,153 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model\n",
      "2017-01-14 23:51:51,462 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.docvecs.* with mmap=None\n",
      "2017-01-14 23:51:51,463 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-14 23:52:06,503 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.syn1neg.npy with mmap=None\n",
      "2017-01-14 23:52:11,511 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_10/model.syn0.npy with mmap=None\n",
      "2017-01-14 23:52:16,379 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-14 23:52:16,380 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-14 23:52:18,702 : INFO : Getting training Data\n",
      "2017-01-14 23:53:28,049 : INFO : Training Classifier\n",
      "2017-01-15 00:02:10,031 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:09:33,200 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 00:09:33,203 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.042, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.593, Top 3: 0.897, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.618, F1 Macro: 0.520, Total Pos: 2,578,565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:10:31,569 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.000, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.571, Top 3: 0.889, Top 5: 0.950, \n",
      "\t\t F1 Micro: 0.611, F1 Macro: 0.517, Total Pos: 676,024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:11:00,784 : INFO : ****************** Epoch 11 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11 *******************\n",
      "2017-01-15 00:11:00,837 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model\n",
      "2017-01-15 00:11:08,032 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.docvecs.* with mmap=None\n",
      "2017-01-15 00:11:08,033 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 00:11:23,070 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 00:11:28,730 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_11/model.syn0.npy with mmap=None\n",
      "2017-01-15 00:11:34,520 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 00:11:34,521 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 00:11:36,849 : INFO : Getting training Data\n",
      "2017-01-15 00:12:57,000 : INFO : Training Classifier\n",
      "2017-01-15 00:20:53,302 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:27:53,665 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 00:27:53,669 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.042, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.593, Top 3: 0.897, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.618, F1 Macro: 0.521, Total Pos: 2,575,841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:28:35,753 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.004, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.570, Top 3: 0.888, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.609, F1 Macro: 0.515, Total Pos: 681,804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:29:05,469 : INFO : ****************** Epoch 12 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12 *******************\n",
      "2017-01-15 00:29:05,477 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model\n",
      "2017-01-15 00:29:22,842 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.docvecs.* with mmap=None\n",
      "2017-01-15 00:29:22,843 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 00:29:38,264 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 00:29:43,475 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_12/model.syn0.npy with mmap=None\n",
      "2017-01-15 00:29:48,735 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 00:29:48,736 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 00:29:51,054 : INFO : Getting training Data\n",
      "2017-01-15 00:31:01,059 : INFO : Training Classifier\n",
      "2017-01-15 00:40:12,595 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:48:33,428 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 00:48:33,431 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.043, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.594, Top 3: 0.897, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.618, F1 Macro: 0.521, Total Pos: 2,573,969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:49:16,532 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 3.002, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.569, Top 3: 0.891, Top 5: 0.952, \n",
      "\t\t F1 Micro: 0.610, F1 Macro: 0.516, Total Pos: 680,421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 00:49:46,555 : INFO : ****************** Epoch 13 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13 *******************\n",
      "2017-01-15 00:49:46,565 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model\n",
      "2017-01-15 00:50:04,040 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.docvecs.* with mmap=None\n",
      "2017-01-15 00:50:04,041 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 00:50:22,966 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 00:50:29,561 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_13/model.syn0.npy with mmap=None\n",
      "2017-01-15 00:50:34,981 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 00:50:34,982 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 00:50:37,189 : INFO : Getting training Data\n",
      "2017-01-15 00:52:01,116 : INFO : Training Classifier\n",
      "2017-01-15 01:00:05,310 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 01:07:38,644 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 01:07:38,648 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.041, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.594, Top 3: 0.898, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.619, F1 Macro: 0.521, Total Pos: 2,569,359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 01:08:24,588 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 2.983, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.568, Top 3: 0.892, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.613, F1 Macro: 0.518, Total Pos: 677,624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 01:08:54,628 : INFO : ****************** Epoch 14 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14 *******************\n",
      "2017-01-15 01:08:54,644 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model\n",
      "2017-01-15 01:09:01,954 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.docvecs.* with mmap=None\n",
      "2017-01-15 01:09:01,955 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-15 01:09:20,298 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.syn1neg.npy with mmap=None\n",
      "2017-01-15 01:09:26,508 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_14/model.syn0.npy with mmap=None\n",
      "2017-01-15 01:09:32,427 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-15 01:09:32,428 : INFO : setting ignored attribute cum_table to None\n",
      "2017-01-15 01:09:34,786 : INFO : Getting training Data\n",
      "2017-01-15 01:10:58,566 : INFO : Training Classifier\n",
      "2017-01-15 01:20:15,802 : INFO : Evaluating on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 1 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 01:28:48,772 : INFO : Getting Validation Embeddings\n",
      "2017-01-15 01:28:48,776 : INFO : ===== Loading validation vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training Metrics: Cov Err: 3.047, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.593, Top 3: 0.897, Top 5: 0.960, \n",
      "\t\t F1 Micro: 0.618, F1 Macro: 0.520, Total Pos: 2,574,237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 01:29:36,730 : INFO : Evaluating on Validation Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 0]\n",
      " [1 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 0]]\n",
      "** Validation Metrics: Cov Err: 2.962, Avg Labels: 1.150, \n",
      "\t\t Top 1: 0.577, Top 3: 0.895, Top 5: 0.951, \n",
      "\t\t F1 Micro: 0.616, F1 Macro: 0.520, Total Pos: 674,243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-15 01:30:06,885 : INFO : ****************** Epoch 15 --- Working on doc2vec_size_200_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_15 *******************\n",
      "2017-01-15 01:30:06,887 : INFO : training model with 22 workers on 391521 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10\n",
      "2017-01-15 01:30:06,888 : INFO : expecting 1651226 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-15 01:30:06,912 : INFO : Loading new batch for index: 0\n",
      "2017-01-15 01:30:31,250 : INFO : Finished loading new batch\n",
      "2017-01-15 01:30:32,369 : INFO : PROGRESS: at 0.00% examples, 156 words/s, in_qsize 0, out_qsize 2\n",
      "2017-01-15 01:30:52,352 : INFO : PROGRESS: at 0.22% examples, 344593 words/s, in_qsize 43, out_qsize 0\n",
      "2017-01-15 01:31:12,365 : INFO : PROGRESS: at 0.46% examples, 490311 words/s, in_qsize 43, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph(len(classifications) +2)\n",
    "# when resuming, resume from an epoch with a previously created doc2vec model to get the learning rate right\n",
    "start_from = 1\n",
    "for epoch in range(start_from, DOC2VEC_MAX_EPOCHS+1):\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    info(\"****************** Epoch {} --- Working on {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "    # if we have the model, just load it, otherwise train the previous model\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "        doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "    else:\n",
    "        # train the doc2vec model\n",
    "        training_docs_iterator = DocumentBatchGenerator(training_preprocessed_files_prefix, \n",
    "                                                        training_preprocessed_docids_files_prefix, batch_size=10000)\n",
    "        doc2vec_model.train(sentences=training_docs_iterator, report_delay=REPORT_DELAY)\n",
    "        doc2vec_model.alpha -= 0.001  # decrease the learning rate\n",
    "        doc2vec_model.min_alpha = doc2vec_model.alpha  # fix the learning rate, no decay\n",
    "        ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME))\n",
    "        doc2vec_model.save(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "        \n",
    "        # get the word2vec analogy accuracy score\n",
    "        word2vec_result = doc2vec_model.accuracy(word2vec_questions_file, restrict_vocab=None)\n",
    "        epoch_word2vec_metrics.append(word2vec_result)\n",
    "        pickle.dump(word2vec_result, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME,\n",
    "                                                       WORD2VEC_METRICS_FILENAME), 'w'))\n",
    "\n",
    "        \n",
    "    info('Getting training Data')\n",
    "    X, y = get_training_data(doc2vec_model, classifications)\n",
    "    \n",
    "    \n",
    "    ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                             GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "    \n",
    "    # try warm start and evaluate after every iter\n",
    "    \n",
    "    if not os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER)):\n",
    "        info('Training Classifier')\n",
    "        clf = OneVsRestClassifier(linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                             #alpha is the 1/C parameter\n",
    "                                                             alpha=SVM_REG, fit_intercept=True, n_iter=SVM_ITERATIONS,\n",
    "                                                             #n_jobs=-1 means use all cpus\n",
    "                                                             shuffle=True, verbose=0, n_jobs=1,\n",
    "                                                             #eta0 is the learning rate when we use constant configuration\n",
    "                                                             random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                             class_weight=SVM_CLASS_WEIGHTS, warm_start=False), n_jobs=1)\n",
    "\n",
    "\n",
    "        # Training of a classifier\n",
    "        clf.fit(X,y)\n",
    "        pickle.dump(clf, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                              GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER), 'w'))\n",
    "    else:\n",
    "        clf = pickle.load(open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, CLASSIFIER), 'r'))\n",
    "    \n",
    "    # Training Metrics\n",
    "    info('Evaluating on Training Data')\n",
    "    yp = clf.predict(X)\n",
    "    print yp\n",
    "    training_metrics = get_metrics(y, yp, yp)\n",
    "    print \"** Training Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        training_metrics['coverage_error'], training_metrics['average_num_of_labels'], \n",
    "        training_metrics['top_1'], training_metrics['top_3'], training_metrics['top_5'], \n",
    "        training_metrics['f1_micro'], training_metrics['f1_macro'], training_metrics['total_positive'])\n",
    "    \n",
    "    epoch_training_metrics.append(training_metrics)\n",
    "    \n",
    "    \n",
    "    # Validation Metrics\n",
    "    info('Getting Validation Embeddings')\n",
    "    Xv, yv = get_validation_docs_with_inference_new(doc2vec_model, doc_classification_map, classifications, \n",
    "                                                    validation_docs_list, validation_preprocessed_files_prefix,\n",
    "                                                    validation_preprocessed_docids_files_prefix)\n",
    "    info('Evaluating on Validation Data')\n",
    "    yvp = clf.predict(Xv)\n",
    "    print yvp\n",
    "    validation_metrics = get_metrics(yv, yvp, yvp)\n",
    "    print \"** Validation Metrics: Cov Err: {:.3f}, Avg Labels: {:.3f}, \\n\\t\\t Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}, \\n\\t\\t F1 Micro: {:.3f}, F1 Macro: {:.3f}, Total Pos: {:,d}\".format(\n",
    "        validation_metrics['coverage_error'], validation_metrics['average_num_of_labels'], \n",
    "        validation_metrics['top_1'], validation_metrics['top_3'], validation_metrics['top_5'], \n",
    "        validation_metrics['f1_micro'], validation_metrics['f1_macro'], validation_metrics['total_positive'])\n",
    "    \n",
    "    graph.add_metrics_to_graph(validation_metrics, epoch)\n",
    "    \n",
    "    epoch_validation_metrics.append(validation_metrics)\n",
    "    \n",
    "    \n",
    "    # Saving the metrics\n",
    "    pickle.dump(training_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, TRAINING_METRICS_FILENAME), 'w'))\n",
    "    pickle.dump(validation_metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "                                                          GLOBAL_VARS.SVM_MODEL_NAME, VALIDATION_METRICS_FILENAME), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-07 08:32:48,888 : INFO : ****************** Epoch 6 --- Working on doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6 *******************\n",
      "2017-01-07 08:32:48,891 : INFO : loading Doc2Vec object from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model\n",
      "2017-01-07 08:33:14,046 : INFO : loading docvecs recursively from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.* with mmap=None\n",
      "2017-01-07 08:33:14,048 : INFO : loading doctag_syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2017-01-07 08:33:21,936 : INFO : loading syn1neg from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy with mmap=None\n",
      "2017-01-07 08:33:24,446 : INFO : loading syn0 from /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy with mmap=None\n",
      "2017-01-07 08:33:26,751 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-01-07 08:33:26,768 : INFO : setting ignored attribute cum_table to None\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(6)\n",
    "info(\"****************** Epoch {} --- Working on {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "\n",
    "# if we have the model, just load it, otherwise train the previous model\n",
    "if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "    doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-07 08:05:32,383 : INFO : saving Doc2Vec object under /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model, separately None\n",
      "2017-01-07 08:05:32,384 : INFO : storing numpy array 'doctag_syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.docvecs.doctag_syn0.npy\n",
      "2017-01-07 08:06:07,546 : INFO : storing numpy array 'syn1neg' to /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn1neg.npy\n",
      "2017-01-07 08:06:22,413 : INFO : not storing attribute syn0norm\n",
      "2017-01-07 08:06:22,414 : INFO : storing numpy array 'syn0' to /big/s/shalaby/parameter_search_doc2vec_models_new/full/doc2vec_size_500_w_8_type_dm_concat_0_mean_1_trainwords_0_hs_0_neg_10_vocabsize_None/epoch_6/model.syn0.npy\n",
      "2017-01-07 08:06:37,511 : INFO : not storing attribute cum_table\n",
      "2017-01-07 08:07:37,639 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-07 08:08:36,552 : INFO : capital-common-countries: 9.2% (28/306)\n",
      "2017-01-07 08:09:21,442 : INFO : capital-world: 6.8% (31/453)\n",
      "2017-01-07 08:09:36,517 : INFO : currency: 0.0% (0/152)\n",
      "2017-01-07 08:13:17,488 : INFO : city-in-state: 3.3% (75/2252)\n",
      "2017-01-07 08:13:44,345 : INFO : family: 14.3% (39/272)\n",
      "2017-01-07 08:15:09,837 : INFO : gram1-adjective-to-adverb: 6.8% (59/870)\n",
      "2017-01-07 08:16:14,734 : INFO : gram2-opposite: 17.5% (114/650)\n",
      "2017-01-07 08:18:26,319 : INFO : gram3-comparative: 72.7% (969/1332)\n",
      "2017-01-07 08:19:40,242 : INFO : gram4-superlative: 34.1% (258/756)\n",
      "2017-01-07 08:21:23,693 : INFO : gram5-present-participle: 23.0% (243/1056)\n",
      "2017-01-07 08:23:05,897 : INFO : gram6-nationality-adjective: 11.7% (120/1030)\n",
      "2017-01-07 08:25:25,383 : INFO : gram7-past-tense: 12.2% (172/1406)\n",
      "2017-01-07 08:27:28,904 : INFO : gram8-plural: 43.9% (553/1260)\n",
      "2017-01-07 08:28:50,549 : INFO : gram9-plural-verbs: 47.9% (389/812)\n",
      "2017-01-07 08:28:50,553 : INFO : total: 24.2% (3050/12607)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 47min 44s, sys: 4h 31min 2s, total: 8h 18min 46s\n",
      "Wall time: 21min 14s\n",
      "CPU times: user 3h 48min 38s, sys: 4h 31min 12s, total: 8h 19min 51s\n",
      "Wall time: 23min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME))\n",
    "doc2vec_model.save(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "\n",
    "# get the word2vec analogy accuracy score\n",
    "%time word2vec_result = doc2vec_model.accuracy(word2vec_questions_file, restrict_vocab=None)\n",
    "epoch_word2vec_metrics.append(word2vec_result)\n",
    "pickle.dump(word2vec_result, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME,\n",
    "                                               WORD2VEC_METRICS_FILENAME), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import thesis.utils.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 22:22:21,536 : INFO : Loading new batch\n",
      "2016-12-28 22:22:27,109 : INFO : Finished loading new batch\n"
     ]
    }
   ],
   "source": [
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "i=0\n",
    "doc_contents = []\n",
    "for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "    i += 1\n",
    "    doc_contents.append((doc_id, doc_contents_array))\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def infer_one_doc(doc):\n",
    "    #doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "    rep = doc2vec_model.infer_vector(doc[1])\n",
    "    return (doc[0], rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threaded Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 620 ms, total: 1min 41s\n",
      "Wall time: 9.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = ThreadPool(16)\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "threaded_reps = pool.map(infer_one_doc, doc_contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Threaded Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 44 ms, total: 14.1 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reps = []\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "for doc in doc_contents:\n",
    "    reps.append((doc[0], doc2vec_model.infer_vector(doc[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'08825480',\n",
       " u'08774433',\n",
       " u'08791071',\n",
       " u'08912011',\n",
       " u'08678092',\n",
       " u'08859194',\n",
       " u'08635554',\n",
       " u'08914715',\n",
       " u'08740442',\n",
       " u'08740792',\n",
       " u'08741891',\n",
       " u'08889791',\n",
       " u'08845058',\n",
       " u'08675352',\n",
       " u'08910298',\n",
       " u'08908470',\n",
       " u'07336611',\n",
       " u'07370801',\n",
       " u'08923495',\n",
       " u'08730828']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[0] for d in threaded_reps][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'08825480',\n",
       " u'08774433',\n",
       " u'08791071',\n",
       " u'08912011',\n",
       " u'08678092',\n",
       " u'08859194',\n",
       " u'08635554',\n",
       " u'08914715',\n",
       " u'08740442',\n",
       " u'08740792',\n",
       " u'08741891',\n",
       " u'08889791',\n",
       " u'08845058',\n",
       " u'08675352',\n",
       " u'08910298',\n",
       " u'08908470',\n",
       " u'07336611',\n",
       " u'07370801',\n",
       " u'08923495',\n",
       " u'08730828']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[0] for d in reps][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal([d[0] for d in reps], [d[0] for d in threaded_reps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30695215,  0.62732637, -0.16665867,  0.21510798, -0.31053102,\n",
       "        0.24912256,  0.27854046, -0.18195362, -0.2556676 , -0.5964365 ,\n",
       "        0.21105912, -0.23973639, -0.03185667, -0.07150706,  0.34752986,\n",
       "       -0.10195051, -0.21096784, -0.16357803, -0.36328176,  0.69572109,\n",
       "        0.56532162, -0.2350243 ,  0.29052514,  0.08191228,  0.35617095,\n",
       "       -0.04608935, -0.22245102, -0.2092436 ,  0.03193387,  0.20119652,\n",
       "        0.41143674, -0.00198068,  0.2738685 ,  0.53701001, -0.1117554 ,\n",
       "       -0.03540101, -0.34937236, -0.79319656, -0.24756837,  0.25518459,\n",
       "       -0.13143119, -0.28934225,  0.40138   , -0.98963302,  0.13317154,\n",
       "       -0.78089136,  0.02822817,  0.09919885,  0.06839398,  1.14812255,\n",
       "       -0.35712692,  0.03212974,  0.31967002,  0.01885306,  0.32403627,\n",
       "        0.06881366, -0.36663699, -0.06164655, -0.50977266,  0.13202219,\n",
       "        0.34584206, -0.23481339, -0.26995379, -0.05701207,  0.09176121,\n",
       "        0.05095135, -0.33242008,  0.24291369,  0.01117826,  0.10993928,\n",
       "       -0.1800983 ,  0.49444726,  0.26564318,  0.7361095 , -0.06239768,\n",
       "       -0.21320428, -0.20742436, -0.03807143, -0.12843417, -0.48612225,\n",
       "        0.14675111,  0.1267944 , -0.44746301, -0.68673682, -0.54249072,\n",
       "       -0.07855206, -0.43142584,  0.35044146,  0.15806454, -0.81718534,\n",
       "       -0.24564786, -0.41462311,  0.05346218,  0.13060793, -0.52602261,\n",
       "       -0.68961495, -0.35983112, -0.10904109, -0.70629472, -0.74079585], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44398868,  0.72295773, -0.1431679 ,  0.12140259, -0.35566956,\n",
       "        0.25285348,  0.25987589, -0.25635543, -0.27375746, -0.68261814,\n",
       "        0.2418227 , -0.31993562, -0.04068605, -0.19011304,  0.25827357,\n",
       "       -0.23827454, -0.14665996, -0.24676035, -0.31205919,  0.7144047 ,\n",
       "        0.51341397, -0.27819353,  0.2297533 ,  0.21143083,  0.21526954,\n",
       "       -0.12819654, -0.23137507, -0.18031113, -0.0302615 ,  0.25606248,\n",
       "        0.46331209,  0.03231328,  0.29240945,  0.55419838, -0.08406049,\n",
       "       -0.02534914, -0.30697635, -0.89490503, -0.25361407, -0.0620365 ,\n",
       "       -0.10279118, -0.24122375,  0.2858358 , -0.89883715,  0.2349384 ,\n",
       "       -0.77614403,  0.07704009,  0.00219567,  0.05001302,  1.00935435,\n",
       "       -0.43593982,  0.03736721,  0.49705869, -0.04218138,  0.37695912,\n",
       "        0.0875724 , -0.41761422,  0.01351045, -0.63688326,  0.19897321,\n",
       "        0.29641187, -0.23571339, -0.14795278, -0.12061672,  0.1306804 ,\n",
       "        0.2521036 , -0.36068025,  0.26970887, -0.00897445,  0.17607778,\n",
       "       -0.101063  ,  0.44033691,  0.19987908,  0.65593952, -0.2147298 ,\n",
       "       -0.10094108, -0.20588517, -0.08825132, -0.08381121, -0.44989595,\n",
       "        0.17535064,  0.10233553, -0.57504725, -0.80179036, -0.56347519,\n",
       "       -0.09048223, -0.4018501 ,  0.54773515,  0.20243937, -0.86586028,\n",
       "       -0.30235139, -0.51399952,  0.10769948, -0.03541334, -0.45822388,\n",
       "       -0.72284496, -0.29005697, -0.11217777, -0.75840199, -0.75367755], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threaded_reps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple threading, but problem is that pool.map exhausts the whole iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 23:52:07,981 : INFO : Loading new batch for index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 12 ms, total: 36 ms\n",
      "Wall time: 26.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 23:52:14,764 : INFO : Finished loading new batch\n",
      "2016-12-28 23:52:16,320 : INFO : Loading new batch for index: 10000\n",
      "2016-12-28 23:52:36,742 : INFO : Finished loading new batch\n",
      "2016-12-28 23:52:37,438 : INFO : Loading new batch for index: 12412\n",
      "2016-12-28 23:52:37,487 : INFO : No more batches to load, exiting at index: 12412\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "pool = ThreadPool(16)\n",
    "threaded_reps = pool.map(infer_one_doc, validation_docs_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nothing_func(doc):\n",
    "    1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-29 02:08:42,347 : INFO : Loading new batch for index: 0\n",
      "2016-12-29 02:08:49,943 : INFO : Finished loading new batch\n",
      "2016-12-29 02:09:13,387 : INFO : Finished: 1000\n",
      "2016-12-29 02:09:36,895 : INFO : Finished: 2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-20d2bff78aed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'validation_docs_iterator = DocumentBatchGenerator2(validation_preprocessed_files_prefix, \\n                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\\ngenerator_func = validation_docs_iterator.__iter__()\\npool = ThreadPool(16)\\n# map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\\nthreaded_reps = {}\\nmini_batch_size = 1000\\nwhile True:\\n    threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\\n    info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\\n    if threaded_reps_partial:\\n        #threaded_reps.extend(threaded_reps_partial)\\n        threaded_reps.update(threaded_reps_partial)\\n    else:\\n        break'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    249\u001b[0m         '''\n\u001b[0;32m    250\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_docs_iterator = DocumentBatchGenerator2(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "generator_func = validation_docs_iterator.__iter__()\n",
    "pool = ThreadPool(16)\n",
    "# map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "threaded_reps = {}\n",
    "mini_batch_size = 1000\n",
    "while True:\n",
    "    threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(generator_func, mini_batch_size))\n",
    "    info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "    if threaded_reps_partial:\n",
    "        #threaded_reps.extend(threaded_reps_partial)\n",
    "        threaded_reps.update(threaded_reps_partial)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocumentBatchGenerator2(object):\n",
    "    def __init__(self, filename_prefix, filename_docids_prefix, batch_size=10000 ):\n",
    "        \"\"\"\n",
    "        batch_size cant be > 10,000 due to a limitation in doc2vec training, \n",
    "        None means no batching (only use for inference)\n",
    "        \"\"\"\n",
    "        assert batch_size <= 10000 or batch_size is None\n",
    "        self.filename_prefix = filename_prefix\n",
    "        self.filename_docids_prefix = filename_docids_prefix\n",
    "        self.curr_lines = []\n",
    "        self.curr_docids = []\n",
    "        self.batch_size = batch_size\n",
    "        self.curr_index = 0\n",
    "        self.batch_end = -1\n",
    "    def load_new_batch_in_memory(self):\n",
    "        self.curr_lines, self.docids = [], []\n",
    "        info(\"Loading new batch for index: {}\".format(self.curr_index) )\n",
    "        try:\n",
    "            with open(self.filename_prefix + str(self.curr_index)) as preproc_file:\n",
    "                for line in preproc_file:\n",
    "                    self.curr_lines.append(line.split(\" \"))\n",
    "#                     if i % 1000 == 0:\n",
    "#                         print i\n",
    "            self.curr_docids = pickle.load(open(self.filename_docids_prefix + str(self.curr_index), \"r\"))\n",
    "            self.batch_end = self.curr_index + len(self.curr_lines) -1 \n",
    "            info(\"Finished loading new batch\")\n",
    "        except IOError:\n",
    "            info(\"No more batches to load, exiting at index: {}\".format(self.curr_index))\n",
    "            raise StopIteration()\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            if self.curr_index > self.batch_end:\n",
    "                self.load_new_batch_in_memory()\n",
    "            for (doc_id, tokens) in zip(self.curr_docids, self.curr_lines):\n",
    "                if self.batch_size is not None:\n",
    "                    curr_batch_iter = 0\n",
    "                    # divide the document to batches according to the batch size\n",
    "                    while curr_batch_iter < len(tokens):\n",
    "                        self.curr_index += 1\n",
    "                        yield LabeledSentence(words=tokens[curr_batch_iter: curr_batch_iter + self.batch_size], tags=[doc_id])\n",
    "                        curr_batch_iter += self.batch_size\n",
    "                else:\n",
    "                    self.curr_index += 1\n",
    "                    yield doc_id, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12412"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threaded_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "pool = ThreadPool(20)\n",
    "# map consumes the whole iterator on the spot, so we have to use itertools.islice to fake mini-batching\n",
    "threaded_reps = []\n",
    "mini_batch_size = 1000\n",
    "while True:\n",
    "    threaded_reps_partial = pool.map(infer_one_doc, itertools.islice(validation_docs_iterator, mini_batch_size))\n",
    "    info(\"Finished: {}\".format(str(validation_docs_iterator.curr_index)))\n",
    "    if threaded_reps_partial:\n",
    "        threaded_reps.extend(threaded_reps_partial)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def g():\n",
    "    for el in xrange(50):\n",
    "        yield el\n",
    "\n",
    "go = g()\n",
    "result = []\n",
    "N = 10\n",
    "for i in itertools.islice(go, N):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-28 18:35:17,009 : INFO : Loading new batch\n",
      "2016-12-28 18:35:21,915 : INFO : Finished loading new batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 848 ms, sys: 8 ms, total: 856 ms\n",
      "Wall time: 852 ms\n",
      "CPU times: user 448 ms, sys: 12 ms, total: 460 ms\n",
      "Wall time: 457 ms\n",
      "CPU times: user 248 ms, sys: 4 ms, total: 252 ms\n",
      "Wall time: 250 ms\n",
      "{u'08774433': array([-0.24957576, -0.44971526, -0.56399536,  0.26340374, -0.72280848,\n",
      "        0.07701001,  0.53518784,  0.47400331,  0.00103833, -0.21523826,\n",
      "        0.5090881 , -0.66132861, -0.54403561,  0.44076878,  0.00470332,\n",
      "       -0.60674977,  0.25171441,  0.01955804, -0.42058256,  0.12502177,\n",
      "       -0.16908602, -0.77621526,  0.66039973,  0.22638585, -0.14937432,\n",
      "        0.18073724, -0.22520301, -0.01612019, -0.94866085, -0.56705993,\n",
      "       -0.31372947, -0.61444628,  0.36096638,  0.05321291,  0.31520829,\n",
      "       -0.78794104, -0.02634728,  0.27075273, -0.69757801, -0.11887208,\n",
      "        0.24548931, -0.37358913,  0.30241317, -0.02301121, -0.16444607,\n",
      "        0.32210201, -0.49894542,  0.47786587, -0.7696104 ,  0.57316011,\n",
      "        0.75851572, -0.29875955, -0.39299953,  0.29592195,  0.01002928,\n",
      "       -0.00714504, -0.45345017, -0.45329556, -0.15423954,  0.0956117 ,\n",
      "       -0.17815629,  0.00485223, -0.47434196,  0.8352198 ,  0.29984775,\n",
      "       -0.75325739, -0.2932708 ,  0.22751437, -0.72489858, -0.23059492,\n",
      "       -0.62555069,  1.02729392, -0.00715734, -0.35845065, -0.04130894,\n",
      "       -0.63375956,  0.13670547, -0.35168752, -0.120276  ,  0.06363766,\n",
      "       -0.14529508, -0.73692763, -0.10244129,  0.24102579, -0.39304346,\n",
      "       -0.44905126, -0.02963378,  0.40327483,  0.09173202, -0.20075732,\n",
      "        0.25192481, -0.40484259,  0.03583284,  0.08575827, -0.71413624,\n",
      "       -0.12856877,  0.00697137,  0.17350946, -0.09800411, -0.2387124 ], dtype=float32), u'08825480': array([ 0.43869719,  0.69493228, -0.15423374,  0.18415831, -0.27953076,\n",
      "        0.32741979,  0.25916466, -0.2263912 , -0.30463687, -0.68594444,\n",
      "        0.23562942, -0.26695064, -0.03071095, -0.19515269,  0.16481824,\n",
      "       -0.26835197, -0.1237495 , -0.21595523, -0.31863457,  0.67200935,\n",
      "        0.54566181, -0.3022787 ,  0.21178976,  0.16891097,  0.25907236,\n",
      "       -0.13429914, -0.29047617, -0.19215892, -0.03019565,  0.23971696,\n",
      "        0.4794547 , -0.0125326 ,  0.27816984,  0.5431518 , -0.08415657,\n",
      "       -0.06213364, -0.31795123, -0.95289969, -0.25565225, -0.03096373,\n",
      "       -0.0847759 , -0.239768  ,  0.34742916, -0.92078727,  0.13093236,\n",
      "       -0.80080444,  0.06648453, -0.03016538,  0.06161455,  1.04044044,\n",
      "       -0.43327764,  0.07086919,  0.35355189,  0.01039008,  0.4170292 ,\n",
      "        0.08228578, -0.45204273, -0.00495607, -0.65024465,  0.18624543,\n",
      "        0.29581559, -0.26705703, -0.08137546, -0.06691577,  0.14972705,\n",
      "        0.151612  , -0.31241465,  0.24215488,  0.00248444,  0.1801302 ,\n",
      "       -0.09848733,  0.43015948,  0.1988074 ,  0.64442545, -0.18052702,\n",
      "       -0.18566328, -0.22178149, -0.0649749 , -0.09142254, -0.46278423,\n",
      "        0.15451705,  0.1908915 , -0.52935004, -0.82046568, -0.49538887,\n",
      "       -0.10716466, -0.36556813,  0.5163148 ,  0.19676271, -0.84946609,\n",
      "       -0.29985458, -0.52276957,  0.03275018,  0.06643863, -0.43565878,\n",
      "       -0.76278096, -0.28564611, -0.09855174, -0.72650057, -0.71671903], dtype=float32), u'08791071': array([-0.23259643,  0.41450036,  0.51434827,  0.00787312, -0.2284483 ,\n",
      "       -0.52937728, -0.19830056,  0.03082488,  1.05058038,  0.17992359,\n",
      "        0.31625026, -0.21843682, -0.37463692, -0.30913776,  0.3170667 ,\n",
      "       -0.36334237, -0.70675725,  0.52395636, -0.26112491,  1.05543351,\n",
      "       -1.10443592, -0.21194471, -0.54147512,  0.09155747, -0.32934853,\n",
      "        0.01652185,  0.04093302,  0.08362015,  0.54133213,  0.03441263,\n",
      "       -0.88398618, -0.10849927,  0.56919503, -0.60503298,  0.12571461,\n",
      "        0.18873298,  0.17914939,  0.04950287, -0.28671712, -0.10798603,\n",
      "       -0.744412  ,  0.31562504, -0.27431366,  0.28065825,  0.23825864,\n",
      "       -0.1323806 ,  0.06025767, -0.22927827, -0.44928807,  0.21095365,\n",
      "        0.57495964, -0.1029187 , -0.00365091,  0.61913794, -0.88101172,\n",
      "        0.60874623, -0.38232478,  0.47158134, -0.05255252,  0.4324486 ,\n",
      "        0.3947401 ,  1.06982732,  0.19763152, -0.52621794,  0.30451465,\n",
      "       -0.41999158, -0.23451024,  0.31681204,  0.28471184, -0.22745852,\n",
      "       -0.60245752, -0.37300718, -0.06770302,  0.0346529 ,  0.36362028,\n",
      "       -0.08779243, -0.16030943, -0.11415948, -0.3266314 ,  0.30446157,\n",
      "        0.11385298, -0.21830294,  0.14570464, -0.71273166, -0.22124635,\n",
      "        0.22901915, -0.69352126, -0.81168574,  0.120683  ,  0.68962598,\n",
      "        0.1142956 ,  0.08250535, -0.01027837,  0.10909576,  0.22610265,\n",
      "        0.06197856, -0.4596194 ,  0.27084136,  0.23881529,  0.26482731], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "validation_docs_iterator = DocumentBatchGenerator(validation_preprocessed_files_prefix, \n",
    "                                                  validation_preprocessed_docids_files_prefix, batch_size=None)\n",
    "doc2vec_model.random = np.random.RandomState(DOC2VEC_SEED)\n",
    "i = 0\n",
    "val_docs_reps = {}\n",
    "for (doc_id, doc_contents_array) in validation_docs_iterator:\n",
    "    i += 1\n",
    "    %time val_docs_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array, steps=15)\n",
    "    if i > 2:\n",
    "        break\n",
    "    \n",
    "print val_docs_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_training_data(doc2vec_model, classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yc = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49789, 8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(estimator=linear_model.SGDClassifier(loss='hinge', penalty='l2', \n",
    "                                                         #alpha is the 1/C parameter\n",
    "                                                         alpha=0.001, fit_intercept=True, n_iter=10,\n",
    "                                                         #n_jobs=-1 means use all cpus\n",
    "                                                         shuffle=True, verbose=1, epsilon=0.1, n_jobs=-1,\n",
    "                                                         #eta0 is the learning rate when we use constant configuration\n",
    "                                                         random_state=SVM_SEED, learning_rate='optimal', eta0=0.0, \n",
    "                                                         class_weight=None, warm_start=False), n_jobs=1)\n",
    "\n",
    "# clf = OneVsRestClassifier(estimator=SVC(kernel='linear'), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stud/shalaby/.virtualenv/thesis-env/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "yp = clf.predict(X)\n",
    "\n",
    "print yp\n",
    "\n",
    "training_metrics = get_metrics(np.array(y), yp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "Y = np.array(['a', 'a', 'b', 'b'])\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict([[-0.8, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_svm_epoch = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-11-26 18:25:14,192 : INFO : loading Doc2Vec object from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model\n",
      "2016-11-26 18:25:14,584 : INFO : loading docvecs recursively from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.docvecs.* with mmap=None\n",
      "2016-11-26 18:25:14,585 : INFO : loading doctag_syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2016-11-26 18:25:14,814 : INFO : loading syn1neg from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.syn1neg.npy with mmap=None\n",
      "2016-11-26 18:26:37,586 : INFO : loading syn0 from /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.0001/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_13/model.syn0.npy with mmap=None\n",
      "2016-11-26 18:26:41,876 : INFO : setting ignored attribute syn0norm to None\n",
      "2016-11-26 18:26:41,877 : INFO : setting ignored attribute cum_table to None\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(best_svm_epoch)\n",
    "doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 520 ms, total: 2.13 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifications = sections\n",
    "\n",
    "NN_OUTPUT_NEURONS = len(classifications)\n",
    "one_hot_encoder = OneHotEncoder(classifications)\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for doc_id in training_docs_list:\n",
    "    # converting from memmap to a normal array\n",
    "    normal_array = []\n",
    "    normal_array[:] = doc2vec_model.docvecs[doc_id][:]\n",
    "    training_data.append(normal_array)\n",
    "    eligible_classifications = [clssf for clssf in doc_classification_map[doc_id] if clssf in classifications]\n",
    "    training_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1969, 3000)\n",
      "CPU times: user 2.58 s, sys: 360 ms, total: 2.94 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "validation_labels = []\n",
    "validation_data = pickle.load(open(\n",
    "        os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, VALIDATION_MATRIX)\n",
    "))\n",
    "print validation_data.shape\n",
    "\n",
    "for validation_doc_id in validation_docs_list:\n",
    "    eligible_classifications = [clssf for clssf in doc_classification_map[validation_doc_id] if clssf in classifications]\n",
    "    validation_labels.append(one_hot_encoder.get_label_vector(eligible_classifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 500)           0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_64[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     dropout_65[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 500)           1500500     dropout_66[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)             (None, 500)           0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_67[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)             (None, 500)           0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_68[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     dropout_69[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 500)           1500500     dropout_70[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)             (None, 500)           0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_71[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)             (None, 500)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_72[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     dropout_73[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 500)           1500500     dropout_74[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)             (None, 500)           0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_75[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)             (None, 500)           0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_76[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     dropout_77[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 500)           1500500     dropout_78[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)             (None, 500)           0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_79[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)             (None, 500)           0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_80[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     dropout_81[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 500, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 500)           1500500     dropout_82[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)             (None, 500)           0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             4008        dropout_83[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1504508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)             (None, 1500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_84[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     dropout_85[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 1500)          4501500     dropout_86[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)             (None, 1500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_87[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)             (None, 1500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_88[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     dropout_89[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 1500)          4501500     dropout_90[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)             (None, 1500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_91[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)             (None, 1500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_92[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     dropout_93[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 1500)          4501500     dropout_94[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)             (None, 1500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_95[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)             (None, 1500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_96[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     dropout_97[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)             (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 1500)          4501500     dropout_98[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)             (None, 1500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_99[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)            (None, 1500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_100[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     dropout_101[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 1500, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 1500)          4501500     dropout_102[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)            (None, 1500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             12008       dropout_103[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 4513508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)            (None, 3000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_104[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     dropout_105[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 3000)          9003000     dropout_106[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)            (None, 3000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_107[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)            (None, 3000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_108[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     dropout_109[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 3000)          9003000     dropout_110[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)            (None, 3000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_111[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)            (None, 3000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_112[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     dropout_113[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 3000)          9003000     dropout_114[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)            (None, 3000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_115[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)            (None, 3000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_116[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     dropout_117[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 3000)          9003000     dropout_118[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)            (None, 3000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_119[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)            (None, 3000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_120[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     dropout_121[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 3000, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 3000)          9003000     dropout_122[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)            (None, 3000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             24008       dropout_123[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9027008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)            (None, 4500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_124[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    dropout_125[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 4500)          13504500    dropout_126[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)            (None, 4500)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_127[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)            (None, 4500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_128[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    dropout_129[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 4500)          13504500    dropout_130[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)            (None, 4500)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_131[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)            (None, 4500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_132[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    dropout_133[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 4500)          13504500    dropout_134[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)            (None, 4500)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_135[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)            (None, 4500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_136[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    dropout_137[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 4500)          13504500    dropout_138[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)            (None, 4500)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_139[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)            (None, 4500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_140[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    dropout_141[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 4500, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 4500)          13504500    dropout_142[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)            (None, 4500)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       dropout_143[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)            (None, 6000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_144[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    dropout_145[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_relu[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: relu, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_relu (Dense)        (None, 6000)          18006000    dropout_146[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)            (None, 6000)          0           hidden_layer_relu[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_147[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)            (None, 6000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_148[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    dropout_149[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_sigmoid[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: sigmoid, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_sigmoid (Dense)     (None, 6000)          18006000    dropout_150[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)            (None, 6000)          0           hidden_layer_sigmoid[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_151[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)            (None, 6000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_152[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    dropout_153[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_tanh[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: tanh, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_tanh (Dense)        (None, 6000)          18006000    dropout_154[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)            (None, 6000)          0           hidden_layer_tanh[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_155[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)            (None, 6000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_156[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    dropout_157[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_linear[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: linear, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_linear (Dense)      (None, 6000)          18006000    dropout_158[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)            (None, 6000)          0           hidden_layer_linear[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_159[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: False, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: False, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)            (None, 6000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_160[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: True, Hidden Dropout: False ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    dropout_161[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       hidden_layer_softmax[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "===================================================================================\n",
      "========== Layer Size: 6000, Activation: softmax, Input Dropout: True, Hidden Dropout: True ==========================\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)            (None, 3000)          0           doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer_softmax (Dense)     (None, 6000)          18006000    dropout_162[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)            (None, 6000)          0           hidden_layer_softmax[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             48008       dropout_163[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 18054008\n",
      "____________________________________________________________________________________________________\n",
      "CPU times: user 1h 52min 19s, sys: 2h 41min 12s, total: 4h 33min 31s\n",
      "Wall time: 4h 34min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_list = []\n",
    "hidden_layer_sizes = [500,1500,3000,4500,6000]\n",
    "activations = ['relu','sigmoid', 'tanh', 'linear', 'softmax']\n",
    "input_dropout_options = [False, True]\n",
    "hidden_dropout_options = [False, True]\n",
    "\n",
    "params = list(itertools.product(hidden_layer_sizes, activations, input_dropout_options, hidden_dropout_options))\n",
    "for layer_size, activation_func, input_dropout_do, hidden_dropout_do in params:\n",
    "    print \"===================================================================================\\n\" + \\\n",
    "          \"========== Layer Size: {}, Activation: {}, Input Dropout: {}, Hidden Dropout: {} ==========================\"\"\".format(layer_size, activation_func, input_dropout_do, hidden_dropout_do)\n",
    "    doc_input = Input(shape=(DOC2VEC_SIZE,), name='doc_input')\n",
    "    if input_dropout_do:\n",
    "        hidden = Dropout(0.7)(doc_input)\n",
    "    hidden = Dense(layer_size, activation=activation_func, name='hidden_layer_{}'.format(activation_func))(doc_input if not input_dropout_do else hidden)\n",
    "    if hidden_dropout_do:\n",
    "        hidden = Dropout(0.5)(hidden)\n",
    "    softmax_output = Dense(NN_OUTPUT_NEURONS, activation='sigmoid', name='softmax_output')(hidden)\n",
    "    model = Model(input=doc_input, output=softmax_output)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', 'fbeta_score', theano_coverage_error])\n",
    "    model.summary()\n",
    "    history = model.fit(x=training_data, y=training_labels, \n",
    "          validation_data=(validation_data, validation_labels), \n",
    "          nb_epoch=NN_EPOCHS, verbose=0)\n",
    "    history_list.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(history_list, open('/mnt/data2/shalaby/history_list_sample_0.0001.pickle','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.66835957339\n",
      "2.51193499238\n",
      "2.40680548502\n",
      "2.281361097\n",
      "2.76536312849\n",
      "2.42001015744\n",
      "2.3844591163\n",
      "2.3092940579\n",
      "3.03910614525\n",
      "2.50482478415\n",
      "2.52412392077\n",
      "2.38547486034\n",
      "2.89588623667\n",
      "2.85017775521\n",
      "2.46267140681\n",
      "2.45962417471\n",
      "2.91010665312\n",
      "2.81513458608\n",
      "3.01218892839\n",
      "3.13052310818\n",
      "2.61097003555\n",
      "2.64144235653\n",
      "2.39918740477\n",
      "2.29456576943\n",
      "2.89893346877\n",
      "2.5876079228\n",
      "2.49212798375\n",
      "2.42153377349\n",
      "3.01422041646\n",
      "2.63484002031\n",
      "2.50837988827\n",
      "2.39969527679\n",
      "2.87455561199\n",
      "2.94261046216\n",
      "2.50431691214\n",
      "2.52615540884\n",
      "2.71203656679\n",
      "2.96901980701\n",
      "2.96597257491\n",
      "3.17013712544\n",
      "2.81665820213\n",
      "2.87760284408\n",
      "2.39918740477\n",
      "2.3001523616\n",
      "3.03098019299\n",
      "2.67394616557\n",
      "2.64347384459\n",
      "2.6719146775\n",
      "2.95226003047\n",
      "2.68359573388\n",
      "2.50279329609\n",
      "2.49771457593\n",
      "2.89233113255\n",
      "2.9939055358\n",
      "2.54647028949\n",
      "2.63941086846\n",
      "2.93143727781\n",
      "2.97206703911\n",
      "3.06094464195\n",
      "3.22346368715\n",
      "2.93905535805\n",
      "3.12341289995\n",
      "2.39969527679\n",
      "2.32453021838\n",
      "3.03859827324\n",
      "2.76231589639\n",
      "2.66124936516\n",
      "2.64550533266\n",
      "2.96800406298\n",
      "2.75825292026\n",
      "2.5281868969\n",
      "2.60589131539\n",
      "2.92432706958\n",
      "2.97257491112\n",
      "2.59878110716\n",
      "2.71051295074\n",
      "2.7374301676\n",
      "3.09192483494\n",
      "2.88725241239\n",
      "3.50380904012\n",
      "3.09446419502\n",
      "3.2092432707\n",
      "2.43219908583\n",
      "2.34890807517\n",
      "3.05688166582\n",
      "2.80700863382\n",
      "2.84255967496\n",
      "2.86084306755\n",
      "2.92737430168\n",
      "2.84560690706\n",
      "2.55510411376\n",
      "2.64093448451\n",
      "2.8938547486\n",
      "3.13610970036\n",
      "2.63026917217\n",
      "2.81056373794\n",
      "2.83646521077\n",
      "3.1188420518\n",
      "3.19857795835\n",
      "3.59268664297\n"
     ]
    }
   ],
   "source": [
    "for history in history_list:\n",
    "    hist = history.history\n",
    "    max_val_fbeta = max(hist['val_coverage error'])\n",
    "    print max_val_fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_input = Input(shape=(DOC2VEC_SIZE,), name='doc_input')\n",
    "hidden = Dense(NN_HIDDEN_NEURONS, activation='relu', name='hidden_layer')(doc_input)\n",
    "softmax_output = Dense(NN_OUTPUT_NEURONS, activation='sigmoid', name='softmax_output')(hidden)\n",
    "model = Model(input=doc_input, output=softmax_output)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', 'fbeta_score', theano_coverage_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "doc_input (InputLayer)           (None, 3000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden_layer (Dense)             (None, 4500)          13504500    doc_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax_output (Dense)           (None, 8)             36008       hidden_layer[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 13540508\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8979 samples, validate on 1969 samples\n",
      "Epoch 1/1\n",
      "8979/8979 [==============================] - 4s - loss: 0.0427 - acc: 0.9835 - fbeta_score: 0.9504 - coverage error: 1.4936 - val_loss: 2.1309 - val_acc: 0.8531 - val_fbeta_score: 0.4738 - val_coverage error: 3.4474\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=training_data, y=training_labels, \n",
    "          validation_data=(validation_data, validation_labels), \n",
    "          nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_prediction = model.predict(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.70263344e-01,   3.49998474e-02,   3.13610617e-05,\n",
       "          1.08150870e-03,   3.11665332e-07,   7.09001958e-01,\n",
       "          4.97711152e-02,   2.63609409e-01],\n",
       "       [  1.70166213e-02,   5.36046147e-01,   2.61311390e-04,\n",
       "          4.87348643e-06,   1.27638310e-01,   9.57404263e-03,\n",
       "          3.39831635e-02,   2.13784515e-03]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = T.matrix('y_true')\n",
    "y_score = T.matrix('y_score')\n",
    "\n",
    "y_score_true = y_true * y_score # mark the scores of actually true labels\n",
    "zero_true_elem = T.eq(y_true, 0).nonzero()\n",
    "y_score_masked = T.set_subtensor(y_score_true[zero_true_elem], 100)\n",
    "#zero_elements = T.eq(true_scores,0)\n",
    "min_true_scores = T.min(y_score_masked, axis=1, keepdims=True) # we do keepdims in order to keep the broadcastable columns\n",
    "coverage_per_row = (y_score >= min_true_scores).sum(axis=1)\n",
    "coverage = T.mean(coverage_per_row)\n",
    "theano_coverage_err_func = function(inputs=[y_true, y_score], outputs=coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uu = np.array([[1,0,1],[0,0,1]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yc = T.set_subtensor(y_true[T.eq(y_true,0).nonzero()], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,  100.,    1.],\n",
       "       [ 100.,  100.,    1.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yc.eval({y_true: uu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T.set_subtensor(y_true[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1, 1]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.08178342e-08,   1.02713175e-05,   4.41441728e-28,\n",
       "          1.19779872e-36,   0.00000000e+00,   1.00000000e+00,\n",
       "          2.75591228e-05,   2.31643662e-06]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 8.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(2.5129507364144237)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "theano_coverage_err_func(validation_labels, val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.08178342e-08,   1.02713175e-05,   4.41441728e-28,\n",
       "          1.19779872e-36,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000028e+02,   1.00000002e+02]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(validation_labels[:1] , 100) + val_prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000231643662"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction[0,7] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-99.99999768])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.multiply(validation_labels[:1] , -100) + val_prediction[:1]).min(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 5.51 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5129507364144237"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "coverage_error(validation_labels, val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.43536258e-08,   2.79983366e-03,   1.15342544e-08,\n",
       "          7.79373941e-17,   5.66347130e-03,   9.99988794e-01,\n",
       "          6.53333089e-04,   5.85054120e-20],\n",
       "       [  2.85919495e-02,   4.81873751e-02,   1.16070651e-05,\n",
       "          2.11304723e-04,   9.95886266e-01,   7.23218254e-05,\n",
       "          2.44005350e-03,   9.50191250e-08],\n",
       "       [  1.57324195e-01,   4.55876261e-01,   1.18607618e-01,\n",
       "          1.59025192e-02,   5.29134236e-02,   3.10803294e-01,\n",
       "          7.60788023e-02,   4.09732945e-02],\n",
       "       [  8.80629957e-01,   8.06344330e-01,   8.66507888e-01,\n",
       "          8.60296586e-06,   8.48201476e-03,   3.66728357e-03,\n",
       "          4.01142472e-03,   6.63176891e-09],\n",
       "       [  3.67009136e-07,   2.43742179e-04,   4.91571154e-05,\n",
       "          3.91778943e-16,   2.10585220e-08,   9.19317733e-03,\n",
       "          2.35959844e-04,   9.99994278e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(training_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.07762730e-06,   4.37068702e-05,   8.50037267e-16,\n",
       "          3.26617112e-20,   5.99386426e-25,   9.99954700e-01,\n",
       "          4.03022398e-08,   5.06598099e-07],\n",
       "       [  7.84522370e-02,   7.51568982e-03,   3.02292941e-10,\n",
       "          1.27776785e-27,   8.58146071e-01,   5.19246235e-02,\n",
       "          3.96136660e-03,   9.01197339e-09],\n",
       "       [  8.13455582e-01,   3.37661535e-04,   1.86206713e-01,\n",
       "          2.93652289e-25,   1.42611062e-11,   8.11548398e-11,\n",
       "          1.56509191e-13,   3.87454735e-10],\n",
       "       [  9.48790824e-10,   4.76847440e-02,   2.83465356e-01,\n",
       "          2.84471139e-27,   8.79647612e-15,   5.65862817e-15,\n",
       "          4.19551939e-01,   2.49298021e-01],\n",
       "       [  1.14569569e-10,   1.01953819e-12,   1.14190914e-01,\n",
       "          4.46660243e-30,   3.54068044e-18,   8.85809124e-01,\n",
       "          1.19672533e-14,   2.22166152e-09]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(validation_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='529ae006-9318-4a66-885e-c1acfd8626d5'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-11-27 12:06:37,744 : INFO : ****************** Epoch 1 --- Working on doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1 *******************\n",
      "2016-11-27 12:06:37,755 : INFO : training model with 12 workers on 243681 vocabulary and 51000 features, using sg=0 hs=0 sample=1e-05 negative=10\n",
      "2016-11-27 12:06:37,756 : INFO : expecting 49789 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-11-27 12:07:05,285 : INFO : PROGRESS: at 0.00% examples, 40 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:08:05,390 : INFO : PROGRESS: at 0.18% examples, 1894 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:09:05,994 : INFO : PROGRESS: at 0.37% examples, 2579 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:10:06,043 : INFO : PROGRESS: at 0.61% examples, 2862 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:11:06,643 : INFO : PROGRESS: at 0.83% examples, 2995 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:12:07,595 : INFO : PROGRESS: at 1.07% examples, 3100 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:13:08,002 : INFO : PROGRESS: at 1.29% examples, 3203 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:14:09,096 : INFO : PROGRESS: at 1.50% examples, 3232 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:15:09,907 : INFO : PROGRESS: at 1.71% examples, 3282 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:16:09,978 : INFO : PROGRESS: at 1.90% examples, 3288 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:17:10,530 : INFO : PROGRESS: at 2.13% examples, 3349 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:18:14,161 : INFO : PROGRESS: at 2.34% examples, 3345 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:19:14,616 : INFO : PROGRESS: at 2.61% examples, 3389 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:20:15,627 : INFO : PROGRESS: at 2.84% examples, 3394 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:21:15,663 : INFO : PROGRESS: at 3.08% examples, 3417 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:22:15,936 : INFO : PROGRESS: at 3.30% examples, 3423 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:23:16,886 : INFO : PROGRESS: at 3.57% examples, 3448 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:24:17,161 : INFO : PROGRESS: at 3.80% examples, 3465 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:25:17,872 : INFO : PROGRESS: at 4.04% examples, 3477 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:26:19,350 : INFO : PROGRESS: at 4.23% examples, 3478 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:27:19,567 : INFO : PROGRESS: at 4.46% examples, 3486 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:28:19,671 : INFO : PROGRESS: at 4.66% examples, 3494 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:29:20,065 : INFO : PROGRESS: at 4.91% examples, 3506 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:30:20,207 : INFO : PROGRESS: at 5.13% examples, 3509 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:31:20,227 : INFO : PROGRESS: at 5.37% examples, 3519 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:32:21,132 : INFO : PROGRESS: at 5.60% examples, 3519 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:33:21,471 : INFO : PROGRESS: at 5.83% examples, 3531 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:34:22,513 : INFO : PROGRESS: at 6.10% examples, 3534 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 12:35:23,635 : INFO : PROGRESS: at 6.32% examples, 3539 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:36:23,744 : INFO : PROGRESS: at 6.57% examples, 3544 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:37:25,751 : INFO : PROGRESS: at 6.81% examples, 3540 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:38:25,994 : INFO : PROGRESS: at 7.05% examples, 3554 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:39:26,711 : INFO : PROGRESS: at 7.26% examples, 3550 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:40:27,694 : INFO : PROGRESS: at 7.49% examples, 3556 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:41:27,976 : INFO : PROGRESS: at 7.73% examples, 3560 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:42:27,996 : INFO : PROGRESS: at 7.97% examples, 3568 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:43:28,208 : INFO : PROGRESS: at 8.21% examples, 3572 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:44:28,550 : INFO : PROGRESS: at 8.44% examples, 3575 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:45:28,867 : INFO : PROGRESS: at 8.65% examples, 3578 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:46:29,758 : INFO : PROGRESS: at 8.88% examples, 3582 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:47:30,399 : INFO : PROGRESS: at 9.11% examples, 3584 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:48:32,137 : INFO : PROGRESS: at 9.34% examples, 3589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:49:32,723 : INFO : PROGRESS: at 9.58% examples, 3588 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:50:34,411 : INFO : PROGRESS: at 9.79% examples, 3587 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:51:36,420 : INFO : PROGRESS: at 9.99% examples, 3589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:52:37,124 : INFO : PROGRESS: at 10.19% examples, 3599 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:53:37,138 : INFO : PROGRESS: at 10.40% examples, 3602 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:54:37,311 : INFO : PROGRESS: at 10.63% examples, 3607 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:55:39,995 : INFO : PROGRESS: at 10.87% examples, 3607 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:56:40,373 : INFO : PROGRESS: at 11.09% examples, 3611 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:57:41,091 : INFO : PROGRESS: at 11.33% examples, 3614 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:58:41,147 : INFO : PROGRESS: at 11.55% examples, 3616 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 12:59:42,045 : INFO : PROGRESS: at 11.79% examples, 3618 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:00:42,422 : INFO : PROGRESS: at 12.05% examples, 3619 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:01:42,940 : INFO : PROGRESS: at 12.28% examples, 3620 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:02:43,099 : INFO : PROGRESS: at 12.51% examples, 3626 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:03:43,389 : INFO : PROGRESS: at 12.76% examples, 3626 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:04:43,883 : INFO : PROGRESS: at 13.00% examples, 3629 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:05:44,325 : INFO : PROGRESS: at 13.24% examples, 3631 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:06:44,716 : INFO : PROGRESS: at 13.49% examples, 3634 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:07:45,235 : INFO : PROGRESS: at 13.71% examples, 3639 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:08:45,909 : INFO : PROGRESS: at 13.94% examples, 3642 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:09:45,937 : INFO : PROGRESS: at 14.17% examples, 3642 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:10:46,236 : INFO : PROGRESS: at 14.41% examples, 3645 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:11:46,816 : INFO : PROGRESS: at 14.64% examples, 3652 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:12:47,090 : INFO : PROGRESS: at 14.86% examples, 3652 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:13:48,900 : INFO : PROGRESS: at 15.11% examples, 3654 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:14:49,108 : INFO : PROGRESS: at 15.35% examples, 3655 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:15:50,781 : INFO : PROGRESS: at 15.57% examples, 3658 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:16:51,094 : INFO : PROGRESS: at 15.79% examples, 3662 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:17:51,147 : INFO : PROGRESS: at 15.98% examples, 3664 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:18:52,657 : INFO : PROGRESS: at 16.17% examples, 3663 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:19:53,850 : INFO : PROGRESS: at 16.41% examples, 3670 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:20:54,106 : INFO : PROGRESS: at 16.65% examples, 3670 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:21:54,118 : INFO : PROGRESS: at 16.88% examples, 3673 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:22:54,360 : INFO : PROGRESS: at 17.12% examples, 3672 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:23:55,945 : INFO : PROGRESS: at 17.33% examples, 3680 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:24:55,966 : INFO : PROGRESS: at 17.57% examples, 3678 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:25:56,032 : INFO : PROGRESS: at 17.81% examples, 3684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:26:57,736 : INFO : PROGRESS: at 18.10% examples, 3683 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:27:58,649 : INFO : PROGRESS: at 18.37% examples, 3687 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:29:00,395 : INFO : PROGRESS: at 18.61% examples, 3686 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:30:00,548 : INFO : PROGRESS: at 18.84% examples, 3690 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:31:01,628 : INFO : PROGRESS: at 19.08% examples, 3692 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:32:02,692 : INFO : PROGRESS: at 19.34% examples, 3695 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:33:03,441 : INFO : PROGRESS: at 19.57% examples, 3696 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:34:03,603 : INFO : PROGRESS: at 19.81% examples, 3696 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:35:04,129 : INFO : PROGRESS: at 20.05% examples, 3698 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:36:04,342 : INFO : PROGRESS: at 20.30% examples, 3701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:37:04,515 : INFO : PROGRESS: at 20.55% examples, 3705 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:38:04,606 : INFO : PROGRESS: at 20.77% examples, 3705 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:39:07,558 : INFO : PROGRESS: at 21.01% examples, 3707 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:40:07,760 : INFO : PROGRESS: at 21.25% examples, 3709 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:41:08,162 : INFO : PROGRESS: at 21.51% examples, 3711 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:42:08,511 : INFO : PROGRESS: at 21.74% examples, 3715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:43:09,995 : INFO : PROGRESS: at 21.98% examples, 3715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:44:12,443 : INFO : PROGRESS: at 22.22% examples, 3716 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:45:12,783 : INFO : PROGRESS: at 22.50% examples, 3719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:46:12,856 : INFO : PROGRESS: at 22.72% examples, 3720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:47:12,912 : INFO : PROGRESS: at 22.92% examples, 3721 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:48:13,354 : INFO : PROGRESS: at 23.15% examples, 3724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:49:14,160 : INFO : PROGRESS: at 23.37% examples, 3726 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:50:14,577 : INFO : PROGRESS: at 23.61% examples, 3729 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:51:15,438 : INFO : PROGRESS: at 23.90% examples, 3729 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:52:15,861 : INFO : PROGRESS: at 24.15% examples, 3732 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:53:16,073 : INFO : PROGRESS: at 24.37% examples, 3733 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 13:54:16,314 : INFO : PROGRESS: at 24.61% examples, 3734 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:55:16,996 : INFO : PROGRESS: at 24.89% examples, 3735 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:56:17,309 : INFO : PROGRESS: at 25.11% examples, 3737 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:57:18,897 : INFO : PROGRESS: at 25.35% examples, 3738 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:58:19,271 : INFO : PROGRESS: at 25.59% examples, 3740 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 13:59:20,328 : INFO : PROGRESS: at 25.84% examples, 3742 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:00:20,444 : INFO : PROGRESS: at 26.08% examples, 3742 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:01:21,553 : INFO : PROGRESS: at 26.33% examples, 3743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:02:21,901 : INFO : PROGRESS: at 26.55% examples, 3749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:03:22,303 : INFO : PROGRESS: at 26.79% examples, 3749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:04:22,445 : INFO : PROGRESS: at 27.06% examples, 3750 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:05:22,795 : INFO : PROGRESS: at 27.31% examples, 3750 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:06:23,435 : INFO : PROGRESS: at 27.56% examples, 3752 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:07:23,547 : INFO : PROGRESS: at 27.80% examples, 3752 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:08:23,668 : INFO : PROGRESS: at 28.07% examples, 3754 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:09:24,668 : INFO : PROGRESS: at 28.32% examples, 3754 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:10:25,781 : INFO : PROGRESS: at 28.54% examples, 3756 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:11:26,837 : INFO : PROGRESS: at 28.78% examples, 3758 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:12:28,205 : INFO : PROGRESS: at 28.99% examples, 3759 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:13:29,199 : INFO : PROGRESS: at 29.25% examples, 3760 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:14:30,036 : INFO : PROGRESS: at 29.49% examples, 3761 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:15:31,272 : INFO : PROGRESS: at 29.71% examples, 3762 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:16:32,173 : INFO : PROGRESS: at 29.92% examples, 3764 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:17:32,589 : INFO : PROGRESS: at 30.16% examples, 3761 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:18:32,648 : INFO : PROGRESS: at 30.44% examples, 3766 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:19:33,214 : INFO : PROGRESS: at 30.66% examples, 3765 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:20:33,301 : INFO : PROGRESS: at 30.88% examples, 3766 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:21:33,306 : INFO : PROGRESS: at 31.12% examples, 3769 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:22:33,772 : INFO : PROGRESS: at 31.36% examples, 3769 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:23:33,884 : INFO : PROGRESS: at 31.60% examples, 3771 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:24:33,907 : INFO : PROGRESS: at 31.83% examples, 3772 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:25:34,438 : INFO : PROGRESS: at 32.08% examples, 3770 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:26:35,310 : INFO : PROGRESS: at 32.30% examples, 3771 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 14:27:36,287 : INFO : PROGRESS: at 32.55% examples, 3776 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:28:36,659 : INFO : PROGRESS: at 32.81% examples, 3776 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:29:38,235 : INFO : PROGRESS: at 33.05% examples, 3778 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:30:39,040 : INFO : PROGRESS: at 33.29% examples, 3777 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:31:39,149 : INFO : PROGRESS: at 33.53% examples, 3778 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:32:39,746 : INFO : PROGRESS: at 33.73% examples, 3780 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:33:40,393 : INFO : PROGRESS: at 33.97% examples, 3781 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:34:41,110 : INFO : PROGRESS: at 34.20% examples, 3782 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:35:41,428 : INFO : PROGRESS: at 34.46% examples, 3784 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:36:41,802 : INFO : PROGRESS: at 34.72% examples, 3785 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:37:41,945 : INFO : PROGRESS: at 34.97% examples, 3787 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:38:42,424 : INFO : PROGRESS: at 35.21% examples, 3788 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:39:42,632 : INFO : PROGRESS: at 35.44% examples, 3789 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:40:42,650 : INFO : PROGRESS: at 35.67% examples, 3788 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:41:42,729 : INFO : PROGRESS: at 35.90% examples, 3792 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:42:43,062 : INFO : PROGRESS: at 36.11% examples, 3792 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:43:44,539 : INFO : PROGRESS: at 36.36% examples, 3793 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:44:45,034 : INFO : PROGRESS: at 36.61% examples, 3795 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:45:45,860 : INFO : PROGRESS: at 36.85% examples, 3794 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:46:46,532 : INFO : PROGRESS: at 37.07% examples, 3795 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:47:47,010 : INFO : PROGRESS: at 37.32% examples, 3798 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:48:47,158 : INFO : PROGRESS: at 37.57% examples, 3799 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:49:47,192 : INFO : PROGRESS: at 37.81% examples, 3798 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:50:47,381 : INFO : PROGRESS: at 38.04% examples, 3799 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:51:47,770 : INFO : PROGRESS: at 38.25% examples, 3802 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:52:48,094 : INFO : PROGRESS: at 38.48% examples, 3803 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:53:48,834 : INFO : PROGRESS: at 38.73% examples, 3803 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:54:49,413 : INFO : PROGRESS: at 38.96% examples, 3804 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:55:49,470 : INFO : PROGRESS: at 39.22% examples, 3805 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:56:49,600 : INFO : PROGRESS: at 39.44% examples, 3806 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:57:50,476 : INFO : PROGRESS: at 39.71% examples, 3807 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:58:50,657 : INFO : PROGRESS: at 39.94% examples, 3807 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 14:59:51,537 : INFO : PROGRESS: at 40.19% examples, 3809 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:00:52,562 : INFO : PROGRESS: at 40.42% examples, 3808 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:01:53,476 : INFO : PROGRESS: at 40.64% examples, 3810 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:02:55,361 : INFO : PROGRESS: at 40.90% examples, 3809 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:03:55,573 : INFO : PROGRESS: at 41.15% examples, 3811 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:04:56,214 : INFO : PROGRESS: at 41.39% examples, 3811 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:05:57,202 : INFO : PROGRESS: at 41.65% examples, 3813 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:06:58,459 : INFO : PROGRESS: at 41.89% examples, 3812 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:07:59,897 : INFO : PROGRESS: at 42.13% examples, 3812 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:09:00,216 : INFO : PROGRESS: at 42.38% examples, 3815 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:10:01,291 : INFO : PROGRESS: at 42.60% examples, 3814 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:11:01,798 : INFO : PROGRESS: at 42.84% examples, 3816 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:12:02,237 : INFO : PROGRESS: at 43.10% examples, 3815 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:13:02,729 : INFO : PROGRESS: at 43.38% examples, 3817 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:14:02,965 : INFO : PROGRESS: at 43.61% examples, 3817 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:15:03,094 : INFO : PROGRESS: at 43.81% examples, 3818 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:16:04,555 : INFO : PROGRESS: at 44.07% examples, 3819 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:17:05,176 : INFO : PROGRESS: at 44.31% examples, 3820 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:18:05,499 : INFO : PROGRESS: at 44.57% examples, 3820 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:19:05,809 : INFO : PROGRESS: at 44.80% examples, 3822 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:20:06,080 : INFO : PROGRESS: at 45.02% examples, 3822 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:21:07,820 : INFO : PROGRESS: at 45.25% examples, 3822 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:22:08,802 : INFO : PROGRESS: at 45.46% examples, 3823 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:23:09,905 : INFO : PROGRESS: at 45.72% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:24:11,410 : INFO : PROGRESS: at 45.93% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:25:12,732 : INFO : PROGRESS: at 46.17% examples, 3826 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:26:13,796 : INFO : PROGRESS: at 46.41% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:27:14,710 : INFO : PROGRESS: at 46.65% examples, 3825 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:28:15,152 : INFO : PROGRESS: at 46.89% examples, 3826 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:29:15,300 : INFO : PROGRESS: at 47.15% examples, 3827 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:30:15,568 : INFO : PROGRESS: at 47.39% examples, 3827 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:31:15,937 : INFO : PROGRESS: at 47.61% examples, 3828 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:32:15,997 : INFO : PROGRESS: at 47.84% examples, 3829 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 15:33:16,769 : INFO : PROGRESS: at 48.08% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:34:17,608 : INFO : PROGRESS: at 48.32% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:35:17,871 : INFO : PROGRESS: at 48.52% examples, 3832 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:36:18,551 : INFO : PROGRESS: at 48.78% examples, 3833 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:37:19,257 : INFO : PROGRESS: at 49.06% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:38:19,846 : INFO : PROGRESS: at 49.31% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:39:19,872 : INFO : PROGRESS: at 49.56% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:40:20,518 : INFO : PROGRESS: at 49.81% examples, 3835 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:41:21,740 : INFO : PROGRESS: at 50.05% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:42:21,806 : INFO : PROGRESS: at 50.27% examples, 3835 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:43:21,861 : INFO : PROGRESS: at 50.51% examples, 3836 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:44:21,950 : INFO : PROGRESS: at 50.75% examples, 3837 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:45:22,252 : INFO : PROGRESS: at 51.00% examples, 3838 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:46:22,377 : INFO : PROGRESS: at 51.22% examples, 3839 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:47:22,727 : INFO : PROGRESS: at 51.46% examples, 3840 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:48:22,741 : INFO : PROGRESS: at 51.67% examples, 3841 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:49:23,232 : INFO : PROGRESS: at 51.91% examples, 3840 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 15:50:23,718 : INFO : PROGRESS: at 52.15% examples, 3841 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:51:23,847 : INFO : PROGRESS: at 52.40% examples, 3840 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:52:24,316 : INFO : PROGRESS: at 52.68% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:53:24,843 : INFO : PROGRESS: at 52.90% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:54:25,804 : INFO : PROGRESS: at 53.14% examples, 3843 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:55:26,238 : INFO : PROGRESS: at 53.34% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:56:26,612 : INFO : PROGRESS: at 53.61% examples, 3843 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:57:26,654 : INFO : PROGRESS: at 53.85% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:58:27,203 : INFO : PROGRESS: at 54.10% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 15:59:27,465 : INFO : PROGRESS: at 54.34% examples, 3845 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:00:27,535 : INFO : PROGRESS: at 54.58% examples, 3846 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:01:27,717 : INFO : PROGRESS: at 54.80% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:02:28,146 : INFO : PROGRESS: at 55.04% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:03:28,536 : INFO : PROGRESS: at 55.28% examples, 3847 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:04:28,978 : INFO : PROGRESS: at 55.56% examples, 3847 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:05:29,040 : INFO : PROGRESS: at 55.77% examples, 3848 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:06:29,192 : INFO : PROGRESS: at 56.01% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:07:29,843 : INFO : PROGRESS: at 56.24% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:08:30,027 : INFO : PROGRESS: at 56.50% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:09:30,213 : INFO : PROGRESS: at 56.75% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:10:31,597 : INFO : PROGRESS: at 57.01% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:11:31,816 : INFO : PROGRESS: at 57.29% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:12:31,941 : INFO : PROGRESS: at 57.55% examples, 3851 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:13:32,174 : INFO : PROGRESS: at 57.77% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:14:32,200 : INFO : PROGRESS: at 58.00% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:15:32,302 : INFO : PROGRESS: at 58.22% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:16:32,923 : INFO : PROGRESS: at 58.46% examples, 3852 words/s, in_qsize 20, out_qsize 0\n",
      "2016-11-27 16:17:33,586 : INFO : PROGRESS: at 58.71% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:18:34,611 : INFO : PROGRESS: at 58.97% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:19:35,200 : INFO : PROGRESS: at 59.21% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:20:35,371 : INFO : PROGRESS: at 59.41% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:21:35,707 : INFO : PROGRESS: at 59.66% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:22:35,715 : INFO : PROGRESS: at 59.93% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:23:35,949 : INFO : PROGRESS: at 60.15% examples, 3853 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:24:36,451 : INFO : PROGRESS: at 60.38% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:25:36,661 : INFO : PROGRESS: at 60.65% examples, 3853 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:26:37,261 : INFO : PROGRESS: at 60.87% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:27:37,316 : INFO : PROGRESS: at 61.10% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:28:37,458 : INFO : PROGRESS: at 61.36% examples, 3855 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:29:38,067 : INFO : PROGRESS: at 61.60% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:30:39,788 : INFO : PROGRESS: at 61.86% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:31:41,442 : INFO : PROGRESS: at 62.08% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:32:41,788 : INFO : PROGRESS: at 62.29% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:33:41,878 : INFO : PROGRESS: at 62.53% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:34:42,541 : INFO : PROGRESS: at 62.78% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:35:42,541 : INFO : PROGRESS: at 63.02% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:36:43,306 : INFO : PROGRESS: at 63.27% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:37:43,331 : INFO : PROGRESS: at 63.50% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:38:43,466 : INFO : PROGRESS: at 63.73% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:39:44,227 : INFO : PROGRESS: at 63.95% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:40:44,430 : INFO : PROGRESS: at 64.18% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:41:47,124 : INFO : PROGRESS: at 64.43% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:42:47,589 : INFO : PROGRESS: at 64.67% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:43:47,628 : INFO : PROGRESS: at 64.94% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:44:47,669 : INFO : PROGRESS: at 65.17% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:45:47,680 : INFO : PROGRESS: at 65.41% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:46:47,687 : INFO : PROGRESS: at 65.62% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:47:49,221 : INFO : PROGRESS: at 65.85% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:48:49,277 : INFO : PROGRESS: at 66.08% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:49:50,278 : INFO : PROGRESS: at 66.34% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:50:51,221 : INFO : PROGRESS: at 66.58% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:51:52,038 : INFO : PROGRESS: at 66.81% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:52:52,907 : INFO : PROGRESS: at 67.06% examples, 3858 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:53:53,344 : INFO : PROGRESS: at 67.31% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:54:54,263 : INFO : PROGRESS: at 67.55% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:55:54,376 : INFO : PROGRESS: at 67.80% examples, 3858 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 16:56:55,078 : INFO : PROGRESS: at 68.01% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:57:55,290 : INFO : PROGRESS: at 68.25% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:58:55,506 : INFO : PROGRESS: at 68.50% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 16:59:55,739 : INFO : PROGRESS: at 68.73% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:00:56,353 : INFO : PROGRESS: at 68.97% examples, 3859 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:01:57,413 : INFO : PROGRESS: at 69.21% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:02:59,446 : INFO : PROGRESS: at 69.45% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:04:00,869 : INFO : PROGRESS: at 69.68% examples, 3859 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:05:01,259 : INFO : PROGRESS: at 69.93% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:06:03,301 : INFO : PROGRESS: at 70.18% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:07:05,741 : INFO : PROGRESS: at 70.43% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:08:06,579 : INFO : PROGRESS: at 70.70% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:09:07,149 : INFO : PROGRESS: at 70.96% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:10:07,340 : INFO : PROGRESS: at 71.19% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:11:08,053 : INFO : PROGRESS: at 71.44% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:12:08,346 : INFO : PROGRESS: at 71.65% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:13:08,403 : INFO : PROGRESS: at 71.88% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:14:08,715 : INFO : PROGRESS: at 72.11% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:15:09,343 : INFO : PROGRESS: at 72.35% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:16:09,701 : INFO : PROGRESS: at 72.58% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:17:09,770 : INFO : PROGRESS: at 72.83% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:18:09,948 : INFO : PROGRESS: at 73.07% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:19:10,260 : INFO : PROGRESS: at 73.27% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:20:10,457 : INFO : PROGRESS: at 73.51% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:21:12,006 : INFO : PROGRESS: at 73.75% examples, 3857 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:22:12,423 : INFO : PROGRESS: at 74.02% examples, 3858 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:23:12,864 : INFO : PROGRESS: at 74.28% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:24:13,619 : INFO : PROGRESS: at 74.50% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:25:13,633 : INFO : PROGRESS: at 74.74% examples, 3856 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:26:13,792 : INFO : PROGRESS: at 74.93% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:27:15,185 : INFO : PROGRESS: at 75.16% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:28:16,374 : INFO : PROGRESS: at 75.38% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:29:17,040 : INFO : PROGRESS: at 75.61% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:30:18,028 : INFO : PROGRESS: at 75.83% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:31:18,620 : INFO : PROGRESS: at 76.07% examples, 3857 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:32:19,137 : INFO : PROGRESS: at 76.31% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:33:19,177 : INFO : PROGRESS: at 76.56% examples, 3857 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:34:20,893 : INFO : PROGRESS: at 76.81% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:35:21,113 : INFO : PROGRESS: at 77.04% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:36:21,423 : INFO : PROGRESS: at 77.29% examples, 3856 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 17:37:23,028 : INFO : PROGRESS: at 77.53% examples, 3856 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:38:23,085 : INFO : PROGRESS: at 77.76% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:39:23,474 : INFO : PROGRESS: at 78.02% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:40:24,945 : INFO : PROGRESS: at 78.22% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:41:25,386 : INFO : PROGRESS: at 78.47% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:42:25,656 : INFO : PROGRESS: at 78.72% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:43:25,679 : INFO : PROGRESS: at 78.97% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:44:25,724 : INFO : PROGRESS: at 79.17% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:45:26,503 : INFO : PROGRESS: at 79.39% examples, 3856 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:46:26,751 : INFO : PROGRESS: at 79.63% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:47:27,402 : INFO : PROGRESS: at 79.87% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:48:27,790 : INFO : PROGRESS: at 80.12% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:49:27,908 : INFO : PROGRESS: at 80.33% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:50:30,324 : INFO : PROGRESS: at 80.54% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:51:30,580 : INFO : PROGRESS: at 80.80% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:52:30,974 : INFO : PROGRESS: at 80.99% examples, 3855 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:53:31,603 : INFO : PROGRESS: at 81.21% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:54:31,727 : INFO : PROGRESS: at 81.46% examples, 3855 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 17:55:31,852 : INFO : PROGRESS: at 81.68% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:56:33,918 : INFO : PROGRESS: at 81.94% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:57:35,239 : INFO : PROGRESS: at 82.18% examples, 3855 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:58:35,671 : INFO : PROGRESS: at 82.41% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 17:59:36,050 : INFO : PROGRESS: at 82.65% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:00:36,300 : INFO : PROGRESS: at 82.89% examples, 3854 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:01:38,453 : INFO : PROGRESS: at 83.13% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:02:39,104 : INFO : PROGRESS: at 83.38% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:03:39,910 : INFO : PROGRESS: at 83.59% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:04:41,486 : INFO : PROGRESS: at 83.82% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:05:41,765 : INFO : PROGRESS: at 84.03% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:06:42,376 : INFO : PROGRESS: at 84.29% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:07:42,776 : INFO : PROGRESS: at 84.52% examples, 3853 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:08:42,903 : INFO : PROGRESS: at 84.79% examples, 3853 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:09:44,183 : INFO : PROGRESS: at 85.01% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:10:44,538 : INFO : PROGRESS: at 85.25% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:11:45,248 : INFO : PROGRESS: at 85.51% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:12:45,373 : INFO : PROGRESS: at 85.74% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:13:46,019 : INFO : PROGRESS: at 85.96% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:14:46,761 : INFO : PROGRESS: at 86.20% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:15:46,898 : INFO : PROGRESS: at 86.42% examples, 3852 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:16:46,987 : INFO : PROGRESS: at 86.65% examples, 3851 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:17:47,811 : INFO : PROGRESS: at 86.86% examples, 3851 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:18:47,842 : INFO : PROGRESS: at 87.10% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:19:47,897 : INFO : PROGRESS: at 87.33% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:20:48,647 : INFO : PROGRESS: at 87.56% examples, 3851 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:21:48,829 : INFO : PROGRESS: at 87.80% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:22:48,845 : INFO : PROGRESS: at 88.03% examples, 3850 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 18:23:50,486 : INFO : PROGRESS: at 88.25% examples, 3850 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:24:50,848 : INFO : PROGRESS: at 88.46% examples, 3850 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:25:50,931 : INFO : PROGRESS: at 88.69% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:26:51,107 : INFO : PROGRESS: at 88.91% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:27:51,168 : INFO : PROGRESS: at 89.13% examples, 3849 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:28:51,448 : INFO : PROGRESS: at 89.38% examples, 3848 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:29:51,753 : INFO : PROGRESS: at 89.58% examples, 3848 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:30:52,853 : INFO : PROGRESS: at 89.83% examples, 3847 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:31:52,974 : INFO : PROGRESS: at 90.07% examples, 3847 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:32:54,092 : INFO : PROGRESS: at 90.28% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:33:54,281 : INFO : PROGRESS: at 90.51% examples, 3846 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:34:55,199 : INFO : PROGRESS: at 90.72% examples, 3846 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:35:56,721 : INFO : PROGRESS: at 90.91% examples, 3845 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:36:57,442 : INFO : PROGRESS: at 91.12% examples, 3845 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:37:59,098 : INFO : PROGRESS: at 91.34% examples, 3845 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:38:59,783 : INFO : PROGRESS: at 91.56% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:39:59,822 : INFO : PROGRESS: at 91.80% examples, 3844 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:40:59,917 : INFO : PROGRESS: at 92.01% examples, 3844 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:42:01,200 : INFO : PROGRESS: at 92.23% examples, 3843 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:43:02,262 : INFO : PROGRESS: at 92.44% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:44:02,292 : INFO : PROGRESS: at 92.64% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:45:02,311 : INFO : PROGRESS: at 92.91% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:46:02,583 : INFO : PROGRESS: at 93.14% examples, 3842 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:47:02,596 : INFO : PROGRESS: at 93.39% examples, 3841 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:48:03,333 : INFO : PROGRESS: at 93.61% examples, 3841 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:49:03,370 : INFO : PROGRESS: at 93.86% examples, 3840 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:50:05,308 : INFO : PROGRESS: at 94.11% examples, 3840 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:51:05,472 : INFO : PROGRESS: at 94.34% examples, 3839 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:52:05,722 : INFO : PROGRESS: at 94.57% examples, 3839 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:53:05,875 : INFO : PROGRESS: at 94.77% examples, 3839 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:54:06,951 : INFO : PROGRESS: at 94.99% examples, 3838 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:55:07,928 : INFO : PROGRESS: at 95.22% examples, 3838 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:56:08,759 : INFO : PROGRESS: at 95.41% examples, 3837 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 18:57:08,926 : INFO : PROGRESS: at 95.64% examples, 3837 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:58:09,117 : INFO : PROGRESS: at 95.84% examples, 3836 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 18:59:10,087 : INFO : PROGRESS: at 96.07% examples, 3836 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:00:10,102 : INFO : PROGRESS: at 96.29% examples, 3835 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:01:10,634 : INFO : PROGRESS: at 96.48% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:02:11,459 : INFO : PROGRESS: at 96.72% examples, 3835 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:03:11,719 : INFO : PROGRESS: at 96.94% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:04:11,985 : INFO : PROGRESS: at 97.17% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:05:12,982 : INFO : PROGRESS: at 97.39% examples, 3834 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:06:13,099 : INFO : PROGRESS: at 97.66% examples, 3833 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:07:13,105 : INFO : PROGRESS: at 97.86% examples, 3832 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:08:13,454 : INFO : PROGRESS: at 98.11% examples, 3832 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:09:13,568 : INFO : PROGRESS: at 98.32% examples, 3832 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:10:13,978 : INFO : PROGRESS: at 98.53% examples, 3831 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:11:14,467 : INFO : PROGRESS: at 98.75% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:12:14,471 : INFO : PROGRESS: at 98.99% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:13:15,543 : INFO : PROGRESS: at 99.21% examples, 3830 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:14:15,651 : INFO : PROGRESS: at 99.42% examples, 3829 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:15:15,673 : INFO : PROGRESS: at 99.66% examples, 3829 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:16:16,457 : INFO : PROGRESS: at 99.87% examples, 3828 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:16:44,065 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2016-11-27 19:16:44,870 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2016-11-27 19:16:45,467 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2016-11-27 19:16:46,775 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2016-11-27 19:16:46,851 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2016-11-27 19:16:46,951 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2016-11-27 19:16:47,279 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2016-11-27 19:16:47,761 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2016-11-27 19:16:48,298 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-11-27 19:16:48,667 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-11-27 19:16:48,896 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-11-27 19:16:49,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-11-27 19:16:49,651 : INFO : training on 390507860 raw words (98830815 effective words) took 25811.9s, 3829 effective words/s\n",
      "2016-11-27 19:16:49,652 : INFO : saving Doc2Vec object under /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model, separately None\n",
      "2016-11-27 19:16:49,654 : INFO : storing numpy array 'doctag_syn0' to /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model.docvecs.doctag_syn0.npy\n",
      "2016-11-27 19:16:50,043 : INFO : storing numpy array 'syn1neg' to /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model.syn1neg.npy\n",
      "2016-11-27 19:18:13,911 : INFO : not storing attribute syn0norm\n",
      "2016-11-27 19:18:13,912 : INFO : storing numpy array 'syn0' to /mnt/data2/shalaby/parameter_search_doc2vec_models/sample_0.01/doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_1/model.syn0.npy\n",
      "2016-11-27 19:18:19,424 : INFO : not storing attribute cum_table\n",
      "2016-11-27 19:18:27,517 : INFO : ****************** Epoch 2 --- Working on doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_2 *******************\n",
      "2016-11-27 19:18:27,526 : INFO : training model with 12 workers on 243681 vocabulary and 51000 features, using sg=0 hs=0 sample=1e-05 negative=10\n",
      "2016-11-27 19:18:27,527 : INFO : expecting 49789 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-11-27 19:18:30,758 : INFO : PROGRESS: at 0.00% examples, 670 words/s, in_qsize 2, out_qsize 0\n",
      "2016-11-27 19:19:31,559 : INFO : PROGRESS: at 0.27% examples, 3909 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:20:31,739 : INFO : PROGRESS: at 0.52% examples, 4063 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:21:31,795 : INFO : PROGRESS: at 0.78% examples, 4211 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:22:32,265 : INFO : PROGRESS: at 1.05% examples, 4206 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:23:32,379 : INFO : PROGRESS: at 1.30% examples, 4237 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:24:32,547 : INFO : PROGRESS: at 1.55% examples, 4284 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:25:32,624 : INFO : PROGRESS: at 1.85% examples, 4297 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:26:33,040 : INFO : PROGRESS: at 2.11% examples, 4291 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:27:34,585 : INFO : PROGRESS: at 2.40% examples, 4330 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:28:34,900 : INFO : PROGRESS: at 2.66% examples, 4342 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:29:35,379 : INFO : PROGRESS: at 2.93% examples, 4355 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:30:35,647 : INFO : PROGRESS: at 3.19% examples, 4338 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:31:36,400 : INFO : PROGRESS: at 3.44% examples, 4364 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:32:36,517 : INFO : PROGRESS: at 3.75% examples, 4390 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:33:36,765 : INFO : PROGRESS: at 4.07% examples, 4401 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:34:36,920 : INFO : PROGRESS: at 4.37% examples, 4399 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:35:37,033 : INFO : PROGRESS: at 4.65% examples, 4414 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:36:37,544 : INFO : PROGRESS: at 4.92% examples, 4413 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:37:39,340 : INFO : PROGRESS: at 5.21% examples, 4442 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:38:39,396 : INFO : PROGRESS: at 5.46% examples, 4445 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:39:39,440 : INFO : PROGRESS: at 5.77% examples, 4469 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:40:39,934 : INFO : PROGRESS: at 6.07% examples, 4472 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:41:40,065 : INFO : PROGRESS: at 6.35% examples, 4486 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:42:41,252 : INFO : PROGRESS: at 6.66% examples, 4485 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:43:41,969 : INFO : PROGRESS: at 6.94% examples, 4499 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:44:42,204 : INFO : PROGRESS: at 7.20% examples, 4513 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:45:42,909 : INFO : PROGRESS: at 7.46% examples, 4518 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:46:43,340 : INFO : PROGRESS: at 7.77% examples, 4527 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:47:45,937 : INFO : PROGRESS: at 8.04% examples, 4530 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:48:46,229 : INFO : PROGRESS: at 8.30% examples, 4538 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:49:46,284 : INFO : PROGRESS: at 8.57% examples, 4551 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:50:48,122 : INFO : PROGRESS: at 8.90% examples, 4554 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:51:48,272 : INFO : PROGRESS: at 9.19% examples, 4562 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:52:48,459 : INFO : PROGRESS: at 9.47% examples, 4566 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:53:48,875 : INFO : PROGRESS: at 9.78% examples, 4583 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:54:49,025 : INFO : PROGRESS: at 10.06% examples, 4589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:55:49,470 : INFO : PROGRESS: at 10.35% examples, 4593 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 19:56:50,296 : INFO : PROGRESS: at 10.65% examples, 4601 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:57:51,032 : INFO : PROGRESS: at 10.94% examples, 4605 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:58:51,285 : INFO : PROGRESS: at 11.25% examples, 4614 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 19:59:51,754 : INFO : PROGRESS: at 11.56% examples, 4620 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:00:51,874 : INFO : PROGRESS: at 11.86% examples, 4631 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:01:52,014 : INFO : PROGRESS: at 12.18% examples, 4640 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:02:52,564 : INFO : PROGRESS: at 12.47% examples, 4639 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:03:52,904 : INFO : PROGRESS: at 12.79% examples, 4650 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:04:53,246 : INFO : PROGRESS: at 13.10% examples, 4654 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:05:53,455 : INFO : PROGRESS: at 13.39% examples, 4664 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:06:53,934 : INFO : PROGRESS: at 13.68% examples, 4666 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:07:54,607 : INFO : PROGRESS: at 13.96% examples, 4673 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:08:55,063 : INFO : PROGRESS: at 14.27% examples, 4675 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:09:55,757 : INFO : PROGRESS: at 14.58% examples, 4684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:10:57,225 : INFO : PROGRESS: at 14.87% examples, 4684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:11:57,498 : INFO : PROGRESS: at 15.20% examples, 4693 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:12:57,937 : INFO : PROGRESS: at 15.53% examples, 4699 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:13:58,220 : INFO : PROGRESS: at 15.84% examples, 4705 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:14:58,854 : INFO : PROGRESS: at 16.15% examples, 4711 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:15:59,174 : INFO : PROGRESS: at 16.45% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:16:59,188 : INFO : PROGRESS: at 16.78% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:17:59,987 : INFO : PROGRESS: at 17.08% examples, 4730 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:19:00,127 : INFO : PROGRESS: at 17.36% examples, 4733 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:20:00,206 : INFO : PROGRESS: at 17.66% examples, 4743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:21:00,225 : INFO : PROGRESS: at 18.00% examples, 4744 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:22:00,645 : INFO : PROGRESS: at 18.26% examples, 4748 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:23:01,336 : INFO : PROGRESS: at 18.58% examples, 4757 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:24:01,439 : INFO : PROGRESS: at 18.89% examples, 4763 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:25:01,622 : INFO : PROGRESS: at 19.21% examples, 4769 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:26:02,045 : INFO : PROGRESS: at 19.52% examples, 4775 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:27:02,147 : INFO : PROGRESS: at 19.89% examples, 4779 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:28:02,507 : INFO : PROGRESS: at 20.20% examples, 4785 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:29:04,324 : INFO : PROGRESS: at 20.53% examples, 4786 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:30:05,600 : INFO : PROGRESS: at 20.83% examples, 4794 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:31:06,919 : INFO : PROGRESS: at 21.10% examples, 4794 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:32:06,982 : INFO : PROGRESS: at 21.39% examples, 4792 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:33:07,113 : INFO : PROGRESS: at 21.66% examples, 4789 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:34:08,404 : INFO : PROGRESS: at 21.95% examples, 4784 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:35:09,226 : INFO : PROGRESS: at 22.24% examples, 4780 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:36:09,463 : INFO : PROGRESS: at 22.52% examples, 4779 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:37:09,529 : INFO : PROGRESS: at 22.81% examples, 4776 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:38:10,189 : INFO : PROGRESS: at 23.08% examples, 4772 words/s, in_qsize 18, out_qsize 0\n",
      "2016-11-27 20:39:10,764 : INFO : PROGRESS: at 23.33% examples, 4771 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:40:11,025 : INFO : PROGRESS: at 23.64% examples, 4770 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:41:11,805 : INFO : PROGRESS: at 23.90% examples, 4767 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:42:11,900 : INFO : PROGRESS: at 24.17% examples, 4761 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:43:11,985 : INFO : PROGRESS: at 24.46% examples, 4758 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:44:12,403 : INFO : PROGRESS: at 24.77% examples, 4757 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:45:12,859 : INFO : PROGRESS: at 25.06% examples, 4752 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:46:14,003 : INFO : PROGRESS: at 25.34% examples, 4750 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:47:14,018 : INFO : PROGRESS: at 25.63% examples, 4751 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:48:14,653 : INFO : PROGRESS: at 25.95% examples, 4749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:49:14,977 : INFO : PROGRESS: at 26.22% examples, 4750 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:50:14,993 : INFO : PROGRESS: at 26.50% examples, 4749 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:51:15,068 : INFO : PROGRESS: at 26.78% examples, 4747 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:52:16,106 : INFO : PROGRESS: at 27.06% examples, 4743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:53:16,485 : INFO : PROGRESS: at 27.35% examples, 4743 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:54:17,102 : INFO : PROGRESS: at 27.65% examples, 4741 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:55:17,623 : INFO : PROGRESS: at 27.92% examples, 4740 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:56:17,686 : INFO : PROGRESS: at 28.18% examples, 4739 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 20:57:18,534 : INFO : PROGRESS: at 28.47% examples, 4736 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 20:58:18,743 : INFO : PROGRESS: at 28.74% examples, 4735 words/s, in_qsize 22, out_qsize 0\n",
      "2016-11-27 20:59:19,727 : INFO : PROGRESS: at 29.02% examples, 4733 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:00:20,022 : INFO : PROGRESS: at 29.28% examples, 4731 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:01:20,325 : INFO : PROGRESS: at 29.59% examples, 4730 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:02:20,680 : INFO : PROGRESS: at 29.91% examples, 4729 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:03:21,121 : INFO : PROGRESS: at 30.17% examples, 4728 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:04:21,494 : INFO : PROGRESS: at 30.47% examples, 4727 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:05:21,973 : INFO : PROGRESS: at 30.73% examples, 4727 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:06:22,037 : INFO : PROGRESS: at 31.00% examples, 4727 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:07:22,133 : INFO : PROGRESS: at 31.29% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:08:22,518 : INFO : PROGRESS: at 31.60% examples, 4727 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:09:22,534 : INFO : PROGRESS: at 31.88% examples, 4726 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:10:23,429 : INFO : PROGRESS: at 32.13% examples, 4726 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:11:23,597 : INFO : PROGRESS: at 32.38% examples, 4727 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:12:23,773 : INFO : PROGRESS: at 32.66% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:13:23,783 : INFO : PROGRESS: at 32.96% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:14:23,802 : INFO : PROGRESS: at 33.24% examples, 4724 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:15:24,876 : INFO : PROGRESS: at 33.52% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:16:25,391 : INFO : PROGRESS: at 33.83% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:17:25,601 : INFO : PROGRESS: at 34.10% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:18:25,870 : INFO : PROGRESS: at 34.38% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:19:26,112 : INFO : PROGRESS: at 34.70% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:20:27,197 : INFO : PROGRESS: at 35.01% examples, 4725 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:21:27,908 : INFO : PROGRESS: at 35.31% examples, 4725 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:22:28,027 : INFO : PROGRESS: at 35.60% examples, 4723 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:23:29,967 : INFO : PROGRESS: at 35.90% examples, 4723 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:24:30,506 : INFO : PROGRESS: at 36.18% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:25:30,658 : INFO : PROGRESS: at 36.47% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:26:30,912 : INFO : PROGRESS: at 36.77% examples, 4724 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:27:31,019 : INFO : PROGRESS: at 37.06% examples, 4723 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:28:31,104 : INFO : PROGRESS: at 37.34% examples, 4722 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:29:31,580 : INFO : PROGRESS: at 37.62% examples, 4722 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:30:32,006 : INFO : PROGRESS: at 37.91% examples, 4721 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:31:33,500 : INFO : PROGRESS: at 38.24% examples, 4721 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:32:34,504 : INFO : PROGRESS: at 38.50% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:33:34,538 : INFO : PROGRESS: at 38.80% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:34:34,665 : INFO : PROGRESS: at 39.10% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:35:34,718 : INFO : PROGRESS: at 39.38% examples, 4719 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:36:34,961 : INFO : PROGRESS: at 39.66% examples, 4719 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:37:35,048 : INFO : PROGRESS: at 39.93% examples, 4720 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:38:35,167 : INFO : PROGRESS: at 40.22% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:39:35,211 : INFO : PROGRESS: at 40.52% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:40:35,360 : INFO : PROGRESS: at 40.77% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:41:35,499 : INFO : PROGRESS: at 41.04% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:42:35,690 : INFO : PROGRESS: at 41.31% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:43:35,826 : INFO : PROGRESS: at 41.61% examples, 4717 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:44:35,968 : INFO : PROGRESS: at 41.89% examples, 4720 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:45:36,533 : INFO : PROGRESS: at 42.22% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:46:37,165 : INFO : PROGRESS: at 42.53% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:47:37,643 : INFO : PROGRESS: at 42.79% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:48:38,053 : INFO : PROGRESS: at 43.09% examples, 4719 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:49:38,221 : INFO : PROGRESS: at 43.40% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:50:39,593 : INFO : PROGRESS: at 43.70% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:51:39,788 : INFO : PROGRESS: at 43.99% examples, 4718 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:52:40,092 : INFO : PROGRESS: at 44.28% examples, 4717 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:53:40,167 : INFO : PROGRESS: at 44.56% examples, 4717 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:54:40,971 : INFO : PROGRESS: at 44.83% examples, 4715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:55:41,156 : INFO : PROGRESS: at 45.12% examples, 4715 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:56:41,412 : INFO : PROGRESS: at 45.42% examples, 4713 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 21:57:42,417 : INFO : PROGRESS: at 45.75% examples, 4716 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:58:43,073 : INFO : PROGRESS: at 46.03% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 21:59:43,356 : INFO : PROGRESS: at 46.32% examples, 4714 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:00:43,663 : INFO : PROGRESS: at 46.57% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:01:43,853 : INFO : PROGRESS: at 46.88% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:02:44,194 : INFO : PROGRESS: at 47.14% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:03:44,299 : INFO : PROGRESS: at 47.45% examples, 4714 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:04:44,875 : INFO : PROGRESS: at 47.72% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:05:44,961 : INFO : PROGRESS: at 48.01% examples, 4714 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:06:45,093 : INFO : PROGRESS: at 48.30% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:07:45,348 : INFO : PROGRESS: at 48.59% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:08:45,438 : INFO : PROGRESS: at 48.83% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:09:47,994 : INFO : PROGRESS: at 49.17% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:10:48,784 : INFO : PROGRESS: at 49.49% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:11:49,496 : INFO : PROGRESS: at 49.80% examples, 4713 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:12:50,118 : INFO : PROGRESS: at 50.11% examples, 4712 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:13:50,173 : INFO : PROGRESS: at 50.39% examples, 4711 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:14:51,105 : INFO : PROGRESS: at 50.66% examples, 4711 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:15:51,136 : INFO : PROGRESS: at 50.93% examples, 4710 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:16:51,475 : INFO : PROGRESS: at 51.22% examples, 4710 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:17:51,722 : INFO : PROGRESS: at 51.49% examples, 4709 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:18:52,008 : INFO : PROGRESS: at 51.77% examples, 4710 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:19:52,071 : INFO : PROGRESS: at 52.02% examples, 4709 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:20:52,342 : INFO : PROGRESS: at 52.30% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:21:52,478 : INFO : PROGRESS: at 52.57% examples, 4708 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:22:52,970 : INFO : PROGRESS: at 52.83% examples, 4708 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:23:53,625 : INFO : PROGRESS: at 53.11% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:24:53,883 : INFO : PROGRESS: at 53.37% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:25:54,299 : INFO : PROGRESS: at 53.65% examples, 4709 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:26:55,831 : INFO : PROGRESS: at 53.96% examples, 4708 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:27:56,645 : INFO : PROGRESS: at 54.27% examples, 4707 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:28:58,077 : INFO : PROGRESS: at 54.57% examples, 4706 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:29:58,372 : INFO : PROGRESS: at 54.86% examples, 4706 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:31:00,043 : INFO : PROGRESS: at 55.14% examples, 4704 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:32:00,755 : INFO : PROGRESS: at 55.38% examples, 4706 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:33:01,966 : INFO : PROGRESS: at 55.64% examples, 4704 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:34:02,174 : INFO : PROGRESS: at 55.95% examples, 4705 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:35:02,625 : INFO : PROGRESS: at 56.21% examples, 4705 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:36:02,636 : INFO : PROGRESS: at 56.51% examples, 4704 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:37:03,274 : INFO : PROGRESS: at 56.78% examples, 4703 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:38:03,533 : INFO : PROGRESS: at 57.06% examples, 4703 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:39:04,418 : INFO : PROGRESS: at 57.35% examples, 4703 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:40:05,753 : INFO : PROGRESS: at 57.64% examples, 4702 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:41:05,795 : INFO : PROGRESS: at 57.91% examples, 4702 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:42:05,875 : INFO : PROGRESS: at 58.20% examples, 4701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:43:06,336 : INFO : PROGRESS: at 58.49% examples, 4701 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:44:07,305 : INFO : PROGRESS: at 58.82% examples, 4701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:45:07,710 : INFO : PROGRESS: at 59.09% examples, 4700 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:46:08,059 : INFO : PROGRESS: at 59.37% examples, 4700 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:47:08,806 : INFO : PROGRESS: at 59.66% examples, 4700 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:48:09,041 : INFO : PROGRESS: at 59.96% examples, 4699 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:49:09,517 : INFO : PROGRESS: at 60.23% examples, 4701 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:50:09,651 : INFO : PROGRESS: at 60.48% examples, 4700 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:51:09,847 : INFO : PROGRESS: at 60.78% examples, 4699 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:52:10,024 : INFO : PROGRESS: at 61.07% examples, 4699 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:53:10,180 : INFO : PROGRESS: at 61.32% examples, 4698 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:54:10,673 : INFO : PROGRESS: at 61.56% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:55:11,157 : INFO : PROGRESS: at 61.86% examples, 4698 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 22:56:11,199 : INFO : PROGRESS: at 62.15% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:57:11,654 : INFO : PROGRESS: at 62.43% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:58:12,037 : INFO : PROGRESS: at 62.67% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 22:59:13,390 : INFO : PROGRESS: at 62.93% examples, 4696 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:00:14,699 : INFO : PROGRESS: at 63.23% examples, 4697 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:01:15,084 : INFO : PROGRESS: at 63.49% examples, 4696 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:02:16,581 : INFO : PROGRESS: at 63.74% examples, 4696 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:03:19,138 : INFO : PROGRESS: at 64.03% examples, 4695 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:04:19,434 : INFO : PROGRESS: at 64.33% examples, 4695 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:05:19,548 : INFO : PROGRESS: at 64.61% examples, 4694 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:06:20,611 : INFO : PROGRESS: at 64.92% examples, 4693 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:07:20,979 : INFO : PROGRESS: at 65.20% examples, 4692 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:08:21,523 : INFO : PROGRESS: at 65.45% examples, 4691 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:09:22,349 : INFO : PROGRESS: at 65.75% examples, 4691 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:10:22,645 : INFO : PROGRESS: at 66.01% examples, 4690 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:11:23,033 : INFO : PROGRESS: at 66.29% examples, 4689 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:12:23,629 : INFO : PROGRESS: at 66.56% examples, 4689 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:13:23,654 : INFO : PROGRESS: at 66.82% examples, 4688 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:14:23,911 : INFO : PROGRESS: at 67.08% examples, 4687 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:15:24,602 : INFO : PROGRESS: at 67.36% examples, 4686 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:16:25,216 : INFO : PROGRESS: at 67.64% examples, 4685 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:17:26,234 : INFO : PROGRESS: at 67.89% examples, 4685 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:18:26,255 : INFO : PROGRESS: at 68.15% examples, 4684 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:19:26,691 : INFO : PROGRESS: at 68.44% examples, 4682 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:20:26,768 : INFO : PROGRESS: at 68.71% examples, 4682 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:21:27,115 : INFO : PROGRESS: at 68.99% examples, 4682 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:22:28,086 : INFO : PROGRESS: at 69.26% examples, 4680 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:23:28,183 : INFO : PROGRESS: at 69.50% examples, 4680 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:24:28,480 : INFO : PROGRESS: at 69.75% examples, 4679 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:25:28,664 : INFO : PROGRESS: at 70.02% examples, 4679 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:26:28,958 : INFO : PROGRESS: at 70.30% examples, 4678 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:27:29,611 : INFO : PROGRESS: at 70.57% examples, 4677 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:28:31,935 : INFO : PROGRESS: at 70.84% examples, 4675 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:29:34,809 : INFO : PROGRESS: at 71.09% examples, 4674 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:30:35,029 : INFO : PROGRESS: at 71.39% examples, 4674 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:31:35,325 : INFO : PROGRESS: at 71.66% examples, 4673 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:32:36,165 : INFO : PROGRESS: at 71.93% examples, 4672 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:33:38,164 : INFO : PROGRESS: at 72.22% examples, 4672 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:34:39,251 : INFO : PROGRESS: at 72.51% examples, 4671 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:35:39,274 : INFO : PROGRESS: at 72.75% examples, 4671 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:36:39,917 : INFO : PROGRESS: at 73.02% examples, 4669 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:37:40,285 : INFO : PROGRESS: at 73.26% examples, 4669 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:38:40,463 : INFO : PROGRESS: at 73.55% examples, 4668 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:39:40,811 : INFO : PROGRESS: at 73.82% examples, 4667 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:40:41,118 : INFO : PROGRESS: at 74.09% examples, 4665 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-27 23:41:41,332 : INFO : PROGRESS: at 74.35% examples, 4665 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:42:41,451 : INFO : PROGRESS: at 74.61% examples, 4664 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:43:41,680 : INFO : PROGRESS: at 74.88% examples, 4662 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:44:42,720 : INFO : PROGRESS: at 75.18% examples, 4660 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:45:43,101 : INFO : PROGRESS: at 75.44% examples, 4660 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:46:43,541 : INFO : PROGRESS: at 75.69% examples, 4658 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:47:44,124 : INFO : PROGRESS: at 75.93% examples, 4657 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:48:44,422 : INFO : PROGRESS: at 76.18% examples, 4656 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:49:44,538 : INFO : PROGRESS: at 76.44% examples, 4654 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:50:44,570 : INFO : PROGRESS: at 76.75% examples, 4653 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:51:44,733 : INFO : PROGRESS: at 77.04% examples, 4651 words/s, in_qsize 12, out_qsize 0\n",
      "2016-11-27 23:52:45,977 : INFO : PROGRESS: at 77.25% examples, 4649 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:53:46,560 : INFO : PROGRESS: at 77.47% examples, 4648 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:54:47,410 : INFO : PROGRESS: at 77.73% examples, 4647 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:55:47,740 : INFO : PROGRESS: at 77.98% examples, 4645 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:56:48,972 : INFO : PROGRESS: at 78.24% examples, 4644 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:57:49,252 : INFO : PROGRESS: at 78.49% examples, 4642 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:58:49,286 : INFO : PROGRESS: at 78.76% examples, 4641 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-27 23:59:49,727 : INFO : PROGRESS: at 79.02% examples, 4640 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:00:49,764 : INFO : PROGRESS: at 79.28% examples, 4639 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:01:50,123 : INFO : PROGRESS: at 79.54% examples, 4637 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:02:50,442 : INFO : PROGRESS: at 79.77% examples, 4636 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:03:50,471 : INFO : PROGRESS: at 80.04% examples, 4635 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:04:50,724 : INFO : PROGRESS: at 80.28% examples, 4634 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:05:51,023 : INFO : PROGRESS: at 80.57% examples, 4633 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:06:51,695 : INFO : PROGRESS: at 80.85% examples, 4632 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:07:53,317 : INFO : PROGRESS: at 81.11% examples, 4630 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:08:53,494 : INFO : PROGRESS: at 81.33% examples, 4628 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:09:54,678 : INFO : PROGRESS: at 81.58% examples, 4627 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:10:54,852 : INFO : PROGRESS: at 81.82% examples, 4627 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:11:55,022 : INFO : PROGRESS: at 82.10% examples, 4626 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:12:55,274 : INFO : PROGRESS: at 82.35% examples, 4624 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:13:57,220 : INFO : PROGRESS: at 82.64% examples, 4622 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:14:57,887 : INFO : PROGRESS: at 82.92% examples, 4621 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:15:58,365 : INFO : PROGRESS: at 83.17% examples, 4619 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:16:59,359 : INFO : PROGRESS: at 83.43% examples, 4618 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:18:00,202 : INFO : PROGRESS: at 83.69% examples, 4616 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:19:00,897 : INFO : PROGRESS: at 83.96% examples, 4616 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:20:01,400 : INFO : PROGRESS: at 84.20% examples, 4614 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:21:01,697 : INFO : PROGRESS: at 84.46% examples, 4613 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:22:01,858 : INFO : PROGRESS: at 84.74% examples, 4612 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:23:02,181 : INFO : PROGRESS: at 84.98% examples, 4610 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:24:03,004 : INFO : PROGRESS: at 85.23% examples, 4608 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:25:03,645 : INFO : PROGRESS: at 85.52% examples, 4607 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:26:04,022 : INFO : PROGRESS: at 85.78% examples, 4606 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:27:04,109 : INFO : PROGRESS: at 86.05% examples, 4604 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:28:04,494 : INFO : PROGRESS: at 86.28% examples, 4603 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:29:04,600 : INFO : PROGRESS: at 86.51% examples, 4602 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:30:04,630 : INFO : PROGRESS: at 86.78% examples, 4600 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:31:04,808 : INFO : PROGRESS: at 87.03% examples, 4598 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:32:04,857 : INFO : PROGRESS: at 87.28% examples, 4595 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:33:04,979 : INFO : PROGRESS: at 87.51% examples, 4595 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:34:05,662 : INFO : PROGRESS: at 87.77% examples, 4593 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:35:05,721 : INFO : PROGRESS: at 88.04% examples, 4591 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:36:06,006 : INFO : PROGRESS: at 88.27% examples, 4589 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:37:06,056 : INFO : PROGRESS: at 88.55% examples, 4587 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:38:06,189 : INFO : PROGRESS: at 88.78% examples, 4586 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:39:06,876 : INFO : PROGRESS: at 89.04% examples, 4584 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:40:07,140 : INFO : PROGRESS: at 89.28% examples, 4582 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:41:08,709 : INFO : PROGRESS: at 89.53% examples, 4581 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:42:08,871 : INFO : PROGRESS: at 89.81% examples, 4580 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:43:08,912 : INFO : PROGRESS: at 90.04% examples, 4578 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:44:09,131 : INFO : PROGRESS: at 90.28% examples, 4577 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 00:45:10,040 : INFO : PROGRESS: at 90.52% examples, 4576 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:46:10,043 : INFO : PROGRESS: at 90.76% examples, 4575 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:47:10,374 : INFO : PROGRESS: at 91.02% examples, 4574 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:48:10,832 : INFO : PROGRESS: at 91.29% examples, 4572 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:49:11,616 : INFO : PROGRESS: at 91.56% examples, 4571 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:50:11,860 : INFO : PROGRESS: at 91.83% examples, 4569 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:51:12,301 : INFO : PROGRESS: at 92.09% examples, 4567 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:52:12,671 : INFO : PROGRESS: at 92.33% examples, 4566 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:53:13,345 : INFO : PROGRESS: at 92.59% examples, 4565 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:54:15,373 : INFO : PROGRESS: at 92.87% examples, 4563 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:55:17,078 : INFO : PROGRESS: at 93.12% examples, 4561 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:56:17,317 : INFO : PROGRESS: at 93.37% examples, 4559 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:57:17,437 : INFO : PROGRESS: at 93.65% examples, 4558 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:58:18,082 : INFO : PROGRESS: at 93.90% examples, 4556 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 00:59:18,770 : INFO : PROGRESS: at 94.20% examples, 4555 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:00:18,773 : INFO : PROGRESS: at 94.44% examples, 4553 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:01:19,927 : INFO : PROGRESS: at 94.68% examples, 4551 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:02:20,352 : INFO : PROGRESS: at 94.93% examples, 4550 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:03:20,692 : INFO : PROGRESS: at 95.18% examples, 4549 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:04:20,693 : INFO : PROGRESS: at 95.43% examples, 4547 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 01:05:21,223 : INFO : PROGRESS: at 95.71% examples, 4546 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:06:22,718 : INFO : PROGRESS: at 95.96% examples, 4544 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:07:22,827 : INFO : PROGRESS: at 96.20% examples, 4543 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:08:23,342 : INFO : PROGRESS: at 96.41% examples, 4541 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:09:23,551 : INFO : PROGRESS: at 96.68% examples, 4540 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:10:24,202 : INFO : PROGRESS: at 96.93% examples, 4538 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:11:24,292 : INFO : PROGRESS: at 97.19% examples, 4537 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:12:24,502 : INFO : PROGRESS: at 97.42% examples, 4536 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:13:24,973 : INFO : PROGRESS: at 97.66% examples, 4534 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 01:14:25,121 : INFO : PROGRESS: at 97.89% examples, 4533 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:15:26,315 : INFO : PROGRESS: at 98.16% examples, 4531 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:16:26,937 : INFO : PROGRESS: at 98.40% examples, 4530 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:17:28,062 : INFO : PROGRESS: at 98.64% examples, 4529 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:18:28,187 : INFO : PROGRESS: at 98.89% examples, 4528 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:19:28,267 : INFO : PROGRESS: at 99.15% examples, 4527 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:20:28,419 : INFO : PROGRESS: at 99.41% examples, 4525 words/s, in_qsize 23, out_qsize 0\n",
      "2016-11-28 01:21:28,625 : INFO : PROGRESS: at 99.71% examples, 4524 words/s, in_qsize 24, out_qsize 0\n",
      "2016-11-28 01:22:28,777 : INFO : PROGRESS: at 99.96% examples, 4523 words/s, in_qsize 17, out_qsize 0\n",
      "2016-11-28 01:22:31,614 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2016-11-28 01:22:32,235 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2016-11-28 01:22:32,657 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2016-11-28 01:22:32,724 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2016-11-28 01:22:33,007 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2016-11-28 01:22:35,805 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2016-11-28 01:22:35,809 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph()\n",
    "# when resuming, resume from an epoch with a previously created doc2vec model to get the learning rate right\n",
    "start_from = 1\n",
    "for epoch in range(start_from,DOC2VEC_MAX_EPOCHS+1):\n",
    "    GLOBAL_VARS.MODEL_NAME = placeholder_model_name.format(epoch)\n",
    "    info(\"****************** Epoch {} --- Working on {} *******************\".format(epoch, GLOBAL_VARS.MODEL_NAME))\n",
    "    \n",
    "    # if we have the model, just load it, otherwise train the previous model\n",
    "    if os.path.exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX)):\n",
    "        doc2vec_model = Doc2Vec.load(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "    else:\n",
    "        # train the doc2vec model\n",
    "        doc2vec_model.train(sentences=StochasticDocumentGenerator(training_file, training_docs_list, line_positions), \n",
    "                            report_delay=REPORT_DELAY)\n",
    "        #doc2vec_model.alpha -= 0.001  # decrease the learning rate\n",
    "        #doc2vec_model.min_alpha = doc2vec_model.alpha  # fix the learning rate, no decay\n",
    "        ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME))\n",
    "        doc2vec_model.save(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, MODEL_PREFIX))\n",
    "        GLOBAL_VARS.DOC2VEC_MODEL = doc2vec_model\n",
    "\n",
    "#     # Training and validation of SVMs using those docvecs\n",
    "#     train_classifications(sections)\n",
    "#     validation_vectors_matrix = get_validation_docs_with_inference(doc2vec_model, doc_classification_map)\n",
    "#     metrics = do_validation(validation_vectors_matrix, doc_classification_map, sections, \"sections\")\n",
    "#     ensure_disk_location_exists(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, \n",
    "#                                              GLOBAL_VARS.SVM_MODEL_NAME))\n",
    "#     pickle.dump(metrics, open(os.path.join(doc2vec_model_save_location, GLOBAL_VARS.MODEL_NAME, GLOBAL_VARS.SVM_MODEL_NAME, METRICS), 'w'))\n",
    "#     print \"Coverage Error: {}, Average No of Labels: {}, Top 1: {}, Top 3: {}, Top 5: {}, F1 Micro: {}, Total Positive: {}\".format(\n",
    "#         metrics['coverage_error'], metrics['average_num_of_labels'], metrics['top_1'], metrics['top_3'], metrics['top_5'], \n",
    "#         metrics['f1_micro'], metrics['total_positive'])\n",
    "                                                                                     \n",
    "#     epoch_metrics.append(metrics)\n",
    "#     graph.add_metrics_to_graph(metrics, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loaded metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/local/shalaby/parameter_search_doc2vec_models/sample_0.0001'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model_save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8AAAAHgCAYAAABq5QSEAAAgAElEQVR4nOzdeXgT1cI/8Mwk6ZruCyldSCg7FEGhFGUp8hRkkQsivLKXrVx/gBflsgstCly8LoDse9lFSoEC2o2yuhQtL3i5KhUoi6CIWipYS7fv74++GTvJJE2hUAzfz/OcR3PmTOZM6OTkmzMzUamIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIjIXi4qlcqThYWFhYVFobioiIiIiByEi1ar/UWlUoGFhYWFhcW8/N8YwRBMREREDsFTpVLh6tWrKCgoYGFhYWFhkcrVq1dNQdizlscqIiIiohrhqVKpUFBQACIiosoKCgoYgImIiMihMAATEZEiBmAiIiJyNAzARESkiAGYiIiIHA0DMBERKWIAJiIiIkfjcAE4MTERgiBYFFEUcejQIandjBkz0K1bN/j5+UEQBGzatMnubXTu3BmCIOCZZ55RXB4bGwtBEBAaGiqrFwQBc+fOvbcdI3IQ5seok5MTwsPDMXPmTBQVFdV291CvXj2MHDlSerxx40YIgoDLly/bXM/acW+SkJAgvReVlZXVaJ8fFAZgIiIicjQOGYBFUURycjKys7Nl5fbt21I7Dw8PdOrUCbGxsRBFsVoBODo6Gl5eXhBFERcuXJAtKywshIeHB7y8vCw+CGdnZ+PatWv3t4NEf3Hmx2hmZibGjx8PQRDwyiuv1Hb3YDAYZAHY1F97ArC7uzs0Gg2ysrIsloeHh0vvGwzARERERLXDYQOweTC15vz589WeAY6OjkbHjh3RqFEjixndLVu2wNPTEwMHDrQ6E3S/7t69+0Cel+hhsHaMxsTEQKfT1VKv/nQ/ATg0NBQxMTGy9QHg+PHjEEURI0eOfKgB+H7fKxiAiYiIyNEwAN9HAH7zzTfRsGFD2bJu3bohNjZW+jBcmdIp0KdPn0bfvn3h5+cHV1dXNG7cGAsXLpSWd+7cGR06dMD+/fvRunVruLi4YPHixQCA3377DePHj0fdunXh7OyMxo0bY9GiRXbvB1FtsHaMTps2DaIo4ubNm7L6vLw8DB48GAEBAXB2dkarVq2wZ88ei+et6lhKT09Hz549ERQUBDc3N7Ro0QLvvvuuRRi93wC8ZcsWeHh44I8//pCWxcXFITo6GgkJCRYB+IMPPsCzzz6LgIAA6HQ6tG7dWvH9qLS0FAsXLkSzZs3g4uKCgIAA9OjRA+fOnQMAHDlyBIIgIDk5GWPHjkVAQAB8fHyk9T/++GO0b98erq6u8PLyQt++faV1rWEAJiIiIkfjsAE4NzcXpaWlUrE243I/ATgvLw+iKOKzzz4DAFy7dg1qtRpZWVl2BeDs7Gy4ubnhiSeewNatW3H48GGsWbMGEyZMkG0rMDAQ9evXx8aNG3H06FH85z//QXl5OTp06ACdTodFixYhIyMDkyZNgiAImDVrVnVeMqKHyloAHjhwIHx8fFBeXi7VXb16FQEBAYiIiMD27duRnp6O0aNHQxRF7N+/X2pnz7G0atUqvPfee0hNTcWRI0fwzjvvwNPTEzNmzJD1434DcGFhIXQ6HXbs2AEAKCoqgo+PDzZs2KAYgBcsWICVK1ciIyMDhw4dQnx8PJycnLB69WrZ8/fv3x9arRZTp05FWloa9u3bh8mTJ+PIkSMA/gzAISEhGDt2rNQGqAi/arUa3bt3x4EDB7Bjxw40aNAAgYGBuH79utV9YgAmIiIiR2N3AC4vL0dBUcEDLZU/+N4razfB6tixo2L7+wnAANCpUye8/PLLAIC33noL9erVAwC7AnDHjh0RFhZm88Y/0dHRUKvV+Oqrr2T1+/fvhyAI2Lx5s6x+zJgxcHFxwS+//GL3/pDjKCoCCgqUS2mp8jqlpdbXeRD3pDL/kio/Px/r16+HVqvFihUrZG1HjRqFwMBA5Ofny+pjYmLQunVr6bE9x5K50tJSzJ8/H76+vrL6+w3AADB8+HD06NEDALBz5064u7vj9u3bigG4svLycpSWlmLs2LFo1aqVVH/o0CEIgoBly5ZZ3b4pAPfv399i2VNPPYVGjRrJtpuXlwetVovJkydbfU4GYCIiInI0dgfggqICqBJUD7QUFN3/TLTpw2pKSgpycnKkkpubq9j+fgPwunXr4Ofnh7t376JFixbS7GtVAbiwsBBqtRozZ86sclvh4eEW9VOnToVGo0FJSYms/siRIxBFEQcOHLB7f8hxxMcDKpVyOXtWeZ2zZ62vEx9f83209iVV5dlak+DgYMTGxsrO5igpKcHbb78NURRx+/Ztu4+lH374AXFxcahXrx60Wq3sDvE3btyQ2tVEAM7MzIRWq8WNGzfQu3dvDB48GAAUA/B3332Hl156CcHBwVCr1VK/XF1dpTbTp0+HWq22GfBNAXjLli2y+t9//x2iKGL27NkW60RHR6NNmzZWn5MBmIiIiByNQ84AP6xrgIGKD4hubm6YNWsWRFGUrqmrKgBfu3YNgiBg+fLlVW6rQ4cOFvVjxoxBYGCgRf23336rODNMj4e/0gyw6Uuq1NRUdOvWTTG8abVaiKKoGJjVajUuXbpk17FUXl6ONm3aICQkBOvXr8eJEyeQk5OD119/3SLc1kQALi8vR1hYGKZNmwatVou0tDQAlgH4zp07qFevHpo3b45t27bhs88+Q05OjnSat4npml5bTAE4MzNTVv/9999DEASL2XUAeOmll1C/fn2rz8kATERERI7GYa8BflgBGKj4EKlWq9GuXTupriZngJVO37Y1AywIAmeA6ZGldIzevXsXjRs3hl6vR2FhoVSv1+sxcOBAnDp1SnZGh6kUFxfbdSx99913EAQB27dvl9XPmTPngQRg4M9Z27p160pf7pkH4IyMDIiiiE8//VT2XMOHD5cF4BkzZtg9A1z5986BP2eA58yZY7EOZ4CJiIjoccMAXAMB+MSJE+jXrx+SkpKkOnuuAe7cubNd1wArBeCDBw8qfqDnNcD0qLN2jKakpEAQBLzzzjtSXWxsLJo0aVLltb1VHUtnzpyBIAj48MMPpbri4mKEh4c/sACcm5uLfv36YeXKlVKdeQDet28fRFHEyZMnpTa//vorvL29ZQH48OHDdl0DLIqiRQAGgLZt26Jp06ays2wuXboEJycnTJkyxepzMgATERGRo3lsA/DRo0eRlJSEpUuXStcfJiUlyUKsNdZCaWX2BOAvvvgC7u7uaNWqFbZs2YLDhw9j/fr1mDhxYpXbKi8vR8eOHeHp6YnFixdLd4EWRRGvv/56lftAVFtsHaORkZEICgqSguyVK1cQFBSEtm3bYtOmTTh69Cj27t2LefPmYfTo0dJ6VR1LxcXFMBgMaNiwIZKSkrB3715ER0ejYcOGDywAKzEPwDdv3oSXlxfatm2LgwcPYufOnWjZsqXUr8pefPFFODk5YerUqUhNTcX+/fsxZcoUHD16FID1GWAASE1NhUajQY8ePbB//35s374djRo1Qp06dfDDDz9Y7S8DMBERETmaxzYAR0dHQxRFxVKV6OhodOrUyWab2NhYhIWFyepEUcQbb7whqzt9+jT69OkDHx8fuLm5oWnTpvj3v/9t17Zu376NiRMnyn4HeMmSJVX2n6g22TpG09PTIYqi9FvXQMX18mPHjkVISAicnZ1Rt25ddOvWDdu2bZOtW9WxdObMGXTs2BHu7u4IDQ1FfHw81q9fbxFujUYjRo0aZdFfewKw+TFvLiEhAWq1WnYTrMOHD+PJJ5+Em5sbGjRogKVLl0pBubKysjIsWLAAjRs3hrOzMwIDA9GrVy/pBn+2ZoABIC0tDU8//TTc3Nzg7e2Nfv36Wb05oAkDMBERETkahwvARERUMxiAiYiIyNEwABMRkSIGYCIiInI0DMBERKSIAZiIiIgcDQMwEREpYgAmIiIiR8MATEREihiAiYiIyNEwABMRkSIGYCIiInI0DMBERKSIAZiIiIgcDQMwEREpYgAmIiIiR8MATEREihiAiYiIyNEwABMRkSIGYCIiInI0DMBERKSIAZiIiIgcjcMF4MTERAiCIBUPDw888cQTWLZsGUpLSx9qXxISEiCKYrXWiY6ORpcuXR5Qj6wzvV6zZs1SXG40GiEIAoYNGybVHTlyBIIg4OjRow+rm/QXV/nYtFaMRuND68+lS5cwfvx4REVFwdXVFYIg4MaNG3atW1paildffRUBAQEICwvDihUrLNps2rQJ9erVQ2FhYU13/aFgACYiIiJH45ABWBRFJCcnIzs7GxkZGYiLi4MgCIiPj3+ofbl27Rqys7Ortc4333yDb7755gH1yDpBEODl5QWDwWCx7NixYxBFER4eHrIAfPv2bWRnZ+P27dsPs6v0F5adnS0rQUFB6NGjB06ePCnVnT59+qH1JzU1FXXr1sXzzz+PmJgYiKJodwBevnw5/P39sXv3bixfvhxqtRqff/65tPzWrVuoU6cO9u3b96C6/8AxABMREZGjcdgAfOHCBVl9ly5d4O3tbXPd4uLiB9m1R5ogCBgxYgTUarXFjO6YMWPw7LPPwmg0ygJwTSkrK3vos/P0aDAYDA/kb+peLFu2rFoB+Pnnn8fkyZOlx126dEFCQoL0ePz48Xj++edrvJ8PEwMwEREROZrHJgBPnToVoiji5s2bACo+eA8dOhQbNmxAkyZN4OTkhL179wIACgsLMXXqVBiNRjg5OcFoNGL+/PkoLy+XPefNmzfx8ssvIzQ0FM7OzggNDcWwYcOkIB0fHw9BEGTrLF68GE2bNoWrqyt8fHzQpk0babsA0LlzZ4tToM+dO4e+ffvC29sbrq6uiIqKQmpqqqyNaVvfffcdevXqBZ1Oh3r16uGNN96w63UTBAGzZ89G165dMWbMGKm+qKgI3t7eSExMtAgr1k6BTk5OxjPPPAOdTgdPT09ERkZi//79sm3NmjULCxcuhNFohEajkWb97NlXchxVBeANGzYgIiICzs7OCAgIwMiRI/HTTz/J2uj1eowZMwYrVqxA/fr14eLigrZt2+L48ePV6kt1A3D37t3x+uuvS4979eqF6dOnAwBycnLg6emJy5cvV6sPjxoGYCIiInI0j00AfvHFF6HVavHHH38AqPjgHRwcjIiICHzwwQfIysrCxYsXUVpaig4dOsDf3x/vv/8+srKysGDBAri4uOCf//yn9Hz5+flo0KAB/P39sWTJEmRlZeGDDz7AoEGDcOfOHQCW1wBv3boVGo0G8+bNw5EjR/Dxxx/jrbfewoYNG6Q25tcAX79+Hf7+/ggPD8f27dtx4MAB9OjRA2q1WhYMExISIAgCIiIi8N577+HQoUOYNGkSBEFAYmJila+bKQAnJibCy8sLd+/eBQDs2LEDOp0Od+7cUQzAoijKAvD7778PQRDQv39/JCcnIz09HQsXLsTSpUtl2woODkanTp2QnJyMtLQ0/PTTT3bvKzkOWwF4yZIl0pkJqampWLNmDfz8/NCiRQsUFRVJ7fR6PUJDQ9GyZUvs3r0be/bsQWRkJNzd3XHp0iW7+1LdADxnzhw0atQIeXl5+Pzzz+Hm5oZ9+/ahvLwc7dq1w4IFC+ze9qOKAZiIiIgcjf0BuLwcKCh4sMVshvVemAJwbm4uSktLkZ+fj1WrVkGtVuOFF16Q2hkMBri7u1vMJm3evBmiKOLEiROy+vnz58PZ2VmaQZ49ezY0Gg3OnDljtS/mAXjChAl46qmnbPbfPABPnjwZWq0WFy9elOrKysrQuHFj2XOZtrVp0ybZ80VERKB79+42twn8GYDv3LkDd3d37Ny5EwDQs2dPKaBUFYB/++03eHh44MUXX6xyW8HBwVLIru6+knVFJUUoKCpAQVEBbt9Vvja7sLgQRSVFistM6xYUFeBu6V3FNjXJWgAuLi6Gn58fevbsKavPzMyEIAhYu3atVKfX6+Hm5iY7lvPz8+Hp6Ym4uDi7+1LdAHzr1i106NABgiBAFEWMGjUKALB69Wo0adIEJSUldm/7UcUATERERI7G/gBcUACoVA+21MBMtPldoAVBgEajQWxsLPLz86V2BoMBXbt2tVh/yJAhMBqNKC0tlZWTJ09CEATpVN6oqCi0b9/eZl/MA/CmTZugVqsxceJEZGZmKt4Z1jwAR0ZGomPHjorPrVarpRtQmbZlCugmgwYNQtOmTW32E/gzAAPA0KFD0bt3b/z444/QaDTIyMgAUHUATk1NhSiKSEtLq3Jbo0ePtqi3d1/JuvjD8VAlqKBKUKHZ8maKbUbvG434w/GKyzwWeEjrr81Zq9imJlkLwKdOnYIgCNi2bZvFMr1ej6FDh8oeK33JM2DAAERERNjdl+oGYJPLly9L4fvmzZvw8/NDVlYWSktLMWXKFAQHByMsLAxz586t1vM+ChiAiYiIyNE47AxwSkoKcnJykJubazHTCPx5DbC5mJgYqz/PIoqidDpxw4YNMWDAAJt9UfoZpDVr1qBdu3bQaDRwcXHBCy+8IDtN0zwAN2jQAAMHDrR47lWrVkEURVy5ckW2rbKyMlm72NhYu35WpnIATk9Ph1arxbRp0xAcHCxd+1xVAN62bRtEUcR///vfKrdV+drJ6u4rWecoM8CZmZkQRRFZWVkWy1q1aiWbGdbr9Rg+fLhFuwkTJsDX19fuvtxrAK5s1KhRGDJkCICKywEaNmyI77//HufPn0dQUBC2b99+z89dGxiAiYiIyNE8NtcAm7P2wfull15CeHg4Tp06hZycHIvyyy+/AADat2+Pp59+2uY2bP0O8K1bt/Dhhx8iJCQEUVFRUr3SDHCnTp0s1o+Pj1ecAa6JAFxeXo7g4GBoNBpMmzZNalNVAE5LS4MgCEhPT7d7W5XZu6/kOKqaAVYKjI/aDLDJp59+Ch8fH2n9Xr16yb7oGT9+vGJQf5QxABMREZGjYQBWWN/JyQnnzp2zuX58fDw0Gg2++uorq21sBWCT1157DTqdTnpsHoCnTJkCJycn2d1ky8rK0KRJE7Rt29ZiWzURgIGK6xj79euHb7/9VqqrKgDfvn3b7muAlQKwvftKjqOqa4D79OkjqzddA7x+/XqpznQNcOXg+uuvv8LT0xPjxo2zuy/3E4DLysrQqlUrLFu2TKrr1asXXn31VenxiBEjHpmffLIXAzARERE5GgZgMyUlJYiOjkZwcLB0N+WPP/4YS5cuRbdu3aS7SN+6dQsNGzZEYGCgdBfonTt3YsiQIVbvAh0XF4fJkycjKSkJx44dw9q1axEQEID+/ftLbZTuAh0YGIhGjRph+/bt2L9/P3r06AGNRiObaa3pAGzPa6b0M0imEGG6C3RGRgbefvttWTCwti1795Uch627QL///vsQRREjR45EamoqVq9ejYCAAERERFjcBTosLAwtW7bErl27sHv3brRp0wbu7u5V/gxReXk5kpKSkJSUhNGjR0MURaxbtw5JSUkWN8KzZfHixXjqqadkP5W2aNEi+Pn54YMPPkBiYiLc3NywdetWu5/zUcAATERERI7msQ3ARqPR6umId+/exdy5c9G0aVO4uLjAz88PkZGReOONN2QB8+bNmxg3bhzq1q0LZ2dnhIWFYeTIkdLvAJtu3mSyefNmdOnSBXXq1IGLiwvq16+PyZMny07tjY6OxrPPPivrT25uLvr16yf9Nm779u0tAqFpW0oBuH79+jZfCwAQRRFz5syx2cb8NVP6GSQA2L17N6KiouDm5gYvLy9ERUXh4MGDdm3Lnn0lx2HrOASAjRs3omXLlnBxcUFgYCBGjRplcaM3vV6PsWPHYuXKlTAajXBxcUFkZCQ++eSTKrdfVFQkXd9vXnr06GHXPvz444/w9fXFF198IasvKSnBpEmTUKdOHej1esXr3h91DMBERETkaBwuABPR48UUgKnmMQATERGRo2EAJqK/NAbgB4cBmIiIiBwNAzAR/aUFBQUhLi6utrvhkBiAiYiIyNEwABMRkSIGYCIiInI0DMBERKSIAZiIiIgcDQMwEREpYgAmIiIiR8MATEREihiAiYiIyNEwABMRkSIGYCIiInI0DMBERKSIAZiIiIgcDQMwEREpYgAmIiIiR8MATEREihiAiYiIyNE4XABOTEyEIAhScXJyQnh4OGbOnImioqLa7h7q1auHkSNHSo83btwIQRBw+fJlm+vFxsZCEASEhoYqLk9ISIAgCBBFEWVlZVK9wWCQbY+oNlU+Nq0Vo9H40Ppz4MABREdHo06dOnB2dkZoaCgGDRqEc+fOVbnujRs38Pzzz8PT0xMtW7bE8ePHLdqMHDkSL7744oPo+kPBAExERESOxiEDsCiKSE5ORnZ2NjIzMzF+/HgIgoBXXnmltrtnEUhN/bUnALu7u0Oj0SArK8tieXh4OLy8vCwC8OnTp3Hx4sWa2wGi+5CdnS0rQUFB6NGjB06ePCnVnT59+qH1Z9OmTZg+fTr27NmDY8eOYfPmzWjcuDF8fX3xww8/2Fx3wIABaNu2LTIyMjBu3DgEBgbizp070vJPPvkEXl5euH79+oPejQeGAZiIiIgcjcMG4AsXLsjqY2JioNPpaqlXf7qfABwaGoqYmBiLGd3jx49DFEWMHDnSIgDXlLt379b4cxIZDAYMGzastrshc+bMGQiCgBUrVths5+npiQMHDgAAiouL4ezsjCNHjgAAysrK0KpVK7z77rsPvL8PEgMwEREROZrHJgBPmzYNoiji5s2bsvq8vDwMHjwYAQEBcHZ2RqtWrbBnzx6L5z19+jT69u0LPz8/uLq6onHjxli4cKG0PD09HT179kRQUBDc3NzQokULvPvuuxZh9H4D8JYtW+Dh4YE//vhDWhYXF4fo6GgkJCRYBGDzU65N+zx06FDo9Xo4Ozujfv36mDRpkrR8xIgRCAkJwWeffYann34arq6u0vKSkhLMmjULBoMBTk5OMBgMeP3111FSUmKz/0RKqgrAGzZsQEREBJydnREQEICRI0fip59+krXR6/UYM2YMVqxYgfr168PFxQVt27ZVPCXZHlevXoUgCFizZo3Ndq6ursjMzJQe63Q6pKamAgAWLVqEli1bPpAvox4mBmAiIiJyNI9NAB44cCB8fHxQXl4u1V29ehUBAQGIiIjA9u3bkZ6ejtGjR0MURezfv19ql52dDTc3NzzxxBPYunUrDh8+jDVr1mDChAlSm1WrVuG9995Damoqjhw5gnfeeQeenp6YMWOGrB/3G4ALCwuh0+mwY8cOAEBRURF8fHywYcMGxQBsvr28vDz4+/vDYDBg3bp1OHLkCDZv3oyhQ4fKtuXh4QGDwYBly5bh6NGjOHnyJABg0KBB0Gq1SEhIQEZGBubOnQutVoshQ4bY7D+RElsBeMmSJRAEASNGjEBqairWrFkDPz8/tGjRQnY9v16vR2hoKFq2bIndu3djz549iIyMhLu7Oy5dumRXP8rKylBcXIxvv/0WvXv3Rr169ZCfn29znU6dOqF///749ddfsXz5cri6uuLGjRu4fv06vL298cknn9j/QjyiGICJiIjI0dgdgMvLgYKCB1sqZdN7ZgqUubm5KC0tRX5+PtavXw+tVmtxSuOoUaMQGBho8UE3JiYGrVu3lh537NgRYWFh1bqJVmlpKebPnw9fX19Z/f0GYAAYPnw4evToAQDYuXMn3N3dcfv2bbsC8LBhw+Dh4YEff/zR5rbMvwQAgLNnz0IQBLzxxhuy+nnz5kEURfznP/+xuQ/0EBQV/XlA3b6t3KawsKKdksoH5EM47d1aAC4uLoafnx969uwpq8/MzIQgCFi7dq1Up9fr4ebmJpsZzs/Ph6enJ+Li4uzqR4sWLaSbcDVr1gznz5+vcp3//d//RWhoKARBgLOzs9SnQYMGYdSoUXZt91HHAExERESOxu4AXFAAqFQPttTERLT5XaBNpfJsrUlwcDBiY2NRWloqlZKSErz99tsQRRG3b99GYWEh1Go1Zs6caXO7P/zwA+Li4lCvXj1otVppu6Io4saNG1K7mgjAmZmZ0Gq1uHHjBnr37o3BgwcDgF0BWK/XY9CgQVVuy9nZWTZbDgArVqxQnF2/dOkSBEHAsmXLbD4vPQTx8X8eUM2aKbcZPbqinRIPjz/XrxQyHxRrAfjUqVMQBAHbtm2zWKbX62VnLOj1enTv3t2i3YABAxAREWFXP77++mtkZ2dj+/btaNWqFQwGA65du1blemVlZcjNzZVufnXo0CH4+/vjl19+wY0bN/DCCy/Az88PzZs3x969e+3qy6OEAZiIiIgcjcPOAKekpCAnJwepqano1q0bBEHAli1bZG21Wi1EUVQMzGq1GpcuXcK1a9cgCAKWL19u47UpR5s2bRASEoL169fjxIkTyMnJweuvv24RbmsiAJeXlyMsLAzTpk2DVqtFWloaAPsCsFarxZQpU6rcVkhIiEW9aaa3sLBQVl9UVKQ4M0y1wEFmgDMzMyGKouIdz1u1aiWbGdbr9Rg+fLhFuwkTJlicgWGPn3/+GTqdDq+++mq11ispKUHTpk2lmeAXXngB/fv3R2FhIQ4cOABXV1fk5eVVuz+1iQGYiIiIHM1jcQ3w3bt30bhxY+j1ell40+v1GDhwIE6dOoWcnByLUlxcbNcM8HfffQdBELB9+3ZZ/Zw5cx5IAAaA6dOnQ61Wo27dutJMrT0BOCgoSJoxtndbJqYZYPOfVeIMMN2rqmaAzY8p4MHMAJtr0aIFnn/++Wqt869//QtRUVHSY51OJ7tJVvPmzbFhw4Z76k9tYQAmIiIiR/NYBGAASElJgSAIeOedd6S62NhYNGnSpMprezt37mzzGmDTz6Z8+OGHUl1xcTHCw8MfWADOzc1Fv379sHLlSqnOngA8YsQIeHp6VnkNsFIANl0DvGDBAlm9aWb47NmzNveByFxV1wD36dNHVm+6Bnj9+vVSneka4MqXGvz666/w9PTEuHHjqt2n77//Hi4uLtWaAaQioO4AACAASURBVL58+TK8vLxw5swZqU6n02Hfvn3SY4PBIOv3XwEDMBERETmaxyYAA0BkZCSCgoKkIHvlyhUEBQWhbdu22LRpE44ePYq9e/di3rx5GD16tLTeF198AXd3d7Rq1QpbtmzB4cOHsX79ekycOBFAxYd1g8GAhg0bIikpCXv37kV0dDQaNmz4wAKwEnsC8KVLlxAYGAij0Yi1a9fi8OHD2LJli8VdoK1ta/DgwXBycsLcuXNld4GuvD6RvWzdBfr999+Xft86NTUVq1evlu7abn4X6LCwMLRs2RK7du3C7t270aZNG7i7u1d5XPXu3RsLFixASkoKDh8+jBUrVqBhw4YICAiw+w7SANC3b1/ZT4kBwN/+9jc8+eSTSEtLw8yZM+Hs7Kz4vvQoYwAmIiIiR/NYBeD09HSIoojFixdLddeuXcPYsWMREhICZ2dn1K1bF926dbO4+c7p06fRp08f+Pj4wM3NDU2bNsW///1vafmZM2fQsWNHuLu7IzQ0FPHx8Vi/fr1FuDUajbI7xFYnAIeFhdlsk5CQALVaLQvA5tsDgIsXL0q/fezq6ooGDRpg8uTJdm2rpKQEs2fPlv0O8Jw5c1BaWmqzb0RKjEaj4vW7Jhs3bkTLli3h4uKCwMBAjBo1yuK3vPV6PcaOHYuVK1fCaDTCxcUFkZGRdv0M0fz58/Hkk0/Cx8cH7u7uaNq0KSZMmIDvv//e7n346KOPULduXdw2u+b6+vXr6NOnD7y8vNCoUSMkJSXZ/ZyPCgZgIiIicjQOF4CJ6PFiCsBU8xiAiYiIyNEwABPRXxoD8IPDAExERESOhgGYiP7SgoKCEBcXV9vdcEgMwERERORoGICJiEgRAzARERE5GgZgIiJSxABMREREjoYBmIiIFDEAExERkaNhACYiIkUMwERERORoGICJiEgRAzARERE5GgZgIiJSxABMREREjoYBmIiIFDEAExERkaNhACYiIkUMwERERORoHC4AJyYmQhAEiyKKIg4dOiS1mzFjBrp16wY/Pz8IgoBNmzbZvY3OnTtDEAQ888wzistjY2MhCAJCQ0Pve3+IHInSsWlejEbjQ+tPamqqYh+CgoKqXPfOnTsYPnw4fHx80LBhQyQnJ1u0mTt3LiIjIx9E1x8KBmAiIiJyNA4ZgEVRRHJyMrKzs2Xl9u3bUjsPDw906tQJsbGxEEWxWgE4OjoaXl5eEEURFy5ckC0rLCyEh4cHvLy8GICJzJgfk0FBQejRowdOnjwp1Z0+ffqh9Sc1NRWiKGLdunWyfv3v//5vletOmTIF4eHh+OijjzBnzhy4uLjgypUr0vILFy5Ap9PZ9VyPKgZgIiIicjQOG4DNg6k158+fr/YMcHR0NDp27IhGjRph7ty5smVbtmyBp6cnBg4c+FAD8N27dx/atohqisFgwLBhw2pt+6YA/Mknn1R73YiICCxdulR6bDQakZiYKD3u3bs3Jk6cWCP9rC0MwERERORoGIDvIwC/+eabaNiwoWxZt27dEBsbi9jYWIsAvGzZMrRv3x6+vr7w9vZGVFQUDh48aPH8v//+O6ZNm4bw8HA4OztDr9fjxRdfxE8//QQA2LhxIwRBwLFjxzBgwAB4e3ujdevW0vpbtmzBE088ARcXF/j7+2PYsGH44Ycf7N4/ooelqgC8YcMGREREwNnZGQEBARg5cqR0HJjo9XqMGTMGK1asQP369eHi4oK2bdvi+PHjVW7fdAr0vQTgxo0bY926ddLj5s2bY9WqVQCAPXv2ICgo6C//3soATERERI7GYQNwbm4uSktLpVJWVqbY/n4CcF5eHkRRxGeffQYAuHbtGtRqNbKyshQD8JQpU7BhwwZkZWUhPT0dEydOhCiKSEtLk9oUFxejffv20Ol0mD9/PjIzM7F7927ExcXh3Llz0j4KgoCwsDBMmzYNhw4dkp5j9erVEAQBgwcPxscff4z169cjMDAQjRs3xu+//16t15LoQbMVgJcsWQJBEDBixAikpqZizZo18PPzQ4sWLVBUVCS10+v1CA0NRcuWLbF7927s2bMHkZGRcHd3x6VLl2xu3xSA9Xo91Go1AgICMGzYMFy7dq3Kvg8fPhzPPPMMbty4gZSUFKjVapw5cwaFhYUwGAzYvn179V6MRxADMBERETmaagXgopIiFBQVKJbSslLFdUrLSq2uU1RSpLjO/bB2E6yOHTsqtr+fAAwAnTp1wssvvwwAeOutt1CvXj0AUAzAlZWXl6O0tBTdunVD3759pfr169dDFEUcOHCgyn2cPHmyrL6srAx16tRB165dZfUnTpyAIAiy0zXJMRUVAQUFFaXSJe8yhYUV7ZSY1i0oAB7GWfXWAnBxcTH8/PzQs2dPWX1mZiYEQcDatWulOr1eDzc3N9nMcH5+Pjw9PREXF2dz+ydPnsT06dNx8OBBHDt2DO+99x78/PxgMBiQn59vc93Lly+jefPmEAQBarUa8fHxACpusPfss89Wtet/CQzARERE5GiqFYDjD8dDlaBSLGdvnFVc5+yNs1bXiT8cX4Mf1SqYZoBTUlKQk5MjldzcXMX29xuA161bBz8/P9y9exctWrTArFmzACgH4C+//BK9evVCnTp1IIqiFM6bNm0qtXnppZdQt25du/bR/BTPr7/+GoIgYP369RbrGAwGvPjii3bvI/01xccDKlVFadZMuc3o0RXtlHh4/Ll+pYz5wFgLwKdOnYIgCNi2bZvFMr1ej6FDh8oed+/e3aLdgAEDEBERUe0+ff755xBFEfPnz7er/YULF6Sw/M0338DDwwPnzp3DnTt3MGrUKAQGBiI8PByrV6+udl9qGwMwERERORqHnAF+WNcAAxUfEN3c3DBr1iyIoiidpmwegK9evQpvb28888wz2LVrF7Kzs5GTk4MePXrIfvYlJiYGbdu2tWsfz58/L6s3zfR+9NFHFutERUU5zKwUWecoM8CZmZkQRRFZWVkWy1q1aiWbGdbr9Rg+fLhFuwkTJsDX1/ee+lW/fn3ZmRn26tq1q/Ql2GuvvYann34a+fn5+OKLL+Dm5oZPP/30nvpTWxiAiYiIyNE47DXADysAAxWztmq1Gu3atZPqzAPw2rVrIYoirl+/Lnuuzp07ywLwoEGD7J4BNt9H0wzwhg0bLNbhDDA9iqqaAVa6jvZBzwADFQG4X79+1Vpnx44dMBqN0vXJzZs3l90kq1evXpgzZ8499ae2MAATERGRo2EAroEAfOLECfTr1w9JSUlSnXkAXrJkCURRlF2neO7cOWg0GlkA3rhxo13XACvtY1lZGfR6Pbp16yar/+STTyAIApYvX273PhI9DFVdA9ynTx9Zveka4Mqn+ZuuAb5x44ZU9+uvv8LT0xPjxo2rdp8++eQTiKKIhQsX2r3O7du3ERwcLDtumzdvjiVLlkiPO3fujNmzZ1e7P7WJAZiIiIgczWMbgI8ePYqkpCQsXboUgiBgwoQJSEpKkoVYa8wDsBLzAPzf//4XWq0W3bt3R3p6OhITE2EwGBAeHi4LwCUlJXj66afh4eEh3QU6OTkZf//732V3gba2j2vWrIEoihg6dChSU1Oxbt066PV6NGnSBIWFhVXuG9HDZOsu0O+//z5EUcTIkSORmpqK1atXIyAgABERERZ3gQ4LC0PLli2xa9cu7N69G23atIG7uzsuX75sc/sDBw5EfHw89uzZg0OHDuGtt96Cr68vGjRogFu3btm9H5MmTcLf/vY3Wd0//vEPGI1GpKSkYPHixVCr1Thx4oTdz/koYAAmIiIiR/PYBuDo6GiIoqhYqhIdHY1OnTrZbBMbG4uwsDBZ3a5du9C0aVO4urqiRYsW2LlzJ2JjY1G/fn1Zu99//x1Tp06FwWCAs7Mz6tatiwEDBuDmzZt27eO2bdvQqlUr6XeAR4wYgR9//LHK/SJ62IxGo+L1uyYbN25Ey5Yt4eLigsDAQIwaNUo6Dkz0ej3Gjh2LlStXwmg0wsXFBZGRkXb9tu+bb76Jli1bwsvLC05OTjAYDBg/frzFNmz56quv4OXlhStXrsjqf/vtNwwfPhy+vr4ICwvDsmXL7H7ORwUDMBERETkahwvARPR4MQVgqnkMwERERORoGICJ6C+NAfjBYQAmIiIiR8MATER/aUFBQYiLi6vtbjgkBmAiIiJyNAzARESkiAH40eCiqvgHYGFhYWFhMS8uKqouTxUDMBERKWAArn0uWq32F1XFPwILCwsLC4us/N8YwRBcPQzARESkiAG49nmqVCpcvXoVBQUFLCwsLCwsUrl69SoH6XvDAExERIoKChiAaxsHaSIiUsRB+p5xbCUiIkUcW2sfB2kiIlLEQfqecWwlIiJFHFtrHwdpIiJSxEH6nnFsJSIiRRxbax8HaSIiUsRB+p5xbCUiIkUcW2ufww7Sn376KQYOHIi6devCyckJfn5+iImJwaZNm1BWVlbb3XvkHTlyBIIgKBZRFB3yb+ZRNmbMGAiCgNdee63W+pCQkABBENCgQQOUlpbKlp0/fx6CIGDTpk211LuaNX/+fISFhUGj0aB169ZW23Xu3BkdO3a87+1dunQJgiBg/fr19/1cJoIgYO7cuff1HByk75nDja2JiYmyccDDwwNPPPEEli1bZvF+8KAlJCRAFMVqrRMdHY0uXbo8oB5ZZ3q9Zs2apbjcaDRCEAQMGzbsIfeMiGoLx9ba53CDNAAsWrQIoigiJiYGW7duxfHjx5GSkoIJEybA3d0dKSkptd3FR96RI0cgiiKWL1+O7Oxsi1JeXl7bXXxs/PHHH/Dy8oIoitDr9bX2BY4pAIuiiNWrV8uWOVIAPnnyJARBwPTp0/H555/j7NmzVttGR0czAJMShxtbExMTIYoikpOTkZ2djYyMDMTFxUEQBMTHxz/Uvly7dg3Z2dnVWuebb77BN99884B6ZJ0gCPDy8oLBYLBYduzYMYiiCA8PDwZgoscIx9ba53CD9NGjRyGKIiZNmqS4/OLFi/jPf/7zkHtl2927d2u7CxZMM8CHDh2q9rq29ud+97WsrOyhzzbUtu3bt0MQBPTu3RuiKOLgwYO10g9TAH7uuecQGhoq+7d0pABs+qCfl5dXZVsGYLLC4cZW03Fx4cIFWX2XLl3g7e1tc93i4uIH2bVHmiAIGDFiBNRqNY4ePSpbNmbMGDz77LMwGo0PNQA/ip85iB4nHFtrn8MN0j179kRAQIDdb/DZ2dno2rUrdDod3N3d0bVrV5w8eVJa/vbbb8PJyQm//vqrxbpNmzZF3759pceFhYWYOnUqjEYjnJycYDQaMX/+fNlsqSlYJicnY+zYsQgICICPjw+AihAxbNgwGI1GuLq6on79+nj55ZeRn59vse1FixbBYDDAxcUF7dq1w6effgqDwYCRI0fK2uXl5WHw4MEICAiAs7MzWrVqhT179lT5utgbgG3tT3x8PARBwNmzZ9G9e3fodDrZ6/Xee++hcePGcHJyQlBQECZMmIDffvtN9vymU8cWLlwIo9EIjUaD06dPV9l/R9K9e3f4+fnh559/hpubGwYOHChbvmvXLgiCoPjFTo8ePdCqVSvp8c2bN/HSSy/B09MTPj4+GDVqFFJSUiAIgsWHM3Om0w5zcnIgiiLee+89aZlSAB4xYoTirEfnzp1lpyKa/ob27t2LcePGwdfXF97e3pg0aRLKyspw8uRJdOjQAe7u7mjevDnS0tKqftGsqOp4j46Olma5Tf+1FSLtCcDLli1D+/btpf2Kioqy+BLDFIBXrlyJ1157DYGBgXBzc0Pv3r1x6dIli+dcvXo1nnjiCbi4uMDf3x+jR4+2eI8yD8C5ubno27cvAgMD4eLigrCwMAwcONDmGQUcpO+Zw42t1gLw1KlTIYoibt68CQAwGAwYOnQoNmzYgCZNmsDJyQl79+4FYN8YCVS8T7388ssIDQ2Fs7MzQkNDMWzYMClIm8aWyhYvXoymTZvC1dUVPj4+aNOmjbRdwPJ9BwDOnTuHvn37wtvbG66uroiKikJqaqqsjWlb3333HXr16gWdTod69erhjTfesOt1EwQBs2fPRteuXTFmzBipvqioCN7e3khMTITBYJAF4KKiIrz66qto0aIFdDod9Ho9nn/+eXz77bcWz5+Xl4ehQ4dCr9fD2dkZ9evXl00AjBgxAiEhIfjss8/w9NNPw9XVVVpeUlKCWbNmwWAwwMnJCQaDAa+//jpKSkrs2jciujccW2ufQw3SZWVlcHNzw5AhQ+xqf+bMGbi6uqJNmzZITk5GcnIy2rZtC1dXV3z11VcAKk61UqvVWLlypWzdL7/8EoIgSGGytLQUHTp0gL+/P95//31kZWVhwYIFcHFxwT//+U9pPdOH/ZCQEIwdOxZpaWnYt28fgIrToWbNmoX9+/fj+PHj2LRpExo3boynn35atu21a9dCEATExcUhPT0dK1euhMFggI+PjywAX716FQEBAYiIiMD27duRnp6O0aNHQxRF7N+/3+ZrY+pnRkYGSktLZaXyB2Zb+1P5mtF//etfOHz4sBSyZsyYAUEQ8MorryA9PR2LFy+GTqdDp06dZP0QBAHBwcHo1KkTkpOTkZaWhp9++qnqf1wHcf36dWg0GowfPx4AMHjwYLi6uuLWrVtSG9MHqWnTpsnWvXHjBjQaDRYtWiTVdejQAT4+Pli5ciXS09Mxbtw41KtXD6Io2h2Ay8rK8D//8z8IDAzEnTt3ACgH4NjYWBiNRovnMb8Wz/Q3ZDQaMXnyZGRmZmLOnDkQBAETJ05Es2bNkJiYiPT0dHTs2BE6nQ6//PJLNV7FCvYc79988w1mzpwJURSxb98+ZGdn49q1a1af054APGXKFGzYsAFZWVlIT0/HxIkTIYqiLMibAnBoaCj69OmDjz76CImJiQgKCkLjxo1lZz1MmzYNWq0WU6ZMQUZGBhITExEcHIyoqChZkDAPwA0aNEC7du2wZ88eHDt2DDt27MCwYcNsftjlIH3PHGpsBawH4BdffBFarRZ//PEHgIoAHBwcjIiICHzwwQfIysrCxYsX7R4j8/Pz0aBBA/j7+2PJkiXIysrCBx98gEGDBknvN+bXAG/duhUajQbz5s3DkSNH8PHHH+Ott97Chg0bpDbm7zvXr1+Hv78/wsPDsX37dhw4cAA9evSAWq2WhWDTOBYREYH33nsPhw4dwqRJkyAIAhITE6t83UwBODExEV5eXtKX8zt27IBOp8OdO3csAnBBQQHGjh2LDz/8EMeOHcPevXvRrVs3+Pj44MaNG1K7vLw8+Pv7w2AwYN26dThy5Ag2b96MoUOHSm1iY2Ph4eEBg8GAZcuW4ejRo9KXfoMGDYJWq0VCQgIyMjIwd+5caLVauz9DEdG94dha++wfpMvLgYKCB1vu87rSGzduQBAEzJw50672/fv3h4+Pj2zW8bfffoOvry/69+8v1cXExFiE0H/84x/w9fWVvpHevHkzRFHEiRMnZO3mz58PZ2dn6dtx04f9ys9vTWlpKU6cOAFRFKVZz/LycoSGhqJ3796ytsnJyRAEQRaAR40ahcDAQIsZ5JiYGJs39qncT9NMWOUSERFh0U5pf0wfUpYuXSqr//XXX+Hs7IxRo0bJ6rdu3QpBEGTh3BSAa/KUrfLychQUFTywUpPXR7/11lsQRVG63i0tLQ2CIFhcgzt27FiEhobK6hYtWgStVosff/xRtm5SUpKsXZ8+faodgHNzc6HRaPDmm28CqJkAXHl2BACefPJJiKKITz/9VKr76quvIAgCNm/ebLOvSuw93tetWwdRFHH58uUqn7O6p0CXl5ejtLQU3bp1k50NYQrALVq0kLX/5JNPIAiC9EH+0qVLUKvVmDdvnqzdp59+CkEQpC+fAHkA/vnnny2OLXtwkL5n1QvARUXWx0Vrl3yUllpfp6ioWv/O9jAF4NzcXJSWliI/Px+rVq2CWq3GCy+8ILUzGAxwd3e3+KLS3jFy9uzZ0Gg0OHPmjNW+mAfgCRMm4KmnnrLZf/P3ncmTJ0Or1eLixYtSXVlZGRo3bix7LtO2zC/viIiIQPfu3W1uE/gzAN+5cwfu7u7YuXMngIqz1Uyh1zwAmysrK0NhYSE8PDywePFiqX7YsGHw8PCQ3uOVxMbGKn7pffbsWQiCYDGTPW/ePIii+MhdKkbkSDi21j77B+mCAkClerDlPr8tr24ADgwMVBx0YmNj4e/vLz3esmWL7Jvv0tJS1KlTBy+//LLUZsiQITAajRazpaYb6pgGH9OH/S1btlhst7i4GPPnz0eTJk3g6uoqu+uyadC8cuWK4jfPZWVl0Gq1sgAcHByM2NhYWX9KSkrw9ttvQxRF3L592+prY+rnqlWrkJOTIytff/21RTul/TF9cLh69aqs/qOPPoIoihanV5eWlkKr1cpmAwRBwOjRo632814UFBVAlaB6YKWgqOZmfZo3b44mTZpIj8vKyhAcHGzxhczx48ctTll/6qmn8Nxzz0mP33jjDWi1WotrqE0fTKsTgAFg9OjR8Pb2Rn5+fo0EYPNgPnjwYHh4eMjqiouLIQgC5s+fb7OvSuw93ms6AH/55Zfo1asX6tSpI/tCqWnTplIbUwBWuplQaGgoxo4dCwBYs2YNRFGUZtQqH9eenp6YPHmytJ75DHB4eDiaN2+OtWvX4rvvvqty3wAO0vehegE4Pt76uGjtJmxnz1pf5wHclMr8LtCCIECj0SA2Nlb2JavBYEDXrl0t1rd3jIyKikL79u1t9sU8AG/atAlqtRoTJ05EZmYmCgsLLdYxf9+JjIxUPHYTEhKgVqul8dG0LVNANxk0aJDsGLbGFIABYOjQoejduzd+/PFHaDQaZGRkAFAOwDt37kS7du3g7e0t+yxQ+XOHXq/HoEGDbG4/NjYWzs7OFl/MrlixQnFG3/RetGzZsir3jYjuDcfW2udQM8ClpaXVOgVao9Fg6tSpFvXTp0+HWq2WHv/+++/Q6XRISEgAABw8eBCiKOKzzz6T2sTExNj82SBTYDV92M/MzLTY7muvvQZnZ2csWLAAhw8fxpdffom9e/fKgkV2djYEQcBHH31ksX5QUJAsAGu1WsUZXEEQoFarFa8tNKnuNcBK+2P64GAeuLZu3QpRFGVB2kSv18tmhgVBwOuvv26zD9X1V5kB/uKLLyAIAmbMmIFbt27h1q1byM/Pl06hNQ8xRqMRsbGxAICvv/4agiBgx44d0vKXX34ZgYGBFttJS0u7pwB85coVuLi4YPr06TUSgM3/1mJjYy1mtQH5B8rqsPd4r8kAfPXqVXh7e+OZZ57Brl27kJ2djZycHPTo0UP22pg+dK5YscLiOdq0aYOePXsCqJgts/U+Y/r3BywDcF5eHkaMGIGAgAAIgoD69etbXNphjoP0PXPYGeCUlBTk5OQgNzdX8cwc0zXA5uwdIxs2bIgBAwbY7IvSzyCtWbMG7dq1g0ajgYuLC1544QXZGGf+vtOgQQOL+ykAwKpVqyCKIq5cuSLblvm18tbe38xVfr9KT0+HVqvFtGnTEBwcLI0V5gHYdF+GUaNG4eOPP8YXX3yBnJwcBAYGWozxU6ZMsbn92NhYhISEWNSbZnrNvywoKipSnBkmoprDsbX2Odx1Sj179kRgYKBdd50MDAzE8OHDLerNZ4SAilONGjZsCKDim98GDRrIlr/00ksIDw/HqVOnLGZMc3JypGsWbQXL4OBgxMXFyeoOHz4sCxbVmQHW6/UYOHCg1T7Zeo2qG4CV2ln74PDRRx9BEARkZWXJ6q3NAN9L2HEEEyZMUDwNXRRFiKJo8brMnj0bnp6e+OOPPzBjxgzp/01qegYYqLgUQKfT4cSJExYB+O9//zuCg4MtniciIqJWArC9x3tNBuC1a9dCFEVcv35dVt+5c2fFAFzVDLDpw/mhQ4cUj+nKH/jNA3BlZ86cwdixYyEIgsVNfyrjIH3PHG5stXYNsDlrp/PaO0a2b9/e4gwXc7Z+B/jWrVv48MMPERISgqioKKleaQbY/J4TQMVNr5RmgGsiAJeXlyM4OBgajUZ2zwbz12zIkCFo1KiR7HlKSkqg0WhkY3xQUBAGDx5sc/vW3kdNM8CVTwEHOANM9DBwbK19DjdIHzt2DGq1Gv/4xz8Ul+fl5Uk3vBkwYAD8/f2lG2sAFdcE+vn5WXwDnZGRId24xs3NzeKDZWJiIpycnHDu3Dmb/TP9vq5SYPTx8cH/+3//T1Y3bNgw2fVHpmuAe/XqJWuXlJRkcQ1wbGwsmjRpgqJ7mA2w1U9721n74GC6Btg87Jtmhg8cOCDVPa4BuLi4GP7+/mjfvj2OHj1qUVq3bm1xh+Xc3FyIooitW7eiXr16FncET09PhyAI2LVrl6ze9PNK9xKAf/rpJ+h0Ojz33HMW18n961//gkajwc8//yzVnT9/Hk5OThYBWOlvqKYDsL3He00G4CVLlkAURdn1kOfOnYNGo1EMwM2bN5etb/piYePGjQCACxcuQKPRyG7uY42tAAxU7LsgCHjnnXestuEgfc8cbmy93wBs7xgZHx8PjUYjjdNKbAVgk9deew06nU56bB6Ap0yZAicnJ9lxXlZWhiZNmqBt27YW26qJAAxU3MG9X79+sjs6m79m/fr1Q7NmzWTPs379eosxfsSIEfD09KzyGmCl91HTNcALFiyQ1Ztmhm39/jkR3R+OrbXP4QZpoOLnENRqNWJiYrBt2zYcP34cKSkpeOWVV+Du7o6UlBQAFTfUcXNzQ2RkJHbv3o3du3cjMjISbm5uFjeAMH1zGxISovghoKSkBNHR0QgODpbuFPnxxx9j6dKl6NatmzQTZ2vGdNCgQXB3d8eKFSuQnp6Ov//972jQoIFFsFi3bp1006C0tDSsWLEC9erVg4+Pj+x62StXriAoKAht27bFpk2bcPToUezduxfz5s2r8rpaUz+XLl2Kzz//3KL8/vvvVe6PtQ8OAKQ77U6aNEm6YzS7kwAAIABJREFUC7SHhwc6d+4sa/e4BmDTTc2Urq0GKmYCBUHAkSNHZPVRUVHS36j5DDvw512gTX9jcXFxCAsLgyiKOH78uM0+Wfv3nDVrljQzXfnv9Pz589BoNOjevTvS0tKwdetWtGjRAsHBwTU6A7xp0yZoNBocO3bMZv9tHe+VP2xXNwA3a9YMSUlJFiU3Nxf//e9/odVq0b17d6Snp0s/eRIeHq4YgMPCwtCnTx8cPHgQGzduRFBQEJo0aSKbtZ85cybc3NwwdepUHDx4EIcOHcLGjRsxZMgQ2d9D5QD81VdfoUuXLli1ahUyMzORlpaGl156CU5OTjh16pTV/eMgfc8cbmy93wBs7xh569YtNGzYEIGBgdJdoHfu3IkhQ4ZYvQt0XFwcJk+ejKSkJBw7dgxr165FQECA7OZ2SneBDgwMRKNGjbB9+3bs378fPXr0gEajQXp6utSupgOwPa/Z6tWrIYoiXn31VRw6dAgLFy5ESEgIfH19ZQH40qVLCAwMhNFoxNq1a3H48GFs2bLF4i7QSu+jQMV9FpycnDB37lzZXaCVTmEnoprDsbX2OdwgbfLZZ59h4MCBqFu3LpycnODn54fu3btj+/btsnYnT55ETEwMPDw8oNPpEBMTgy+//FLxOadMmQJRFNGhQwfF5Xfv3sXcuXPRtGlTuLi4wM/PD5GRkXjjjTekwdPWjOnPP/+MQYMGwdfXF76+vhg2bBi+/PJLxTtQLlmyBAaDAa6urmjbti1OnDgBHx8fvPbaa7J2165dw9ixYxESEgJnZ2fUrVsX3bp1w7Zt22y+fqZ+Wis5OTlV7o/pZiLWfmd08eLFaNKkidSviRMnWtyYSxRFzJkzx2ZfHZHptykrn8JcWUFBAdzd3S1meZcvXw5RFBEWFqa4nulvzPQ7wLGxsdi0aRNEUbQ54wJY//e8desW/Pz8oFarLf5O9+3bh4iICLi5uaFVq1bIyMhAly5d8Oyzz0ptbM0AK+2H+d+E6YN5VTPYgH3He3UDsLVj5N133wVQ8TvNpt8nbdGiBXbu3Gnx4fnSpUsQRRErV67E5MmTERAQAHd3dzz//POK1+pv3boV7du3h06ng4eHB5o1a4aJEyfKfrJJFEXpOr6ffvoJsbGxaNy4Mdzd3eHn54fo6GjpJjzWcJC+Zw43ttobgI1Go+KlBoB9YyRQ8TvA48aNQ926deHs7IywsDCMHDlSumzH9F5ksnnzZnTp0gV16tSBi4sL6tevj8mTJ8vGk+joaNn7DlBx1ky/fv2k3wFu3769LPxW3pZSAK5fv77N1wKwbwwzf83Ky8sxe/ZsBAcHw93dHdHR0Th9+jSMRqPFrydcvHgRgwcPRkBAAFxdXdGgQQPZzfCsvY8CFV9KzJ49W/Y7wHPmzLG4TIaIahbH1trncIP048p0w6Sqgi2RufHjx0On09l13Tw9XjhI3zOOrUREpIhja+3jIP0XlJeXh3/+85/Yt28fDh8+jOXLlyMkJAQNGjSwOmNIBFTM4ixZsgSZmZk4ePAgJk6cCI1GY/dPh9HjhYP0PePYSkREiji21j4O0n9BP/74I5577jnUqVMHTk5OqFOnDoYOHWrxe7tE5nbt2oXWrVvD09MTzs7OaNKkCd5+++3a7hY9ojhI3zOOrUREpIhja+3jIE1ERIo4SN8zjq1ERKSIY2vt4yBNRESKOEjfM46tRESkiGNr7eMgTUREijhI3zOOrUREpIhja+3jIE1ERIo4SN8zjq1ERKSIY2vt4yBNRESKOEjfM46tRESkiGNr7fNUqVS4evUqCgoKWFhYWFhYpHL16lUO0veGYysLCwsLi2Lh2Fr7XLRa7S+qin8EFhYWFhYWWfm/McJFRdXBsZWFhYWFxWpx9LH1f1Qq1TGVSlWgUqnKVCqVaLa8pUqlOqpSqe6oVKrvVSpVvB3P+aJKpfpGpVL9rlKp/qtSqfqZLfdWqVTbVCrVLZVK9atKpdqiUqm8bDyfi6riGwgWFhYWFhbz8igO0FWNrebsGRc5trKwsLCwPKzyKI6tNSZGVTFQj1RZDtI6lUp1XaVSzVOpVE4qlaqFSqW6qlKp/mHj+dqpVKo/VCpVX5VKpVapVC+oVKpClUr1ZKU2B1UqVbpKpfJRqVS+KpUqQ6VS7b3/XSEiInok2BpblVQ1LnJsJSIiqmGdVZaD9AiVSvWjWd3/Z+/Ow5sq8/aBf5PupbSl7PsqDJv4w2VkUXAZXEDUEUURRRl4R6ny2nFwROU1ZRdEEMQBZEQQR5RFVHQq4ja4gSiDDqIDggjaka2tCGW/f388Pc32JE1O05yT5P5cVy7as+VpE3rnOc82WkS2B7nOsyKy0mfbKhF5puLrliJyRlRl2nB2xbZmYZeaiIjIvnTZ6quFVJ2LzFYiIqII04X0EyLyD5/jelQclxXgOl+IyF98to0VkU0VX18r6q61r2MiMiCM8hIREdldKBXggVJ1LjJbiYiIIkwX0gtF5EWf435TcVyTANfZISJ/9Nl2l4j8p+LroSJSrDnvvyIyRLPdISJNxfp+8HzwwQcffNjz0VRUVthRKBXgUHKR2coHH3zwwUc0H3bO1oiJVgvwQAnvLnVTscFMaHzwwQcffNj60VTsqY9UrwW4f8XXzFY++OCDDz6i/bBrtkZMH/EP6dvF3BjgFT7bVop7nFKLiufxHad0WvTjlLJFuFZhpB75+fmWl4EPvjax9uBrY99HDKxVqMtWX8Fy0fjwwWy18YN/I+z74Gtj7wdfH3s+YiBbq80pImki0k9UUGZWfO8Q1cr7o4hMEDUVdhcR2S1VzwJ9VNR4pGRRyzQcEe+ZKl8XkSIRqSsi9UTkLRF5JcD1skUEZWVloOorKCiwuggUAF8b++JrY19lZWV2Delg2apTVS4yW22MfyPsi6+NvfH1sScbZ2vEDBM1S+Tpiofx9cUV+7uIWsvwiKglkcb5nP9XUUsveLpB1FqFR0Xka1HLNnjKFZGlotYqLBGRJRL4F8yQjiD+obEvvjb2xdfGvmwc0sGytbmIHBaRXh7Hh5KLzFab4t8I++JrY298fezJxtmaMBjSEVRUVGR1ESgAvjb2xdfGvhjSpjFbI4h/I+yLr4298fWxJ2ar9RjSRESkxZA2jdlKRERazFbrMaSJiEiLIW0as5WIiLSYrdZjSBMRkRZD2jRmKxERaTFbrceQJiIiLYa0acxWIiLSYrZajyFNRERaDGnTmK1ERKTFbLUeQ5qIiLQY0qYxW4mISIvZaj2GNBERaTGkTWO2EhGRFrPVegxpIiLSYkibxmwlIiItZqv1GNJERKTFkDaN2UpERFrMVusxpImISIshbRqzlYiItJit1mNIExGRFkPaNGYrEQW1eTMwbBjQti1w6aVWl4aiidlqPYY0ERFpMaRNY7YSEUaOBFq10u8TcT+czsDHDB9ec+UjazBbrceQJiIiLYa0acxWojj32GNAaqq7Ert0qf8xDRqofTpLlwL79gV/jlq1gAUL/Ld36OBdgd66NbyyP/WUqpwPHAhMnKg/Jj0d+Nvf/LePGwekpQHZ2ern277d/5iSEqC8PLwyRcPHHwPz5wOFhcDChfpjOnQA5szx375zJ9C0KXD22cAll+h/7kOHVMt+VZit1mNIExGRFkPaNGYrUZy77jrvSmigClVNWLJEdZ3OzFStx8eP+x9Tty6QkqI/37PctWrpj0lKAqZN898+caI6JyVFPfeuXf7HtGwJOBz66zZqpM7Py1MVcJ1zzwVefdV/+4oV6rzcXFUB/+QT/2NmzwY6dtRft00bVea0NKBHD/0xhYXAp5/6bz96FPjoI+C114Bnn1WVXV/vvacqxzrTpgHXXw+MGAHMmcNstRpDmoiItFgBNo3ZSkSWuuce4M479ftOnKjZ596+HfjHP/T7WrZUFdCkJFUh1alfH5g3z3/7668DjRsDzZqp6+haWz/+GHC5zJa85rz3HjBzJvDII8Ds2cxWqzGkiYhIixVg05itRESkxWy1HkOaiIi0GNKmMVuJiEiL2Wo9hjQREWkxpE1jthLFoeTkwGNbiULFbLUeQ5qIiLQY0qYxW4niUKdOavwpUXUwW63HkCYiIi2GtGnMViIi0mK2Wo8hTUREWgxp05itRESkxWy1HkOaiIi0GNKmMVuJiEiL2Wo9hjQREWkxpE1jthIRkRaz1XoMaSIi0mJIm8ZsJYojw4dz8iuKHGar9RjSRESkxZA2jdlKFEccDkDE6lJQvGC2Wo8hTUREWgxp05itRHFEBHA6rS4FxQtmq/UY0kREpMWQNo3ZShQnNm9WFeBBg6wuCcULZqv1GNJERKTFkDaN2UoUR4qLrS4BxRNmq/UY0kREpMWQNo3ZSkREWsxW6zGkiYhIiyFtGrOViIi0mK3WY0gTEZEWQ9o0ZisREWkxW63HkCYiIi2GtGnMViIi0mK2Wo8hTUREWgxp05itRHFABGje3OpSULxhtlqPIU1ERFoMadOYrURxICcHGDvW6lJQvGG2Wo8hTUREWgxp05itRESkxWy1HkOaiIi0GNKmMVuJiEiL2Wo9hjQREWkxpE1jthIRkRaz1XoMaSIi0mJIm8ZsJSIiLWar9RjSRESkxZA2jdlKFMMaNQL69LG6FBSvmK3WY0gTEZEWQ9o0ZitRDBMBkpOtLgWF7Z13gLPOAvr1A+68E9i50+oSaTFbrceQJiIiLYa0acxWohg1daqqAN99dxSe7JxzgHr19PtE3I/MzMDHXHed//YuXbzPX7bM/5j27QGHQ3/dlBT3uVlZ+mPatQOmTfPfvn8/sGgRsHEjUF6uPzeY48eBTz4BZswA5szRH5OaCtx+u//2Dz5QzfctWwK5ucDHH/sfM28e0LWr/rq7dwNHjoRf5jAxW63HkCYiIi2GtGnMVqIY1bixqvdV28CB3pXQffv8j6lTB0hK0p/ftKmqxOXlAQMG6I/p2VO1evr67DNgzBjg4YeB++4DSkv9j3n6aWDQIP11L7wQaNAAqFtXfa2TlQXcc4//9nHjvH9u3ULKf/pT4Ip1rVruc3Nz9cdMngxs2qTfV5X164EHHtDvM158hwM491z9MV98AZSUmHvuCsxW6zGkiYhIiyFtGrOVKIaF1XApAtx0k//2iy9W+5xOID0d2LEjYuWzvcOHVevr/PlAcbH//mnTgFat9Odu2mRd1+UjR9TNg8WLgVWr9Mdcdhnw7rv+23/4ARgxQt10mDMnaCWZ2Wo9hjQREWkxpE1jthIlirw8YOFCq0tBVvvxR+CRR1Ql+JprgP/+1/+Yt94C7riD2WoDDGkiItJiSJvGbCUiIm979wIffMBstQGGNBERaTGkTWO2EsWrgQOBDRusLgXFMGar9RjSRESkxZA2jdlKFK9E1EzDRCYxW63HkCYiIi2GtGnMVqIYM3asqtuuXx/koMJCddDcuVErF8UfZqv1GNJERKTFkDaN2UoUY958U81nFVS9ehFaI4kSGbNVaSAifxeR/4rIIRH5SEQuDnJ8cxF5XUR+EZF9IjJHRJJ9jskXkV0i8quIbBKRiwJciyFNRERaMRDShSLyo4gcFpH3RaRzkGPPE5F3ReXsPhFZKSItfI6pKjtDyV8RZitRfNqwQY0BJqqGGMjWqFgpIh+ISJ6IOETkT6LCNVdzrENEvhSRRSJSS1QYbxGRmR7H3CgiJSLSW1QwjxL14aCp5noMaSIi0rJ5SI8Rkd0i0klE0kRksojsFZFMzbEOEflZRJ4QlYu1ROQlUTecDVVlZyj5a2C2EhGRls2zNWr+JSL3enxfS0TOiMj5mmP7iMhxEanjsW2gqJBOrfj+XRGZ4XPeFyLysOZ6DGkiItKyeUjvFJF7PL5PEtUqe6vm2FwROS0iXT229ReRIx7fV5WdoeSvgdlKRERaNs/WqLlFVPA2EpEUEfmLiPxH1B1tX6NFZJvPtsaiKsxdKr4/JCKDfY6ZLyIrNNdjSBMRkZaNQzpbVO791mf7WyLyeIBzZovqspwhqkK8XESWeOyvKjtDyV/P8jFbiYjIj42zNapaiMibokL0hKixwD0CHPuIiHzisy294tyeFd+fEpErfI6ZKiJrNddjSBMRkZaNQ7qZqNzr4LN9mYgsCHDOxSLytYicFJWTm0Skvsf+qrIzlPw1MFuJYkhyMjB1qtWloERh42yNGoeIfCcifxORHBFxiupSVSoiZ2uOD3YH2pj8gy3ARERUbTYO6XBbgNuJ6r78R1E9rTJETaC1o+JrEbYAEyWkggI1sfO4cVUc2KED0LBhVMpE8c3G2Ro1eaLCs5vP9s9FTfDh62IROSZVjwH2/QDwuQQZA5yfn4+CggIUFBSgqKjI6vcFERFZpKioqDIP8vPz7RzSujHAP4t+DPDvRU1w5am2eM+3UVV2hpK/BmYrUYxITg5xZaO0NMDhqPHyUHyKoWyNmn+L6rJVW1SL8AARKReRSzTHOkRNmvWsiGSJ6j69WbxnoRwk6k52b1F3uu8WNas0Z4EmIqKQ2fwu9Z9F5HtRvZ8yRGSSiOwR/SzQLURNeDVCVEU5XUQeFZEyUb2vRKrOzlDy18BsJYoRDgfrtRRdNs/WqGkrIq+IunNdKiJficgfKvb1FhXAzTyOby4ia0Tddd4vIk+KCmtPo0R9MDgiapxT7wDPzZAmIiKtGAhpl4gUi1q3931xDwVqLioje3kce7mIfCyqknuw4njfbKwqO0PJXxFmKxERBRAD2Rr3GNJERKTFkDaN2UpERFrMVusxpImISIshbRqzlYiItJit1mNIExGRFkPaNGYrERFpMVutx5AmIiIthrRpzFYimysvD+NgESAjo8bKQomF2Wo9hjQREWkxpE1jthLZXMjLHwHqQK4BTBHCbLUeQ5qIiLQY0qYxW4lsrrAQOO+8EA6cPl1VgJ98ssbLRImB2Wo9hjQREWkxpE1jthLFi+nTAafT6lJQHGG2Wo8hTUREWgxp05itRESkxWy1HkOaiIi0GNKmMVuJiEiL2Wo9hjQREWkxpE1jthIRkRaz1XoMaSIi0mJIm8ZsJbKpu+/mkF6yFrPVegxpIiLSYkibxmwlsimnM4zlj154QU0XTRRBzFbrMaSJiEiLIW0as5XIpkQAhyPEg9PSwqgtE4WG2Wo9hjQREWkxpE1jthLZUHm5qs927x7GSZs311h5KDExW63HkCYiIi2GtGnMViIi0mK2Wo8hTUREWgxp05itRESkxWy1HkOaiIi0GNKmMVttYv161eV1/Xr/fa++Gv3yEBExW63HkCYiIi2GtGnMVpv48ktVAe7Y0Xt7WZnaLqKWxSEiihZmq/UY0kREpMWQNo3ZGiVJSe6KbLiT9dav7z4vJ6dmykf2UVIS5gkZGUBWVo2UhRIbs9V6DGkiItJiSJvGbI0Sz8qvmUqs0RL84ouRLxvZiwiQmhrmCSGvl0QUOmar9RjSRESkxZA2jdkahpISoKAAaNJE3x25bl1VFyktjX7ZKH4MHQqMGxfGCSJAgwY1Vh5KXMxW6zGkiYhIiyFtWsJma6BupiKA0+m/ffNm71ZcXTfmJUvUubt3R7aswaxbpy8vJYht29SbcepUq0tCcYjZar2EDWkiIgqOIW1aQmXrpk1Vj8MNtq9uXeD664Fdu2qsiGGrXVuV95NPrC4JEcUbZqv1EiqkiYgodAxp0xIqWz0rv7m5VpcmchLk5SOiKGO2Wi+hQpqIiELHkDYtobJ19WrVZTgRJMhLSkQ1iNlqvYQKaSIiCh1D2rRqZ+ubb6oJaAONQ61fHzh40PTlTTGz1FC8MX4HV15pdUkoVDk5XOaK7IXZaj1WgImISIshbVq1srWqSaF69VLbr7uumi+wyXIlsrPOMr/uMEXfkCFczYjsh9lqPVaAiYhIiyFtWpXZ+u23aqIlHWPG5I8/DvzazJkT+FwRYOTIMF5oHzfdpB4UmAiQnh7eOb/8AkyfDvTvr1+O58cf1XV1r+1llwHJyUBmJtCwIXD4sLlyx6Nly1RFV8f4/3DzzWFc8LzzeHeDahSz1XqsABMRkRZD2rQqszUnR33GfuaZyL5mVbUeB5OUxNbN6gplJuxAx/zyi9p+7bX++5xO73N1FeBQnzsrS39Mq1bAiy/q91lt+3bg4ov13f4djsA/9969Jp5s7lx1l4GohjBbrccKMBERaTGkTcsWEWRmlgWslBw4EPnKr6fcXNViGGifriJhlDU1tebKFe/S0tRDp3dv1VK5dKmq7EZa9+6B622h3BgRAZo189+ekeF97tix/sdkZwe+bnKy+9zsbP0x7doBU6b4b+/Uyfu5hw/3P8ZUJZfIQsxW67ECTEREWgxp07JFBCKBK8BWGTlSlefss60uCcWK2bOBRo1Ul/3UVOCrr/yPadEi8DjbUCvftWr5b581S3X77ttXtQITxQNmq/VYASYiIi2GtGnZIoJRo+yZrYsWWV0CIqLExWy1HivARESkxZA2jdlKRERazFbrMaSJiEiLIW0as5UoFg0apAZTE9UgZqv1GNJERKTFkDaN2UoUi4JNKU0UIcxW6zGkiYhIiyFtGrOVKBaJBJ7NiyhCmK3WY0gTEZEWQ9o0ZitRLBIB6tULesjq1WrG6vLyKJUpXuzfD5SU6PcdPgwcPRrd8liI2Wo9hjQREWkxpE1jthLFom3bgF27gh5i9JIWAZ5+OjrFiimff64WvG7XTt0pcDrdv7CbbtKfc+21an+LFsDLL0e3vBZgtlqPIU3kadUqNQlGhw5Abq5a9NAz7XSP1FT1h55JSHGGIW0as5UoDpWUqNhPSnJ/BOjY0epSWeDw4cD7Ond2dyVPTVWLSF92mVpQOtB5hw8DgwcDaWnq3JQUoH9/4ODBmim/xZit1lMhHezDvfEmzskBrr8eOHCg+q/8okWqwpCSEvx5g5Un0F0kqjnPPAO0agUkJwd/fZxOICMDaNgQ6N0bmDgx+B/LSPn0U2D0aODii4HWrVUFNi3N++5jtB9JSeqP/+jRCdW9h+IDQ9o0VoCJ4lCdOiraN28Gjh1zV4SdTiAu/7svWwZcdJHqFp6S4t0gsHGj/pyTJ6v3nGvXqjqC8TxxWAlmtlovtApwrDwcDnXHiMLz44/q95adXXVrZ7w9nE4gPR2oXx845xzgrrtU9x0zCguBZs2qvkHg+X7NzQWuuUa9BkQ2w5A2jRVgojhkxLen7t3d2ydNsqZcpp04Abz7buD9ng1VTieQlwf06QM8/njND4I+fly1GschZqv1Qg/pb78Ffvc7ICurehWOtDSgfXvVClwdPXuG97w9e4Z3/ZIS4MEHgU6dgNq1w29FbNgQWL++ej9jJJSVAQMGqEqe2dfM4VCV4/79w6+obd8O3HuvqlzWq6e6w0SiRdbpVBXNWrVUC2vXrqrr8vz5wM8/18zvsjqWLVPvJaN7T6AHZ9UgG2FIm8YKMFGcGTRIxfTw4f77li51x3irVtEvW0iGDAGaNNEP7QrkxInolS9cRUVWl8A0Zqv14i+k+/e3fytm8+bAl19G7meeO1dVLs2UJTkZaNNGdW8ma3z2GfDb36rXo0MHq0tDVIkhbVr8ZStRPNu2TWXw6tUBD6mqrnjsmHeD6b59NVDO6jA+Gzscapha69aqUhyoK7OdHT3q/lm6dwe2bLG6RGFhtlovcUJ66NDQWh4dDtVK17gxcPXVwHvvmXu+L79UFd1wW1rbtwd27/a+1tatQJcu3rMuhPrIzgbGjav2r4+ioKp0JYoyhrRpiZOtRPFg7lyVvwGW6Vm/Xu2uYoUkAGoaEiPOCwoiXE5y27FD9e40PttnZan5Vk6diujTnD59GkdPRHYOF2ar9RjSVigqMt9i6/tISVETTfE1jH0ZGawAk60wpE1jthLFkdTU8EYprVnj/pjWoEFky3L8+HHt9pRxgvNHCDIfEjR/ornf/rU71kJcgm/2f+O3b8ALA5A+IR2ZkzJR97G62us/veFpLPx8oXbfzctvxuWLL8dFz16EKf+coj2mxcwW2LjXv7V51der0G9JP9zzxj1YvHkxjp/S/3xBzZjh/lzdp0/YpxcfLsa679Zp93V6qhOuX3Z9+GUKgtlqPYa03SxZ4p5m0GgVbtoUePVVq0tGNW35cvWaX3qp1SUhAsCQrgZmK1EcMT6Ohcu4ry2iGiyDeeXrV3DlkivRdlZbNHm8ifYYh8sBp8vpv2PIEPzvFYJHLhH89q4UjH5jtN8h3+z/Bs2faI7SI6V++3ou7AmHy1H50EmbkIbUCakByyUugbgEZz15lvYYp8uJ5VuX+23/33/8L5yFzsrzjx73b2194O0HcMvyW7TX9VJcDOzd67f58PHDOL1zp5oPp3Fj4LzzgFtuwUMPXYjkR1XZkwqTtJf8z4H/4NDRQ37bj544igfWPoA3/vMGyo6F97ee2Wo9hjSRnZhNWaIawJA2jdlKFCe6dlXRPHeuufMHDHBXgu+8M/BxaRPSKiuB4tL3BpvywRQs+nyRe8Px42oyUOOzw9at5gppE6cCdF/+/bLfo/v87tp9GRMzkDo+FTlTcjDi1RF++0vKSyAuwVffrgfGjgUGDlTDCuvWxfd5Sfi0iWB3r7Nx+vRpfaGOHNFu/vnXnzHi1RFoN7sdnIVObct6IMxW6zGkiezEWEKJyAYY0qYxW4niRCSm5zDGEIuchtzZE2PXjvU7JlDX5oAWLHAXrn376hUwhg1dORTd53dH0xlNMXy1ZopuABv3bsTJ0wHWJy4vVy3HgSQnq5VdHngA+Ne/gDNn/A7ZW7YXp8/4V6C/+OkLfPD9B37bma3WY0gT2cm4cSrMRo60uiREDGnzmK1EsWLXroCTXxlzY3XrFpmnys4G5JJHIE02VH/y5Y4dVeGqu6woBbdlC/DSS2rG7Fq11O99wgRg584qT33hyxcw7cNpftuZrdZjSBPZjYia1ZDIYgxp05itRLGidu2ATbzGykGh2rhnI5o83iRoN+aFyX43AAAgAElEQVRbb3U33N5wg5kCxxlNi6pt/for8OKLwDXXADNnmr5MaWkps9ViDGkiuwk3cYlqCCvApiVstp4M0MuQyLYCZG5Jidqclhb6pZIKkyorv4FmUwbUUF2jElyrlplCx4CTJ4GPPwYeegjo1w846ywgN1dNqW38zo1HUpJaxqhVK+CSS4D77wfWro34kkZ2wQqwWw8ReUdEfhGREhH5MMixuSLygoiUisghEXleRHJ8jhkkIttE5IiIbBWR6wNcK2FDmsi2br5ZBcLUqVaXhBKczSvA74vIaVHlKxWRgVUce9Lj+DOiMtfgEJElInKiYv8xEZnoc42OIvJ9xblnRGS3iLQP8HwJma3BVuxzOoEmTVTjCZGtBJh8sm5dtWvDBu/tx44dQ73H6mHhJv8lgXbs24Fjx46F/NSeK2K+806Ag44fVw87OXxY/WceORK48EKgWTNVgU1O9q/ceq5qkpysjmvaVJ33hz+otXsvuwxo3Vq1xicl+Z+Xmqp+WV27AoMHA3PmAD/8YPVvQe/LL1XT/sqVAdfNsnm2Rk0PUZXeW0UkTUScInJ+kOPfEJG1IlJHRPJE5G0RWe2x/7ciUi4i14lIkoj8XkSOikh3zbUSMqSJbM9Y45nIQjYO6TUickpErhGR2iLyUcX3dQMcv0PUDeOeojI2Q0TO8dg/U1SlNl9Ubs4Q9XPfXLHfISJlIvKjiDQWkeYi8l9R2a2TcNm6enVklrbPyVETtRJFTevWwKBBfpsDTX415Z9TIC7B+fPPj8jT33uv+7lq1wYOHvTYOXu2e0e4SktVZeyVV9Q6ufffD9x2G3D11UDPnmom5DZt1J2punXVAOWMDFXZTE5Wd60cjsAVWl0lNTcXaNdOtfiOHatm/zLbLaS4GJg3T429PeccoH591RwfqPW4ZUugb1+goEAtHfr990CgmZ1r0o8/Av/3f+r3kJ0N3HGHas32+D3YOFuj6p8iMj3EY1uICukuHtvOrtjWrOL7Z0Vkpc95q0TkGc31Ei6kiWICu0GTDdg4pE+KyMse36eIysG5mmNri6oc/z3I9faJyFc+2w6I6kklInKpqN/DRR77r67Ypmt5TrhsNT6Lrl4d+JjNm4FOnfwbeEJ5EEXTsGHqfXfzzdF5vpISIC/P/X5v0gQ41aKVe8OyZaFdqLgYaNvW/B0oo8KblKRuwqelAZmZqiJXr57qojxokKqY79lTs7+UYE6dAt57T83MHKz12Oh+kp4O1KkDtGgBnH02cOmlwC23AH/+s/pZXn8d+OabyI7hOHMG2LgRuO8+tfZww4aVs03bOFujJkNUMD8mIhtEBe5nolptdQaKas31dUxEBlR8/YWI/MVn/1gR2aQ5L+FCmigm9OhR9adJohpm05BuKqpMw322G/np64qK438V1QX6lIh8J6q3lOGIiLzpc973FdtFVMswRKShx/72Fdv+qnnOhMrW3/42chXVkhLVeJSezkowWceq99z27UCjlP34q/wRv0om3nBcXXX35+PHVYuuZ8uowwH06aO6KW/cqFqDE8np08Du3cC6dcD8+Woc8h13AFdeCZx7rmr5rl9fVe4DdbnOyVFdtTt1Aq64QrVmm+2KfuqUOr9iwi+bZmtUNRV117pYVBdlp6jxusfFO5wNQyuO9fVfERlS8fUOEfmjz/67ROQ/mvMSKqSJYkZ5ufpDnJlpdUkogdk0pM8TVaYrfbbvFneLradbReXshyLSSFTW/lfUzeTaFcccrHicLSLJFeecFjUmWETkNlGtzotF/S7yRGRFRTmWaZ4zobK1pioLJSXue4EBhmkSRdzmzer9lpdnwZOPGgWI4KQkoa+8U/neHzhQc+xtt6nWTc/KW8eOPn2oKWT79wMffggsXgwUFqrxzQMGqDt8v/mNu8J8xRXAY4+pGwsmJ+myabZGVbaoYJ7ss71IRKZojg/WAty/4uuwW4Dz8/NRUFCAgoICFBUVRfgdRUSmsNmDLFBUVFSZB/n5+XYM6XBbgK8RlbP9PLb1rbiGZ8+ptaJuFB8QVan9QlSrsYjK3nJRw4t+EtU6PKriGnM0z5kw2ZqcHPnKQrAemqmpkXseIp20NPVeC7A0cMQcO3YM/V/oj+TxyZUzR9e/XzCvuyDrYSeyJmehTv4VkDo7IHIa4jiJaT2Wq/8Env8pGjZUa9VSzTpzBvjqK9Vl+rrr1HjnnBx1d2LWLDXeOsiY4xjI1qjbLqFXgFuIuivtOwb4tKgPBSJqDPAKn/NWCscAE8WW1q1VuG3bZnVJKEHZ+C61bgzwadGPAW4mVVeAdblZIiKfV3yty95BFdfopXnOhKgAHzoU2n26669XwwlD7dJs7K9VS80j43teTk5kfw5KYM2b+w01CtbbYO6GuVi/a73pp5v0/iTUmlSrssJrPJyFqsKbMj4FDpfDa1/OXwQ3/K4lfpf1HNLlKG7Imo27LmqIhvcLHC4HUsanIGdKDto92Q5XPX8Vnvj4CRw8zFbgGnfqFLBpEzBtmupaXauWaiW+6Sbgr38Fvv3Wa41jVoD9jRZ1R7mbqJkmjVbe8wIc/7qoCnJdEaknIm+JyCse+39bcf61orpyXS9qHBNngSaKJcYihJb0wyKydQX4dVFjeQeKWhHhQwk8C3SDiv3/rPj6HFGZe1REsiqOuVJUC++1Fce8KqrS3MfjOu+LyLqK5+gjalbo7wKULyGy1aiQ/uEP+v19+wafayfc5/H8ukWL6pefEpwx1Khfv8pN552nNj35pP4UcQlkXBLatgVCWe1o/ffr0WRGE78Kr7gETWY0wfrvA1Smt2xRLbsVb/jTIthdx4le5/0Jkv0DxHkc0nE5ZEw97bU9H7Un18Yty2/BkRNHTPySKGQnTgAffQRMmKDWMk5LU2OIb7sNWLRIzUpdwcbZGnV/EZEfRAXqJnHflW4uIofF+w5zrogsFbXuYYmotQt9f4E3iBoLdVREvha1JJJOQoQ0UcxiN2iykM1D+n3RrwN8QcW2uyq+byGqa/Txiu3GJFjnelzrHBHZ63G9MvHvYj1BVCUZFcdtksC/l7jP1vvvr/rP065dquX3xhur/3zGHD6lpe7nveCC6l+XyFOVvRNcArn67srjxo3z3l92rAznzz8fzkKnX0W01qRamPz+5MAXP3gQ6NzZfwbjIUP8Du3WzX1IerqaPMuwpXgL7n/rfpw//3xkTsz0K0f25GzctvI2Vohr2tGjanHnhx9Wk5QlJ6vJt0aMQNnChXbO1oQQ9yFNFNOMdRFqejASkYbNK8B2FvfZanz4/u676D/37t3u5x88OPrPT/Fp0SL1nurUSb+/pLwE8qgD0ngDMjLc78GkJv9C2oQ0v4pm8vhkDHhhAI4Fayo2/kZ4jut1OFSFqYoZh48fV8slGafl5QGHD+uP3X9kPwa8MEBbIc6ZkoM7X7mTFeKa9ssvwJtvAn/+M8q6dWO2WizuQ5oopm3bppKtdWurS0IJiBVg0+I6Wxs0cDdOAWqJ0Gh3VCkqcn/wf/DB6D43xSdjQuVASspLkHZNASTpCHKn5KoK5O+HQPoVQFxqPG6HOR2wY9+O0J7QWK/XeOL69SvXiQ3HwYNqCVzj/0PbtlWv1vNT6U+48vkrtRXi3Cm5GPnaSJw4cSLsslBomK3Wi+uQJooL7AZNFmFImxbX2er5J2nePOv+RM2f737uJUui//wUP4zhwCkpVR+bPTm7srJYZ2odLP3X0vCf8N13vbs6d+0a/jV8bNni3ZDcq1fo5+4u3Y3fLfkdMiZmeFWGHS4H6kytg/w38hOuQnzy9El8X/I9Ptz9Id78z5vYU7YHpeWlOHXa3NJHnpit1ovrkCaKC5mZKs3Ky60uCSUYhrRpcZutxofrzp29v3/++eiWwxgT/L//6y7DevOT81KCM+abCuU9ZFQOq8Wz8tuxY/Wu5ePll72XB9auIVyF3aW7cclzlyB9Yrp/1+7CZKROSEXmxExkT85GvWn10PyJ5mg/uz26z++OS567BDcsuwF3vX4XXO+5sPDzhXjnu3ewp2QPTp48GdGfNZDTp0+j+HAxNu7diNXbVmPeZ/NQ+H4h7nnjHtyy4hZc+fyV6LGwBzrP7YyWM1uiwbQGyJ6cjbQJaUgqTPL7mX1n5s6anIXGjzdGhzkdcP6C83Hp4ktx3bLrcNuq25D/Rj7GrhuLyf+cjKc2PIXF/1qMV7a9gnd2voONezfim/3f4Nu93zJbLRa3IU0UN958U6VYjx5Wl4QSDCvApsVltq5bp5+ROTc3uuWYOdN7gvwBA9xl+eGH6JaFYtTdd3vNrxFOLwZxCVLHV70gdd++AWaK7trV/YRnnRVGocMzc6b38mMek12Hbcf+Hbj42YuRMyUHeVPzkDU5C+kT0pEyPgVJhUlwuBx+lcRQHw6XA85CZ+U1qnOtQI+kwiSkTUhD7cm1UX9afbSc2RKdnuqE3z7zW/Rb0g83L78Zo94YhUfffRRzN87Fqq9X4dM9n2JP2R6cPK0q7adOn0JpeSl+KP0BW/dtxSd7PsFbO97Ciq0r8OwXz+LJT5/EhA8mYMzaMbjr9bswZOUQXPP3a9BnUR/8v3n/D+1mt0OD6Q1UK/uDwmy1WFyGNFHckTDXDSGKAFaATYvLbPVs7W3VytrRGb6tvl26uLcZrcNEAXkMXDfqwr//fdWnrf56NcQluHn5zUGP27jR/X4sKPDYsXmze0ebNtX4AUK3dKl3RfiSS6LytJXKT5ZjS/EWrNy6EjM/mYk/v/Vn3LbqNly99Gr0WNgDfRf1xXUvXocbXroBN718E25ZfguGrhyKYauGYfjq4Rjx6gj88fU/Iv+NfIx+czQKigow5q0xeHDdg3jknUfges+F8e+Px+R/TsZjHz6GGR/PwNs73sbOQztx/GQVg6EtcuDQAWarxeIypInijpFeRFHECrBpcZetl1+ub/21iuf4X0PjxtaXi2KEw1H5RgnlPTN89XBkTsxEvWlq3d0zZ85U+RRPP+29VNGxYx5P1qRJBH6I8KxY4T9GOMGG9doGs9V6cRfSRHFp+nSVWDcHv+tMFEkMadPiLlt9KwnXXqvWAraS8WE+M9O9rVYtVoIpBGlpQGZm5UILOTmBD3U4gPQhg7261IajXj31HC1lF3ZLM6BRo2oWvnrWrFEVcuP/yfnnsyIcTWfOADt3MlutFnchTRS32A2aoowVYNPiKlvT0tSfn1q1rC6JP+ND/IoV7m1JSawEU2iM9XwPHdLv795d7R86VH0vLoGz0Bn283yZeg5uk8WoK/urUdrIWrsWXusZn3MOK8KRcOYMsG+f6gb/8suq/SI/H+jfX00eqG7SMVutFlchTRTXqlqkkCjCWAE2LW6y9dAhe1cmV6xQZUtK8t5ulNmu5SZ7qOq+sud7aFvxNohL0OOZMCekNMYbN2qEVavMl7Wm/POf7sUmRIBOnVgRDubMGeDnn4ENG4CXXgIeewwYNQq4+mr1uzN+l/XrA+edBwwaBPz5z8BTT6nW93//G/jxR2ar1eImpIni3siR6q/quHFWl4QSBCvApsVNthofim+6yeqSBPbll/rtRtnZcYZ0evZU74/CQv3+tm3V/jFjKr6f1RbiEpSUl4T+JLm57tqQzW3cCGRluf/ftG8PHDlidamss20bMGMGcMMNqpv4VVepFauMVvMGDYALLgBuvFG9R+bOBd54A9i6Ffj11+DXZrZaL25CmighiADJyVaXghIEQ9q0uMjWiRNjvxXVKH9KitUlIbup6r3tu99YmidkdeqoC9StW+Wh2uWSLPLVV+5GaxGgdev4rgj/9BOwcCFw++2qG3idOu4Od0lJqqLbo4ea1OzNN4Gvv666glsVZqv14iKkiRKGx8yVRDWNIW1aXGSrZzdiEeC776wukTlG+bOza+b6r72mPiBfdpmaHOz224H77lM3EBYsUN20P/sM+OWXmnl+ClNJCV54Qb0n2rXTH9Kggdr/5JPubcaatSExZr4K4e7LsWPue9tPPBHizxAF33zjbsAWAVq0iO0lxg4fVv8X8/PV/9eGDdXv3OglkpsLdOsG3HabmmV+z56aKwuz1XpxEdJECePSS9Vf6xdesLoklAAY0qbFfLZ6rvMb663AgPtnaN48/HNffVWdZ7QKWfnIzAT69AGKiyP+K0ocInhUxkFEjefU6dBBzTIOVEx85XJCXIK2s9pWfX2j9mzMxtahQ5Wn+P5/69IFOG6TJWx37FCN2J5DCjIzVRfxm28G3nnH6hJ6O3ECWLcOePBBdVOqeXP3RH5SMZlfhw7A9dcD06apMbnRxmy1XsyHNFHCEVGDUIhqGEPatJjPVt+K16ZNVpcoPL4tVaWl7p/l3HO99734ItC0qbuDTTiP5GSga1fg3XdV98hnnlEtv2PGqGkbbrgBuOIKoHdvNY6wc2fgrLPUh/KmTVVdKS9PLcOTlaU+nKelqcqX2fK0aqVasEiv/JZhyJaSkEcTGS2/4hJsK94W/GBjMWrPWaXCMHy49+vesWNYp9eon35SLadNm6r3qO79mZKiWlb79AFmzlStrpF06hSwZYsamztkiPo/1ayZ+r9jtOYaj/R0oGVLoF8/4JFHgPXrgZMnI1ses5it1ov5kCZKOPHQHEMxgSFtWkxnq+8H27POsrpE4Qn0J3L3bnMVyu7d1cQ2dvHqq6oinZIS/s+TlgaMHm31T2CtJk3U7+LNN6s+dvXXq0Nf/7dpU3cTo1EbKyoyVcYtW9RY1CFDTJ0eVRs3An/4g6qsZ2Xpe0okJakhCF27AvfcE7jVdedOYN48dSOgVy91Myc7W/9edzjU9pwcdVzv3sCIEeomVEkY85RFwolTJ7Duu3VY/K/FmPTPSRi1ZhSuffFanLfgPDz8zsN+xzNbrRfTIU2UkDp0UH/9N260uiQU5xjSpsVstm7a5P9BM9Y0bx647OvX+7dYnX9+ZMf7GS24fftaM+738GHV8pydHVorcnKyOj5RhPO+XvDZgsrW36AV4BYt3C2/w4apr5s1i0h5Y9X+/ao3RM+eaki0bwutUYlNTta/T5OTVYW6WTM12/LQoapV+auvovcznDx9Euu+W4e/f/l3PL3xaXx74FvtccdPHUe72e1w8aKLMWTlEIxZOwazPpmFFVtXYNt+/14DzFbrxWxIEyWs8nKVDjk5VpeE4hxD2rSYzdZYr/wajPLfemvNXP/ZZ6t+bt3DDkaP9h4TqXs4ncBFF1V/tlu7KShQP99VV4V+Tnl5OcQlqDetnv6A1q3dfW6BiL/Yo9aMQq+/9ULXuV3RZlYbNJreCNL5RUjDzbj0Uv05HeZ0gLgEqeNT0XpWa9z3j/tQesQeM1idPAmsXKnG4LZsqcYS33ADMGEC8OGHqpuzldZ9tw6d53ZG7cm1K298tJjZAlctvQrrd6+PyHMwW60XsyFNlNDs9GmK4hZD2rRsEcGoUWVYtgw4cMDqVzI0117r/aclVmd9BrzH/EbSlVe6r9ujR/Bjly4FGjXybt0KxJgvyehBO3JkZMtdlccf914DVvdwOIBOnYCff45u2SLJzEIKg14aBHEJVn+92n+nsViwUfkFgM2bgTVrgl5zX9k+XPy3i5EyPkVNslXoDHisZxfsyscfLoD8ZmXla5OVBXzwgfucfov7IXV8qlfrtfG47x/3hfcLiDOnT5/GZz9+hrJyfd3nvV3v4dz55+KPr/0Ry7cux+HjER7IDGarHbACTBSLGjZUqcepQKkGMaRNyxYRiJSFPUazqkfjxjX3ehvPcehQzT1HNHXpErlKcI8e/l2nIylYV+W2ASYeNmIg3NbmlBSgf/+qy/Tii2qCrqpaij/6yNzPHG27tpXjXpmFLqn+XVI3bFA/z733+p+XOj5V3/3ZGI5kTBddhWPHjsFZ6NRWaH/z1G/C/XEAAK+/7j3fljNAPXr/kf0Y+dpItHiiBd7d+a72mAWfL7Bda3F1HT5+GMu+WoYRr45A93ndUWdqncqbAs9tfq7Gn/+//wWeew4YPBgoLHRvZ7ZajxVgoli0axfHGFGNY0ibli0iOPfcMrRqpca/1aqlPicnJZmb3Vf36NUrcq91rVrqmmlpkbumHYgAE+QhfY1QRL0gQYwb5/07j9YE/Pfdp8Y9nnOO6haqs3ixem/l5ak1TLOzVUtgZqaaEEjn55/1Yy1nzw6tXJ9+6p5Eyvfxl7+Y+1mj5XdJa3FKnChe4j/7lTFxk27yJO34386dTd0JEZcgZXwKei3shX1l+8I6N5jjx4ELLwTq1zd/jauXXu1XMXe4HMidkosZH8+IWFkj7fipwOtF/fG1P0Jcguwp2ej6dFfcvup2PLf5Oew/sr/GyvPRR8DDD6vJ85xONcfA//2f6hhgYLZajxVgolgVqaYNogAY0qbVWLZ26qSvfFRnZt9Dh+L3z0lpKXBUUv1b6crKvH+B69Zpz9+6Ve2uXTsKhY2i0aP1s/WGa/9+9av1vMY550S+vJEwRJ7HPvEfx7t6tbvruafC9wox7p1xEJcga3KWe8d113lVft/d+S7azGrj1boby/Yf2Y8Rr45A8yeaV3bR7rekn/bY7Qe2o9H0Ruj6dFcMeGEAxr49Fv/4zz9QfrI84uWaun4qLnzmQjR7ohmyJmUhqTCp8vf91c/6mbGOHD+Ck6eju/bRpZeq2buffx7YF+AeB7PVeqwAE8UqY8BWeeSDhghgSFdDVLI1N1dfGV6xIrzrGOddfnnNlDNqevYEliwJ75ycHPXDd+lSM2WKEd27q5sr1eE5+7ZUjEs9ciQy5auuSy8F/iAL8Itk+e0zemT4RqlnhXbqB1M9djhxWjTjcl2CpMIk9FoYwa4ZEfL00+4bOUuXRu66a7evhdOl79adPTk74HkjXxuJPxX9CSu3rsSab9fggbcfwJXPXxmwog0AHZ/qiJTxKciZkoPWs1rj4mcvxt1r7sbzW57H0eNHI/dDVeHkSbWkWnUwW63HCjBRrFq3zt632ynmMaRNi2q2HjyoX2JEBNi+Pfi58+a5j33Yf7lK+yst9W/KNCHQOFsC5s93/2odDmDUqODHDxrk/XI4HNaPEw701pg7V22vW1d/Xtr4NP8W3YqLOQudqDWpFvbUFhwbfGPkCx1BX32lJmTzfF26dFEt+JH275//jZmfzMQLW14IeIxuci5noRP1Hgsw07bFfvoJWLQIuOkmdePxoouqdz1mq/VYASaKZfHab5FsgSFtmmXZun27viKcnKwqyr6qWW+0nud0z4FqMUEYY59FgG7daqB8ceDTT1VvX937qkGDwOe9+KL/8fffH71yG4wuzi1b+u8zyhWoI5W2S7OIexnC7Gz1/aRJES1zTXrgAe/X8z4LJ4XecXAHDh7V/GGyid/9TnXxdzrVmHyXS02YVt2lmpit1mMFmCiWGYOviGoAQ9o0W2TrokX6SktentpvrOAiEuMzP5eGP2Ot7zq43bv7HJCUFPmpnuPE4MHubsOhTICsGycczR7nRu8IXSW3Z09VsQlEXIK0CR4zw40dqy725JPAjBn6wcMxorRUdSCriVbgWHL6dOB9Dz2kesZEekk4Zqv1bBHSRGSS0X9r4ECrS0JxiCFtWtBlkKwwerS+MiwS2pI4lhs8WBX20UerdZlHH/X+2fv2DXBgTDeL21fLlt6//8zMyI0TPnpUtW62bu1f4a5ism+t5V8th7gEw1YNc2805t4A3Bc/diwi5bebNWuAEyesLkXk7dyp/g706KEa8jMzo18GZqv1WAEminXGICuiCGNIm2aqAhyogioSeHmi7t2Dn6fTq5f1FfKgdu3y32Z0dZ4ypdqXdziAAQOqfRmqhptv9h8n/M47wc/58kvgqqtUD4akpODve99rB5jkO6i8x/ICjv9F3brq3wceCP/CMcLzJsXTT1tdmuq7+mp3z4+UFOCss4Bhw4A33oh+WZit1mMFmCjWGRPAEEUYQ9o0U9nav3/gyawCjbX0bdH0bPFq0aL674GosUMzOUXEkSPqJbziiqqPXbbM/6XPyAhvrWyHQzXMnnuuup6WcVCIPCdp8vRtnuCUo+KJ09NDvl4s+uYb9TfE83d91llq/Wm7Oh54SWA89BDw4IPAv/8dvfIEwmy1HivARLGuoEAl05gxVpeE4gxD2jRmq87w4YErt56fss87L7rlCtXdd6vyxdCER1ZYtcr75ayqZRdQ41B9x2Ubj+RkdQNo0CBg716ThcrOBjp2DOnQ8vJyr2WNDEVr5yHtEcGE/rXVukpx2vVZZ+JEVd83Xg872LdPTUp1/vmqK7PDETud4Zit1mNIE8UDs4OciIJgSJuW2Nn6t78BhYX+2xs3Vn+rdF2cY0GPHu5aWYxOfBRNnutUh9NYGmxSokgoLg6+f+jKoZUV4Iv+5l7v5qYbnWh+n6C8qgvEuZMnA+/Lzgbq1VPTkmzcWHNlMCbfNirkjRurYQ0BewDYDLPVeokd0kTxwugvRjWjrCyh7vYbGNKmVS9bu3b1bgI7cCCyL2xNOHQoMboxb90a3z9fhG3b5v2W+Pxza8tzwQWqHJs3Bz6m58KelRXgco+po/sME9xwI1/3YBo39l+WOzk5vFm/S0uBqVOB/PzAx0ydCrzwQvWXI7IKs9V6rAATxYP+/VXSLFhgdUnspbwc+PhjYOFCNVnJkCHAJZeoBT9btwbq11e3ktPTVUo7naEPPnM61TlpaWpsWV4e0KQJ0K6duv5FF6nb4HfeqZ77ySdV38DNm4HDh63+zYSEIW1aaNkqotZh0W33fDzzTOBjou3QIWDoUP0+o0zNmgElJdEtV7Tt2RPZ6y1dGnhNoe7d1d+Z+vWDr9ljY3fcYY97BqH+tzHGAHtqWiCYcJENfogYsXy5isHs7ODrRc+cqf4M1qnjXXnOzo5eWaON2Wo9VoCJ4oVI4Kli490nn6gZUHzXvqhq5hRjrc+MDNVfr1EjVYE991w1g8sdd6hBRosXAwSxVgMAACAASURBVM8/Dzz+OHD//cBtt6kpJXv2VLe2W7dW59apo7pGpqW5K9TBypCcrFK+WTNVab7iCmDkSDXT7apVwPbtNd8fMAiGtGkqW6tqDZWKGX/MqF9fvWd9bd+urjt6tLnrVoWtn4ElJanBiL5++cX/b4+vyy5T+775xn9fKC3roexzOkObmSpOtW+vfg0FBVUfKy6Bw+V+nYauHIrkcYLNLS1YMyfOpaaq/zoNGgD9+qn71cEms4oHzFbrsQJMFC8S6YPpsmXq04zvlLkOh1qeYsAA1eq6cKFqAbZLi+vx48C33wJFRcC8eapCfffdqjLdvbuacjMnR1XKPX+upCTVytykieoee/nlqmV5wgTgpZfUtJa6gVlnzqg+YseOAb/+qvqWHTwI/Pwz8OOPwO7dwHffqTJt3Qps2aL6KG7YAHz0EcrefJMhbU5oFeCa4Dtta15eeOdv2uR+/7Vp47///vuBhx+OTFnjTSiV0KQk4NprzT9HoL9lublq8GWw5w5U+f70U/Waf/WV+XLZ2bBhQHFxyP8VS8pLIC5B+9ntK7e1us+B3neylxVFBivA1mMFmChedOum0n39eqtLEnlTpgBNm/q3qDqdansE1ga1peJiYO1aYNYs4N571Qfn884DWrVSrc2+Ld5Gd2yjS3coLeHJyer4rCz3h+hGjYBmzVDWvDlD2hzrs9VYp/TRR/339eqlejH4mjjR+70RqEsuxRdjCM3PP/vv+81v1N+FsWNr7OmNUSdBZ4s+elS/vU4d1WtHd7zHe3mC8xGIANOnV12e7n/tDnEJdpXsqtz2fDcH3mpd8X9i2LCqL0IUBCvA1rM+pIkoMsrL42PgzIkTwF13qQ/wvuNxk5NVy2+sTPUYLfv3A++9B7z5pmrJ/fZb1bK7e7dq6f35Z9XyW1amWoKPHVMtw2fOBL0sQ9o0e2drsKawtDRg3brolofsK5Tu12efDYwY4b/988/da9OI6LtfDx2Kr6RT5eW9Zov2/fsfqHyB1uWpXVvdzOvbFyKnQ1oip7y8HM5Cp9/4X69ydO9e9YWIgmC2Ws/eIU1E4YnFbtD79gHXXac+rPh+2EpNVYv8ffKJ1aVMSAxp0+yfrXPmWF0CiiVjxqjhFzqBulb7LgjcqJH/MUOHAiLYvdv/z39fWadu6LZuDVx/vddpdeuqynJenronetllwLhxagi8zr33qkmZqmLM/uw5/rfyZzQeCb4MElUfs9V69g9pIgpdkyYqoO26zubx48CoUWoCH91sy5mZahaM3butLimBIV0NzFYiE8aNU5XbjAw1uiWQYKM6qmPEqhEQl6DhtIbujZs3R+4JiMBstQOGNFE8KS4OfKfdChMnqkp5oNmQs7LUUkG//mp1SUmDIW0as5Uoio4eVSNj/ud/qnedgS8OhLgEb+94273RmD46UEs3UZiYrdZjSBPFG6vuUi9aBLRtG3jypYwMNfnOli3RLxuZwpA2jdlKFINSClP8x/969lYKNNM2URiYrf5eEZEzInJpgP21RORdEfmviJSJyG4RmSEiaT7H5YvILhH5VUQ2ichFAa7HkCaKNzk5KqjLy2vuOYqK1HiwQOvupqaqiVGCTutJdseQNo3ZShSDjDHAhkufuxSbGnlkWygDiYmqwGz1druIFInIaQlcAU4Wkc4V/4qINBCR90VkuscxN4pIiYj0rjhulIgcFpGmmusxpInizYYNKqg7dozM9d54A+jQQa1fqavsJierZSiWLInM85FtMKRNY7YSxSBxCbInZ3t9P/oKUUtB3XuvhSWjeMJsdWsmIt9X/BusBdhXI1Etwq95bHtXVKuwpy9E5GHN+Qxponhkthv0qlVAmzaBK7siQMOG8bvuLnlhSJvGbCWKMU6XWv7oyY+fBFCxJNL/Cd5pJcBzz1lcOoonzFa3t0TkDxVfh1IBXiqqe/MZETkgIr089h0SkcE+x88XkRWa6zCkieJRWlrVFeClS4FWrQJXdh0ONR3nAw9UuV4sxSeGtGnMVqIYsuGHDX7dn895+hwkjROUJ3HmZ4osZqsySlQF2BBOC3BXEZkkIi09tp0SkSt8jpsqIms15zOkieLRokWqEnv55er7hQuBFi0Cz8bsdKqlicaNs7TYZC8MadOYrUQxpP3s9n4VYIfLgXP+yKWPKPKYrSJtROQnEWnusS2cCrCIGvO7yeN7tgATUeAuzE6nWiZp0iSrS0g2x5A2jdlKFEMyJmZAXIK0CWmV28QlmHCRACkpFpaM4hGzVWSYiBwTkX0isr/icUbUJFbzQrzGrSLyi8f374rI4z7HfC5BxgDn5+ejoKAABQUFKCoqsvp9QUSR0KaN6sbcpAkwY4bVpaEYUVRUVJkH+fn5CR/SJrECTBRDFn2xCOISjHxtJABg+VfLIY8Kvs3z6ElFFCGsAIuki0gTn8cZUa26uZrjzxeRy0UkQ0QcInKuiHwrIi96HDNIVCtwbxFJEZG7RVWQOQs0ERGFjCFtGrOVKIbkTcnz6v5cUl6Ch/pVrGmflAQMHWph6SjeMFv1PJdB6i2q8tqs4vteIrJRVAtxmYj8R9T43lo+1xglalbpI6K6R/cO8FwMaSIi0mJIm8ZsJYohvuN/AageVMbQoW7drCkYxSVmq79XpOoxwM1F5HVRFeN9IjJH3OsCG/JFZJeomaI3ichFAa7FkCYiIq0YCOlCEflR1Fr374tI5xDOqS3qBvFpEXH67KsqO0PJXxFmK1FMEZcguTDZZ6PH3BnFxdYUjOJSDGRrVN0uIkXi3QLsyyEiX4rIIlGtvs1FZIuIzPQ45kZRLcS9RQXzKFEfDtgFmoiIQmbzkB4jIrtFpJOIpInIZBHZKyKZVZz3NxH5h/hXgKvKzlDy18BsJYoRxhJIlz53qfcOzwowUQTZPFujqpmoO9LNJHgLcB8ROS4idTy2DRQV0qkV378rIjN8zvtCgkyCxZAmIiJfNg/pnSJyj8f3SaJaZW8Ncs41IrJBVMb6VoCrys5Q8tfAbCWKEUb35/LycvfG4cPdlV+Hw7rCUVyyebZG1Vsi8oeKr4NVgEeLyDafbY0rzulS8T2XQSIiomqzcUhni8q93/psf0v8V0Ew1BV1o7mjqMqsbwW4quwMJX89y8dsJYoB2vG/GRnuCnDdutYUjOKWjbM1qkaJCm1DsArwIyLyic+29IpzelZ8f0pErvA5ZqqIrNVcjyFNRERaNg5po7dUB5/ty0RkQYBzXhKRsRVf6yrAVWVnKPlrYLYSxQhxCRwu1cq7uXgznIVO/JLi0f35hRcsLiHFGxtna9S0EZGfRI0lMphtATYm/2ALMBERVZuNQzrcFuCbReQzcVd4+4qqACd5HMMWYKIEU1xSDHEJOj3VCQDQaHojiEtwyiFAaipQUGBxCSke2Thbo2aYiBwTNW5pf8XjjKiJOOZpjr+44viqxgD7fgD4XIKMAc7Pz0dBQQEKCgpQVFRk9fuCiIgsUlRUVJkH+fn5dg5p3Rjgn0U/BniRqJw0crZUVNbuE5HbKo6pKjtDyV8Ds5UoBnSb2w3iEhSXqFmexSVIHlfR8nvVVRaXjuJJDGVrVKSLSBOfxxlRs1Hmao53iMi/RORZEckSkRYislm8Z6EcJOpOdm8RSRGRu0Ut2cBZoImIKGQ2v0v9Z1FjejuLSIaITBKRPaKfBTpHvHN2kKgW4GYV54pUnZ2h5K+B2UoUA5yFTq/xv+ISXH1LRQXYc1IsogiyebZaxnMZpN6iAriZx/7mIrJG3HeznxQV1p5GifpgcETUWoa9AzwXQ5qIiLRiIKRdIlIsat3e98U9FKi5qIzsFeA83RhgkaqzM5T8FWG2EsUEzwmwxrw1BuISfFWPSx9RzYqBbI17DGkiItJiSJvGbCWyufteuw/iEuRMzgEApI5PVZVhLn1ENYzZaj2GNBERaTGkTWO2EtlckisJ4hKs37UeQEVr8KMVFeBGjSwuHcUzZqv1GNJERKTFkDaN2Upkc77r/xaXFOOfN/ZQFWCnExg0yMLSUTxjtlqPIU1ERFoMadOYrUQ251sBBgCkpbnX/+3UyZqCUdxjtlqPIU1ERFoMadOYrUQ2Jy5BzpQcn43ifuzaZUm5KP4xW63HkCYiIi2GtGnMViIbK/hHAcQlmLthrvcOzwowUQ1htlqPIU1ERFoMadOYrUQ2ljExw7/787p1rABTVDBbrceQJiIiLYa0acxWIhvTjv9t0sRd+c3Ls6ZglBCYrdZjSBMRkRZD2jRmK5GNiUvgcKm1fp2FTjR+vLFa+9eoAC9aZG0BKa4xW63HkCYiIi2GtGnMViKbmrthLsQlaPBYA5SXl7snwxJRleAxY6wuIsU5Zqv1GNJERKTFkDaN2UpkUzlTciq7P/db0g/iEqze/LKqADdrZnHpKBEwW63HkCYiIi2GtGnMViKb8hz/6yx0qq9//3tVAV63zuLSUSJgtlqPIU1ERFoMadOYrUQ2JS5BcmFy5dcOlwNIS+PMzxQ1zFbrMaSJiEiLIW0as5XIhtbvWg9xCa56/ips+GEDxCU4b955XPqIoorZaj2GNBERaTGkTWO2EtlQg6kNIC5BeXk5Lph/QeXXEFGtwERRwGy1HkOaiIi0GNKmMVuJbMgY/1teXg4A6t/Vq90zQP/+9xaXkBIBs9V6DGkiItJiSJvGbCWyIc8JsCo1auTuAt2xozUFo4TCbLUeQ5qIiLQY0qYxW4lsprikWF8BdjjcFeBduywpGyUWZqv1GNJERKTFkDaN2UpkM52e6gRxCTrP6ey9w6j8chIsihJmq/UY0kREpMWQNo3ZSmQzDpfDv/XXmACLFWCKImar9RjSRESkxZA2jdlKZDOVa/56uuoqd+U3L8+aglHCYbZajyFNRERaDGnTmK02U++xen7bysrKkDI+ha9TAigvL4e4BM1mNKvsCg0ASE11V4AXLLC2kJQwmK3WY0gTEZEWQ9o0ZquN9HymJ8QlGPzSYK/tbWe1rZwUKbkw2aLSUTRcvvhyiEuw4YcN3l2hjcrvuHHWFpASCrPVegxpIiLSYkibxmy1mfkb52u33/3q3ZWV4Gc/fzbKpaJoSS5MhrgEm4s3e9/wEAEyMqwtHCUcZqv1GNJERKTFkDYtYbP1zJkzlj13aWkp0iakmTp3656tES4N2Ylxk+PCBRdCXILhq4cDy5erCvDw4VYXjxIMs9V6CRvSREQUHEPatITK1vzX8ysrGNV9OF1OpE9IR/2p9XH2nLMxfNVwjF4zGv0W90OXp7qg6eNNUWdKHWROyERKYQqSXEmmnytlfArmfjo34M+1dc9WtJnZJoq/Saop4hJkT8xGxsQMd/fnBg048zNZgtlqvYQKaSIiCh1D2rS4z9bLF10esUqvnR4p41Mw48MZAICU8SkQl2BP2R6Lf9tUHSNfGwlxCRZ9sajydQYAOBysAJMlmK3Wi/uQJiIicxjSpsVltp416yxtpbHWxFo18nxrvl6DG1+6ETe/dDNmfjQTX+7+MuCxu0t3h339srIydJzTMaxKMcWetAlplZVecQkaTW+kdoioSjBRlDFbrReXIU1ERNXHkDbNVLYu+9cyNHisQUgtlcmuZMz5aE4NvfJueZPztM9fWYnw8N2h77yOSR+fHtGy7C7dDXEJSktLI3pdT2VlZejyVJeQXoPH1z9eY+WgyPFq9TWUl7tngB440JqCUcJitlqPFWAiItJiSJvmla0HDhzABfMuQLIruca78KZPSMeKL1eYfs0PHTqEtPFp2muf+/S5AAJUKCp4Hu90Of329322L8QlWPP1Gr99he8Warcb7nr1LohLcMH8C0z+dOaUlZWh29xuEXl9HC4HHC4HnC4nkgqTkDw+GanjU5ExIQNZk7KQOzkX9R+rj6aPN0XbWW3R+anOOOfpc3DBggvQe2FvXLboMvRf2h83/P0G3LriVvzP6v9BwT8KMG7dOExfPx3zN87Hy1+9jLe3v43NxZtRfLgYhw8frvxZfv31V7y/833M/mQ2Rq8ZjcEvDcYliy5Bt6e7oe2stmgyvQnqTq2L2pNrI2NiBlLHpyK5MBlOl7Ny+SC/mzGFyaj7WF1c/fzV2LZ/W1RfG19f7v0S17xwDRpMa1A587O4BOkTfW7GXH65uwLcvr01haWExWy1HivARESkxZA2LVtEIA+GVzlqNK0Rlv1rWUivzcGDB9FwWsOQr117Um1s2L5Be63vDn0XsHLT/2/9/Y4PVgGuSsGbBSFVngMdU5Otv+Go6RsZ8fZwuBzImJiBTk91wlOfPGXqd7734F4MfnkwGj/eGKnjU8Mug5eUFHcFeJu1lXZKPMxW67ECTEREWgxp0/wqwHesvMPv9ysuQUphit/23Mm5Xh/c602t53dMrYm1tJXEDds3RLTiYrT6mrGrZFfoFRIA7+16D+1mtQt6jpmxvjWlrKwMly+6XLtPXIKmjzf1225MrGU8Jr430e8Y42aEr8OHD/v9PmZ/PBsT35uIv7z1F9y75l4MXzUc4hKkF6bjiueuQJ9n+6DHMz3QfV53ZE/K9jp34NKBeH/n+/j1118rn+OsJ89C+gRzXdc//+FzXLHkCuRNzfNqfQ3nYbSIh31eYTIaTm+I61+8HtsPbq/692lUfoWTYFH0MVutxwowERFpMaRN86sA64hLkDUxy2/7BfMu8Ppwf8nfLvE7xqhgBLqub0Xzre1vIWNCRsAKxOp/rwYA3LTsJohL0OCxBjh06FDA90arJ1oFrcwCQElJSVgV4EDl93wEagH2XQ7J4XKgzpQ6uOvVuyxpNc6ZnINnPnvGb/sNy26A0+Ws7FL82Y+f+R3T/Inm2u7jADB9/XS8vf3tiJfX4HQ5A742KeNTkD0lG2PfHmv6+tt2b8NVi69Cm5ltkD4hPWDPA9/KbZIrCTmTcnDhggsx6+NZYT2n8X7w3sgKMFmH2Wo9VoCJiEiLIW2a5dm6/eB23LTsJvR7rp92v7gkrJa+dd+tC1hByZrkX4mPtmCthn6Vnwov/utFJBUmofnjzYOuB0xKVTcwdu9Xk5Td88Y9fvt8b1AEu76Z5zaOaT2rtd92h8uB9rM8xvkuWuSu/ObkaK9FVJOYrdazPKSJiMieGNKmxV22Pr/5ea8KSP/n/ccG201paSluXXErlny+RLu/qtmeSW/0mtEYvWa03/YjR47A4XLguS+e89s348MZ6LmwJwYtG4S/vPUXHDlyxPTzHz16VLv9ssWXYd2Oddp94hK0mNlCfVO3rrsCPJc3Pij6mK3Wi7uQJiKiyGBIm2YqWw8cOIDfPfc7bVflNjPbaM/ZsH0DRq4eiYMHD1b79X747YcDPk8821O2B5cvurxyXLXR7TaQQBXmQN2WAeD2FbfjwgUXYsjLQzDxvYnars9UM4atGgZxCRZ8tkBtcDhU5XfqVGsLRgmL2Wo9VoCJiEiLIW1atojg7c/fRqfZnZBSmBJSy2Kw1shaE2tpzwk2rreqVsxDhw55VfrY8hka34msqvva9n6mt/ac+o/VD7tbd1XPZeacR995VHvOxc9eXHmzoM3MNlj171UBr28lv/HyIqoSTGQRZqv1WAEmIiIthrRpQZdBCuSOlXfg+heux4EDB0J+jbYf3I5eC3oFrAgHEmgsb7CJr6h6vvnxG8z5ZA5Grh6Jvgv7ouOcjmgyvUnA1uDBLw0OWCltPqN5wOcx00IdbAz1pPcnac/5zZzfBL5hM0l/wyba9h7c633DoKSEa/+S5Zit1mMFmIiItBjSpmWLCOoV1sNDbz1k9cuolTclD87/3969B8lVFQgY/2YyTEjIDCEREglhE8QFAhVKfGSBSBABBSIBQVghtZTUbhE32VDZElARAQ2yFo9lDbAWLsEFEVBh5aFGEY1rLMEVUFxeitEwYIRAyIMEXCFn/zi3nU7ndE/n0ul7M/P9qk5lpvv2nTvTk3w599F9UWc4/97zi94UDQIbNmwIs2+fHXo+1xM6LuoIU66eklxu1YZVm+1wOeGWE5q+Hnjjxo3hxodvDMfcdEzY88o9w8iFI8PIhSPrLl89IX/HF98Rb3z3u33vXxXOthbPCbAkKclI52ZbpYQvP/Tllp+iXc/8e+aHk289efMXxurq8q2PVDjbWjwjLUlKMtK52VapCd9+8tth30X7hq7PdIWxnx9bd7kpi6aEaV+aFi7+wcXhxY1v4AXf8L1/VTzbWjwjLUlKMtK52VapjCoT4OPK/zZeGrxsa/GMtCQpyUjnZlulsrnmmv4J8N57F701GsJsa/GMtCQpyUjnZlulshkzpn8C7ItgqUC2tXhGWpKUZKRzs61S2VQmv14DrILZ1uIZaUlSkpHOzbZKZeMEWCVhW4tnpCVJSUY6N9sqlclLL/VPfnt7i94aDXG2tXhGWpKUZKRzs61SmRx8cP8E+LLLit4aDXG2tXhGWpKUZKRzs61SmXR1OflVadjW4hlpSVKSkc7Ntkpl4rW/KhHbWjwjLUlKMtK52VapTCCEnp6it0IKIdhWgEuBR4C1wLPAV4E9BnhMN3ANsCp73F2JxxwOPAhsAH4LzKmzLiMtSUoqeaQvJnZzPbAU2L/OcrsCXwaWA+uyPz9HbGm1w2nczWbaW2FbpbK47LI4Ab7ggqK3RAohlL6tbXEJ8Dagi/hDuBl4eIDHXAP8ghjeUcB/Ag9V3b8n8DIx3l3AYcAaYFZiXUZakpRU4kifA6wApgDDiRPaZ4CRiWUnAx/P/gTYC/glcGXVMs10c6D2VrOtZXTjjSGMGtX/SsA//WnRW6R22HlnT39WqZS4rYU5EHgd2LnO/cOJe6dnVt02Fvg/4NDs808T92JXuxK4N7E+Iy1JSipxpJcD86o+HwY8D5ze5OPPZvOdzQN1s5n2VrOtRbr00hB23HHz931tZkyYEILP2eDj9b8qmRK3tTDnEsNez1TiBHlcze1P0v+fgTuAf6+5/8PAC4n1GWlJUlJJI90LbAKm1dz+XeDyJtfxLWBx1ecDdbOyc7pRe2u3sTVtffLJEPbbL4Rhw+Ir2R57bAgvvvjG1zsYzJkTwg47ND/BnTQphBUr4mMffTSEXXYZ+DEHHVTs96j8Nm6MO0Mqz+XRRxe9RVIIobRtLcyRxGuZjmqwzHRihIfX3H4/8Mns4+8Try2u9n7inupaToAlSUkljfQexAnwPjW33wpc18TjLyBeO7x71W0DdbOZ9lYbuK0vvBDCcceF0N299UcqG42urvgf/W05SV69OoS5c0MYP77/7WW2dnR2xseOGBFPUR0/PoR99glh+vQQZs8OYdGiEJYvj1/vhBPiDoBm1tvREcLb3x7CmjVb/33dcsvAR447OkI46aTW/jy3Z5s2tffrbdwYwlVXxff1HTMm/v3p6Gjud2Py5PZuq1RHSdtaiJnAS8DxAyy3TY4Az507NyxYsCAsWLAgLFmypOjfC0lSQZYsWfKXHsydO7eMkX4jR4A/S7x2eO+a2wfqZjPtrd3GMBfCgmwsyTuh7ekJ4ZOf7H+CTjkl3+m9tZPkGTPiJPmb3wzhwANDGDmy+YlEGUZnZwhHHNHcL/WKFfkmxCHEF04aaPI9bFgIJ58cl120KIRvfCOEJ54IYd26fF9zW7r//hDOOSeEww6LE8LRo0MYPjz+PIt8Pjs64u9ld3c8qp/3d7GjI65j111DOPTQEK69Nv4JITz8cNE/fQ1h20Fb2+504uT3yCaWTV2H9CbgT8Ah2eefBn5e8zivAZYkbZUS76VOXQP8HI2vAb4G+DUwMXHfQN1s1N761wA3+o96d3c8AvzCC61/4k499Y1PkhtNPEePDuGtb40TqJ12ipOOL34xvS3HHlt/Xbvvvvmyy5eHcP31IXz0o+lJZmWCU0+j7T7wwPRjRozYctkddohHouv93+jUU7evnQWtfv67u+PvwKRJIUydGo/cjx8fX1hsxIj48+vsbN3PqKMjrnPMmBCmTYtHgDduHPjvQUXlLAWpJErc1raZB6wmHdB6ria+8uREoIf4SpTVL95ReTXLs4AdgHcTJ9i+CrQkqWkljvTHgN8T3/poBPEdFfpIvwr0MOI7LPyKLY/gVjTTzYHaWy1fW1OTscoYPjz9mMmTG08e6ml07Ww9jb7O+PHpx/T05Nu+PI+pPVI7bFh81edJk0L48Y/Tj3nnO/N9rcMP33yCfP75ceJ+2mlxx8b06fH64f32i19/woQQdtstTuJ6e+OOgxEj4mSyqytua2dn/8SxMiq3Va4B7+qKz113d/ydGDEiHr3v6Ymnko8eHcLYsfEI6LhxIUycGL/+W94Swr77hjBrVghf+EIIzz1X/3sbbAZ6LqU2K3Fb22YTcQ/yumysz/6snhCvJ56KVdENLCKemrUOuBuYULPew4ih3kDcU35Wna/vBFiSlFTySF8ErCROXJfS/z7AE4ndrHT0MOLpyxvZsrXVBupmM+2tiG2td31sPY0mYieemH7MjBntm2DuumuciPX2hnDIIfH06cFq8eI4Ui65JN/Pr/aIaGWC29VV/zELF8brXadPD+G9742T61mz4lHoe+9NP2b9+hDuvDOEZcviab8rV8bbXn658cR38uTNJ+WV06IbHXXfbbf+76erK07Ap04N4bzzQli1qv7j2qXyd7C3t+gtkf6i5G0dEpwAS5KSjHRujU+BLounnip6C7ZfV1wRdwikTvOtp9U7KupNnM88s307RSrvq5wao0enH3PddZsfod9rr/jCZ48/Xv/rhND4lOp6enri4+qdASAVwLYWzwmwJCnJSOdmW9U669fHo7i/+U08qnvnnSF87Wvx85SVK+MrVc+aFcL73hfPEjj44HjU/hOf2Pbbu2FDCFdfHcKDD6bvnz37jU/QOzriKeDjxoVwzDHb5vuQthHbWjwjLUlKMtK52VZpa9x3Xwgf+EB8b2dpkLOtxTPSkqQkI52bbZUkJdnW4hlpSVKSkc7NtkqSkmxr8Yy0JCnJCYirkAAADHpJREFUSOdmWyVJSba1eEZakpRkpHOzrZKkJNtaPCMtSUoy0rnZVklSkm0tnpGWJCUZ6dxsqyQpybYWz0hLkpKMdG62VZKUZFvhKmAN8YcQgGEDLL8SeC1b9nXgSWCvqvvnV62rMl5rsD4jLUlKMtK52VZJUpJthfOIk+DraW4C/EGgJ/t4IrACeKbq/soEuKPJr2+kJUlJRjo32ypJSrKt/SoT14EmwNUmAb8DXkmsZ4cm12GkJUlJRjo32ypJSrKt/bZmAvwTNj/F+fOJ9bxGPEX6RWBeg3UZaUlSkpHOzbZKkpJsa788R4BnAD8CTqq6bQrxNOlhwK7AXdl6T9ri0ZGRliQlGencbKskKcm29sszAQY4g3ikt9Epzy8BP65zXy8QZn5pZjjx5hNbOk659ZSWjtO/fnqY/fXZLR0fueMj4cw7zmzpOOvOs8KcO+e0bMy/Z344+56zWzrOWXJOOHfJuS0dn/r+p8IF37+gZWPh0oXhkqWXtHRcvuzycMWyK1o6rrn/mnDtA9e2bCx+cHG44aEbWjpufeTWcNuvbmvpuOvxu8LdT9zdsnHfb+8LP1j+g5aOB/oeCD975mctHY8+92h47PnHWjaeXvN06Fvb19Kx5pU1Ye2ra1sy+p7vM9L5OAGWJCU5Ae6XdwI8J3vcXg2WWQ0sq3NfLxAYR2B8No4gcJHD4XA4huQ4gv4ejMNI5+MEWJKU5AQ4Tnh7gI8TfxBjs89Tr+J8JPAvwJuzz98PrAPWVy3zcWB69vhdgNuz9Z5W5+t7BNgjwB4B9giwR4A9AuwR4NZyAixJSnICDNfBX/awV495wLuyj+dkyx4NrAU2Zbf/Gfhf4nW/FffS/z7Bm4hHf+c3+PpGWpKUZKRzs62SpCTbWjwjLUlKMtK52VZJUpJtLZ6RliQlGencbKskKcm2Fs9IS5KSjHRutlWSlGRbi2ekJUlJRjo32ypJSrKtxTPSkqQkI52bbZUkJdnW4hlpSVKSkc7NtkqSkmxr8Yy0JCnJSOdmWyVJSba1eEZakpRkpHOzrZKkJNtaPCMtSUoy0rnZVklSkm0tnpGWJCUZ6dxsqyQpybYWz0hLkpKMdG62VZKUZFuLZ6QlSUlGOjfbKklKsq3FM9KSpCQjnZttlSQl2dbiGWlJUpKRzs22SpKSbGvxjLQkKclI52ZbJUlJtrV4RlqSlGSkc7OtkqQk21o8Iy1JSjLSudlWSVKSbS2ekZYkJRnp3GyrJCnJthbPSEuSkox0brZVkpRkW4tnpCVJSUY6N9sqSUqyrcUz0pKkJCOdm22VJCXZ1uIZaUlSkpHOzbZKkpJsa/GMtCQpyUjnZlslSUm2tXhGWpKUZKRzs62SpCTbWjwjLUlKMtK52VZJUpJtLZ6RliQlGencbKskKcm2Fs9IS5KSjHRutlWSlGRbi2ekJUlJRjo32ypJSrKtxTPSkqQkI52bbZUkJdnW4hlpSVKSkc7NtkqSkmxr8Yy0JCnJSOdmWyVJSba1eEZakpRkpHOzrZKkJNva72LgWWA9sBTYv8Gyo4GbgTXAauAmYOeaZU4GHgc2AI8CJ9ZZl5GWJCWVPNLt7mYz66iwrZKkpJK3tW3OAVYAU4DhwOeAZ4CRdZb/FvA9YBdgDHAv8M2q+6cBrwAnAMOADwIbgYMS6zLSLbRkyZKiN0F1+NyUl89NeZU40kV0c6B1VLOtLeS/EeXlc1NuPj/lVOK2ttVyYF7V58OA54HTE8vuCWwCDqi6bWp22x7Z54uB22sedwfwpcT6jHQLLViwoOhNUB0+N+Xlc1NeJY50u7v5V02so5ptbSH/jSgvn5ty8/kppxK3tW16iQGdVnP7d4HLE8sfT9wrXetVYGb28UPAeTX3fwL4eZ2vb6RbxH9oysvnprx8bsqrpJEuopuzmlhH7Tba1hbx34jy8rkpN5+fcippW9tqD2LI96m5/VbgusTys4GVidv/CJyWffwUcFbN/XOAXyce1wuEvr6+sHbtWscbHHPnzi18Gxw+N9vb8Lkp7+jr6ytjpIvoZjPrqGZbWzj8N6K8w+em3MPnp5yjpG1tq1buyT4u+3hrjgBPID4BDofD4XDUGxMojyK62cxR5Gq21eFwOBwDjTK1te1S1zI9R/1rmV5ny+uQXqf/h7gY+EbN424nfQ1wR/a4XofD4XA4EmMCsRVl0u5uNlpH6hpg2+pwOByORqOMbW2rjwG/J76FwwjgEqCP+q9meTewBBgLvIm41/u/qu6fRtxTPQvoIr6VwwbSrwItSdL2pohuDrQOSZK0FS4iXl/0Mpu/n+FE4nscHlq17GjgK8T3InwJuJG4J6HaScT3M9wIPEZ8awdJkgaLi2hvN5tZhyRJkiRJkiRJ2t5dCLwGrCMecVgH3FzoFg1tpwL/DawlXpvXWXP/VOBHxCNGzxCfP7XHQM/NJuKRt+q/S/ujdrgUeIT43DwLfJUtr2udSDwFeB3x/XYXEU8VlrYV+1oetrXc7Gs52VYNWhcS/9FRORxFDMFH2DICo4A/AAuBbuKL2fQBZ7d5G4eqRs8NxEC/p90bJSBeP/s2YnR7iZOMh6vu7yBG/AZgJ2Kwfwn8a3s3U0OMfS0P21pu9rWcbKsGLQNdTjPYMgJnEN+zs/q2+cBv2rhdSj83EAN9RPs3RwkHEp+jnbPPZwB/AnapWuZ44pGE7vZumoYQ+1o+trXc7Gu52VYNGhcSf1GfA35H3LszqcgNEpCOwJXAd2qWOzhbblSbtkuNA/0HYBXxvVf/vs3bpX7nEt9mqGI+8cWhqr2Z+JwdgLRt2Nfysa3lZl/LzbZq0JhCPGUB4i/tV4CnqP9WHGqPVAT+A7ilZrl9s+V2b9N2qX6g3wMMJ54qdAywGjirvZsm4EjipOOoqts+Bfy0ZrkdiZE+pE3bpaHHvpaPbS03+1petlWDWjfwCvEXXcVxL3V51Qt0rQuBZdt+c1RlJvHtfY6vud291CoD+1o821pu9rWcbKsGvW7iK+0dNdCC2qZSEfg7vE6pDJoN9KeBn2z7zVHmdGKgU5OLw4BX8TolFcu+Fs+2lpt9LR/bqkHpQ8DY7ONxwI3E8/t3KmyLhrZO4mk+RxMjMDL7vIO4J/pZ4LPEU0wOAFbgK1W2S6Pn5m3AQcAOwLBsmReBuYVs6dAzj3hK3KF17u8AfgEsJv492pP4Spa+UqW2JftaHra13OxrOdlWDVp3El+g42Xiy/7fDOxV6BYNbWcQTx15PRuVjw/L7j+A+KqiG4gvCHFBAds4VDV6bmYCjxHfB281MQD/UMxmDkmbiK9EuY7N3yeyOtoTgXuy+1YB/0b8D5W0rdjX8rCt5WZfy8m2SpIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkafCYAWwCOoveEEmSBgnbKklSA0uBPwHrsrE++/NDbfjaM4DXMdKSpMFlKbZVkqRS+iHwmYK+tpGWJA1GtlWSpJJqFOkzgD5gfvbnKuB6YGTVMrsDtwF/BFYCtwJvrrp/GPDPwKPEvd9PA+dk91UifRLwJLAW+F7N4+cBT2X3rQQWb/23KElSW9lWSZJKaqBI/5kY5h2J8fwZcF12fyfwMPAVYBTQSwz2/wAd2TILgV8Db88+Hw1Myz6uXKd0U/b4HmAZcEN2/97ABmC/7PORwPRc36UkSe1jWyVJKqkfAq8Aq7PxUvbnW+iP9Kiq5d8PvEqM8MHAa8Q4V4wh7nl+V/b5OuDEOl+7spd6QtVt/0jcow0wiRjpDxEDLknS9sC2SpJUUgPtpX6+5rZ9iGEdT4xn7f0ALwAnA28i7oXev876U9cpnUE8laviA8B3iP95eAD42zrrkiSpLGyrJEkl1cxpWtV7iKv3Uv9Ndv/OVfdX9lK/M/u8mb3UjSJd0Un8T8HrxNO3JEkqK9sqSVJJNRPp64jXCO0O3M+W1yndRAz5zsAtbH6d0iXAE/Rfp7QLMe4wcKT/GjgG2Cn7/H3E08Imb923KElSW9lWSZJK6ofEvc6171X4MfqD+U/AM8TTr66nP5oQrzH6GvAc8dUqbyPGvKIzW9cT2bqfzj6HgSN9APGFO14C1gCPAB9+Y9+uJEnbnG2VJGk7VO+UKUmSlI9tlSSppIy0JEmtZVslSSopIy1JUmvZVkmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEnSduX/ARL9e2mECBu+AAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec_size_3000_w_8_type_dm_concat_1_mean_0_trainwords_0_hs_0_neg_10_vocabsize_None_curriter_{}_iter_1000_reg_0.001\n",
      "Epoch 01: Coverage Error -> 6.56\n",
      "Epoch 02: Coverage Error -> 6.51\n",
      "Epoch 03: Coverage Error -> 6.56\n",
      "Epoch 04: Coverage Error -> 6.45\n",
      "Epoch 05: Coverage Error -> 6.49\n",
      "Epoch 06: Coverage Error -> 6.39\n",
      "Epoch 07: Coverage Error -> 6.48\n",
      "Epoch 08: Coverage Error -> 6.55\n",
      "Epoch 09: Coverage Error -> 6.51\n",
      "Epoch 10: Coverage Error -> 6.54\n",
      "Epoch 11: Coverage Error -> 6.59\n",
      "Epoch 12: Coverage Error -> 6.50\n",
      "Epoch 13: Coverage Error -> 4.30\n",
      "Epoch 14: Coverage Error -> 4.44\n",
      "Epoch 15: Coverage Error -> 4.58\n",
      "Epoch 16: Coverage Error -> 4.75\n",
      "Epoch 17: Coverage Error -> 4.79\n",
      "Epoch 18: Coverage Error -> 4.75\n",
      "Epoch 19: Coverage Error -> 4.68\n",
      "Epoch 20: Coverage Error -> 4.69\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "graph = MetricsGraph()\n",
    "graph.init_graph()\n",
    "print placeholder_model_name + \"_\" + GLOBAL_VARS.SVM_MODEL_NAME\n",
    "\n",
    "for epoch in range(1,DOC2VEC_MAX_EPOCHS+1):\n",
    "    try:\n",
    "        model_name = placeholder_model_name.format(epoch)\n",
    "        metrics = pickle.load(open(os.path.join(doc2vec_model_save_location, model_name, GLOBAL_VARS.SVM_MODEL_NAME, METRICS)))\n",
    "        print \"Epoch {:02d}: Coverage Error -> {:.2f}\".format(epoch, metrics['coverage_error'])\n",
    "        graph.add_metrics_to_graph(metrics, epoch)\n",
    "    except IOError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0518029456576938,\n",
       " 4.3138649060436771,\n",
       " 3.7851701371254443,\n",
       " 1.4565769426104622,\n",
       " 1.3819197562214323]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[metric['coverage_error'] for metric in epoch_metrics]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
