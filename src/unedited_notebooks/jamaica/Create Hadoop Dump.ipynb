{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import coverage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_SIZE = 3\n",
    "MIN_DOCUMENTS = 5\n",
    "TOP_N_FEATURES = 10000\n",
    "\n",
    "TEST_SET_PERCENTAGE = 0.2\n",
    "VALIDATION_IN_TRAINING_PERCENTAGE = 0.2\n",
    "MIN_DOCUMENTS_FOR_TEST = 1\n",
    "MIN_DOCUMENTS_FOR_VALIDATION = 1\n",
    "\n",
    "MIN_DOCUMENTS_FOR_TRAINING_SAMPLE = 10\n",
    "MIN_DOCUMENTS_FOR_TEST_SAMPLE = 1\n",
    "MIN_DOCUMENTS_FOR_VALIDATION_SAMPLE = 1\n",
    "\n",
    "SVM_ITERATIONS = 1000\n",
    "SVM_CONVERGENCE = 0.1\n",
    "SVM_REG = 0.01\n",
    "\n",
    "BM25_K = 1.5  # controls power of tf component\n",
    "BM25_b = 0.75  # controls the BM25 length normalization\n",
    "\n",
    "RANDOM_SEED = 10000\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer().stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text, doc_id):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    previous_unigram = None\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            elif is_stopword(stem):\n",
    "                stem = None\n",
    "            else:\n",
    "                stem = stemmer(token)\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append((stem,{doc_id: 1}))\n",
    "                # extract bi-grams\n",
    "                if previous_unigram: stems.append((previous_unigram + \" \" + stem,{doc_id: 1}))\n",
    "                previous_unigram = stem\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_stopword(word):\n",
    "  return word in STOP_WORDS\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_postings(postings_list1, postings_list2):\n",
    "    # key could be either a doc id or a term\n",
    "    for key in postings_list2:\n",
    "        if postings_list1.get(key):\n",
    "            postings_list1[key] += postings_list2[key]\n",
    "        else:\n",
    "            postings_list1[key] = postings_list2[key]\n",
    "    return postings_list1\n",
    "\n",
    "def get_term_dictionary(terms):\n",
    "    \"\"\"\n",
    "    Maps string terms to indexes in an array\n",
    "    \"\"\"\n",
    "    term_dictionary = {}\n",
    "    term_array = [None] * len(terms)\n",
    "    def put(key):\n",
    "        hashvalue = hashfunction(key, len(term_array))\n",
    "        if term_array[hashvalue] == None:\n",
    "            term_array[hashvalue] = key\n",
    "            return hashvalue\n",
    "        else:\n",
    "            nextslot = rehash(hashvalue, len(term_array))\n",
    "            while term_array[nextslot] != None:\n",
    "                nextslot = rehash(nextslot, len(term_array))\n",
    "            if term_array[nextslot] == None:\n",
    "                term_array[nextslot] = key\n",
    "                return nextslot\n",
    "    def hashfunction(key, size):\n",
    "        return hash(key) % size\n",
    "    def rehash(oldhash, size):\n",
    "        return (oldhash + 1) % size\n",
    "    i = 0\n",
    "    for term in terms:\n",
    "        corresponding_index = put(term)\n",
    "        term_dictionary[term] = corresponding_index\n",
    "        i+=1\n",
    "        if i%10000 == 0: print \"finished \" + str(i)\n",
    "    return term_dictionary\n",
    "\n",
    "def get_doc_index(term, postings_list, term_dictionary):\n",
    "    #return [(doc_id, {term: postings_list[doc_id]}) for doc_id in postings_list]\n",
    "    return [(doc_id, {term_dictionary[term]: postings_list[doc_id]}) for doc_id in postings_list]\n",
    "\n",
    "def get_classes(ipc_classification):\n",
    "    sections = []\n",
    "    classes = []\n",
    "    subclasses = []\n",
    "    for classification in ipc_classification:\n",
    "        # we do the check because some documents have repetitions\n",
    "        section_name = classification['section']\n",
    "        class_name = classification['section'] + \"-\" + classification['class']\n",
    "        subclass_name = classification['section'] + \"-\" + classification['class'] + \"-\" + classification['subclass']\n",
    "        if section_name not in sections:\n",
    "            sections.append(section_name)\n",
    "        if class_name not in classes:\n",
    "            classes.append(class_name)\n",
    "        if subclass_name not in subclasses:\n",
    "            subclasses.append(subclass_name)\n",
    "    return {\"sections\": sections, \"classes\": classes, \"subclasses\": subclasses}\n",
    "\n",
    "\n",
    "def get_training_vector_old(classification, term_list, classifications, classification_key_name, number_of_terms):\n",
    "    clss = 1 if classification in classifications[classification_key_name] else 0\n",
    "    return LabeledPoint(clss, SparseVector(number_of_terms, term_list))\n",
    "\n",
    "def get_training_vector(classification, term_list, classifications, number_of_terms):\n",
    "    clss = 1 if classification in classifications else 0\n",
    "    return LabeledPoint(clss, SparseVector(number_of_terms, term_list))\n",
    "\n",
    "\n",
    "def calculate_sublinear_tf(tf):\n",
    "    # laplace smoothing with +1 in case of term with no documents (useful during testing)\n",
    "    return math.log10(1 + tf)\n",
    "\n",
    "\n",
    "def calculate_tf_idf(tf, df, N):\n",
    "    # laplace smoothing with +1 in case of term with no documents (useful during testing)\n",
    "    return tf * math.log10((N+1) / (df + 1))\n",
    "\n",
    "\n",
    "def calculate_bm25(tf, df, N, d_len, d_avg):\n",
    "    idf = max(0, math.log10((N-df + 0.5)/(df+0.5))) # in rare cases where the df is over 50% of N, this could become -ve, so we guard against that\n",
    "    tf_comp = float(((BM25_K + 1) * tf)) / ( BM25_K * ((1-BM25_b) + BM25_b*(float(d_len)/d_avg)) + tf)\n",
    "    return tf_comp * idf\n",
    "\n",
    "\n",
    "def calculate_rf(df_relevant, df_non_relevant):\n",
    "    return math.log( (2 + (float(df_relevant)/max(1, df_non_relevant))), 2)\n",
    "\n",
    "\n",
    "def calculate_tf_rf(tf, df_relevant, df_non_relevant):\n",
    "    return tf * calculate_rf(df_relevant, df_non_relevant)\n",
    "\n",
    "\n",
    "def compare_classifications(x,y):\n",
    "    len_comp = cmp(len(x), len(y))\n",
    "    if len_comp == 0:\n",
    "        return cmp(x,y)\n",
    "    return len_comp\n",
    "\n",
    "\n",
    "def create_doc_index(term_index, term_dictionary):\n",
    "    return term_index \\\n",
    "        .flatMap(lambda (term, postings_list): get_doc_index(term, postings_list, term_dictionary)) \\\n",
    "        .reduceByKey(lambda x, y: merge_postings(x, y))\n",
    "\n",
    "\n",
    "def get_rf_stats(postings, classification):\n",
    "    a_plus_c = set(postings.keys())\n",
    "    a_plus_b = set(classifications_index[classification])\n",
    "    # first intersection is to get (a), second difference is to get (c) (checkout tf-rf paper for reference)\n",
    "    a = a_plus_c.intersection(a_plus_b)\n",
    "    c = a_plus_c.difference(a_plus_b)\n",
    "    size_a = len(a)\n",
    "    size_c = len(c)\n",
    "    return size_a, size_c\n",
    "\n",
    "\n",
    "def get_rf_postings(classification):\n",
    "    def get_rf_postings_internal(postings):\n",
    "        size_a, size_c = get_rf_stats(postings, classification)\n",
    "        return {docId: calculate_rf(size_a, size_c)\n",
    "                for docId, tf in postings.items()}\n",
    "    return get_rf_postings_internal\n",
    "\n",
    "\n",
    "def get_tf_rf_postings(classification):\n",
    "    def get_tf_rf_postings_internal(postings):\n",
    "        size_a, size_c = get_rf_stats(postings, classification)\n",
    "        return {docId: calculate_tf_rf(tf, size_a, size_c)\n",
    "                for docId, tf in postings.items()}\n",
    "    return get_tf_rf_postings_internal\n",
    "\n",
    "\n",
    "def train_level_old(docs_with_classes, classification, classification_label):\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector_old(classification, term_list, classifications,\n",
    "                                                                           classification_label, number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE)\n",
    "    return training_vectors, svm\n",
    "\n",
    "\n",
    "def train_level(docs_with_classes, classification, number_of_terms):\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector(classification, term_list,\n",
    "                                                                           classifications, number_of_terms))\n",
    "    svm = SVMWithSGD.train(training_vectors, iterations=SVM_ITERATIONS, convergenceTol=SVM_CONVERGENCE, regParam=SVM_REG)\n",
    "    return training_vectors, svm\n",
    "\n",
    "\n",
    "def get_error(svm, test_vectors):\n",
    "    labelsAndPreds = test_vectors.map(lambda p: (p.label, svm.predict(p.features)))\n",
    "    trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(test_vectors.count())\n",
    "    return trainErr\n",
    "\n",
    "\n",
    "def train_all(docs_with_classes):\n",
    "    training_errors = {}\n",
    "    for section in sections:\n",
    "        training_vectors, svm = train_level(docs_with_classes, section, \"sections\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[section] = train_err\n",
    "    #\n",
    "    with open(training_errors_output, 'w') as file:\n",
    "        file.write(json.dumps(training_errors))\n",
    "    #\n",
    "    for clss in classes:\n",
    "        training_vectors, svm = train_level(docs_with_classes, clss, \"classes\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[clss] = train_err\n",
    "    \n",
    "    with open(training_errors_output, 'w') as file:\n",
    "        file.write(json.dumps(training_errors))\n",
    "    \n",
    "    for subclass in subclasses:\n",
    "        training_vectors, svm = train_level(docs_with_classes, subclass, \"subclasses\")\n",
    "        train_err = get_error(svm, training_vectors)\n",
    "        training_errors[subclass] = train_err\n",
    "    return training_errors\n",
    "\n",
    "\n",
    "def get_labeled_points_from_doc_index(doc_index, doc_classification_map, number_of_terms):\n",
    "    docs_with_classes = doc_index.map(lambda (doc_id, terms): (doc_id, (terms, doc_classification_map[doc_id])))\n",
    "    training_vectors = docs_with_classes.map(\n",
    "        lambda (doc_id, (term_list, classifications)): get_training_vector(classification, term_list,\n",
    "                                                                           classifications, number_of_terms))\n",
    "    return training_vectors\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    \n",
    "    def __init__(self, labels, scores, threshold=0.5):\n",
    "        self.threshold = 0\n",
    "        self.count = len(self.labels)\n",
    "        \n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tn = 0\n",
    "        \n",
    "        for (l,s) in zip(labels,scores):\n",
    "            if self.is_true(l) and self.is_true(s):\n",
    "                self.tp += 1\n",
    "            if self.is_true(l) and not self.is_true(s):\n",
    "                self.fn += 1\n",
    "            if not self.is_true(l) and self.is_true(s):\n",
    "                self.fp += 1\n",
    "            if not self.is_true(l) and not self.is_true(s):\n",
    "                self.tn += 1\n",
    "        self.precision = self.get_precision()\n",
    "        self.recall = self.get_precision()\n",
    "        self.fa = self.get_f1()\n",
    "        self.error_rate = self.get_error_rate()\n",
    "        \n",
    "    def calculate_contingency(self, label, contingency):\n",
    "        \n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tn = 0\n",
    "        \n",
    "        for (l,s) in zip(labels,scores):\n",
    "            if self.is_true(l) and self.is_true(s):\n",
    "                self.tp += 1\n",
    "            if self.is_true(l) and not self.is_true(s):\n",
    "                self.fn += 1\n",
    "            if not self.is_true(l) and self.is_true(s):\n",
    "                self.fp += 1\n",
    "            if not self.is_true(l) and not self.is_true(s):\n",
    "                self.tn += 1\n",
    "    \n",
    "    def is_true(self, label):\n",
    "        return label > self.threshold\n",
    "    \n",
    "    def get_error_rate(self):\n",
    "        return float(self.tp + self.tn) / len(labels)\n",
    "    \n",
    "    def get_precision(self):\n",
    "        # self.calculate_contingency()\n",
    "        if self.tp == 0: return 0\n",
    "        return float(self.tp) / (self.tp + self.fp)\n",
    "        \n",
    "    def get_recall(self):\n",
    "        # self.calculate_contingency()\n",
    "        if self.tp == 0: return 0\n",
    "        return float(self.tp) / (self.tp + self.fn)\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return 2 * (self.get_precision() * self.get_recall()) / (self.get_precision() + self.get_recall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc = SparkContext(\"\", \"Generate Inverted Index Job\")\n",
    "es_server = \"hekto.cip.ifi.lmu.de\"\n",
    "es_port = \"9200\"\n",
    "\n",
    "save_parent_location = \"hdfs://hekto.cip.ifi.lmu.de/svm/new/\"\n",
    "if IS_SAMPLE: \n",
    "    save_parent_location = save_parent_location + \"sample/\"\n",
    "\n",
    "file_name = \"sample.json\"\n",
    "test_file_name = \"sample.json\"\n",
    "#url = \"/media/Work/workspace/thesis/benchmark/output/\" + file_name\n",
    "sample_location = save_parent_location + file_name\n",
    "sample_test_location = save_parent_location + test_file_name\n",
    "docs_output = save_parent_location + \"docs_output\"\n",
    "postings_list_output = save_parent_location + \"postings_list_full.json\"\n",
    "postings_list_chi_selected_output = save_parent_location + \"postings_list_{}.json\"\n",
    "classification_index_output = save_parent_location + \"classification_index.pkl\"\n",
    "doc_classification_map_output = save_parent_location + \"doc_classification_map.pkl\"\n",
    "sections_output = save_parent_location + \"sections.pkl\"\n",
    "classes_output = save_parent_location + \"classes.pkl\"\n",
    "subclasses_output = save_parent_location + \"subclasses.pkl\"\n",
    "classifications_output = save_parent_location + \"classifications.pkl\"\n",
    "# training, validation and test set lists\n",
    "training_docs_list_output = save_parent_location + \"training_docs_list.pkl\"\n",
    "validation_docs_list_output = save_parent_location + \"validation_docs_list.pkl\"\n",
    "test_docs_list_output = save_parent_location + \"test_docs_list.pkl\"\n",
    "test_postings_list_output = save_parent_location + \"test_postings_list_50000.json\"\n",
    "training_errors_output = save_parent_location + \"training_errors.json\"\n",
    "model_output = save_parent_location + \"models/\" + \"iter_\" + str(SVM_ITERATIONS) + \"_reg_\" + str(SVM_REG) + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 4.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "read_conf = {\n",
    "    'es.nodes': es_server,\n",
    "    'es.port': es_port,\n",
    "    'es.resource': 'patents3/patent',\n",
    "    'es.query': '{ \"query\" : { \"match_all\" : {} }}',\n",
    "    'es.scroll.keepalive': '120m',\n",
    "    'es.scroll.size': '1000',\n",
    "    'es.http.timeout': '20m'\n",
    "}\n",
    "data = sc.newAPIHadoopRDD(\n",
    "    inputFormatClass = 'org.elasticsearch.hadoop.mr.EsInputFormat',\n",
    "    keyClass = 'org.apache.hadoop.io.NullWritable', \n",
    "    valueClass = 'org.elasticsearch.hadoop.mr.LinkedMapWritable',\n",
    "    conf = read_conf\n",
    ")\n",
    "\n",
    "#data = sc.textFile(sample_location)\n",
    "#doc_count = data.count()\n",
    "#doc_objs = data.persist(pyspark.StorageLevel.MEMORY_AND_DISK_SER)\n",
    "doc_objs = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Create Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 98.2 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Postings List\n",
    "doc_list = doc_objs.map(lambda (doc_id, doc): (doc_id, doc['description']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Postings List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save Postings List\n",
    "# min_doc_postings_lists.map(lambda (term, postings_list): \",\".join([term, json.dumps(postings_list)])).repartition(1).saveAsTextFile(postings_list_output)\n",
    "doc_list.saveAsTextFile(docs_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
