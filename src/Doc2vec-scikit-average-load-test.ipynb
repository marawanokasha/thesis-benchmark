{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import coverage_error\n",
    "import sklearn.metrics\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # adds a default StreamHanlder\n",
    "#root.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
    "NUMBER_INDICATOR = \"number_inidicator\"\n",
    "CURRENCY_INDICATOR = \"currency_inidicator\"\n",
    "CHEMICAL_INDICATOR = \"chemical_inidicator\"\n",
    "MIN_WORD_COUNT = 5\n",
    "MIN_SIZE = 0\n",
    "NUM_CORES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_file = \"/home/local/shalaby/docs_output_sample_100.json\"\n",
    "root_location = \"/big/s/shalaby/\"\n",
    "doc2vec_model_location = root_location + \"paragraph_vector_models/\"\n",
    "training_file = root_location + \"docs_output.json\"\n",
    "doc_classifications_map_file = root_location + \"exported_data_non_spark_format/doc_classification_map.pkl\"\n",
    "sections_file = root_location + \"exported_data_non_spark_format/sections.pkl\"\n",
    "training_docs_list_file = root_location + \"exported_data_merged/training_docs_list.pkl\"\n",
    "validation_docs_list_file = root_location + \"exported_data_merged/validation_docs_list.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_save_location = \"/home/local/shalaby/models/scikit-svm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_classifications_map = pickle.load(open(doc_classifications_map_file))\n",
    "sections = pickle.load(open(sections_file))\n",
    "training_docs_list = pickle.load(open(training_docs_list_file))\n",
    "validation_docs_list = pickle.load(open(validation_docs_list_file))\n",
    "#open(sections_file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286325"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemtokenizer(text):\n",
    "    \"\"\" MAIN FUNCTION to get clean stems out of a text. A list of clean stems are returned \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stems = []  # result\n",
    "    for token in tokens:\n",
    "        stem = token.lower()\n",
    "        stem = stem.strip(string.punctuation)\n",
    "        if stem:\n",
    "            if is_number(stem):\n",
    "                stem = NUMBER_INDICATOR\n",
    "            elif is_currency(stem):\n",
    "                stem = CURRENCY_INDICATOR\n",
    "            elif is_chemical(stem):\n",
    "                stem = CHEMICAL_INDICATOR\n",
    "            elif is_stopword(stem):\n",
    "                stem = None\n",
    "            else:\n",
    "                stem = stem.strip(string.punctuation)\n",
    "            if stem and len(stem) >= MIN_SIZE:\n",
    "                # extract uni-grams\n",
    "                stems.append(stem)\n",
    "    del tokens\n",
    "    return stems\n",
    "\n",
    "def is_stopword(word):\n",
    "  return word in STOP_WORDS\n",
    "\n",
    "def is_number(str):\n",
    "    \"\"\" Returns true if given string is a number (float or int)\"\"\"\n",
    "    try:\n",
    "        float(str.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_currency(str):\n",
    "    return str[0] == \"$\"\n",
    "\n",
    "def is_chemical(str):\n",
    "    return str.count(\"-\") > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOC2VEC_SIZE = 400\n",
    "DOC2VEC_WINDOW = 8\n",
    "DOC2VEC_MAX_VOCAB_SIZE = None\n",
    "DOC2VEC_SAMPLE = 1e-5\n",
    "DOC2VEC_TYPE = 1\n",
    "DOC2VEC_HIERARCHICAL_SAMPLE = 0\n",
    "DOC2VEC_NEGATIVE_SAMPLE_SIZE = 10\n",
    "DOC2VEC_CONCAT = 0\n",
    "DOC2VEC_MEAN = 0\n",
    "DOC2VEC_EPOCHS = 1\n",
    "REPORT_DELAY = 30 # report the progress every x seconds\n",
    "REPORT_VOCAB_PROGRESS = 10000 # report the progress every x terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_ITERATIONS = 1000\n",
    "SVM_CONVERGENCE = 0.001\n",
    "SVM_REG = 1/0.1 # scikit uses a C parameter not a lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Doc2vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-25 11:39:29,754 : INFO : loading Doc2Vec object from /big/s/shalaby/paragraph_vector_models/doc2vec_size_400_w_8_type_dm_concat_0_mean_0_hs_0_iter_10\n",
      "2016-08-25 11:40:54,766 : INFO : loading docvecs recursively from /big/s/shalaby/paragraph_vector_models/doc2vec_size_400_w_8_type_dm_concat_0_mean_0_hs_0_iter_10.docvecs.* with mmap=r\n",
      "2016-08-25 11:40:54,768 : INFO : loading doctag_syn0 from /big/s/shalaby/paragraph_vector_models/doc2vec_size_400_w_8_type_dm_concat_0_mean_0_hs_0_iter_10.docvecs.doctag_syn0.npy with mmap=r\n",
      "2016-08-25 11:40:54,772 : INFO : loading syn1neg from /big/s/shalaby/paragraph_vector_models/doc2vec_size_400_w_8_type_dm_concat_0_mean_0_hs_0_iter_10.syn1neg.npy with mmap=r\n",
      "2016-08-25 11:40:54,774 : INFO : loading syn0 from /big/s/shalaby/paragraph_vector_models/doc2vec_size_400_w_8_type_dm_concat_0_mean_0_hs_0_iter_10.syn0.npy with mmap=r\n",
      "2016-08-25 11:40:54,776 : INFO : setting ignored attribute syn0norm to None\n",
      "2016-08-25 11:40:54,777 : INFO : setting ignored attribute cum_table to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 24.7 s, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_hs_{}_iter_{}'.format(DOC2VEC_SIZE, DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE)\n",
    "\n",
    "doc2vec_model = Doc2Vec.load(doc2vec_model_location + '{}'.format(file_name), mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x7f341d6be650>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiLabelBinarizer().fit_transform([[\"B\",\"C\"],[\"D\"],[\"E\"],[\"A\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_vectors = []\n",
    "training_labels = []\n",
    "for doc_id in training_docs_list:\n",
    "    training_vectors.append(doc2vec_model.docvecs[doc_id])\n",
    "    training_labels.append([classf for classf in doc_classifications_map[doc_id] if classf in sections])\n",
    "training_vectors = np.array(training_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_labels = MultiLabelBinarizer().fit_transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286325, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286325, 400)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_model = OneVsRestClassifier(LinearSVC(penalty='l2', tol=SVM_CONVERGENCE, \n",
    "                                          C=SVM_REG, verbose=1, random_state=SVM_SEED, max_iter=SVM_ITERATIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]CPU times: user 6h 44min 16s, sys: 1h 33min 31s, total: 8h 17min 47s\n",
      "Wall time: 8h 17min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_model.fit(training_vectors, binary_labels)\n",
    "pickle.dump(svm_model, open(model_save_location + file_name, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "svm_model2 = OneVsRestClassifier(LinearSVC(penalty='l2', tol=SVM_CONVERGENCE, \n",
    "                                          C=SVM_REG, verbose=1, random_state=SVM_SEED, max_iter=10000))\n",
    "svm_model2.fit(training_vectors, binary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d400,n10,w8,mc5,s1e-05,t7)\n"
     ]
    }
   ],
   "source": [
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model using the vocab from the previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-16 15:49:28,921 : INFO : using concatenative 6800-dimensional layer1\n",
      "using concatenative 6800-dimensional layer1\n",
      "2016-08-16 15:49:28,925 : INFO : resetting layer weights\n",
      "resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.reset_from(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now for the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-21 05:36:43,143 : INFO : collecting all words and their counts\n",
      "2016-08-21 05:36:43,576 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.build_vocab(sentences=LabeledLineSentence(training_file), progress_per=REPORT_VOCAB_PROGRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-21 05:32:48,403 : INFO : training model with 7 workers on 5794 vocabulary and 6800 features, using sg=0 hs=0 sample=1e-05 negative=10\n",
      "2016-08-21 05:32:48,405 : INFO : expecting 65 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-08-21 05:32:51,066 : INFO : PROGRESS: at 1.54% examples, 658 words/s, in_qsize 0, out_qsize 0\n",
      "2016-08-21 05:33:05,759 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2016-08-21 05:33:05,762 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2016-08-21 05:33:05,763 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2016-08-21 05:33:05,865 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-08-21 05:33:05,894 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-08-21 05:33:06,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-08-21 05:33:06,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-08-21 05:33:06,553 : INFO : training on 326384 raw words (70839 effective words) took 18.1s, 3905 effective words/s\n",
      "2016-08-21 05:33:06,554 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.1 s, sys: 2.58 s, total: 34.7 s\n",
      "Wall time: 18.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70839"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.train(sentences=LabeledLineSentence(training_file), report_delay=REPORT_DELAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-20 15:22:45,778 : INFO : saving Doc2Vec object under /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10, separately None\n",
      "saving Doc2Vec object under /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10, separately None\n",
      "2016-08-20 15:22:45,783 : INFO : storing numpy array 'doctag_syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.docvecs.doctag_syn0.npy\n",
      "storing numpy array 'doctag_syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.docvecs.doctag_syn0.npy\n",
      "2016-08-20 15:22:50,011 : INFO : storing numpy array 'syn1neg' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn1neg.npy\n",
      "storing numpy array 'syn1neg' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn1neg.npy\n",
      "2016-08-20 15:40:39,540 : INFO : not storing attribute syn0norm\n",
      "not storing attribute syn0norm\n",
      "2016-08-20 15:40:39,545 : INFO : storing numpy array 'syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn0.npy\n",
      "storing numpy array 'syn0' to /home/local/shalaby/models/doc2vec_size_400_w_8_type_dm_concat_1_mean_0_hs_0_iter_10.syn0.npy\n",
      "2016-08-20 15:42:06,912 : INFO : not storing attribute cum_table\n",
      "not storing attribute cum_table\n"
     ]
    }
   ],
   "source": [
    "# file_name = 'doc2vec_size_{}_w_{}_type_{}_hs_{}_iter_{}'.format(DOC2VEC_SIZE, DOC2VEC_WINDOW, \n",
    "#                                                                 'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "#                                                                 DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE)\n",
    "file_name = 'doc2vec_size_{}_w_{}_type_{}_concat_{}_mean_{}_hs_{}_neg_{}_vocabsize_{}_iter_{}'.format(DOC2VEC_SIZE, DOC2VEC_WINDOW, \n",
    "                                                                'dm' if DOC2VEC_TYPE == 1 else 'pv-dbow',\n",
    "                                                                DOC2VEC_CONCAT, DOC2VEC_MEAN,\n",
    "                                                                DOC2VEC_HIERARCHICAL_SAMPLE,DOC2VEC_NEGATIVE_SAMPLE_SIZE,\n",
    "                                                                str(DOC2VEC_MAX_VOCAB_SIZE), DOC2VEC_EPOCHS)\n",
    "model.save('/home/local/shalaby/models/{}'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ValidationDocumentGenerator(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename):\n",
    "            (doc_id, text) = eval(line)\n",
    "            if doc_id in validation_docs_list:\n",
    "                yield doc_id, stemtokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validation_documents_reps = {}\n",
    "i = 0\n",
    "for (doc_id, doc_contents_array) in ValidationDocumentGenerator(training_file):\n",
    "    i += 1\n",
    "    if i % 1000 == 0: print i\n",
    "    \n",
    "    validation_documents_reps[doc_id] = doc2vec_model.infer_vector(doc_contents_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validation_vectors = []\n",
    "validation_labels = []\n",
    "for validation_doc_id in validation_docs_list:\n",
    "    validation_vectors.append(validation_documents_reps[validation_doc_id])\n",
    "    validation_labels.append([classf for classf in doc_classifications_map[validation_doc_id] if classf in sections])\n",
    "validation_vectors = np.array(validation_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-08-16 14:34:05,764 : INFO : precomputing L2-norms of word weight vectors\n",
      "precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'syn0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-aa93d828dd27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'08887671'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \"\"\"\n\u001b[1;32m-> 1208\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36minit_sims\u001b[1;34m(self, replace)\u001b[0m\n\u001b[0;32m   1536\u001b[0m                     \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1537\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1538\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mestimate_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'syn0'"
     ]
    }
   ],
   "source": [
    "model.most_similar('08887671')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'syn0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-717e96f4d1c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'08887671'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/stud/shalaby/.virtualenv/thesis-env/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m   1474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'syn0'"
     ]
    }
   ],
   "source": [
    "model['08887671']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6147817"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "model.raw_vocab = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.raw_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__hash__',\n",
       " '__ignoreds',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__numpys',\n",
       " '__recursive_saveloads',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__scipys',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_do_train_job',\n",
       " '_load_specials',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " 'accuracy',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'cbow_mean',\n",
       " 'clear_sims',\n",
       " 'comment',\n",
       " 'corpus_count',\n",
       " 'create_binary_tree',\n",
       " 'dbow',\n",
       " 'dbow_words',\n",
       " 'dm',\n",
       " 'dm_concat',\n",
       " 'dm_tag_count',\n",
       " 'docvecs',\n",
       " 'doesnt_match',\n",
       " 'estimate_memory',\n",
       " 'finalize_vocab',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'index2word',\n",
       " 'infer_vector',\n",
       " 'init_sims',\n",
       " 'intersect_word2vec_format',\n",
       " 'iter',\n",
       " 'layer1_size',\n",
       " 'load',\n",
       " 'load_word2vec_format',\n",
       " 'log_accuracy',\n",
       " 'make_cum_table',\n",
       " 'max_vocab_size',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'n_similarity',\n",
       " 'negative',\n",
       " 'null_word',\n",
       " 'random',\n",
       " 'raw_vocab',\n",
       " 'reset_from',\n",
       " 'reset_weights',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'scale_vocab',\n",
       " 'scan_vocab',\n",
       " 'score',\n",
       " 'seed',\n",
       " 'seeded_vector',\n",
       " 'sg',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'sort_vocab',\n",
       " 'sorted_vocab',\n",
       " 'syn0_lockf',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'vector_size',\n",
       " 'vocab',\n",
       " 'window',\n",
       " 'wmdistance',\n",
       " 'workers']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6147817"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Doc2Vec.wmdistance of <gensim.models.doc2vec.Doc2Vec object at 0x7fd85f134210>>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wmdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
